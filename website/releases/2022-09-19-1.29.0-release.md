---
title: MLflow 1.29.0
slug: 1.29.0
authors: [mlflow-maintainers]
---

We are happy to announce the availability of [MLflow 1.29.0](https://github.com/mlflow/mlflow/releases/tag/v1.29.0)!

MLflow 1.29.0 includes several major features and improvements:

Features:

- [Pipelines] Improve performance and fidelity of dataset profiling in the scikit-learn regression Pipeline (#6792, @sunishsheth2009)
- [Pipelines] Add an mlflow pipelines get-artifact CLI for retrieving Pipeline artifacts (#6517, @prithvikannan)
- [Pipelines] Introduce an option for skipping dataset profiling to the scikit-learn regression Pipeline (#6456, @apurva-koti)
- [Pipelines / UI] Display an mlflow pipelines CLI command for reproducing a Pipeline run in the MLflow UI (#6376, @hubertzub-db)
- [Tracking] Automatically generate friendly names for Runs if not supplied by the user (#6736, @BenWilson2)
- [Tracking] Add load_text(), load_image() and load_dict() fluent APIs for convenient artifact loading (#6475, @subramaniam02)
- [Tracking] Add creation_time and last_update_time attributes to the Experiment class (#6756, @subramaniam02)
- [Tracking] Add official MLflow Tracking Server Dockerfiles to the MLflow repository (#6731, @oojo12)
- [Tracking] Add searchExperiments API to Java client and deprecate listExperiments (#6561, @dbczumar)
- [Tracking] Add mlflow_search_experiments API to R client and deprecate mlflow_list_experiments (#6576, @dbczumar)
- [UI] Make URLs clickable in the MLflow Tracking UI (#6526, @marijncv)
- [UI] Introduce support for csv data preview within the artifact viewer pane (#6567, @nnethery)
- [Model Registry / Models] Introduce mlflow.models.add_libraries_to_model() API for adding libraries to an MLflow Model (#6586, @arjundc-db)
- [Models] Add model validation support to mlflow.evaluate() (#6582, @zhe-db, @jerrylian-db)
- [Models] Introduce sample_weights support to mlflow.evaluate() (#6806, @dbczumar)
- [Models] Add pos_label support to mlflow.evaluate() for identifying the positive class (#6696, @harupy)
- [Models] Make the metric name prefix and dataset info configurable in mlflow.evaluate() (#6593, @dbczumar)
- [Models] Add utility for validating the compatibility of a dataset with a model signature (#6494, @serena-ruan)
- [Models] Add predict_proba() support to the pyfunc representation of scikit-learn models (#6631, @skylarbpayne)
- [Models] Add support for Decimal type inference to MLflow Model schemas (#6600, @shitaoli-db)
- [Models] Add new CLI command for generating Dockerfiles for model serving (#6591, @anuarkaliyev23)
- [Scoring] Add /health endpoint to scoring server (#6574, @gabriel-milan)
- [Scoring] Support specifying a variant_name during Sagemaker deployment (#6486, @nfarley-soaren)
- [Scoring] Support specifying a data_capture_config during SageMaker deployment (#6423, @jonwiggins)

Bug fixes:

- [Tracking] Make Run and Experiment deletion and restoration idempotent (#6641, @dbczumar)
- [UI] Fix an alignment bug affecting the Experiments list in the MLflow UI (#6569, @sunishsheth2009)
- [Models] Fix a regression in the directory path structure of logged Spark Models that occurred in MLflow 1.28.0 (#6683, @gwy1995)
- [Models] No longer reload the main module when loading model code (#6647, @Jooakim)
- [Artifacts] Fix an mlflow server compatibility issue with HDFS when running in --serve-artifacts mode (#6482, @shidianshifen)
- [Scoring] Fix an inference failure with 1-dimensional tensor inputs in TensorFlow and Keras (#6796, @LiamConnell)

Documentation updates:

- [Tracking] Mark the SearchExperiments API as stable (#6551, @dbczumar)
- [Tracking / Model Registry] Deprecate the ListExperiments, ListRegisteredModels, and list_run_infos() APIs (#6550, @dbczumar)
- [Scoring] Deprecate mlflow.sagemaker.deploy() in favor of SageMakerDeploymentClient.create() (#6651, @dbczumar)

For a comprehensive list of changes, see the [release change log](https://github.com/mlflow/mlflow/releases/tag/v1.29.0), and check out the latest documentation on [mlflow.org](http://mlflow.org/).
