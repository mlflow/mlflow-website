---
title: MLflow 2.20.0rc0
slug: 2.20.0rc0
authors: [mlflow-maintainers]
---

MLflow 2.20.0rc0 is a release candidate for 2.20.0. To install, run the following command:

```sh
pip install mlflow==2.20.0rc0
```

### Major New Features

- **üí°Type Hint-Based Model Signature**: Define your model's [signature](https://www.mlflow.org/docs/latest/model/signatures.html) in the most **Pythonic** way. MLflow now supports defining a model signature based on the type hints in your `PythonModel`'s `predict` function, and validating input data payloads against it. ([#14182](https://github.com/mlflow/mlflow/pull/14182), [#14168](https://github.com/mlflow/mlflow/pull/14168), [#14130](https://github.com/mlflow/mlflow/pull/14130), [#14100](https://github.com/mlflow/mlflow/pull/14100), [#14099](https://github.com/mlflow/mlflow/pull/14099), [@serena-ruan](https://github.com/serena-ruan))

- **üß† Bedrock / Groq Tracing Support**: [MLflow Tracing](https://mlflow.org/docs/latest/llms/tracing/index.html) now offers a one-line auto-tracing experience for **Amazon Bedrock** and **Groq** LLMs. Track LLM invocation within your model by simply adding `mlflow.bedrock.tracing` or `mlflow.groq.tracing` call to the code. ([#14018](https://github.com/mlflow/mlflow/pull/14018), [@B-Step62](https://github.com/B-Step62), [#14006](https://github.com/mlflow/mlflow/pull/14006), [@anumita0203](https://github.com/anumita0203))

- **üóíÔ∏è Inline Trace Rendering in Jupyter Notebook**: MLflow now supports rendering a trace UI **within** the notebook where you are running models. This eliminates the need to frequently switch between the notebook and browser, creating a seamless local model debugging experience. ([#13955](https://github.com/mlflow/mlflow/pull/13955), [@daniellok-db](https://github.com/daniellok-db))
- **‚ö°Ô∏èFaster Model Validation with `uv` Package Manager**: MLflow has adopted [uv](https://github.com/astral-sh/uv), a new Rust-based, super-fast Python package manager. This release adds support for the new package manager in the [mlflow.models.predict](https://www.mlflow.org/docs/latest/model/dependencies.html#validating-environment-for-prediction) API, enabling faster model environment validation. Stay tuned for more updates! ([#13824](https://github.com/mlflow/mlflow/pull/13824), [@serena-ruan](https://github.com/serena-ruan))
- **üñ•Ô∏è New Chat Panel in Trace UI**: THe MLflow Trace UI now shows a unified `chat` panel for LLM invocations. The update allows you to view chat messages and function calls in a rich and consistent UI across LLM providers, as well as inspect the raw input and output payloads. ([#14211](https://github.com/mlflow/mlflow/pull/14211), [@TomuHirata](https://github.com/TomuHirata))

### Other Features:

- Introduced `ChatAgent` base class for defining custom python agent (#13797, @bbqiu)
- Supported Tool Calling in DSPy Tracing (#14196, @B-Step62)
- Added support for invokers rights in Databricks Resources (#14212, @aravind-segu)
- Applied timeout override to within-request local scoring server for Spark UDF inference (#14202, @BenWilson2)
- Supported dictionary type for inference params (#14091, @serena-ruan)
- Makd `context` parameter optional for calling `PythonModel` instance (#14059, @serena-ruan)
- Set default task for `ChatModel` (#14068, @stevenchen-db)

Please try it out and report any issues on [the issue tracker](https://github.com/mlflow/mlflow/issues)!
