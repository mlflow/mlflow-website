"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["7431"],{25735(e,n,t){t.r(n),t.d(n,{metadata:()=>o,default:()=>k,frontMatter:()=>f,contentTitle:()=>g,toc:()=>_,assets:()=>w});var o=JSON.parse('{"id":"tracing/integrations/listing/bedrock","title":"Tracing Amazon Bedrock with MLflow","description":"MLflow supports automatic tracing for Amazon Bedrock, a fully managed service on AWS that provides high-performing","source":"@site/docs/genai/tracing/integrations/listing/bedrock.mdx","sourceDirName":"tracing/integrations/listing","slug":"/tracing/integrations/listing/bedrock","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/bedrock","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4.5,"frontMatter":{"sidebar_position":4.5,"sidebar_label":"Bedrock"},"sidebar":"genAISidebar","previous":{"title":"Anthropic","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/anthropic"},"next":{"title":"BytePlus","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/byteplus"}}'),r=t(74848),l=t(28453),a=t(54725),i=t(89001),s=t(8060),c=t(46077),p=t(10440),d=t(77541),h=t(93893),m=t(60665),u=t(43975);let f={sidebar_position:4.5,sidebar_label:"Bedrock"},g="Tracing Amazon Bedrock with MLflow",w={},_=[{value:"Getting Started",id:"getting-started",level:2},...s.RM,{value:"Supported APIs",id:"supported-apis",level:2},{value:"Raw Inputs and Outputs",id:"raw-inputs-and-outputs",level:2},{value:"Token Usage",id:"token-usage",level:2},{value:"Supported APIs",id:"supported-apis-1",level:4},{value:"Streaming",id:"streaming",level:2},{value:"Function Calling Agent",id:"function-calling-agent",level:2},{value:"Disable auto-tracing",id:"disable-auto-tracing",level:2},{value:"Next steps",id:"next-steps",level:2}];function x(e){let n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h4:"h4",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"tracing-amazon-bedrock-with-mlflow",children:"Tracing Amazon Bedrock with MLflow"})}),"\n",(0,r.jsxs)(n.p,{children:["MLflow supports automatic tracing for Amazon Bedrock, a fully managed service on AWS that provides high-performing\nfoundations from leading AI providers such as Anthropic, Cohere, Meta, Mistral AI, and more. By enabling auto tracing\nfor Amazon Bedrock by calling the ",(0,r.jsx)(a.B,{fn:"mlflow.bedrock.autolog"})," function, MLflow will capture traces for LLM invocation\nand log them to the active MLflow Experiment."]}),"\n",(0,r.jsx)(c.A,{src:"/images/llms/tracing/bedrock-tracing-agent.png",alt:"Bedrock DIY Agent Tracing"}),"\n",(0,r.jsx)(n.p,{children:"MLflow trace automatically captures the following information about Amazon Bedrock calls:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Prompts and completion responses"}),"\n",(0,r.jsx)(n.li,{children:"Latencies"}),"\n",(0,r.jsx)(n.li,{children:"Model name"}),"\n",(0,r.jsx)(n.li,{children:"Additional metadata such as temperature, max_tokens, if specified."}),"\n",(0,r.jsx)(n.li,{children:"Function calling if returned in the response"}),"\n",(0,r.jsx)(n.li,{children:"Any exception if raised"}),"\n",(0,r.jsx)(n.li,{children:"and more..."}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"getting-started",children:"Getting Started"}),"\n",(0,r.jsx)(i.A,{number:1,title:"Install Dependencies"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"pip install 'mlflow[genai]' boto3\n"})}),"\n",(0,r.jsx)(i.A,{number:2,title:"Start MLflow Server"}),"\n",(0,r.jsx)(s.Ay,{}),"\n",(0,r.jsx)(i.A,{number:3,title:"Enable Tracing and Make API Calls"}),"\n",(0,r.jsxs)(n.p,{children:["Enable tracing with ",(0,r.jsx)(n.code,{children:"mlflow.bedrock.autolog()"})," and invoke Bedrock as usual using the boto3 runtime client. Ensure your AWS credentials and region are configured (e.g., ",(0,r.jsx)(n.code,{children:"AWS_ACCESS_KEY_ID"}),", ",(0,r.jsx)(n.code,{children:"AWS_SECRET_ACCESS_KEY"}),", ",(0,r.jsx)(n.code,{children:"AWS_REGION"}),")."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import boto3\nimport mlflow\n\n# Enable auto-tracing for Amazon Bedrock\nmlflow.bedrock.autolog()\nmlflow.set_tracking_uri("http://localhost:5000")\nmlflow.set_experiment("Bedrock")\n\n# Create a boto3 client for invoking the Bedrock API\nbedrock = boto3.client(\n    service_name="bedrock-runtime",\n    region_name="<REPLACE_WITH_YOUR_AWS_REGION>",\n)\n\n# Make a standard Bedrock call\nresponse = bedrock.converse(\n    modelId="anthropic.claude-3-7-sonnet-20250219-v1:0",\n    messages=[\n        {\n            "role": "user",\n            "content": "Describe the purpose of a \'hello world\' program in one line.",\n        },\n    ],\n    inferenceConfig={\n        "maxTokens": 512,\n        "temperature": 0.1,\n        "topP": 0.9,\n    },\n)\n'})}),"\n",(0,r.jsx)(i.A,{number:4,title:"View Traces in MLflow UI"}),"\n",(0,r.jsxs)(n.p,{children:["Open the MLflow UI at ",(0,r.jsx)(n.a,{href:"http://localhost:5000",children:"http://localhost:5000"})," (or your MLflow server URL) to see the trace for your Bedrock API calls."]}),"\n",(0,r.jsx)(c.A,{src:"/images/llms/tracing/bedrock-tracing-stream.png",alt:"Bedrock Trace"}),"\n",(0,r.jsx)(n.h2,{id:"supported-apis",children:"Supported APIs"}),"\n",(0,r.jsx)(n.p,{children:"MLflow supports automatic tracing for the following Amazon Bedrock APIs:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime/client/converse.html",children:"converse"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime/client/converse_stream.html",children:"converse_stream"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime/client/invoke_model.html",children:"invoke_model"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime/client/invoke_model_with_response_stream.html",children:"invoke_model_with_response_stream"})}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"raw-inputs-and-outputs",children:"Raw Inputs and Outputs"}),"\n",(0,r.jsxs)(n.p,{children:["By default, MLflow renders the rich chat-like UI for input and output messages in the ",(0,r.jsx)(n.code,{children:"Chat"})," tab. To view the raw input and output payload, including configuration parameters, click on the ",(0,r.jsx)(n.code,{children:"Inputs / Outputs"})," tab in the UI."]}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"Chat"})," panel is only supported for the ",(0,r.jsx)(n.code,{children:"converse"})," and ",(0,r.jsx)(n.code,{children:"converse_stream"})," APIs. For the other APIs, MLflow only displays the ",(0,r.jsx)(n.code,{children:"Inputs / Outputs"})," tab."]})}),"\n",(0,r.jsx)(n.h2,{id:"token-usage",children:"Token Usage"}),"\n",(0,r.jsxs)(n.p,{children:["MLflow automatically captures token usage statistics for supported Bedrock models and APIs. The token usage for each LLM call will be logged in the ",(0,r.jsx)(n.code,{children:"mlflow.chat.tokenUsage"})," attribute. The total token usage throughout the trace will be available in the ",(0,r.jsx)(n.code,{children:"token_usage"})," field of the trace info object."]}),"\n",(0,r.jsx)(n.p,{children:"Token usage includes:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Input tokens"})," (prompt tokens)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Output tokens"})," (completion/generation tokens)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Total tokens"})," (sum of input and output)"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Token usage is extracted from the response for all major Bedrock providers, including:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Anthropic (Claude)"}),"\n",(0,r.jsx)(n.li,{children:"AI21 (Jamba)"}),"\n",(0,r.jsx)(n.li,{children:"Amazon Titan/Nova"}),"\n",(0,r.jsx)(n.li,{children:"Meta Llama"}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"supported-apis-1",children:"Supported APIs"}),"\n",(0,r.jsx)(n.p,{children:"Token usage is logged for:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"invoke_model"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"invoke_model_with_response_stream"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"converse"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"converse_stream"})}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import boto3\nimport mlflow\n\nmlflow.bedrock.autolog()\n\n# Create a boto3 client for invoking the Bedrock API\nbedrock = boto3.client(\n    service_name="bedrock-runtime",\n    region_name="<REPLACE_WITH_YOUR_AWS_REGION>",\n)\n\n# Use the converse method to create a new message\nresponse = bedrock.converse(\n    modelId="anthropic.claude-3-5-sonnet-20241022-v2:0",\n    messages=[\n        {\n            "role": "user",\n            "content": "Explain the importance of low latency LLMs.",\n        }\n    ],\n    inferenceConfig={\n        "maxTokens": 512,\n        "temperature": 0.1,\n        "topP": 0.9,\n    },\n)\n\n# Get the trace object just created\nlast_trace_id = mlflow.get_last_active_trace_id()\ntrace = mlflow.get_trace(trace_id=last_trace_id)\n\n# Print the token usage\ntotal_usage = trace.info.token_usage\nprint("== Total token usage: ==")\nprint(f" Input tokens: {total_usage[\'input_tokens\']}")\nprint(f" Output tokens: {total_usage[\'output_tokens\']}")\nprint(f" Total tokens: {total_usage[\'total_tokens\']}")\n\n# Print the token usage for each LLM call\nprint("\\n== Detailed usage for each LLM call: ==")\nfor span in trace.data.spans:\n    if usage := span.get_attribute("mlflow.chat.tokenUsage"):\n        print(f"{span.name}:")\n        print(f" Input tokens: {usage[\'input_tokens\']}")\n        print(f" Output tokens: {usage[\'output_tokens\']}")\n        print(f" Total tokens: {usage[\'total_tokens\']}")\n'})}),"\n",(0,r.jsx)(n.p,{children:"If a provider or model does not return usage information, this attribute will be omitted."}),"\n",(0,r.jsx)(n.h2,{id:"streaming",children:"Streaming"}),"\n",(0,r.jsxs)(n.p,{children:["MLflow supports tracing streaming calls to Amazon Bedrock APIs. The generated trace shows the aggregated output message in the ",(0,r.jsx)(n.code,{children:"Chat"})," tab, while the individual chunks are displayed in the ",(0,r.jsx)(n.code,{children:"Events"})," tab."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'response = bedrock.converse_stream(\n    modelId="anthropic.claude-3-5-sonnet-20241022-v2:0",\n    messages=[\n        {\n            "role": "user",\n            "content": [\n                {"text": "Describe the purpose of a \'hello world\' program in one line."}\n            ],\n        }\n    ],\n    inferenceConfig={\n        "maxTokens": 300,\n        "temperature": 0.1,\n        "topP": 0.9,\n    },\n)\n\nfor chunk in response["stream"]:\n    print(chunk)\n'})}),"\n",(0,r.jsx)(c.A,{src:"/images/llms/tracing/bedrock-tracing-stream.png",alt:"Bedrock Stream Tracing"}),"\n",(0,r.jsx)(n.admonition,{type:"warning",children:(0,r.jsxs)(n.p,{children:["MLflow does not create a span immediately when the streaming response is returned. Instead, it creates a span when the streaming chunks are ",(0,r.jsx)(n.strong,{children:"consumed"}),", for example, the for-loop in the code snippet above."]})}),"\n",(0,r.jsx)(n.h2,{id:"function-calling-agent",children:"Function Calling Agent"}),"\n",(0,r.jsxs)(n.p,{children:["MLflow Tracing automatically captures function calling metadata when calling Amazon Bedrock APIs. The function definition and instruction in the response will be highlighted in the ",(0,r.jsx)(n.code,{children:"Chat"})," tab on trace UI."]}),"\n",(0,r.jsxs)(n.p,{children:["Combining this with the manual tracing feature, you can define a function-calling agent (ReAct) and trace its execution. The entire agent implementation might look complicated, but the tracing part is pretty straightforward: (1) add the ",(0,r.jsx)(n.code,{children:"@mlflow.trace"})," decorator to functions to trace and (2) enable auto-tracing for Amazon Bedrock with ",(0,r.jsx)(n.code,{children:"mlflow.bedrock.autolog()"}),". MLflow will take care of the complexity such as resolving call chains and recording execution metadata."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import boto3\nimport mlflow\nfrom mlflow.entities import SpanType\n\n# Enable auto-tracing for Amazon Bedrock\nmlflow.bedrock.autolog()\nmlflow.set_experiment("Bedrock")\n# Create a boto3 client for invoking the Bedrock API\nbedrock = boto3.client(\n    service_name="bedrock-runtime",\n    region_name="<REPLACE_WITH_YOUR_AWS_REGION>",\n)\nmodel_id = "anthropic.claude-3-5-sonnet-20241022-v2:0"\n\n\n# Define the tool function. Decorate it with `@mlflow.trace` to create a span for its execution.\n@mlflow.trace(span_type=SpanType.TOOL)\ndef get_weather(city: str) -> str:\n    """ "Get the current weather in a given location"""\n    return "sunny" if city == "San Francisco, CA" else "unknown"\n\n\n# Define the tool configuration passed to Bedrock\ntools = [\n    {\n        "toolSpec": {\n            "name": "get_weather",\n            "description": "Get the current weather in a given location",\n            "inputSchema": {\n                "json": {\n                    "type": "object",\n                    "properties": {\n                        "city": {\n                            "type": "string",\n                            "description": "The city and state, e.g., San Francisco, CA",\n                        },\n                    },\n                    "required": ["city"],\n                }\n            },\n        }\n    }\n]\ntool_functions = {"get_weather": get_weather}\n\n\n# Define a simple tool calling agent\n@mlflow.trace(span_type=SpanType.AGENT)\ndef run_tool_agent(question: str) -> str:\n    messages = [{"role": "user", "content": [{"text": question}]}]\n    # Invoke the model with the given question and available tools\n    response = bedrock.converse(\n        modelId=model_id,\n        messages=messages,\n        toolConfig={"tools": tools},\n    )\n    assistant_message = response["output"]["message"]\n    messages.append(assistant_message)\n    # If the model requests tool call(s), invoke the function with the specified arguments\n    tool_use = next(\n        (c["toolUse"] for c in assistant_message["content"] if "toolUse" in c), None\n    )\n    if tool_use:\n        tool_func = tool_functions[tool_use["name"]]\n        tool_result = tool_func(**tool_use["input"])\n        messages.append(\n            {\n                "role": "user",\n                "content": [\n                    {\n                        "toolResult": {\n                            "toolUseId": tool_use["toolUseId"],\n                            "content": [{"text": tool_result}],\n                        }\n                    }\n                ],\n            }\n        )\n        # Send the tool results to the model and get a new response\n        response = bedrock.converse(\n            modelId=model_id,\n            messages=messages,\n            toolConfig={"tools": tools},\n        )\n    return response["output"]["message"]["content"][0]["text"]\n\n\n# Run the tool calling agent\nquestion = "What\'s the weather like in San Francisco today?"\nanswer = run_tool_agent(question)\n'})}),"\n",(0,r.jsx)(n.p,{children:"Executing the code above will create a single trace that involves all LLM invocations and the tool calls."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Bedrock DIY Agent Tracing",src:t(82046).A+"",width:"1863",height:"772"})}),"\n",(0,r.jsx)(n.h2,{id:"disable-auto-tracing",children:"Disable auto-tracing"}),"\n",(0,r.jsxs)(n.p,{children:["Auto tracing for Amazon Bedrock can be disabled globally by calling ",(0,r.jsx)(n.code,{children:"mlflow.bedrock.autolog(disable=True)"})," or ",(0,r.jsx)(n.code,{children:"mlflow.autolog(disable=True)"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next steps"}),"\n",(0,r.jsxs)(p.A,{children:[(0,r.jsx)(d.A,{icon:h.A,iconSize:48,title:"Track User Feedback",description:"Record user feedback on traces for tracking user satisfaction.",href:"/genai/tracing/collect-user-feedback",linkText:"Learn about feedback \u2192",containerHeight:64}),(0,r.jsx)(d.A,{icon:m.A,iconSize:48,title:"Manage Prompts",description:"Learn how to manage prompts with MLflow's prompt registry.",href:"/genai/prompt-registry",linkText:"Manage prompts \u2192",containerHeight:64}),(0,r.jsx)(d.A,{icon:u.A,iconSize:48,title:"Evaluate Traces",description:"Evaluate traces with LLM judges to understand and improve your AI application's behavior.",href:"/genai/eval-monitor/running-evaluation/traces",linkText:"Evaluate traces \u2192",containerHeight:64})]})]})}function k(e={}){let{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(x,{...e})}):x(e)}},8060(e,n,t){t.d(n,{Ay:()=>p,RM:()=>s});var o=t(74848),r=t(28453),l=t(78010),a=t(57250),i=t(95986);let s=[];function c(e){let n={a:"a",code:"code",p:"p",pre:"pre",...(0,r.R)(),...e.components};return(0,o.jsx)(i.A,{children:(0,o.jsxs)(l.A,{children:[(0,o.jsxs)(a.A,{value:"local",label:"Local (pip)",default:!0,children:[(0,o.jsxs)(n.p,{children:["If you have a local Python environment >= 3.10, you can start the MLflow server locally using the ",(0,o.jsx)(n.code,{children:"mlflow"})," CLI command."]}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"mlflow server\n"})})]}),(0,o.jsxs)(a.A,{value:"docker",label:"Local (docker)",children:[(0,o.jsx)(n.p,{children:"MLflow also provides a Docker Compose file to start a local MLflow server with a postgres database and a minio server."}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"git clone --depth 1 --filter=blob:none --sparse https://github.com/mlflow/mlflow.git\ncd mlflow\ngit sparse-checkout set docker-compose\ncd docker-compose\ncp .env.dev.example .env\ndocker compose up -d\n"})}),(0,o.jsxs)(n.p,{children:["Refer to the ",(0,o.jsx)(n.a,{href:"https://github.com/mlflow/mlflow/tree/master/docker-compose/README.md",children:"instruction"})," for more details, e.g., overriding the default environment variables."]})]})]})})}function p(e={}){let{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},75689(e,n,t){t.d(n,{A:()=>s});var o=t(96540);let r=e=>{let n=e.replace(/^([A-Z])|[\s-_]+(\w)/g,(e,n,t)=>t?t.toUpperCase():n.toLowerCase());return n.charAt(0).toUpperCase()+n.slice(1)},l=(...e)=>e.filter((e,n,t)=>!!e&&""!==e.trim()&&t.indexOf(e)===n).join(" ").trim();var a={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};let i=(0,o.forwardRef)(({color:e="currentColor",size:n=24,strokeWidth:t=2,absoluteStrokeWidth:r,className:i="",children:s,iconNode:c,...p},d)=>(0,o.createElement)("svg",{ref:d,...a,width:n,height:n,stroke:e,strokeWidth:r?24*Number(t)/Number(n):t,className:l("lucide",i),...!s&&!(e=>{for(let n in e)if(n.startsWith("aria-")||"role"===n||"title"===n)return!0})(p)&&{"aria-hidden":"true"},...p},[...c.map(([e,n])=>(0,o.createElement)(e,n)),...Array.isArray(s)?s:[s]])),s=(e,n)=>{let t=(0,o.forwardRef)(({className:t,...a},s)=>(0,o.createElement)(i,{ref:s,iconNode:n,className:l(`lucide-${r(e).replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()}`,`lucide-${e}`,t),...a}));return t.displayName=r(e),t}},60665(e,n,t){t.d(n,{A:()=>o});let o=(0,t(75689).A)("book-open",[["path",{d:"M12 7v14",key:"1akyts"}],["path",{d:"M3 18a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h5a4 4 0 0 1 4 4 4 4 0 0 1 4-4h5a1 1 0 0 1 1 1v13a1 1 0 0 1-1 1h-6a3 3 0 0 0-3 3 3 3 0 0 0-3-3z",key:"ruj8y"}]])},43975(e,n,t){t.d(n,{A:()=>o});let o=(0,t(75689).A)("scale",[["path",{d:"m16 16 3-8 3 8c-.87.65-1.92 1-3 1s-2.13-.35-3-1Z",key:"7g6ntu"}],["path",{d:"m2 16 3-8 3 8c-.87.65-1.92 1-3 1s-2.13-.35-3-1Z",key:"ijws7r"}],["path",{d:"M7 21h10",key:"1b0cd5"}],["path",{d:"M12 3v18",key:"108xh3"}],["path",{d:"M3 7h2c2 0 5-1 7-2 2 1 5 2 7 2h2",key:"3gwbw2"}]])},93893(e,n,t){t.d(n,{A:()=>o});let o=(0,t(75689).A)("users",[["path",{d:"M16 21v-2a4 4 0 0 0-4-4H6a4 4 0 0 0-4 4v2",key:"1yyitq"}],["path",{d:"M16 3.128a4 4 0 0 1 0 7.744",key:"16gr8j"}],["path",{d:"M22 21v-2a4 4 0 0 0-3-3.87",key:"kshegd"}],["circle",{cx:"9",cy:"7",r:"4",key:"nufk8"}]])},82046(e,n,t){t.d(n,{A:()=>o});let o=t.p+"assets/images/bedrock-tracing-agent-cae1bcf40457074afa5bfde0b05b292e.png"},57250(e,n,t){t.d(n,{A:()=>l});var o=t(74848);t(96540);var r=t(34164);function l({children:e,hidden:n,className:t}){return(0,o.jsx)("div",{role:"tabpanel",className:(0,r.A)("tabItem_Ymn6",t),hidden:n,children:e})}},78010(e,n,t){t.d(n,{A:()=>x});var o=t(74848),r=t(96540),l=t(34164),a=t(88287),i=t(28584),s=t(56347),c=t(99989),p=t(96629),d=t(80618),h=t(41367);function m(e){return r.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,r.isValidElement)(e)&&function(e){let{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function u({value:e,tabValues:n}){return n.some(n=>n.value===e)}var f=t(19863);function g({className:e,block:n,selectedValue:t,selectValue:r,tabValues:a}){let s=[],{blockElementScrollPositionUntilNextRender:c}=(0,i.a_)(),p=e=>{let n=e.currentTarget,o=a[s.indexOf(n)].value;o!==t&&(c(n),r(o))},d=e=>{let n=null;switch(e.key){case"Enter":p(e);break;case"ArrowRight":{let t=s.indexOf(e.currentTarget)+1;n=s[t]??s[0];break}case"ArrowLeft":{let t=s.indexOf(e.currentTarget)-1;n=s[t]??s[s.length-1]}}n?.focus()};return(0,o.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,l.A)("tabs",{"tabs--block":n},e),children:a.map(({value:e,label:n,attributes:r})=>(0,o.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{s.push(e)},onKeyDown:d,onClick:p,...r,className:(0,l.A)("tabs__item","tabItem_LNqP",r?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function w({lazy:e,children:n,selectedValue:t}){let a=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){let e=a.find(e=>e.props.value===t);return e?(0,r.cloneElement)(e,{className:(0,l.A)("margin-top--md",e.props.className)}):null}return(0,o.jsx)("div",{className:"margin-top--md",children:a.map((e,n)=>(0,r.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function _(e){let n=function(e){let n,{defaultValue:t,queryString:o=!1,groupId:l}=e,a=function(e){let{values:n,children:t}=e;return(0,r.useMemo)(()=>{let e=n??m(t).map(({props:{value:e,label:n,attributes:t,default:o}})=>({value:e,label:n,attributes:t,default:o})),o=(0,d.XI)(e,(e,n)=>e.value===n.value);if(o.length>0)throw Error(`Docusaurus error: Duplicate values "${o.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`);return e},[n,t])}(e),[i,f]=(0,r.useState)(()=>(function({defaultValue:e,tabValues:n}){if(0===n.length)throw Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!u({value:e,tabValues:n}))throw Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}let t=n.find(e=>e.default)??n[0];if(!t)throw Error("Unexpected error: 0 tabValues");return t.value})({defaultValue:t,tabValues:a})),[g,w]=function({queryString:e=!1,groupId:n}){let t=(0,s.W6)(),o=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,p.aZ)(o),(0,r.useCallback)(e=>{if(!o)return;let n=new URLSearchParams(t.location.search);n.set(o,e),t.replace({...t.location,search:n.toString()})},[o,t])]}({queryString:o,groupId:l}),[_,x]=function({groupId:e}){let n=e?`docusaurus.tab.${e}`:null,[t,o]=(0,h.Dv)(n);return[t,(0,r.useCallback)(e=>{n&&o.set(e)},[n,o])]}({groupId:l}),k=u({value:n=g??_,tabValues:a})?n:null;return(0,c.A)(()=>{k&&f(k)},[k]),{selectedValue:i,selectValue:(0,r.useCallback)(e=>{if(!u({value:e,tabValues:a}))throw Error(`Can't select invalid tab value=${e}`);f(e),w(e),x(e)},[w,x,a]),tabValues:a}}(e);return(0,o.jsxs)("div",{className:(0,l.A)(a.G.tabs.container,"tabs-container","tabList__CuJ"),children:[(0,o.jsx)(g,{...n,...e}),(0,o.jsx)(w,{...n,...e})]})}function x(e){let n=(0,f.A)();return(0,o.jsx)(_,{...e,children:m(e.children)},String(n))}},54725(e,n,t){t.d(n,{B:()=>a});var o=t(74848);t(96540);var r=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}'),l=t(66497);function a({fn:e,children:n,hash:t}){let a=(e=>{let n=e.split(".");for(let e=n.length;e>0;e--){let t=n.slice(0,e).join(".");if(r[t])return t}return null})(e);if(!a)return(0,o.jsx)(o.Fragment,{children:n});let i=(0,l.default)(`/${r[a]}#${t??e}`);return(0,o.jsx)("a",{href:i,target:"_blank",children:n??(0,o.jsxs)("code",{children:[e,"()"]})})}},46077(e,n,t){t.d(n,{A:()=>l});var o=t(74848);t(96540);var r=t(66497);function l({src:e,alt:n,width:t,caption:l,className:a}){return(0,o.jsxs)("div",{className:`container_JwLF ${a||""}`,children:[(0,o.jsx)("div",{className:"imageWrapper_RfGN",style:t?{width:t}:{},children:(0,o.jsx)("img",{src:(0,r.default)(e),alt:n,className:"image_bwOA"})}),l&&(0,o.jsx)("p",{className:"caption_jo2G",children:l})]})}},89001(e,n,t){t.d(n,{A:()=>r});var o=t(74848);t(96540);let r=({number:e,title:n})=>(0,o.jsxs)("div",{className:"stepHeader_RqmM",children:[(0,o.jsx)("div",{className:"stepNumber_exmH",children:e}),(0,o.jsx)("h3",{className:"stepTitle_SzBx",children:n})]})},95986(e,n,t){t.d(n,{A:()=>r});var o=t(74848);t(96540);function r({children:e}){return(0,o.jsx)("div",{className:"wrapper_sf5q",children:e})}},77541(e,n,t){t.d(n,{A:()=>c});var o=t(74848);t(96540);var r=t(95310),l=t(34164);let a="tileImage_O4So";var i=t(66497),s=t(92802);function c({icon:e,image:n,imageDark:t,imageWidth:c,imageHeight:p,iconSize:d=32,containerHeight:h,title:m,description:u,href:f,linkText:g="Learn more \u2192",className:w}){if(!e&&!n)throw Error("TileCard requires either an icon or image prop");let _=h?{height:`${h}px`}:{},x={};return c&&(x.width=`${c}px`),p&&(x.height=`${p}px`),(0,o.jsxs)(r.A,{href:f,className:(0,l.A)("tileCard_NHsj",w),children:[(0,o.jsx)("div",{className:"tileIcon_pyoR",style:_,children:e?(0,o.jsx)(e,{size:d}):t?(0,o.jsx)(s.A,{sources:{light:(0,i.default)(n),dark:(0,i.default)(t)},alt:m,className:a,style:x}):(0,o.jsx)("img",{src:(0,i.default)(n),alt:m,className:a,style:x})}),(0,o.jsx)("h3",{children:m}),(0,o.jsx)("p",{children:u}),(0,o.jsx)("div",{className:"tileLink_iUbu",children:g})]})}},10440(e,n,t){t.d(n,{A:()=>l});var o=t(74848);t(96540);var r=t(34164);function l({children:e,className:n}){return(0,o.jsx)("div",{className:(0,r.A)("tilesGrid_hB9N",n),children:e})}},28453(e,n,t){t.d(n,{R:()=>a,x:()=>i});var o=t(96540);let r={},l=o.createContext(r);function a(e){let n=o.useContext(l);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),o.createElement(l.Provider,{value:n},e.children)}}}]);