"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[472],{6789:(e,t,n)=>{n.d(t,{A:()=>c});n(96540);var a=n(28774),s=n(34164);const r={tileCard:"tileCard_NHsj",tileIcon:"tileIcon_pyoR",tileLink:"tileLink_iUbu",tileImage:"tileImage_O4So"};var i=n(86025),o=n(21122),l=n(74848);function c({icon:e,image:t,imageDark:n,imageWidth:c,imageHeight:d,iconSize:p=32,containerHeight:h,title:m,description:u,href:x,linkText:f="Learn more \u2192",className:g}){if(!e&&!t)throw new Error("TileCard requires either an icon or image prop");const _=h?{height:`${h}px`}:{},j={};return c&&(j.width=`${c}px`),d&&(j.height=`${d}px`),(0,l.jsxs)(a.A,{href:x,className:(0,s.A)(r.tileCard,g),children:[(0,l.jsx)("div",{className:r.tileIcon,style:_,children:e?(0,l.jsx)(e,{size:p}):n?(0,l.jsx)(o.A,{sources:{light:(0,i.Ay)(t),dark:(0,i.Ay)(n)},alt:m,className:r.tileImage,style:j}):(0,l.jsx)("img",{src:(0,i.Ay)(t),alt:m,className:r.tileImage,style:j})}),(0,l.jsx)("h3",{children:m}),(0,l.jsx)("p",{children:u}),(0,l.jsx)("div",{className:r.tileLink,children:f})]})}},47020:(e,t,n)=>{n.d(t,{A:()=>r});n(96540);const a={wrapper:"wrapper_sf5q"};var s=n(74848);function r({children:e}){return(0,s.jsx)("div",{className:a.wrapper,children:e})}},49374:(e,t,n)=>{n.d(t,{B:()=>o});n(96540);const a=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}');var s=n(86025),r=n(74848);const i=e=>{const t=e.split(".");for(let n=t.length;n>0;n--){const e=t.slice(0,n).join(".");if(a[e])return e}return null};function o({fn:e,children:t,hash:n}){const o=i(e);if(!o)return(0,r.jsx)(r.Fragment,{children:t});const l=(0,s.Ay)(`/${a[o]}#${n??e}`);return(0,r.jsx)("a",{href:l,target:"_blank",children:t??(0,r.jsxs)("code",{children:[e,"()"]})})}},56955:(e,t,n)=>{n.d(t,{A:()=>H});var a=n(96540);const s="loopContainer_P7aD",r="loopTitle_JPUj",i="loopContent_d_OB",o="circleContainer_r3vu",l="svgCanvas_uDoP",c="arrowPath_C9al",d="arrowHead_pHvN",p="stepNode_dfTI",h="stepNodeContent_qttg",m="highlighted_oNtg",u="focusNode_z3RB",x="stepNumber_LNrP",f="stepLabel_vl8R",g="centerIcon_KAOa",_="loopIconWrapper_xBPW",j="loopText_T4eg",y="tooltip_UzKu",w="tooltipTitle_HAKW",v="tooltipDescription_EDYJ",b="tooltipArrow_WNhr",A="centerTooltip_R18b",N="centerTooltipDescription_ttXB",T="mobileLinearContent_PCYK",k="mobileStepItem_x9mX",D="mobileStepIndicator_zWzO",S="mobileStepNumber_HnjD",C="mobileFocusNode_FTRa",E="mobileStepConnector_kK9y",M="mobileStepContent_jmKx",I="mobileStepTitle_P2DM",R="mobileStepDescription_qbMN",L="mobileLoopBack_nXtn",F="mobileLoopIcon_FAGz",q="mobileLoopContent_BRFV",z="mobileLoopTitle_JcCt",U="mobileLoopDescription_5B8T";var P=n(74848);const H=({steps:e,title:t,loopBackIcon:n,loopBackText:H,loopBackDescription:O,circleSize:B=400})=>{const[$,W]=(0,a.useState)(null),[G,K]=(0,a.useState)(!1),[Y,J]=(0,a.useState)({x:0,y:0}),[X,V]=(0,a.useState)(!1),Z=(0,a.useRef)(null);a.useEffect(()=>{const e=()=>{V(window.innerWidth<=768)};return e(),window.addEventListener("resize",e),()=>window.removeEventListener("resize",e)},[]);const Q=X?280:B,ee=(()=>{const t=B/2,n=X?100:140,a=X?130:220,s=Math.min(1.2,.8+.05*e.length),r=(t-(X?50:80))*s;return Math.max(n,Math.min(a,r))})(),te=Q/2,ne=Q/2,ae=t=>{const n=2*t*Math.PI/e.length-Math.PI/2;return{x:te+ee*Math.cos(n),y:ne+ee*Math.sin(n)}},se=(e,t)=>{const n=ae(e),a=ae(t),s=a.x-n.x,r=a.y-n.y,i=(n.x+a.x)/2,o=(n.y+a.y)/2,l=Math.sqrt(s*s+r*r),c=s/l,d=r/l;return`M ${i-10*c} ${o-10*d} L ${i+10*c} ${o+10*d}`},re=()=>{W(null)};return X?(0,P.jsxs)("div",{className:s,children:[t&&(0,P.jsx)("h3",{className:r,children:t}),(0,P.jsxs)("div",{className:T,children:[e.map((t,n)=>(0,P.jsxs)("div",{className:k,children:[(0,P.jsxs)("div",{className:D,children:[(0,P.jsx)("div",{className:`${S} ${t.isFocus?C:""}`,children:t.icon?(0,P.jsx)(t.icon,{size:20}):(0,P.jsx)("span",{children:n+1})}),n<e.length-1&&(0,P.jsx)("div",{className:E})]}),(0,P.jsxs)("div",{className:M,children:[(0,P.jsx)("h4",{className:I,children:t.title}),(0,P.jsx)("p",{className:R,children:t.detailedDescription||t.description})]})]},n)),n&&O&&(0,P.jsxs)("div",{className:L,children:[(0,P.jsx)("div",{className:F,children:(0,P.jsx)(n,{size:24})}),(0,P.jsxs)("div",{className:q,children:[(0,P.jsx)("h4",{className:z,children:H||"Iterate"}),(0,P.jsx)("p",{className:U,children:O})]})]})]})]}):(0,P.jsxs)("div",{className:s,children:[t&&(0,P.jsx)("h3",{className:r,children:t}),(0,P.jsx)("div",{className:i,children:(0,P.jsxs)("div",{className:o,ref:Z,style:{width:`${Q}px`,height:`${Q}px`},children:[(0,P.jsxs)("svg",{width:Q,height:Q,className:l,children:[e.map((t,n)=>{const a=(n+1)%e.length;return(0,P.jsxs)("g",{children:[(0,P.jsx)("defs",{children:(0,P.jsx)("marker",{id:`arrowhead-${n}`,markerWidth:"6",markerHeight:"6",refX:"5",refY:"3",orient:"auto",children:(0,P.jsx)("path",{d:"M 0 0 L 6 3 L 0 6 L 1.5 3 Z",fill:"currentColor",opacity:"1",className:d})})}),(0,P.jsx)("path",{d:se(n,a),fill:"none",stroke:"currentColor",strokeWidth:"2",strokeDasharray:"0",opacity:"0.9",markerEnd:`url(#arrowhead-${n})`,className:c})]},`arrow-${n}`)}),n&&(0,P.jsxs)("g",{className:g,onMouseEnter:()=>K(!0),onMouseLeave:()=>K(!1),style:{cursor:"pointer"},children:[(0,P.jsx)("foreignObject",{x:te-35,y:ne-35,width:"70",height:"70",children:(0,P.jsx)("div",{className:_,children:(0,P.jsx)(n,{size:32})})}),H&&(0,P.jsx)("text",{x:te,y:ne+50,textAnchor:"middle",className:j,children:H})]})]}),e.map((e,t)=>{const n=ae(t);return(0,P.jsxs)("div",{className:`${p} ${e.highlight?m:""} ${e.isFocus?u:""}`,style:{left:`${n.x}px`,top:`${n.y}px`,transform:"translate(-50%, -50%)"},onMouseEnter:e=>(e=>{if(W(e),Z.current){Z.current.getBoundingClientRect();const t=ae(e);J({x:t.x,y:t.y})}})(t),onMouseLeave:re,children:[(0,P.jsx)("div",{className:h,children:e.icon?(0,P.jsx)(e.icon,{size:24}):(0,P.jsx)("span",{className:x,children:t+1})}),(0,P.jsx)("div",{className:f,children:e.title})]},t)}),null!==$&&(0,P.jsxs)("div",{className:y,style:{left:`${Y.x}px`,top:`${Y.y}px`,transform:"translate(-50%, -120%)"},children:[(0,P.jsx)("h4",{className:w,children:e[$].title}),(0,P.jsx)("p",{className:v,children:e[$].detailedDescription||e[$].description}),(0,P.jsx)("div",{className:b})]}),G&&O&&(0,P.jsx)("div",{className:A,style:{left:`${te}px`,top:`${ne}px`,transform:"translate(-50%, -50%)"},children:(0,P.jsx)("p",{className:N,children:O})})]})})]})}},65592:(e,t,n)=>{n.d(t,{A:()=>i});n(96540);var a=n(34164);const s={tilesGrid:"tilesGrid_hB9N"};var r=n(74848);function i({children:e,className:t,cols:n=3}){const i=`repeat(${n}, 1fr)`;return(0,r.jsx)("div",{className:(0,a.A)(s.tilesGrid,t),style:{gridTemplateColumns:i},children:e})}},79206:(e,t,n)=>{n.d(t,{A:()=>r});n(96540);const a={conceptOverview:"conceptOverview_x8T_",overviewTitle:"overviewTitle_HyAI",conceptGrid:"conceptGrid_uJNV",conceptCard:"conceptCard_oday",conceptHeader:"conceptHeader_HCk5",conceptIcon:"conceptIcon_gejw",conceptTitle:"conceptTitle_TGMM",conceptDescription:"conceptDescription_ZyDn"};var s=n(74848);function r({concepts:e,title:t}){return(0,s.jsxs)("div",{className:a.conceptOverview,children:[t&&(0,s.jsx)("h3",{className:a.overviewTitle,children:t}),(0,s.jsx)("div",{className:a.conceptGrid,children:e.map((e,t)=>(0,s.jsxs)("div",{className:a.conceptCard,children:[(0,s.jsxs)("div",{className:a.conceptHeader,children:[e.icon&&(0,s.jsx)("div",{className:a.conceptIcon,children:(0,s.jsx)(e.icon,{size:20})}),(0,s.jsx)("h4",{className:a.conceptTitle,children:e.title})]}),(0,s.jsx)("p",{className:a.conceptDescription,children:e.description})]},t))})]})}},82238:(e,t,n)=>{n.d(t,{A:()=>r});n(96540);const a={featureHighlights:"featureHighlights_Ardf",highlightItem:"highlightItem_XPnN",highlightIcon:"highlightIcon_SUR8",highlightContent:"highlightContent_d0XP"};var s=n(74848);function r({features:e,col:t=2}){return(0,s.jsx)("div",{className:a.featureHighlights,style:{gridTemplateColumns:`repeat(${t}, 1fr)`},children:e.map((e,t)=>(0,s.jsxs)("div",{className:a.highlightItem,children:[e.icon&&(0,s.jsx)("div",{className:a.highlightIcon,children:(0,s.jsx)(e.icon,{size:24})}),(0,s.jsxs)("div",{className:a.highlightContent,children:[(0,s.jsx)("h4",{children:e.title}),(0,s.jsx)("p",{children:e.description})]})]},t))})}},93256:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>S,contentTitle:()=>D,default:()=>M,frontMatter:()=>k,metadata:()=>a,toc:()=>C});const a=JSON.parse('{"id":"datasets/sdk-guide","title":"Evaluation Datasets SDK Guide","description":"Master the APIs for creating, evolving, and managing evaluation datasets through practical workflows and real-world patterns.","source":"@site/docs/genai/datasets/sdk-guide.mdx","sourceDirName":"datasets","slug":"/datasets/sdk-guide","permalink":"/mlflow-website/docs/latest/genai/datasets/sdk-guide","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"genAISidebar","previous":{"title":"End-to-End Workflow","permalink":"/mlflow-website/docs/latest/genai/datasets/end-to-end-workflow"},"next":{"title":"Feedback Collection","permalink":"/mlflow-website/docs/latest/genai/assessments/feedback"}}');var s=n(74848),r=n(28453),i=n(11470),o=n(19365),l=n(49374),c=n(47020),d=n(79206),p=n(56955),h=n(65592),m=n(6789),u=n(82238),x=n(51004),f=n(80827),g=n(22864),_=n(93164),j=n(96844),y=n(61878),w=n(43197),v=n(15977),b=n(93893),A=n(93610),N=n(99653),T=n(47792);const k={},D="Evaluation Datasets SDK Guide",S={},C=[{value:"Getting Started",id:"getting-started",level:2},{value:"Your Dataset Journey",id:"your-dataset-journey",level:2},{value:"Step 1: Create Your Dataset",id:"step-1-create-your-dataset",level:3},{value:"Step 2: Add Your First Test Cases",id:"step-2-add-your-first-test-cases",level:3},{value:"Step 3: Evolve Your Dataset",id:"step-3-evolve-your-dataset",level:3},{value:"Step 4: Organize with Tags",id:"step-4-organize-with-tags",level:3},{value:"Step 5: Search and Discover",id:"step-5-search-and-discover",level:3},{value:"Common Filter String Examples",id:"common-filter-string-examples",level:4},{value:"Step 6: Manage Experiment Associations",id:"step-6-manage-experiment-associations",level:3},{value:"The Active Record Pattern",id:"the-active-record-pattern",level:2},{value:"How Record Merging Works",id:"how-record-merging-works",level:2},{value:"Understanding Source Types",id:"understanding-source-types",level:2},{value:"Automatic Source Assignment",id:"automatic-source-assignment",level:3},{value:"Manual Source Specification",id:"manual-source-specification",level:3},{value:"Available Source Types",id:"available-source-types",level:3},{value:"Analyzing Data by Source",id:"analyzing-data-by-source",level:3},{value:"Search Filter Reference",id:"search-filter-reference",level:2},{value:"Filter Operators",id:"filter-operators",level:3},{value:"Using the Client API",id:"using-the-client-api",level:2},{value:"Next Steps",id:"next-steps",level:2}];function E(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"evaluation-datasets-sdk-guide",children:"Evaluation Datasets SDK Guide"})}),"\n",(0,s.jsx)(t.p,{children:"Master the APIs for creating, evolving, and managing evaluation datasets through practical workflows and real-world patterns."}),"\n",(0,s.jsx)(t.h2,{id:"getting-started",children:"Getting Started"}),"\n",(0,s.jsx)(t.p,{children:"MLflow provides a fluent API for working with evaluation datasets that makes common workflows simple and intuitive:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:"from mlflow.genai.datasets import (\n    create_dataset,\n    get_dataset,\n    search_datasets,\n    set_dataset_tags,\n    delete_dataset_tag,\n)\n"})}),"\n",(0,s.jsx)(t.h2,{id:"your-dataset-journey",children:"Your Dataset Journey"}),"\n",(0,s.jsx)(t.p,{children:"Follow this typical workflow to build and evolve your evaluation datasets:"}),"\n",(0,s.jsx)(p.A,{title:"Complete Development Workflow",steps:[{icon:x.A,title:"Create/Get Dataset",description:"Initialize or retrieve existing",detailedDescription:"Create a new evaluation dataset or retrieve an existing one. Link to experiments and set initial tags for organization.",isFocus:!0},{icon:f.A,title:"Add Test Cases",description:"From traces or manual",detailedDescription:"Add test cases from production traces with subject matter expert-defined expectations, or manually create critical test scenarios."},{icon:g.A,title:"Run Evaluation",description:"Test model performance",detailedDescription:"Execute MLflow evaluation against your dataset to measure model performance against ground truth expectations."},{icon:_.A,title:"Improve Code",description:"Fix issues & enhance",detailedDescription:"Based on evaluation results, refine prompts, adjust model parameters, add guardrails, or enhance application logic."},{icon:j.A,title:"Test & Trace",description:"Capture new interactions",detailedDescription:"Test your improved application and capture execution traces from both testing and production environments."},{icon:y.A,title:"Update Dataset",description:"Add new cases & expectations",detailedDescription:"Merge new traces into dataset, add edge cases discovered, update expectations based on new insights. Dataset continuously evolves."},{icon:w.A,title:"Update Tags",description:"Track dataset evolution",detailedDescription:"Update dataset tags to reflect new version, validation status, coverage improvements, and other metadata changes."}],loopBackIcon:v.A,loopBackText:"Continuous Improvement",loopBackDescription:"Return to evaluation with your enhanced dataset to test improvements. Each iteration strengthens both your application and test suite.",circleSize:550}),"\n",(0,s.jsx)(t.h3,{id:"step-1-create-your-dataset",children:"Step 1: Create Your Dataset"}),"\n",(0,s.jsxs)(t.p,{children:["Start by creating a new evaluation dataset with meaningful metadata using the ",(0,s.jsx)(l.B,{fn:"mlflow.genai.datasets.create_dataset"})," API:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'from mlflow.genai.datasets import create_dataset\n\n# Create a new dataset with tags for organization\ndataset = create_dataset(\n    name="customer_support_qa_v1",\n    experiment_id=["0"],  # Link to experiments ("0" is default)\n    tags={\n        "version": "1.0",\n        "purpose": "regression_testing",\n        "model": "gpt-4",\n        "team": "ml-platform",\n        "status": "development",\n    },\n)\n'})}),"\n",(0,s.jsx)(t.h3,{id:"step-2-add-your-first-test-cases",children:"Step 2: Add Your First Test Cases"}),"\n",(0,s.jsxs)(t.p,{children:["Build your dataset by adding test cases from production traces and manual curation. ",(0,s.jsx)(t.strong,{children:"Expectations are typically defined by subject matter experts (SMEs)"})," who understand the domain and can establish ground truth for what constitutes correct behavior."]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.a,{href:"/genai/assessments/expectations",children:"Learn how to define expectations \u2192"})," Expectations are the ground truth values that define what your AI should produce. They're added by SMEs who review outputs and establish quality standards."]}),"\n",(0,s.jsx)(c.A,{children:(0,s.jsxs)(i.A,{children:[(0,s.jsx)(o.A,{value:"traces",label:"From Production Traces",default:!0,children:(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'import mlflow\n\n# Search for production traces to build your dataset\n# Request list format to work with individual Trace objects\nproduction_traces = mlflow.search_traces(\n    experiment_ids=["0"],  # Your production experiment\n    filter_string="attributes.user_feedback = \'positive\'",\n    max_results=100,\n    return_type="list",  # Returns list[Trace] for direct manipulation\n)\n\n# Subject matter experts add expectations to define correct behavior\nfor trace in production_traces:\n    # Subject matter experts review traces and define what the output should satisfy\n    mlflow.log_expectation(\n        trace_id=trace.info.trace_id,\n        name="quality_assessment",\n        value={\n            "should_match_production": True,\n            "minimum_quality": 0.8,\n            "response_time_ms": 2000,\n            "contains_citation": True,\n        },\n    )\n\n    # Can also add textual expectations\n    mlflow.log_expectation(\n        trace_id=trace.info.trace_id,\n        name="expected_behavior",\n        value="Response should provide step-by-step instructions with security considerations",\n    )\n\n# Add annotated traces to dataset (expectations are automatically included)\ndataset.merge_records(production_traces)\n'})})}),(0,s.jsx)(o.A,{value:"manual",label:"Manual Test Cases",children:(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# Test cases can be manually defined as dictionaries\n# merge_records() accepts both dict and pandas.DataFrame formats for manual\n# record additions\ntest_cases = [\n    {\n        "inputs": {\n            "question": "How do I reset my password?",\n            "user_type": "premium",\n            "context": "User has been locked out after 3 failed attempts",\n        },\n        "expectations": {\n            "answer_quality": 0.95,\n            "contains_steps": True,\n            "mentions_security": True,\n            "response": "To reset your password, please follow these steps:\\n1. Click \'Forgot Password\' on the login page\\n2. Enter your registered email address\\n3. Check your email for the reset link\\n4. Click the link and create a new password\\n5. Use your new password to log in",\n        },\n        "tags": {\n            "category": "account_management",\n            "priority": "high",\n            "reviewed_by": "security_team",\n        },\n    },\n    {\n        "inputs": {\n            "question": "What are your business hours?",\n            "user_type": "standard",\n        },\n        "expectations": {\n            "accuracy": 1.0,\n            "includes_timezone": True,\n            "mentions_holidays": True,\n        },\n    },\n]\n\n# Add to your dataset (accepts list[dict], list[Trace] or pandas.DataFrame)\ndataset.merge_records(test_cases)\n'})})})]})}),"\n",(0,s.jsx)(t.h3,{id:"step-3-evolve-your-dataset",children:"Step 3: Evolve Your Dataset"}),"\n",(0,s.jsxs)(t.p,{children:["As you discover edge cases and improve your understanding, continuously update your dataset. The ",(0,s.jsx)(l.B,{fn:"mlflow.entities.EvaluationDataset.merge_records"})," method intelligently handles both new records and updates to existing ones:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# Capture a production failure\nfailure_case = {\n    "inputs": {"question": "\'; DROP TABLE users; --", "user_type": "malicious"},\n    "expectations": {\n        "handles_sql_injection": True,\n        "returns_safe_response": True,\n        "logs_security_event": True,\n    },\n    "source": {\n        "source_type": "HUMAN",\n        "source_data": {"discovered_by": "security_team"},\n    },\n    "tags": {"category": "security", "severity": "critical"},\n}\n\n# Add the new edge case\ndataset.merge_records([failure_case])\n\n# Update expectations for existing records\nupdated_records = []\nfor record in dataset.records:\n    if "accuracy" in record.get("expectations", {}):\n        # Raise the quality bar\n        record["expectations"]["accuracy"] = max(\n            0.9, record["expectations"]["accuracy"]\n        )\n        updated_records.append(record)\n\n# Merge updates (intelligently handles duplicates)\ndataset.merge_records(updated_records)\n'})}),"\n",(0,s.jsx)(t.h3,{id:"step-4-organize-with-tags",children:"Step 4: Organize with Tags"}),"\n",(0,s.jsxs)(t.p,{children:["Use tags to track dataset evolution and enable powerful searches. Learn more about ",(0,s.jsx)(l.B,{fn:"mlflow.search_traces",text:"searching traces"})," to build your datasets from production data:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'from mlflow.genai.datasets import set_dataset_tags\n\n# Update dataset metadata\nset_dataset_tags(\n    dataset_id=dataset.dataset_id,\n    tags={\n        "status": "validated",\n        "coverage": "comprehensive",\n        "last_review": "2024-11-01",\n    },\n)\n\n# Remove outdated tags\nset_dataset_tags(\n    dataset_id=dataset.dataset_id,\n    tags={"development_only": None},  # Setting to None removes the tag\n)\n'})}),"\n",(0,s.jsx)(t.h3,{id:"step-5-search-and-discover",children:"Step 5: Search and Discover"}),"\n",(0,s.jsxs)(t.p,{children:["Find datasets using powerful search capabilities with ",(0,s.jsx)(l.B,{fn:"mlflow.genai.datasets.search_datasets"}),":"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'from mlflow.genai.datasets import search_datasets\n\n# Find datasets by experiment\ndatasets = search_datasets(experiment_ids=["0", "1"])  # Search in multiple experiments\n\n# Search by name pattern\nregression_datasets = search_datasets(filter_string="name LIKE \'%regression%\'")\n\n# Complex search with tags\nproduction_ready = search_datasets(\n    filter_string="tags.status = \'validated\' AND tags.coverage = \'comprehensive\'",\n    order_by=["last_update_time DESC"],\n    max_results=10,\n)\n\n# The PagedList automatically handles pagination when iterating\n'})}),"\n",(0,s.jsx)(t.h4,{id:"common-filter-string-examples",children:"Common Filter String Examples"}),"\n",(0,s.jsx)(t.p,{children:"Here are practical examples of filter strings to help you find the right datasets:"}),"\n",(0,s.jsxs)("table",{style:{width:"100%"},children:[(0,s.jsx)("thead",{children:(0,s.jsxs)("tr",{children:[(0,s.jsx)("th",{style:{width:"40%"},children:"Filter Expression"}),(0,s.jsx)("th",{style:{width:"30%"},children:"Description"}),(0,s.jsx)("th",{style:{width:"30%"},children:"Use Case"})]})}),(0,s.jsxs)("tbody",{children:[(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("strong",{children:(0,s.jsx)(t.code,{children:"name = 'production_qa'"})})}),(0,s.jsx)("td",{children:"Exact name match"}),(0,s.jsx)("td",{children:"Find a specific dataset"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("strong",{children:(0,s.jsx)(t.code,{children:"name LIKE '%test%'"})})}),(0,s.jsx)("td",{children:"Pattern matching"}),(0,s.jsx)("td",{children:"Find all test datasets"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("strong",{children:(0,s.jsx)(t.code,{children:"tags.status = 'validated'"})})}),(0,s.jsx)("td",{children:"Tag equality"}),(0,s.jsx)("td",{children:"Find production-ready datasets"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("strong",{children:(0,s.jsx)(t.code,{children:"tags.version = '2.0' AND tags.team = 'ml'"})})}),(0,s.jsx)("td",{children:"Multiple tag conditions"}),(0,s.jsx)("td",{children:"Find team-specific versions"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("strong",{children:(0,s.jsx)(t.code,{children:"created_by = 'alice@company.com'"})})}),(0,s.jsx)("td",{children:"Creator filter"}),(0,s.jsx)("td",{children:"Find datasets by author"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("strong",{children:(0,s.jsx)(t.code,{children:"created_time > 1698800000000"})})}),(0,s.jsx)("td",{children:"Time-based filter"}),(0,s.jsx)("td",{children:"Find recent datasets"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("strong",{children:(0,s.jsx)(t.code,{children:"tags.model = 'gpt-4' AND name LIKE '%eval%'"})})}),(0,s.jsx)("td",{children:"Combined conditions"}),(0,s.jsx)("td",{children:"Model-specific evaluation sets"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:(0,s.jsx)("strong",{children:(0,s.jsx)(t.code,{children:"last_updated_by != 'bot@system'"})})}),(0,s.jsx)("td",{children:"Exclusion filter"}),(0,s.jsx)("td",{children:"Exclude automated updates"})]})]})]}),"\n",(0,s.jsx)(t.h3,{id:"step-6-manage-experiment-associations",children:"Step 6: Manage Experiment Associations"}),"\n",(0,s.jsxs)(t.p,{children:["Datasets can be dynamically associated with experiments after creation using ",(0,s.jsx)(l.B,{fn:"mlflow.genai.datasets.add_dataset_to_experiments"})," and ",(0,s.jsx)(l.B,{fn:"mlflow.genai.datasets.remove_dataset_from_experiments"}),"."]}),"\n",(0,s.jsx)(t.p,{children:"This functionality enables several important use cases:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Cross-team collaboration"}),": Share datasets across teams by adding their experiment IDs"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Lifecycle management"}),": Remove outdated experiment associations as projects mature"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Project reorganization"}),": Dynamically reorganize datasets as your project structure evolves"]}),"\n"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'from mlflow.genai.datasets import (\n    add_dataset_to_experiments,\n    remove_dataset_from_experiments,\n)\n\n# Add dataset to additional experiments\ndataset = add_dataset_to_experiments(\n    dataset_id="d-1a2b3c4d5e6f7890abcdef1234567890", experiment_ids=["3", "4", "5"]\n)\nprint(f"Dataset now linked to experiments: {dataset.experiment_ids}")\n\n# Remove dataset from specific experiments\ndataset = remove_dataset_from_experiments(\n    dataset_id="d-1a2b3c4d5e6f7890abcdef1234567890", experiment_ids=["3"]\n)\nprint(f"Updated experiment associations: {dataset.experiment_ids}")\n'})}),"\n",(0,s.jsx)(t.h2,{id:"the-active-record-pattern",children:"The Active Record Pattern"}),"\n",(0,s.jsxs)(t.p,{children:["The ",(0,s.jsx)(t.code,{children:"EvaluationDataset"})," object follows an active record pattern\u2014it's both a data container and provides methods to interact with the backend:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# Get a dataset\ndataset = get_dataset(dataset_id="d-1a2b3c4d5e6f7890abcdef1234567890")\n\n# The dataset object is "live" - it can fetch and update data\ncurrent_record_count = len(dataset.records)  # Lazy loads if needed\n\n# Add new records directly on the object\nnew_records = [\n    {\n        "inputs": {"question": "What are your business hours?"},\n        "expectations": {"mentions_hours": True, "includes_timezone": True},\n    }\n]\ndataset.merge_records(new_records)  # Updates backend immediately\n\n# Convert to DataFrame for analysis\ndf = dataset.to_df()\n# Access auto-computed properties\nschema = dataset.schema  # Field structure\nprofile = dataset.profile  # Dataset statistics\n'})}),"\n",(0,s.jsx)(t.h2,{id:"how-record-merging-works",children:"How Record Merging Works"}),"\n",(0,s.jsxs)(t.p,{children:["The ",(0,s.jsx)(t.code,{children:"merge_records()"})," method intelligently handles both new records and updates to existing ones. ",(0,s.jsx)(t.strong,{children:"Records are matched based on a hash of their inputs"})," - if a record with identical inputs already exists, its expectations and tags will be updated rather than creating a duplicate record."]}),"\n",(0,s.jsx)(c.A,{children:(0,s.jsxs)(i.A,{children:[(0,s.jsxs)(o.A,{value:"adding",label:"Adding New Records",default:!0,children:[(0,s.jsx)(t.p,{children:"When you add records for the first time, they're stored with their inputs, expectations, and metadata:"}),(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# Initial record\nrecord_v1 = {\n    "inputs": {"question": "What is MLflow?", "context": "ML platform overview"},\n    "expectations": {"accuracy": 0.8, "mentions_tracking": True},\n}\n\ndataset.merge_records([record_v1])\n# Creates a new record in the dataset\n'})})]}),(0,s.jsxs)(o.A,{value:"updating",label:"Updating Existing Records",children:[(0,s.jsxs)(t.p,{children:["When you merge a record with identical inputs, the existing record is updated by ",(0,s.jsx)(t.strong,{children:"merging"})," the new expectations and tags with the existing ones:"]}),(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# Updated version with same inputs but enhanced expectations\nrecord_v2 = {\n    "inputs": {\n        "question": "What is MLflow?",  # Same question\n        "context": "ML platform overview",  # Same context\n    },\n    "expectations": {\n        "accuracy": 0.95,  # Updates existing value\n        "mentions_models": True,  # Adds new expectation\n        "clarity": 0.9  # Adds new metric\n        # Note: "mentions_tracking": True is preserved from record_v1\n    },\n    "tags": {"reviewed": "true", "reviewer": "ml_team"},\n}\n\ndataset.merge_records([record_v2])\n# The record is updated, not duplicated\n# Final record has all expectations from both v1 and v2 merged together\n'})})]}),(0,s.jsxs)(o.A,{value:"bulk",label:"Bulk Updates from Traces",children:[(0,s.jsx)(t.p,{children:"This update behavior is particularly useful when adding expectations to production traces:"}),(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# First pass: Add traces without expectations\ntraces = mlflow.search_traces(experiment_ids=["0"], max_results=100, return_type="list")\ndataset.merge_records(traces)\n\n# Later: Subject matter experts review and add expectations\nfor trace in traces[:20]:  # Review subset\n    mlflow.log_expectation(\n        trace_id=trace.info.trace_id,\n        name="quality_check",\n        value={"approved": True, "quality_score": 0.9},\n    )\n\n# IMPORTANT: Re-fetch traces to get the attached expectations\nupdated_traces = mlflow.search_traces(\n    experiment_ids=["0"], max_results=100, return_type="list"\n)\n\n# Re-merge the updated traces - existing records are updated with expectations\ndataset.merge_records(updated_traces[:20])\n'})})]}),(0,s.jsxs)(o.A,{value:"uniqueness",label:"Input Uniqueness",children:[(0,s.jsxs)(t.p,{children:["Records are considered unique based on their ",(0,s.jsx)(t.strong,{children:"entire inputs dictionary"}),". Even small differences create separate records:"]}),(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# These are treated as different records due to different inputs\nrecord_a = {\n    "inputs": {"question": "What is MLflow?", "temperature": 0.7},\n    "expectations": {"accuracy": 0.9},\n}\n\nrecord_b = {\n    "inputs": {\n        "question": "What is MLflow?",\n        "temperature": 0.8,\n    },  # Different temperature\n    "expectations": {"accuracy": 0.9},\n}\n\ndataset.merge_records([record_a, record_b])\n# Results in 2 separate records due to different temperature values\n'})})]})]})}),"\n",(0,s.jsx)(t.h2,{id:"understanding-source-types",children:"Understanding Source Types"}),"\n",(0,s.jsx)(t.p,{children:"MLflow tracks the provenance of each record in your evaluation dataset through source types. This helps you understand where your test data came from and analyze performance by data source."}),"\n",(0,s.jsx)(d.A,{title:"Source Type Behavior",concepts:[{title:"Automatic Inference",description:"MLflow automatically infers source types based on record characteristics when no explicit source is provided."},{title:"Manual Override",description:"You can always specify explicit source information to override automatic inference."},{title:"Provenance Tracking",description:"Source types enable filtering and analysis of performance by data origin."}]}),"\n",(0,s.jsx)(t.h3,{id:"automatic-source-assignment",children:"Automatic Source Assignment"}),"\n",(0,s.jsx)(t.p,{children:"MLflow automatically assigns source types based on the characteristics of your records:"}),"\n",(0,s.jsx)(c.A,{children:(0,s.jsxs)(i.A,{children:[(0,s.jsxs)(o.A,{value:"trace",label:"TRACE Source",default:!0,children:[(0,s.jsxs)(t.p,{children:["Records created from MLflow traces are automatically assigned the ",(0,s.jsx)(t.code,{children:"TRACE"})," source type:"]}),(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# When adding traces directly (automatic TRACE source)\ntraces = mlflow.search_traces(experiment_ids=["0"], return_type="list")\ndataset.merge_records(traces)  # All records get TRACE source type\n\n# Or when using DataFrame from search_traces\ntraces_df = mlflow.search_traces(experiment_ids=["0"])  # Returns DataFrame\ndataset.merge_records(\n    traces_df\n)  # Automatically detects traces and assigns TRACE source\n'})})]}),(0,s.jsxs)(o.A,{value:"human",label:"HUMAN Source",children:[(0,s.jsxs)(t.p,{children:["Records with expectations are inferred as ",(0,s.jsx)(t.code,{children:"HUMAN"})," source (subject matter expert annotations):"]}),(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# Records with expectations indicate human review/annotation\nhuman_curated = [\n    {\n        "inputs": {"question": "What is MLflow?"},\n        "expectations": {"answer": "MLflow is an ML platform", "quality": 0.9}\n        # Automatically inferred as HUMAN source due to expectations\n    }\n]\ndataset.merge_records(human_curated)\n'})})]}),(0,s.jsxs)(o.A,{value:"code",label:"CODE Source",children:[(0,s.jsxs)(t.p,{children:["Records with only inputs (no expectations) are inferred as ",(0,s.jsx)(t.code,{children:"CODE"})," source (programmatically generated):"]}),(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# Records without expectations indicate programmatic generation\ngenerated_tests = [\n    {"inputs": {"question": f"Test question {i}"}}\n    for i in range(100)\n    # Automatically inferred as CODE source (no expectations field)\n]\ndataset.merge_records(generated_tests)\n'})})]})]})}),"\n",(0,s.jsx)(t.h3,{id:"manual-source-specification",children:"Manual Source Specification"}),"\n",(0,s.jsx)(t.p,{children:"You can explicitly specify the source type and metadata for any record. When no explicit source is provided, MLflow automatically infers the source type before sending records to the backend using these rules:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Records with expectations"})," \u2192 Inferred as ",(0,s.jsx)(t.code,{children:"HUMAN"})," source (indicates manual annotation or ground truth)"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Records with only inputs"})," (no expectations) \u2192 Inferred as ",(0,s.jsx)(t.code,{children:"CODE"})," source (indicates programmatic generation)"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Records from traces"})," \u2192 Always marked as ",(0,s.jsx)(t.code,{children:"TRACE"})," source (regardless of expectations)"]}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:["This inference happens client-side in the ",(0,s.jsx)(t.code,{children:"merge_records()"})," method before records are sent to the tracking backend. You can override this automatic inference by providing explicit source information:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# Specify HUMAN source for manually curated test cases\nhuman_curated = {\n    "inputs": {"question": "What are your business hours?"},\n    "expectations": {"accuracy": 1.0, "includes_timezone": True},\n    "source": {\n        "source_type": "HUMAN",\n        "source_data": {"curator": "support_team", "date": "2024-11-01"},\n    },\n}\n\n# Specify DOCUMENT source for data from documentation\nfrom_docs = {\n    "inputs": {"question": "How to install MLflow?"},\n    "expectations": {"mentions_pip": True, "mentions_conda": True},\n    "source": {\n        "source_type": "DOCUMENT",\n        "source_data": {"document_id": "install_guide", "page": 1},\n    },\n}\n\n# Specify CODE source for programmatically generated data\ngenerated = {\n    "inputs": {"question": f"Test question {i}" for i in range(100)},\n    "source": {\n        "source_type": "CODE",\n        "source_data": {"generator": "test_suite_v2", "seed": 42},\n    },\n}\n\ndataset.merge_records([human_curated, from_docs, generated])\n'})}),"\n",(0,s.jsx)(t.h3,{id:"available-source-types",children:"Available Source Types"}),"\n",(0,s.jsx)(t.p,{children:"Source types enable powerful filtering and analysis of your evaluation results. You can analyze performance by data origin to understand if your model performs differently on human-curated vs. generated test cases, or production traces vs. documentation examples."}),"\n",(0,s.jsx)(u.A,{features:[{icon:j.A,title:"TRACE",description:"Production data captured via MLflow tracing - automatically assigned when adding traces"},{icon:b.A,title:"HUMAN",description:"Subject matter expert annotations - inferred for records with expectations"},{icon:_.A,title:"CODE",description:"Programmatically generated tests - inferred for records without expectations"},{icon:f.A,title:"DOCUMENT",description:"Test cases from documentation or specs - must be explicitly specified"},{icon:A.A,title:"UNSPECIFIED",description:"Source unknown or not provided - for legacy or imported data"}]}),"\n",(0,s.jsx)(t.h3,{id:"analyzing-data-by-source",children:"Analyzing Data by Source"}),"\n",(0,s.jsx)(c.A,{children:(0,s.jsxs)(i.A,{children:[(0,s.jsx)(o.A,{value:"distribution",label:"Source Distribution",default:!0,children:(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# Convert dataset to DataFrame for analysis\ndf = dataset.to_df()\n\n# Check source type distribution\nsource_distribution = df["source_type"].value_counts()\nprint("Data sources in dataset:")\nfor source_type, count in source_distribution.items():\n    print(f"  {source_type}: {count} records")\n'})})}),(0,s.jsx)(o.A,{value:"filtering",label:"Filter by Source",children:(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# Analyze expectations by source\nhuman_records = df[df["source_type"] == "HUMAN"]\ntrace_records = df[df["source_type"] == "TRACE"]\ncode_records = df[df["source_type"] == "CODE"]\n\nprint(f"Human-curated records: {len(human_records)}")\nprint(f"Production trace records: {len(trace_records)}")\nprint(f"Generated test records: {len(code_records)}")\n\n# Filter high-value test cases for critical evaluation\nhigh_value_test_cases = df[\n    (df["source_type"] == "HUMAN") | (df["source_type"] == "DOCUMENT")\n]\n'})})}),(0,s.jsxs)(o.A,{value:"metadata",label:"Source Metadata",children:[(0,s.jsxs)(t.p,{children:["The ",(0,s.jsx)(t.code,{children:"source_data"})," field stores rich metadata about record origins:"]}),(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# Example with detailed source metadata\ndetailed_source = {\n    "inputs": {"question": "Complex integration test"},\n    "expectations": {"passes_validation": True},\n    "source": {\n        "source_type": "TRACE",\n        "source_data": {\n            "trace_id": "tr-abc123",\n            "environment": "production",\n            "user_segment": "enterprise",\n            "timestamp": "2024-11-01T10:30:00Z",\n            "session_id": "sess-xyz789",\n            "feedback_score": 0.95,\n        },\n    },\n}\n\n# Access metadata after merging\ndataset.merge_records([detailed_source])\ndf = dataset.to_df()\n# source_data preserved for analysis\n'})})]})]})}),"\n",(0,s.jsx)(t.h2,{id:"search-filter-reference",children:"Search Filter Reference"}),"\n",(0,s.jsxs)(t.p,{children:["Use these fields in your filter strings. ",(0,s.jsx)(t.strong,{children:"Note:"})," The fluent API returns a ",(0,s.jsx)(t.code,{children:"PagedList"})," that can be iterated directly - pagination is handled automatically when you iterate over the results."]}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{children:"Field"}),(0,s.jsx)(t.th,{children:"Type"}),(0,s.jsx)(t.th,{children:"Example"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"name"})}),(0,s.jsx)(t.td,{children:"string"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"name = 'production_tests'"})})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"tags.<key>"})}),(0,s.jsx)(t.td,{children:"string"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"tags.status = 'validated'"})})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"created_by"})}),(0,s.jsx)(t.td,{children:"string"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"created_by = 'alice@company.com'"})})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"last_updated_by"})}),(0,s.jsx)(t.td,{children:"string"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"last_updated_by = 'bob@company.com'"})})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"created_time"})}),(0,s.jsx)(t.td,{children:"timestamp"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"created_time > 1698800000000"})})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"last_update_time"})}),(0,s.jsx)(t.td,{children:"timestamp"}),(0,s.jsx)(t.td,{children:(0,s.jsx)(t.code,{children:"last_update_time > 1698800000000"})})]})]})]}),"\n",(0,s.jsx)(t.h3,{id:"filter-operators",children:"Filter Operators"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"="}),", ",(0,s.jsx)(t.code,{children:"!="}),": Exact match"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"LIKE"}),", ",(0,s.jsx)(t.code,{children:"ILIKE"}),": Pattern matching with ",(0,s.jsx)(t.code,{children:"%"})," wildcard (ILIKE is case-insensitive)"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:">"}),", ",(0,s.jsx)(t.code,{children:"<"}),", ",(0,s.jsx)(t.code,{children:">="}),", ",(0,s.jsx)(t.code,{children:"<="}),": Numeric/timestamp comparison"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"AND"}),": Combine conditions (OR is not currently supported for evaluation datasets)"]}),"\n"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# Complex filter example\ndatasets = search_datasets(\n    filter_string="""\n        tags.status = \'production\'\n        AND name LIKE \'%customer%\'\n        AND created_time > 1698800000000\n    """,\n    order_by=["last_update_time DESC"],\n)\n'})}),"\n",(0,s.jsx)(t.h2,{id:"using-the-client-api",children:"Using the Client API"}),"\n",(0,s.jsxs)(t.p,{children:["For applications and advanced use cases, you can also use the ",(0,s.jsx)(t.code,{children:"MlflowClient"})," API which provides the same functionality with an object-oriented interface:"]}),"\n",(0,s.jsx)(c.A,{children:(0,s.jsxs)(i.A,{children:[(0,s.jsx)(o.A,{value:"create",label:"Create Dataset",default:!0,children:(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'from mlflow import MlflowClient\n\nclient = MlflowClient()\n\n# Create a dataset\ndataset = client.create_dataset(\n    name="customer_support_qa",\n    experiment_id=["0"],\n    tags={"version": "1.0", "team": "ml-platform"},\n)\n'})})}),(0,s.jsx)(o.A,{value:"get",label:"Get Dataset",children:(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# Get a dataset by ID\ndataset = client.get_dataset(dataset_id="d-7f2e3a9b8c1d4e5f6a7b8c9d0e1f2a3b")\n\n# Access properties\nprint(f"Dataset: {dataset.name}")\nprint(f"Records: {len(dataset.records)}")\n'})})}),(0,s.jsx)(o.A,{value:"search",label:"Search Datasets",children:(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# Search for datasets\ndatasets = client.search_datasets(\n    experiment_ids=["0"],\n    filter_string="tags.status = \'validated\'",\n    order_by=["created_time DESC"],\n    max_results=50,\n)\n\nfor dataset in datasets:\n    print(f"{dataset.name}: {dataset.dataset_id}")\n'})})}),(0,s.jsx)(o.A,{value:"tags",label:"Manage Tags",children:(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# Set tags\nclient.set_dataset_tags(\n    dataset_id=dataset.dataset_id, tags={"status": "production", "validated": "true"}\n)\n\n# Delete a tag\nclient.delete_dataset_tag(dataset_id=dataset.dataset_id, key="deprecated")\n'})})}),(0,s.jsx)(o.A,{value:"delete",label:"Delete Dataset",children:(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:"# Delete a dataset\nclient.delete_dataset(dataset_id=dataset.dataset_id)\n"})})})]})}),"\n",(0,s.jsx)(t.p,{children:"The client API provides the same capabilities as the fluent API but is better suited for:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Production applications that need explicit client management"}),"\n",(0,s.jsx)(t.li,{children:"Scenarios requiring custom tracking URIs or authentication"}),"\n",(0,s.jsx)(t.li,{children:"Integration with existing MLflow client-based workflows"}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsxs)(h.A,{children:[(0,s.jsx)(m.A,{icon:N.A,iconSize:48,title:"End-to-End Workflow",description:"Learn the complete evaluation-driven development workflow from app building to production",href:"/genai/datasets/end-to-end-workflow",linkText:"View complete workflow \u2192",containerHeight:64}),(0,s.jsx)(m.A,{icon:g.A,iconSize:48,title:"Run Evaluations",description:"Use your datasets to systematically evaluate and improve your GenAI applications",href:"/genai/eval-monitor",linkText:"Start evaluating \u2192",containerHeight:64}),(0,s.jsx)(m.A,{icon:T.A,iconSize:48,title:"Define Expectations",description:"Learn how to add ground truth expectations to your test data for quality validation",href:"/genai/assessments/expectations",linkText:"Set expectations \u2192",containerHeight:64}),(0,s.jsx)(m.A,{icon:j.A,iconSize:48,title:"Capture Traces",description:"Instrument your applications to capture production data for building datasets",href:"/genai/tracing",linkText:"Enable tracing \u2192",containerHeight:64})]})]})}function M(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(E,{...e})}):E(e)}}}]);