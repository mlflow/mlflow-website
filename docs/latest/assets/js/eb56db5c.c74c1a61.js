"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8481],{28453:(e,n,o)=>{o.d(n,{R:()=>s,x:()=>a});var i=o(96540);const r={},t=i.createContext(r);function s(e){const n=i.useContext(t);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),i.createElement(t.Provider,{value:n},e.children)}},41227:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>c,frontMatter:()=>s,metadata:()=>i,toc:()=>p});const i=JSON.parse('{"id":"prompt-version-mgmt/prompt-registry/use-prompts-in-apps","title":"Use Prompts in Apps","description":"Learn how to integrate prompts from the MLflow Prompt Registry into your applications and link them to MLflow Models for end-to-end lineage.","source":"@site/docs/genai/prompt-version-mgmt/prompt-registry/use-prompts-in-apps.mdx","sourceDirName":"prompt-version-mgmt/prompt-registry","slug":"/prompt-version-mgmt/prompt-registry/use-prompts-in-apps","permalink":"/docs/latest/genai/prompt-version-mgmt/prompt-registry/use-prompts-in-apps","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Use Prompts in Apps","description":"Learn how to integrate prompts from the MLflow Prompt Registry into your applications and link them to MLflow Models for end-to-end lineage."},"sidebar":"genAISidebar","previous":{"title":"Manage Prompt Lifecycles with Aliases","permalink":"/docs/latest/genai/prompt-version-mgmt/prompt-registry/manage-prompt-lifecycles-with-aliases"},"next":{"title":"Log Prompts with Models","permalink":"/docs/latest/genai/prompt-version-mgmt/prompt-registry/log-with-model"}}');var r=o(74848),t=o(28453);const s={title:"Use Prompts in Apps",description:"Learn how to integrate prompts from the MLflow Prompt Registry into your applications and link them to MLflow Models for end-to-end lineage."},a="Use Prompts in Apps",l={},p=[{value:"Loading Prompts from the Registry",id:"loading-prompts-from-the-registry",level:2},{value:"Formatting Prompts with Variables",id:"formatting-prompts-with-variables",level:2},{value:"Using Prompts with Other Frameworks (LangChain, LlamaIndex)",id:"using-prompts-with-other-frameworks-langchain-llamaindex",level:2},{value:"Linking Prompts to Logged Models for Full Lineage",id:"linking-prompts-to-logged-models-for-full-lineage",level:2},{value:"How to Ensure Linkage (Conceptual)",id:"how-to-ensure-linkage-conceptual",level:3},{value:"Error Handling",id:"error-handling",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Prerequisites",id:"prerequisites",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"use-prompts-in-apps",children:"Use Prompts in Apps"})}),"\n",(0,r.jsx)(n.p,{children:"Once you have created and versioned your prompts in the MLflow Prompt Registry, the next crucial step is to integrate them into your GenAI applications. This page guides you on how to load prompts, bind variables, handle versioning, and ensure complete lineage by linking prompt versions to your logged MLflow Models."}),"\n",(0,r.jsx)(n.p,{children:"You will learn:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["How to load specific prompt versions or aliases using ",(0,r.jsx)(n.code,{children:"mlflow.genai.load_prompt()"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["The process of formatting prompts with dynamic data using ",(0,r.jsx)(n.code,{children:"prompt.format()"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Strategies for managing prompt versions within your application code."}),"\n",(0,r.jsxs)(n.li,{children:["How to use MLflow prompts with other popular frameworks like LangChain or LlamaIndex via ",(0,r.jsx)(n.code,{children:"prompt.to_single_brace_format()"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"The importance of logging the specific prompt version used when logging an MLflow Model."}),"\n",(0,r.jsx)(n.li,{children:"How this linkage aids reproducibility, debugging, and inspection of models."}),"\n",(0,r.jsx)(n.li,{children:"Best practices for error handling."}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"loading-prompts-from-the-registry",children:"Loading Prompts from the Registry"}),"\n",(0,r.jsxs)(n.p,{children:["The primary way to access a registered prompt in your application code is by using the ",(0,r.jsx)(n.code,{children:"mlflow.genai.load_prompt()"})," function. This function retrieves a specific prompt version (or a version pointed to by an alias) from the registry."]}),"\n",(0,r.jsxs)(n.p,{children:["It uses a special URI format: ",(0,r.jsx)(n.code,{children:"prompts:/<prompt_name>/<version_or_alias>"}),"."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"<prompt_name>"}),": The unique name of the prompt in the registry."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"<version_or_alias>"}),": Can be a specific version number (e.g., ",(0,r.jsx)(n.code,{children:"1"}),", ",(0,r.jsx)(n.code,{children:"2"}),") or an alias (e.g., ",(0,r.jsx)(n.code,{children:"production"}),", ",(0,r.jsx)(n.code,{children:"latest-dev"}),")."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import mlflow\n\nprompt_name = "my-sdk-prompt"\n\n# Load by specific version (assuming version 1 exists)\nmlflow.genai.load_prompt(uri=f"prompts:/{prompt_name}/1")\n\n# Load by alias (assuming an alias \'staging\' points to a version of a prompt)\nmlflow.genai.load_prompt(uri=f"prompts:/{prompt_name}@staging")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"formatting-prompts-with-variables",children:"Formatting Prompts with Variables"}),"\n",(0,r.jsxs)(n.p,{children:["Once you have loaded a prompt object (which is a ",(0,r.jsx)(n.code,{children:"Prompt"})," instance), you can populate its template variables using the ",(0,r.jsx)(n.code,{children:"prompt.format()"})," method. This method takes keyword arguments where the keys match the variable names in your prompt template (without the ",(0,r.jsx)(n.code,{children:"{{ }}"})," braces)."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import mlflow\n\n# define a prompt template\nprompt_template = """\\\nYou are an expert AI assistant. Answer the user\'s question with clarity, accuracy, and conciseness.\n\n## Question:\n{{question}}\n\n## Guidelines:\n- Keep responses factual and to the point.\n- If relevant, provide examples or step-by-step instructions.\n- If the question is ambiguous, clarify before answering.\n\nRespond below:\n"""\nprompt = mlflow.genai.register_prompt(\n    name="ai_assistant_prompt",\n    template=prompt_template,\n    commit_message="Initial version of AI assistant",\n)\n\nquestion = "What is MLflow?"\nresponse = (\n    client.chat.completions.create(\n        messages=[{"role": "user", "content": prompt.format(question=question)}],\n        model="gpt-4o-mini",\n        temperature=0.1,\n        max_tokens=2000,\n    )\n    .choices[0]\n    .message.content\n)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"using-prompts-with-other-frameworks-langchain-llamaindex",children:"Using Prompts with Other Frameworks (LangChain, LlamaIndex)"}),"\n",(0,r.jsxs)(n.p,{children:["MLflow prompts use the ",(0,r.jsx)(n.code,{children:"{{variable}}"})," double-brace syntax for templating. Some other popular frameworks, like LangChain and LlamaIndex, often expect a single-brace syntax (e.g., ",(0,r.jsx)(n.code,{children:"{variable}"}),"). To facilitate seamless integration, the MLflow ",(0,r.jsx)(n.code,{children:"Prompt"})," object provides the ",(0,r.jsx)(n.code,{children:"prompt.to_single_brace_format()"})," method. This method returns the prompt template string converted to a single-brace format, ready to be used by these frameworks."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\n\n# Load registered prompt\nprompt = mlflow.genai.load_prompt("prompts:/summarization-prompt/2")\n\n# Create LangChain prompt object\nlangchain_prompt = ChatPromptTemplate.from_messages(\n    [\n        (\n            # IMPORTANT: Convert prompt template from double to single curly braces format\n            "system",\n            prompt.to_single_brace_format(),\n        ),\n        ("placeholder", "{messages}"),\n    ]\n)\n\n# Define the LangChain chain\nllm = ChatOpenAI()\nchain = langchain_prompt | llm\n\n# Invoke the chain\nresponse = chain.invoke({"num_sentences": 1, "sentences": "This is a test sentence."})\nprint(response)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"linking-prompts-to-logged-models-for-full-lineage",children:"Linking Prompts to Logged Models for Full Lineage"}),"\n",(0,r.jsxs)(n.p,{children:["For complete reproducibility and traceability, it is crucial to log which specific prompt versions your application (or model) uses. When you log your GenAI application as an MLflow Model (e.g., using ",(0,r.jsx)(n.code,{children:"mlflow.pyfunc.log_model()"}),", ",(0,r.jsx)(n.code,{children:"mlflow.langchain.log_model()"}),", etc.), you should include information about the prompts from the registry that it utilizes."]}),"\n",(0,r.jsxs)(n.p,{children:["MLflow is designed to facilitate this. When a model is logged, and that model's code loads prompts using the ",(0,r.jsx)(n.code,{children:"prompts:/"})," URI via ",(0,r.jsx)(n.code,{children:"mlflow.genai.load_prompt()"}),", MLflow can automatically record these prompt dependencies as part of the logged model's metadata."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Benefits of this linkage:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Reproducibility"}),": Knowing the exact prompt versions used by a model version allows you to reproduce its behavior precisely."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Debugging"}),": If a model version starts behaving unexpectedly, you can easily check if a change in an underlying prompt (even if updated via an alias) is the cause."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Auditing and Governance"}),": Maintain a clear record of which prompts were used for any given model version."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Impact Analysis"}),": Understand which models might be affected if a particular prompt version is found to be problematic."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"how-to-ensure-linkage-conceptual",children:"How to Ensure Linkage (Conceptual)"}),"\n",(0,r.jsx)(n.p,{children:"While automatic detection is a goal, explicitly ensuring your model logging code or serving environment correctly captures these dependencies is good practice."}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Consistent URI Usage"}),": Always use the ",(0,r.jsx)(n.code,{children:"prompts:/<name>/<version_or_alias>"})," URI with ",(0,r.jsx)(n.code,{children:"mlflow.genai.load_prompt()"})," within your model's code."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"MLflow Model Logging"}),": When you log your model (e.g., your agent, your LangChain chain) using an appropriate ",(0,r.jsx)(n.code,{children:"mlflow.<flavor>.log_model()"})," function, MLflow flavors designed for GenAI will often inspect the model for these ",(0,r.jsx)(n.code,{children:"prompts:/"})," URIs and record them."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"error-handling",children:"Error Handling"}),"\n",(0,r.jsx)(n.p,{children:"When integrating prompts, implement robust error handling:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Prompt Loading"}),": Handle cases where a prompt name, version, or alias doesn't exist."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Formatting"}),": Catch errors if variables are missing or mismatched during ",(0,r.jsx)(n.code,{children:"prompt.format()"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Logging"}),": Ensure that failures during model logging (including prompt linkage) are caught and addressed."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Use ",(0,r.jsx)(n.code,{children:'mlflow.genai.load_prompt(uri="prompts:/<name>/<version_or_alias>")'})," to fetch prompts from the registry."]}),"\n",(0,r.jsxs)(n.li,{children:["Populate template variables with ",(0,r.jsx)(n.code,{children:"prompt.format(**kwargs)"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Leverage ",(0,r.jsx)(n.code,{children:"prompt.to_single_brace_format()"})," for compatibility with frameworks like LangChain."]}),"\n",(0,r.jsx)(n.li,{children:"Logging your application as an MLflow Model should capture the specific prompt versions used, providing crucial lineage and reproducibility."}),"\n",(0,r.jsxs)(n.li,{children:["Using aliases (e.g., ",(0,r.jsx)(n.code,{children:"prompts:/my-prompt/production"}),") in your application code allows you to update the underlying prompt version in the registry without redeploying your application."]}),"\n",(0,r.jsx)(n.li,{children:"Robust error handling is essential for reliable application behavior."}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Application codebase where you intend to use prompts."}),"\n",(0,r.jsx)(n.li,{children:"Access to an MLflow Prompt Registry with registered prompts."}),"\n",(0,r.jsx)(n.li,{children:"Familiarity with MLflow Model Logging concepts if you plan to link prompts to models."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"By following these guidelines, you can effectively integrate version-controlled prompts from the MLflow Prompt Registry into your applications, enhancing their maintainability, reliability, and traceability."})]})}function c(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);