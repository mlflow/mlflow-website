"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["5292"],{5874(e,t,n){n.r(t),n.d(t,{metadata:()=>i,default:()=>u,frontMatter:()=>p,contentTitle:()=>m,toc:()=>d,assets:()=>c});var i=JSON.parse('{"id":"prompt-registry/optimize-prompts","title":"Optimize Prompts (Experimental)","description":"The simple way to continuously improve your AI agents and prompts.","source":"@site/docs/genai/prompt-registry/optimize-prompts.mdx","sourceDirName":"prompt-registry","slug":"/prompt-registry/optimize-prompts","permalink":"/mlflow-website/docs/latest/genai/prompt-registry/optimize-prompts","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"sidebar_label":"Optimize Prompts"},"sidebar":"genAISidebar","previous":{"title":"Structured Output","permalink":"/mlflow-website/docs/latest/genai/prompt-registry/structured-output"},"next":{"title":"LangChain Optimization","permalink":"/mlflow-website/docs/latest/genai/prompt-registry/optimize-prompts/langchain-optimization"}}'),r=n(74848),o=n(28453),s=n(54725),a=n(3340),l=n(95310);let p={sidebar_position:5,sidebar_label:"Optimize Prompts"},m="Optimize Prompts (Experimental)",c={},d=[{value:"Quick Start",id:"quick-start",level:2},{value:"Choosing Your Optimizer",id:"choosing-your-optimizer",level:2},{value:"GEPA (Genetic-Pareto)",id:"gepa-genetic-pareto",level:3},{value:"Metaprompting",id:"metaprompting",level:3},{value:"Comparison Summary",id:"comparison-summary",level:3},{value:"Example: Simple Prompt \u2192 Optimized Prompt",id:"example-simple-prompt--optimized-prompt",level:3},{value:"Components",id:"components",level:2},{value:"1. Target Prompt URIs",id:"1-target-prompt-uris",level:3},{value:"2. Predict Function",id:"2-predict-function",level:3},{value:"3. Training Data",id:"3-training-data",level:3},{value:"4. Optimizer",id:"4-optimizer",level:3},{value:"Advanced Usage",id:"advanced-usage",level:2},{value:"Works with Any Agent Framework",id:"works-with-any-agent-framework",level:3},{value:"Using Custom Scorers",id:"using-custom-scorers",level:3},{value:"Custom Optimization Algorithm",id:"custom-optimization-algorithm",level:3},{value:"Multi-Prompt Optimization",id:"multi-prompt-optimization",level:3},{value:"Result Object",id:"result-object",level:2},{value:"Common Use Cases",id:"common-use-cases",level:2},{value:"Improving Accuracy",id:"improving-accuracy",level:3},{value:"Optimizing for Safeness",id:"optimizing-for-safeness",level:3},{value:"Model Switching and Migration",id:"model-switching-and-migration",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Issue: Optimization Takes Too Long",id:"issue-optimization-takes-too-long",level:3},{value:"Issue: No Improvement Observed",id:"issue-no-improvement-observed",level:3},{value:"Issue: Prompts Not Being Used",id:"issue-prompts-not-being-used",level:3},{value:"See Also",id:"see-also",level:2}];function h(e){let t={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"optimize-prompts-experimental",children:"Optimize Prompts (Experimental)"})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"The simple way to continuously improve your AI agents and prompts."})}),"\n",(0,r.jsx)(t.p,{children:"MLflow's prompt optimization lets you systematically enhance your AI applications with minimal code changes. Whether you're building with LangChain, OpenAI Agent, CrewAI, or your own custom implementation, MLflow provides a universal path from initial prototyping to steady improvement."}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"Minimum rewrites, no lock-in, just better prompts."})}),"\n",(0,r.jsx)(t.p,{children:"MLflow supports multiple optimization algorithms to improve your prompts:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:(0,r.jsx)(t.a,{href:"https://arxiv.org/abs/2507.19457",children:"GEPA"})})," (",(0,r.jsx)(s.B,{fn:"mlflow.genai.optimize.GepaPromptOptimizer",children:(0,r.jsx)(t.code,{children:"GepaPromptOptimizer"})}),"): Iteratively refines prompts using LLM-driven reflection and automated feedback, achieving systematic improvements through trial-and-error learning."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Metaprompting"})," (",(0,r.jsx)(s.B,{fn:"mlflow.genai.optimize.MetaPromptOptimizer",children:(0,r.jsx)(t.code,{children:"MetaPromptOptimizer"})}),"): Restructures prompts to be more systematic and effective, working in both zero-shot mode (without training data) and few-shot mode (learning from your examples)."]}),"\n"]}),"\n",(0,r.jsxs)(t.p,{children:["See ",(0,r.jsx)(t.a,{href:"#choosing-your-optimizer",children:"Choosing Your Optimizer"})," for guidance on which optimizer to use for your specific needs."]}),"\n",(0,r.jsx)(t.admonition,{title:"Why Use MLflow Prompt Optimization?",type:"tip",children:(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Zero Framework Lock-in"}),": Works with ANY agent framework\u2014LangChain, OpenAI Agent, CrewAI, or custom solutions"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Minimal Code Changes"}),": Add a few lines to start optimizing; no architectural rewrites needed"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Data-Driven Improvement"}),": Automatically learn from your evaluation data and custom metrics"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Multi-Prompt Optimization"}),": Jointly optimize multiple prompts for complex agent workflows"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Granular Control"}),": Optimize single prompts or entire multi-prompt workflows\u2014you decide what to improve"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Production-Ready"}),": Built-in version control and registry for seamless deployment"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Extensible"}),": Bring your own optimization algorithms with simple base class extension"]}),"\n"]})}),"\n",(0,r.jsx)(t.admonition,{title:"Version Requirements",type:"note",children:(0,r.jsxs)(t.p,{children:["The ",(0,r.jsx)(t.code,{children:"optimize_prompts"})," API requires ",(0,r.jsx)(t.strong,{children:"MLflow >= 3.5.0"}),"."]})}),"\n",(0,r.jsx)(t.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,r.jsx)(t.p,{children:"Here's a realistic example of optimizing a prompt for medical paper section classification:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'import mlflow\nimport openai\nfrom mlflow.genai.optimize import GepaPromptOptimizer\nfrom mlflow.genai.scorers import Correctness\n\n# Register initial prompt for classifying medical paper sections\nprompt = mlflow.genai.register_prompt(\n    name="medical_section_classifier",\n    template="Classify this medical research paper sentence into one of these sections: CONCLUSIONS, RESULTS, METHODS, OBJECTIVE, BACKGROUND.\\n\\nSentence: {{sentence}}",\n)\n\n\n# Define your prediction function\ndef predict_fn(sentence: str) -> str:\n    prompt = mlflow.genai.load_prompt("prompts:/medical_section_classifier/1")\n    completion = openai.OpenAI().chat.completions.create(\n        model="gpt-5-nano",\n        # load prompt template using PromptVersion.format()\n        messages=[{"role": "user", "content": prompt.format(sentence=sentence)}],\n    )\n    return completion.choices[0].message.content\n\n\n# Training data with medical paper sentences and ground truth labels\n# fmt: off\nraw_data = [\n    ("The emergence of HIV as a chronic condition means that people living with HIV are required to take more responsibility for the self-management of their condition , including making physical , emotional and social adjustments .", "BACKGROUND"),\n    ("This paper describes the design and evaluation of Positive Outlook , an online program aiming to enhance the self-management skills of gay men living with HIV .", "BACKGROUND"),\n    ("This study is designed as a randomised controlled trial in which men living with HIV in Australia will be assigned to either an intervention group or usual care control group .", "METHODS"),\n    ("The intervention group will participate in the online group program ` Positive Outlook \' .", "METHODS"),\n    ("The program is based on self-efficacy theory and uses a self-management approach to enhance skills , confidence and abilities to manage the psychosocial issues associated with HIV in daily life .", "METHODS"),\n    ("Participants will access the program for a minimum of 90 minutes per week over seven weeks .", "METHODS"),\n    ("Primary outcomes are domain specific self-efficacy , HIV related quality of life , and outcomes of health education .", "METHODS"),\n    ("Secondary outcomes include : depression , anxiety and stress ; general health and quality of life ; adjustment to HIV ; and social support .", "METHODS"),\n    ("Data collection will take place at baseline , completion of the intervention ( or eight weeks post randomisation ) and at 12 week follow-up .", "METHODS"),\n    ("Results of the Positive Outlook study will provide information regarding the effectiveness of online group programs improving health related outcomes for men living with HIV .", "CONCLUSIONS"),\n    ("The aim of this study was to evaluate the efficacy , safety and complications of orbital steroid injection versus oral steroid therapy in the management of thyroid-related ophthalmopathy .", "OBJECTIVE"),\n    ("A total of 29 patients suffering from thyroid ophthalmopathy were included in this study .", "METHODS"),\n    ("Patients were randomized into two groups : group I included 15 patients treated with oral prednisolone and group II included 14 patients treated with peribulbar triamcinolone orbital injection .", "METHODS"),\n    ("Both groups showed improvement in symptoms and in clinical evidence of inflammation with improvement of eye movement and proptosis in most cases .", "RESULTS"),\n    ("Mean exophthalmometry value before treatment was 22.6 1.98 mm that decreased to 18.6 0.996 mm in group I , compared with 23 1.86 mm that decreased to 19.08 1.16 mm in group II .", "RESULTS"),\n    ("There was no change in the best-corrected visual acuity in both groups .", "RESULTS"),\n    ("There was an increase in body weight , blood sugar , blood pressure and gastritis in group I in 66.7 % , 33.3 % , 50 % and 75 % , respectively , compared with 0 % , 0 % , 8.3 % and 8.3 % in group II .", "RESULTS"),\n    ("Orbital steroid injection for thyroid-related ophthalmopathy is effective and safe .", "CONCLUSIONS"),\n    ("It eliminates the adverse reactions associated with oral corticosteroid use .", "CONCLUSIONS"),\n    ("The aim of this prospective randomized study was to examine whether active counseling and more liberal oral fluid intake decrease postoperative pain , nausea and vomiting in pediatric ambulatory tonsillectomy .", "OBJECTIVE"),\n]\n# fmt: on\n\n# Format dataset for optimization\ndataset = [\n    {\n        "inputs": {"sentence": sentence},\n        "expectations": {"expected_response": label},\n    }\n    for sentence, label in raw_data\n]\n\n# Optimize the prompt\nresult = mlflow.genai.optimize_prompts(\n    predict_fn=predict_fn,\n    train_data=dataset,\n    prompt_uris=[prompt.uri],\n    optimizer=GepaPromptOptimizer(\n        reflection_model="openai:/gpt-5", max_metric_calls=300\n    ),\n    scorers=[Correctness(model="openai:/gpt-5-mini")],\n)\n\n# Use the optimized prompt\noptimized_prompt = result.optimized_prompts[0]\nprint(f"Optimized template: {optimized_prompt.template}")\n'})}),"\n",(0,r.jsx)(t.p,{children:"The API will automatically improve the prompt to better classify medical paper sections by learning from the training examples."}),"\n",(0,r.jsx)(t.h2,{id:"choosing-your-optimizer",children:"Choosing Your Optimizer"}),"\n",(0,r.jsxs)(t.p,{children:["MLflow currently supports two optimization algorithms: ",(0,r.jsx)(t.strong,{children:"GEPA"})," and ",(0,r.jsx)(t.strong,{children:"Metaprompting"}),". Each uses different strategies to improve your prompts."]}),"\n",(0,r.jsx)(t.h3,{id:"gepa-genetic-pareto",children:"GEPA (Genetic-Pareto)"}),"\n",(0,r.jsx)(t.p,{children:"GEPA is a prompt optimization technique that uses natural language reflection to iteratively improve LLM performance through trial-and-error learning. It's particularly effective at extracting rich learning signals from system behavior by analyzing failures in natural language."}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"Key Features:"})}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Natural Language Reflection"}),": Leverages interpretable language to extract learning signals from execution traces, reasoning chains, and tool interactions"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"High Efficiency"}),": Achieves superior results with dramatically fewer iterations (up to 35x fewer rollouts compared to traditional methods like GRPO)"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Pareto Synthesis"}),": Smartly picks the past prompt to mutate and improve"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Strong Performance"}),": Demonstrates reliable gains on a wide range of tasks, e.g., context compression, Q&A agents, etc."]}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"Best For:"})}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"Tasks where you have clear evaluation metrics and a dataset of decent size (e.g., 100+ records)"}),"\n",(0,r.jsx)(t.li,{children:"Tasks where quality is critical to your system (e.g., medical agents, financial agents, etc.), so that the optimization cost and longer prompt as produced by GEPA is worth it"}),"\n"]}),"\n",(0,r.jsx)(t.admonition,{title:"Reduce the Cost of GEPA Optimization",type:"tip",children:(0,r.jsx)(t.p,{children:"The cost of GEPA optimization is tightly coupled with the reflection model you use and the max number of metric calls you allow. You can reduce the cost by using a cheaper reflection model or reducing the max number of metric calls."})}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.strong,{children:"Learn More:"})," ",(0,r.jsx)(t.a,{href:"https://arxiv.org/abs/2507.19457",children:"GEPA Research Paper"})," | ",(0,r.jsx)(t.a,{href:"https://github.com/gepa-ai/gepa",children:"GEPA GitHub Repository"})]}),"\n",(0,r.jsx)(t.h3,{id:"metaprompting",children:"Metaprompting"}),"\n",(0,r.jsx)(t.p,{children:"Metaprompting is a prompt optimization technique that utilizes a metaprompt to call the language model to restructure your prompts to be more systematic and effective. It operates in two modes:"}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"Zero-Shot Mode:"})}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"Analyzes your initial prompt and restructures it to follow best practices"}),"\n",(0,r.jsx)(t.li,{children:"Makes prompts more systematic without requiring training data"}),"\n",(0,r.jsx)(t.li,{children:"Quick to run and requires no examples"}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"Few-Shot Mode:"})}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"Evaluates the initial prompt on your training data to understand task-specific patterns"}),"\n",(0,r.jsx)(t.li,{children:"Leverages the evaluation results along with general best practices to restructure the prompt to be more systematic and effective"}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"Key Features:"})}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Fast Optimization"}),": Runs fast because it only does one evaluation round in few-shot mode and just one single call to the language model in zero-shot mode"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Minimal Data Requirement"}),": Works well with zero or just a few examples (less than 10)"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Systematic Improvement"}),": Restructures prompts to follow clear patterns and best practices"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Data-Aware"}),": In few-shot mode, learns from your specific data to tailor improvements"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Custom Guidelines"}),": You can provide custom guidelines to the optimizer to tailor the optimization to your specific needs"]}),"\n"]}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.strong,{children:"Best For:"})," Tasks where you want quick improvements based on prompt engineering best practices, or when you have limited training data but want to leverage it for targeted improvements."]}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"Usage Examples:"})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'from mlflow.genai.optimize import MetaPromptOptimizer\n\n# Zero-shot mode: No training data or scorers required\n# The optimizer automatically uses zero-shot mode when train_data is empty and scorers is empty\nresults = mlflow.genai.optimize_prompts(\n    predict_fn=predict_fn,\n    train_data=[],\n    prompt_uris=[prompt.uri],\n    optimizer=MetaPromptOptimizer(\n        reflection_model="openai:/gpt-5",\n        guidelines="This prompt is used in a finance agent to project tax situations.",\n    ),\n    scorers=[],\n)\n\n# Few-shot mode: Learn from training data\n# The optimizer automatically uses few-shot mode when train_data and scorers are provided\nresults = mlflow.genai.optimize_prompts(\n    predict_fn=predict_fn,\n    train_data=dataset,\n    prompt_uris=[prompt.uri],\n    optimizer=MetaPromptOptimizer(\n        reflection_model="openai:/gpt-5",\n        guidelines="This prompt is used in a finance agent to project tax situations.",\n    ),\n    scorers=[Correctness(model="openai:/gpt-5-mini")],\n)\n'})}),"\n",(0,r.jsx)(t.h3,{id:"comparison-summary",children:"Comparison Summary"}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Feature"}),(0,r.jsx)(t.th,{children:"GEPA"}),(0,r.jsx)(t.th,{children:"Metaprompting (Zero-Shot)"}),(0,r.jsx)(t.th,{children:"Metaprompting (Few-Shot)"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Requires Training Data"})}),(0,r.jsx)(t.td,{children:"Yes"}),(0,r.jsx)(t.td,{children:"No"}),(0,r.jsx)(t.td,{children:"Yes"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Optimization Speed"})}),(0,r.jsx)(t.td,{children:"Moderate"}),(0,r.jsx)(t.td,{children:"Fast"}),(0,r.jsx)(t.td,{children:"Fast-Moderate"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Learning Approach"})}),(0,r.jsx)(t.td,{children:"Iterative trial-and-error with reflection"}),(0,r.jsx)(t.td,{children:"Systematic restructuring"}),(0,r.jsx)(t.td,{children:"Data-driven restructuring"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.strong,{children:"Best Use Case"})}),(0,r.jsx)(t.td,{children:"Complex tasks with clear metrics"}),(0,r.jsx)(t.td,{children:"Quick improvements without data"}),(0,r.jsx)(t.td,{children:"Targeted improvements with limited data"})]})]})]}),"\n",(0,r.jsx)(t.p,{children:"Choose the optimizer that best fits your task requirements, available data, and optimization budget."}),"\n",(0,r.jsx)(t.h3,{id:"example-simple-prompt--optimized-prompt",children:"Example: Simple Prompt \u2192 Optimized Prompt"}),"\n",(0,r.jsxs)(a.AC,{cols:2,children:[(0,r.jsxs)(a.Zp,{style:{justifyContent:"flex-start"},children:[(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"Before Optimization:"})}),(0,r.jsx)("div",{style:{maxWidth:"100%"},children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-text",children:"Classify this medical research paper sentence\ninto one of these sections: CONCLUSIONS, RESULTS,\nMETHODS, OBJECTIVE, BACKGROUND.\n\nSentence: {{sentence}}\n"})})})]}),(0,r.jsxs)(a.Zp,{children:[(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"After Optimization:"})}),(0,r.jsx)("div",{style:{maxWidth:"100%"},children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-text",children:'You are a single-sentence classifier for medical research abstracts. For each input sentence, decide which abstract section it belongs to and output exactly one label in UPPERCASE with no extra words, punctuation, or explanation.\n\nAllowed labels: CONCLUSIONS, RESULTS, METHODS, OBJECTIVE, BACKGROUND\n\nInput format:\n- The prompt will be:\n  "Classify this medical research paper sentence into one of these sections: CONCLUSIONS, RESULTS, METHODS, OBJECTIVE, BACKGROUND.\n\n  Sentence: {{sentence}}"\n\nCore rules:\n- Use only the information in the single sentence.\n- Classify by the sentence\'s function: context-setting vs aim vs procedure vs findings vs interpretation.\n- Return exactly one uppercase label from the allowed set.\n\nDecision guide and lexical cues:\n\n1) RESULTS\n- Reports observed findings/outcomes tied to data.\n- Common cues: past-tense result verbs and outcome terms: "showed," "was/were associated with," "increased/decreased," "improved," "reduced," "significant," "p < \u2026," "odds ratio," "risk ratio," "95% CI," percentages, rates, counts or numbers tied to effects/adverse events.\n- If it explicitly states changes, associations, statistical significance, or quantified outcomes, choose RESULTS.\n\n2) CONCLUSIONS\n- Interpretation, implications, recommendations, or high-level takeaways.\n- Common cues: "In conclusion," "These findings suggest/indicate," "We conclude," statements about practice/policy/clinical implications, benefit\u2013risk judgments, feasibility statements.\n- Sentences that forecast the significance/utility of the study\'s results ("Results will provide insight/information," "Findings will inform/guide practice") are CONCLUSIONS.\n- Tie-break with RESULTS: If a sentence describes an outcome as a general claim without specific observed data/statistics, prefer CONCLUSIONS over RESULTS.\n\n3) METHODS\n- How the study was conducted: design, participants, interventions/programs, measurements/outcomes lists, timelines, procedures, or analyses.\n- Common cues: design terms ("randomized," "double-blind," "cross-sectional," "cohort," "case-control"), "participants," "n =," inclusion/exclusion criteria, instruments/scales, dosing/protocols, schedules/timelines, statistical tests/analysis plans ("multivariate regression," "Kaplan\u2013Meier," "ANOVA," "we will compare"), trial registration, ethics approval.\n- Measurement/outcome lists are METHODS (e.g., "Secondary outcomes include: \u2026"; "Primary outcome was \u2026").\n- Numbers specifying sample size (e.g., "n = 200") \u2192 METHODS; numbers tied to effects \u2192 RESULTS.\n- Program/intervention descriptions, components, theoretical basis, and mechanisms are METHODS, even if written in present tense and even if they contain purpose phrases. Examples: "The program is based on self-efficacy theory\u2026," "The intervention uses a self-management approach to enhance skills\u2026," "The device is designed to\u2026"\n  - Important: An infinitive "to [verb] \u2026" inside a program/intervention description (e.g., "uses X to improve Y") is METHODS, not OBJECTIVE, because it describes how the intervention works, not the study\'s aim.\n\n4) OBJECTIVE\n- The aim/purpose/hypothesis of the study.\n- Common cues: "Objective(s):" "Aim/Purpose was," "We aimed/sought/intended to," "We hypothesized that \u2026"\n- Infinitive purpose phrases indicating the study\'s aim without procedures or results: "To determine/evaluate/assess/investigate whether \u2026" \u2192 OBJECTIVE.\n- Phrases like "The aim of this study was to evaluate the efficacy/safety of X vs Y \u2026" \u2192 OBJECTIVE.\n- If "We evaluated/assessed \u2026" is clearly used as a purpose statement (not describing methods or results), label OBJECTIVE.\n\n5) BACKGROUND\n- Context, rationale, prior knowledge, unmet need; introduces topic without specific aims, procedures, or results.\n- Common cues: burden/prevalence statements, "X is common," "X remains poorly understood," prior work summaries, general descriptions.\n- If a sentence merely states that a paper describes/reports a program/design/evaluation without concrete procedures/analyses, label as BACKGROUND.\n\nImportant tie-break rules:\n- RESULTS vs CONCLUSIONS: Observed data/findings \u2192 RESULTS; interpretation/generalization/recommendation \u2192 CONCLUSIONS.\n- OBJECTIVE vs METHODS: Purpose/aim of the study \u2192 OBJECTIVE; concrete design/intervention details/measurements/analysis steps \u2192 METHODS.\n- BACKGROUND vs OBJECTIVE: Context/motivation without an explicit study aim \u2192 BACKGROUND.\n- BACKGROUND vs METHODS: General description without concrete procedures/analyses \u2192 BACKGROUND.\n- The word "Results" at the start does not guarantee RESULTS; e.g., "Results will provide information \u2026" \u2192 CONCLUSIONS.\n\nOutput constraint:\n- Return exactly one uppercase label: CONCLUSIONS, RESULTS, METHODS, OBJECTIVE, or BACKGROUND. No extra text or punctuation.\n'})})})]})]}),"\n",(0,r.jsx)(t.h2,{id:"components",children:"Components"}),"\n",(0,r.jsxs)(t.p,{children:["The ",(0,r.jsx)(s.B,{fn:"mlflow.genai.optimize_prompts"})," API requires the following components:"]}),"\n",(0,r.jsxs)("table",{style:{width:"100%"},children:[(0,r.jsx)("thead",{children:(0,r.jsxs)("tr",{children:[(0,r.jsx)("th",{style:{width:"30%"},children:"Component"}),(0,r.jsx)("th",{style:{width:"70%"},children:"Description"})]})}),(0,r.jsxs)("tbody",{children:[(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{children:(0,r.jsx)("strong",{children:"Target Prompt URIs"})}),(0,r.jsxs)("td",{children:["List of prompt URIs to optimize (e.g., ",(0,r.jsx)("code",{children:'["prompts:/qa/1"]'}),")"]})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{children:(0,r.jsx)("strong",{children:"Predict Function"})}),(0,r.jsxs)("td",{children:["A callable that takes inputs as keyword arguments and returns outputs. Must load templates from MLflow prompt versions (e.g., call ",(0,r.jsx)(s.B,{fn:"mlflow.entities.model_registry.PromptVersion.format",children:(0,r.jsx)(t.code,{children:"PromptVersion.format()"})}),")."]})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{children:(0,r.jsx)("strong",{children:"Training Data"})}),(0,r.jsxs)("td",{children:["Dataset with ",(0,r.jsx)("code",{children:"inputs"})," (dict) and ",(0,r.jsx)("code",{children:"expectations"})," (expected results). Supports pandas DataFrame, list of dicts, or MLflow EvaluationDataset."]})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{children:(0,r.jsx)("strong",{children:"Optimizer"})}),(0,r.jsxs)("td",{children:["Prompt optimizer instance (e.g., ",(0,r.jsx)(s.B,{fn:"mlflow.genai.optimize.GepaPromptOptimizer",children:(0,r.jsx)(t.code,{children:"GepaPromptOptimizer"})})," or ",(0,r.jsx)(s.B,{fn:"mlflow.genai.optimize.MetaPromptOptimizer",children:(0,r.jsx)(t.code,{children:"MetaPromptOptimizer"})}),"). See ",(0,r.jsx)(l.A,{to:"#choosing-your-optimizer",children:"Choosing Your Optimizer"})," for guidance."]})]})]})]}),"\n",(0,r.jsx)(t.h3,{id:"1-target-prompt-uris",children:"1. Target Prompt URIs"}),"\n",(0,r.jsx)(t.p,{children:"Specify which prompts to optimize using their URIs from MLflow Prompt Registry:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'prompt_uris = [\n    "prompts:/qa/1",  # Specific version\n    "prompts:/instruction@latest",  # Latest version\n]\n'})}),"\n",(0,r.jsx)(t.p,{children:"You can reference prompts by:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Specific version"}),": ",(0,r.jsx)(t.code,{children:'"prompts:/qa/1"'})," - Optimize a particular version"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Latest version"}),": ",(0,r.jsx)(t.code,{children:'"prompts:/qa@latest"'})," - Optimize the most recent version"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Alias"}),": ",(0,r.jsx)(t.code,{children:'"prompts:/qa@champion"'})," - Optimize a version with a specific alias"]}),"\n"]}),"\n",(0,r.jsx)(t.h3,{id:"2-predict-function",children:"2. Predict Function"}),"\n",(0,r.jsxs)(t.p,{children:["Your ",(0,r.jsx)(t.code,{children:"predict_fn"})," must:"]}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"Accept inputs as keyword arguments matching the inputs field of the dataset"}),"\n",(0,r.jsxs)(t.li,{children:["Load the template from MLflow prompt versions using one of the following methods:","\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsx)(s.B,{fn:"mlflow.entities.model_registry.PromptVersion.format",children:(0,r.jsx)(t.code,{children:"PromptVersion.format()"})}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsx)(s.B,{fn:"mlflow.entities.model_registry.PromptVersion.template",children:(0,r.jsx)(t.code,{children:"PromptVersion.template"})}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsx)(s.B,{fn:"mlflow.entities.model_registry.PromptVersion.to_single_brace_format",children:(0,r.jsx)(t.code,{children:"PromptVersion.to_single_brace_format()"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["Return outputs in the same format as your training data (e.g., outputs = ",(0,r.jsx)(t.code,{children:'{"answer": "xxx"}'})," if expectations = ",(0,r.jsx)(t.code,{children:'{"expected_response": {"answer": "xxx"}}'}),")"]}),"\n"]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'def predict_fn(question: str) -> str:\n    # Load prompt from registry\n    prompt = mlflow.genai.load_prompt("prompts:/qa/1")\n\n    # Format the prompt with input variables\n    formatted_prompt = prompt.format(question=question)\n\n    # Call your LLM\n    response = your_llm_call(formatted_prompt)\n\n    return response\n'})}),"\n",(0,r.jsx)(t.h3,{id:"3-training-data",children:"3. Training Data"}),"\n",(0,r.jsxs)(t.p,{children:["Provide a dataset with ",(0,r.jsx)(t.code,{children:"inputs"})," and ",(0,r.jsx)(t.code,{children:"expectations"}),". Both columns should have dictionary values. ",(0,r.jsx)(t.code,{children:"inputs"})," values will be passed to the predict function as keyword arguments. Please refer to ",(0,r.jsx)(t.a,{href:"/genai/eval-monitor/scorers/llm-judge/predefined/",children:"Built-in Judges"})," for the expected format of each built in scorers."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'# List of dictionaries - Example: Medical paper classification\ndataset = [\n    {\n        "inputs": {\n            "sentence": "The emergence of HIV as a chronic condition means that people living with HIV are required to take more responsibility..."\n        },\n        "expectations": {"expected_response": "BACKGROUND"},\n    },\n    {\n        "inputs": {\n            "sentence": "This study is designed as a randomised controlled trial in which men living with HIV..."\n        },\n        "expectations": {"expected_response": "METHODS"},\n    },\n    {\n        "inputs": {\n            "sentence": "Both groups showed improvement in symptoms and in clinical evidence of inflammation..."\n        },\n        "expectations": {"expected_response": "RESULTS"},\n    },\n    {\n        "inputs": {\n            "sentence": "Orbital steroid injection for thyroid-related ophthalmopathy is effective and safe."\n        },\n        "expectations": {"expected_response": "CONCLUSIONS"},\n    },\n    {\n        "inputs": {\n            "sentence": "The aim of this study was to evaluate the efficacy, safety and complications..."\n        },\n        "expectations": {"expected_response": "OBJECTIVE"},\n    },\n]\n\n# Or pandas DataFrame\nimport pandas as pd\n\ndataset = pd.DataFrame(\n    {\n        "inputs": [\n            {"sentence": "The emergence of HIV as a chronic condition..."},\n            {"sentence": "This study is designed as a randomised controlled trial..."},\n            {"sentence": "Both groups showed improvement in symptoms..."},\n        ],\n        "expectations": [\n            {"expected_response": "BACKGROUND"},\n            {"expected_response": "METHODS"},\n            {"expected_response": "RESULTS"},\n        ],\n    }\n)\n'})}),"\n",(0,r.jsx)(t.h3,{id:"4-optimizer",children:"4. Optimizer"}),"\n",(0,r.jsxs)(t.p,{children:["Create an optimizer instance for the optimization algorithm. MLflow supports ",(0,r.jsx)(s.B,{fn:"mlflow.genai.optimize.GepaPromptOptimizer",children:(0,r.jsx)(t.code,{children:"GepaPromptOptimizer"})})," and ",(0,r.jsx)(s.B,{fn:"mlflow.genai.optimize.MetaPromptOptimizer",children:(0,r.jsx)(t.code,{children:"MetaPromptOptimizer"})}),". See ",(0,r.jsx)(t.a,{href:"#choosing-your-optimizer",children:"Choosing Your Optimizer"})," for detailed guidance on which optimizer to use."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'from mlflow.genai.optimize import GepaPromptOptimizer, MetaPromptOptimizer\n\n# Option 1: GEPA optimizer\noptimizer = GepaPromptOptimizer(\n    reflection_model="openai:/gpt-5",  # Powerful model for optimization\n    max_metric_calls=100,\n    display_progress_bar=False,\n)\n\n# Option 2: Metaprompting optimizer\n# Note: Zero-shot vs few-shot is determined by whether you provide\n# scorers and train_data to optimize_prompts()\noptimizer = MetaPromptOptimizer(\n    reflection_model="openai:/gpt-5",\n    guidelines="Optional custom guidelines for optimization",\n)\n'})}),"\n",(0,r.jsx)(t.h2,{id:"advanced-usage",children:"Advanced Usage"}),"\n",(0,r.jsx)(t.h3,{id:"works-with-any-agent-framework",children:"Works with Any Agent Framework"}),"\n",(0,r.jsxs)(t.p,{children:["MLflow's optimization is ",(0,r.jsx)(t.strong,{children:"framework-agnostic"}),"\u2014it works seamlessly with LangChain, LangGraph, OpenAI Agent, Pydantic AI, CrewAI, AutoGen, or any custom framework. No need to rewrite your existing agents or switch frameworks."]}),"\n",(0,r.jsx)(t.p,{children:"See these framework-specific guides for detailed examples:"}),"\n",(0,r.jsxs)(a.AC,{isSmall:!0,children:[(0,r.jsx)(a.$3,{link:"/genai/prompt-registry/optimize-prompts/langchain-optimization",children:(0,r.jsx)("span",{children:(0,r.jsx)(t.img,{alt:"LangChain Logo",src:n(13581).A+"",width:"783",height:"138"})})}),(0,r.jsx)(a.$3,{link:"/genai/prompt-registry/optimize-prompts/langgraph-optimization",children:(0,r.jsx)("span",{children:(0,r.jsx)(t.img,{alt:"LangGraph Logo",src:n(65068).A+"",width:"571",height:"88"})})}),(0,r.jsx)(a.$3,{link:"/genai/prompt-registry/optimize-prompts/openai-agent-optimization",children:(0,r.jsx)("span",{children:(0,r.jsx)(t.img,{alt:"OpenAI Agent Logo",src:n(30836).A+"",width:"400",height:"175"})})}),(0,r.jsx)(a.$3,{link:"/genai/prompt-registry/optimize-prompts/pydantic-ai-optimization",children:(0,r.jsx)("span",{children:(0,r.jsx)(t.img,{alt:"Pydantic AI Logo",src:n(81774).A+"",width:"2584",height:"546"})})})]}),"\n",(0,r.jsx)(t.h3,{id:"using-custom-scorers",children:"Using Custom Scorers"}),"\n",(0,r.jsx)(t.p,{children:"Define custom evaluation metrics to guide optimization:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'from typing import Any\nfrom mlflow.genai.scorers import scorer\n\n\n@scorer\ndef accuracy_scorer(outputs: Any, expectations: dict[str, Any]):\n    """Check if output matches expected value."""\n    return 1.0 if outputs.lower() == expectations.lower() else 0.0\n\n\n@scorer\ndef brevity_scorer(outputs: Any):\n    """Prefer shorter outputs (max 50 chars)."""\n    return min(1.0, 50 / max(len(outputs), 1))\n\n\n# Combine scorers with a weighted objective\ndef weighted_objective(scores: dict[str, Any]):\n    return 0.7 * scores["accuracy_scorer"] + 0.3 * scores["brevity_scorer"]\n\n\n# Use custom scorers\nresult = mlflow.genai.optimize_prompts(\n    predict_fn=predict_fn,\n    train_data=dataset,\n    prompt_uris=[prompt.uri],\n    optimizer=GepaPromptOptimizer(reflection_model="openai:/gpt-5"),\n    scorers=[accuracy_scorer, brevity_scorer],\n    aggregation=weighted_objective,\n)\n'})}),"\n",(0,r.jsx)(t.h3,{id:"custom-optimization-algorithm",children:"Custom Optimization Algorithm"}),"\n",(0,r.jsxs)(t.p,{children:["Implement your own optimizer by extending ",(0,r.jsx)(s.B,{fn:"mlflow.genai.optimize.BasePromptOptimizer",children:(0,r.jsx)(t.code,{children:"BasePromptOptimizer"})}),":"]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'from mlflow.genai.optimize import BasePromptOptimizer, PromptOptimizerOutput\nfrom mlflow.genai.scorers import Correctness\n\n\nclass MyCustomOptimizer(BasePromptOptimizer):\n    def __init__(self, model_name: str):\n        self.model_name = model_name\n\n    def optimize(self, eval_fn, train_data, target_prompts, enable_tracking):\n        # Your custom optimization logic\n        optimized_prompts = {}\n        for prompt_name, prompt_template in target_prompts.items():\n            # Implement your algorithm\n            optimized_prompts[prompt_name] = your_optimization_algorithm(\n                prompt_template, train_data, self.model_name\n            )\n\n        return PromptOptimizerOutput(optimized_prompts=optimized_prompts)\n\n\n# Use custom optimizer\nresult = mlflow.genai.optimize_prompts(\n    predict_fn=predict_fn,\n    train_data=dataset,\n    prompt_uris=[prompt.uri],\n    optimizer=MyCustomOptimizer(model_name="openai:/gpt-5"),\n    scorers=[Correctness(model="openai:/gpt-5")],\n)\n'})}),"\n",(0,r.jsx)(t.h3,{id:"multi-prompt-optimization",children:"Multi-Prompt Optimization"}),"\n",(0,r.jsx)(t.p,{children:"Optimize multiple prompts together:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'import mlflow\nfrom mlflow.genai.scorers import Correctness\n\n# Register multiple prompts\nplan_prompt = mlflow.genai.register_prompt(\n    name="plan",\n    template="Make a plan to answer {{question}}.",\n)\nanswer_prompt = mlflow.genai.register_prompt(\n    name="answer",\n    template="Answer {{question}} following the plan: {{plan}}",\n)\n\n\ndef predict_fn(question: str) -> str:\n    plan_prompt = mlflow.genai.load_prompt("prompts:/plan/1")\n    completion = openai.OpenAI().chat.completions.create(\n        model="gpt-5",  # strong model\n        messages=[{"role": "user", "content": plan_prompt.format(question=question)}],\n    )\n    plan = completion.choices[0].message.content\n\n    answer_prompt = mlflow.genai.load_prompt("prompts:/answer/1")\n    completion = openai.OpenAI().chat.completions.create(\n        model="gpt-5-mini",  # cost efficient model\n        messages=[\n            {\n                "role": "user",\n                "content": answer_prompt.format(question=question, plan=plan),\n            }\n        ],\n    )\n    return completion.choices[0].message.content\n\n\n# Optimize both\nresult = mlflow.genai.optimize_prompts(\n    predict_fn=predict_fn,\n    train_data=dataset,\n    prompt_uris=[plan_prompt.uri, answer_prompt.uri],\n    optimizer=GepaPromptOptimizer(reflection_model="openai:/gpt-5"),\n    scorers=[Correctness(model="openai:/gpt-5")],\n)\n\n# Access optimized prompts\noptimized_plan = result.optimized_prompts[0]\noptimized_answer = result.optimized_prompts[1]\n'})}),"\n",(0,r.jsx)(t.h2,{id:"result-object",children:"Result Object"}),"\n",(0,r.jsxs)(t.p,{children:["The API returns a ",(0,r.jsx)(s.B,{fn:"mlflow.genai.optimize.PromptOptimizationResult",children:(0,r.jsx)(t.code,{children:"PromptOptimizationResult"})})," object:"]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'result = mlflow.genai.optimize_prompts(...)\n\n# Access optimized prompts\nfor prompt in result.optimized_prompts:\n    print(f"Name: {prompt.name}")\n    print(f"Version: {prompt.version}")\n    print(f"Template: {prompt.template}")\n    print(f"URI: {prompt.uri}")\n\n# Check optimizer used\nprint(f"Optimizer: {result.optimizer_name}")\n\n# View evaluation scores (if available)\nprint(f"Initial score: {result.initial_eval_score}")\nprint(f"Final score: {result.final_eval_score}")\n'})}),"\n",(0,r.jsx)(t.h2,{id:"common-use-cases",children:"Common Use Cases"}),"\n",(0,r.jsx)(t.h3,{id:"improving-accuracy",children:"Improving Accuracy"}),"\n",(0,r.jsx)(t.p,{children:"Optimize prompts to produce more accurate outputs:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'from mlflow.genai.scorers import Correctness\n\n\nresult = mlflow.genai.optimize_prompts(\n    predict_fn=predict_fn,\n    train_data=dataset,\n    prompt_uris=[prompt.uri],\n    optimizer=GepaPromptOptimizer(reflection_model="openai:/gpt-5"),\n    scorers=[Correctness(model="openai:/gpt-5")],\n)\n'})}),"\n",(0,r.jsx)(t.h3,{id:"optimizing-for-safeness",children:"Optimizing for Safeness"}),"\n",(0,r.jsx)(t.p,{children:"Ensure outputs are safe:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'from mlflow.genai.scorers import Safety\n\n\nresult = mlflow.genai.optimize_prompts(\n    predict_fn=predict_fn,\n    train_data=dataset,\n    prompt_uris=[prompt.uri],\n    optimizer=GepaPromptOptimizer(reflection_model="openai:/gpt-5"),\n    scorers=[Safety(model="openai:/gpt-5")],\n)\n'})}),"\n",(0,r.jsx)(t.h3,{id:"model-switching-and-migration",children:"Model Switching and Migration"}),"\n",(0,r.jsxs)(t.p,{children:["When switching between different language models (e.g., migrating from ",(0,r.jsx)(t.code,{children:"gpt-5"})," to ",(0,r.jsx)(t.code,{children:"gpt-5-mini"})," for cost reduction), you may need to rewrite your prompts to maintain output quality with the new model. The ",(0,r.jsx)(s.B,{fn:"mlflow.genai.optimize_prompts"})," API can help adapt prompts automatically using your existing application outputs as training data."]}),"\n",(0,r.jsxs)(t.p,{children:["See the ",(0,r.jsx)(t.a,{href:"/genai/prompt-registry/rewrite-prompts",children:"Auto-rewrite Prompts for New Models"})," guide for a complete model migration workflow."]}),"\n",(0,r.jsx)(t.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,r.jsx)(t.h3,{id:"issue-optimization-takes-too-long",children:"Issue: Optimization Takes Too Long"}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.strong,{children:"Solution"}),": Reduce dataset size or reduce the optimizer budget:"]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'# Use fewer examples\nsmall_dataset = dataset[:20]\n\n# Use faster model for optimization\noptimizer = GepaPromptOptimizer(\n    reflection_model="openai:/gpt-5-mini", max_metric_calls=100\n)\n'})}),"\n",(0,r.jsx)(t.h3,{id:"issue-no-improvement-observed",children:"Issue: No Improvement Observed"}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.strong,{children:"Solution"}),": Check your evaluation metrics and increase dataset diversity:"]}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"Ensure scorers accurately measure what you care about"}),"\n",(0,r.jsx)(t.li,{children:"Increase training data size and diversity"}),"\n",(0,r.jsx)(t.li,{children:"Try to modify optimizer configurations"}),"\n",(0,r.jsx)(t.li,{children:"Verify outputs format matches expectations"}),"\n"]}),"\n",(0,r.jsx)(t.h3,{id:"issue-prompts-not-being-used",children:"Issue: Prompts Not Being Used"}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.strong,{children:"Solution"}),": Ensure ",(0,r.jsx)(t.code,{children:"predict_fn"})," calls ",(0,r.jsx)(s.B,{fn:"mlflow.entities.model_registry.PromptVersion.format",children:(0,r.jsx)(t.code,{children:"PromptVersion.format()"})})," during execution:"]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'# \u2705 Correct - loads from registry\ndef predict_fn(question: str):\n    prompt = mlflow.genai.load_prompt("prompts:/qa@latest")\n    return llm_call(prompt.format(question=question))\n\n\n# \u274C Incorrect - hardcoded prompt\ndef predict_fn(question: str):\n    return llm_call(f"Answer: {question}")\n'})}),"\n",(0,r.jsx)(t.h2,{id:"see-also",children:"See Also"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.a,{href:"/genai/prompt-registry/rewrite-prompts",children:"Auto-rewrite Prompts for New Models"}),": Adapt prompts when switching between language models"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.a,{href:"/genai/prompt-registry/create-and-edit-prompts",children:"Create and Edit Prompts"}),": Basic Prompt Registry usage"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.a,{href:"/genai/eval-monitor/running-evaluation/prompts",children:"Evaluate Prompts"}),": Evaluate prompt performance"]}),"\n"]})]})}function u(e={}){let{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}},13581(e,t,n){n.d(t,{A:()=>i});let i=n.p+"assets/images/langchain-logo-39d51f94cc9aebac2c191cca0e8189de.png"},65068(e,t,n){n.d(t,{A:()=>i});let i="data:image/png;base64,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"},30836(e,t,n){n.d(t,{A:()=>i});let i=n.p+"assets/images/openai-agent-logo-8afddf736341f2b2dfe5cbb9caeaff45.png"},81774(e,t,n){n.d(t,{A:()=>i});let i=n.p+"assets/images/pydanticai-logo-e225ccce7e8699654c01ff1aeeed6b10.png"},54725(e,t,n){n.d(t,{B:()=>s});var i=n(74848);n(96540);var r=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}'),o=n(66497);function s({fn:e,children:t,hash:n}){let s=(e=>{let t=e.split(".");for(let e=t.length;e>0;e--){let n=t.slice(0,e).join(".");if(r[n])return n}return null})(e);if(!s)return(0,i.jsx)(i.Fragment,{children:t});let a=(0,o.default)(`/${r[s]}#${n??e}`);return(0,i.jsx)("a",{href:a,target:"_blank",children:t??(0,i.jsxs)("code",{children:[e,"()"]})})}},3340(e,t,n){n.d(t,{WO:()=>m,$3:()=>c,jK:()=>d,_C:()=>p,Zp:()=>l,AC:()=>a});var i=n(74848),r=n(34164);let o={CardGroup:"CardGroup_P84T",NoGap:"NoGap_O9Dj",MaxThreeColumns:"MaxThreeColumns_FO1r",AutofillColumns:"AutofillColumns_fKhQ",Card:"Card_aSCR",CardBordered:"CardBordered_glGF",CardBody:"CardBody_BhRs",TextColor:"TextColor_a8Tp",BoxRoot:"BoxRoot_Etgr",FlexWrapNowrap:"FlexWrapNowrap_f60k",FlexJustifyContentFlexStart:"FlexJustifyContentFlexStart_ZYv5",FlexDirectionRow:"FlexDirectionRow_T2qL",FlexAlignItemsCenter:"FlexAlignItemsCenter_EHVM",FlexFlex:"FlexFlex__JTE",Link:"Link_fVkl",MarginLeft4:"MarginLeft4_YQSJ",MarginTop4:"MarginTop4_jXKN",PaddingBottom4:"PaddingBottom4_O9gt",LogoCardContent:"LogoCardContent_kCQm",LogoCardImage:"LogoCardImage_JdcX",SmallLogoCardContent:"SmallLogoCardContent_LxhV",SmallLogoCardRounded:"SmallLogoCardRounded_X50_",SmallLogoCardImage:"SmallLogoCardImage_tPZl",SmallLogoCardImageWithTitle:"SmallLogoCardImageWithTitle_K6Vu",SmallLogoCardImageDefault:"SmallLogoCardImageDefault_nyru",SmallLogoCardRow:"SmallLogoCardRow_kcMP",SmallLogoCardLabel:"SmallLogoCardLabel_f5RQ",SmallLogoCardArrow:"SmallLogoCardArrow_J536",SmallLogoCardLink:"SmallLogoCardLink_Cm5j",NewFeatureCardContent:"NewFeatureCardContent_Rq3d",NewFeatureCardHeading:"NewFeatureCardHeading_f6q3",NewFeatureCardHeadingSeparator:"NewFeatureCardHeadingSeparator_pSx8",NewFeatureCardTags:"NewFeatureCardTags_IFHO",NewFeatureCardWrapper:"NewFeatureCardWrapper_NQ0k",TitleCardContent:"TitleCardContent_l9MQ",TitleCardHeader:"TitleCardHeader_fUQy",TitleCardHeaderRight:"TitleCardHeaderRight_iBLX",TitleCardTitle:"TitleCardTitle__K8J",TitleCardSeparator:"TitleCardSeparator_IN2E",Cols1:"Cols1_Gr2U",Cols2:"Cols2_sRvc",Cols3:"Cols3_KjUS",Cols4:"Cols4_dKOj",Cols5:"Cols5_jDmj",Cols6:"Cols6_Q0OR"};var s=n(95310);let a=({children:e,isSmall:t,cols:n,noGap:s})=>(0,i.jsx)("div",{className:(0,r.A)(o.CardGroup,t?o.AutofillColumns:n?o[`Cols${n}`]:o.MaxThreeColumns,s&&o.NoGap),children:e}),l=({children:e,link:t="",style:n})=>t?(0,i.jsx)(s.A,{className:(0,r.A)(o.Link,o.Card,o.CardBordered),style:n,to:t,children:e}):(0,i.jsx)("div",{className:(0,r.A)(o.Card,o.CardBordered),style:n,children:e}),p=({headerText:e,link:t,text:n})=>(0,i.jsx)(l,{link:t,children:(0,i.jsxs)("span",{children:[(0,i.jsx)("div",{className:(0,r.A)(o.CardTitle,o.BoxRoot,o.PaddingBottom4),style:{pointerEvents:"none"},children:(0,i.jsx)("div",{className:(0,r.A)(o.BoxRoot,o.FlexFlex,o.FlexAlignItemsCenter,o.FlexDirectionRow,o.FlexJustifyContentFlexStart,o.FlexWrapNowrap),style:{marginLeft:"-4px",marginTop:"-4px"},children:(0,i.jsx)("div",{className:(0,r.A)(o.BoxRoot,o.BoxHideIfEmpty,o.MarginTop4,o.MarginLeft4),style:{pointerEvents:"auto"},children:(0,i.jsx)("span",{className:"",children:e})})})}),(0,i.jsx)("span",{className:(0,r.A)(o.TextColor,o.CardBody),children:(0,i.jsx)("p",{children:n})})]})}),m=({description:e,children:t,link:n})=>(0,i.jsx)(l,{link:n,children:(0,i.jsxs)("div",{className:o.LogoCardContent,children:[(0,i.jsx)("div",{className:o.LogoCardImage,children:t}),(0,i.jsx)("p",{className:o.TextColor,children:e})]})}),c=({children:e,link:t,title:n=""})=>(0,i.jsx)(s.A,{className:(0,r.A)(o.Card,o.CardBordered,o.SmallLogoCardRounded,o.SmallLogoCardLink),to:t,children:(0,i.jsx)("div",{className:o.SmallLogoCardContent,children:n?(0,i.jsxs)("div",{className:o.SmallLogoCardRow,children:[(0,i.jsx)("div",{className:(0,r.A)("max-height-img-container",o.SmallLogoCardImage,o.SmallLogoCardImageWithTitle),children:e}),(0,i.jsx)("div",{className:o.SmallLogoCardLabel,children:(0,i.jsx)("span",{children:n})})]}):(0,i.jsx)("div",{className:(0,r.A)("max-height-img-container",o.SmallLogoCardImage,o.SmallLogoCardImageDefault),children:e})})}),d=({title:e,description:t,link:n="",headerRight:s,children:a})=>(0,i.jsx)(l,{link:n,children:(0,i.jsxs)("div",{className:o.TitleCardContent,children:[(0,i.jsxs)("div",{className:(0,r.A)(o.TitleCardHeader),children:[(0,i.jsx)("div",{className:(0,r.A)(o.TitleCardTitle),style:{textAlign:"left",fontWeight:"bold"},children:e}),(0,i.jsx)("div",{className:o.TitleCardHeaderRight,children:s})]}),(0,i.jsx)("hr",{className:(0,r.A)(o.TitleCardSeparator),style:{margin:"12px 0"}}),a?(0,i.jsx)("div",{className:(0,r.A)(o.TextColor),children:a}):(0,i.jsx)("p",{className:(0,r.A)(o.TextColor),dangerouslySetInnerHTML:{__html:t}})]})})},28453(e,t,n){n.d(t,{R:()=>s,x:()=>a});var i=n(96540);let r={},o=i.createContext(r);function s(e){let t=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),i.createElement(o.Provider,{value:t},e.children)}}}]);