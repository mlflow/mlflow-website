"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["6571"],{89748(e,n,t){t.r(n),t.d(n,{metadata:()=>r,default:()=>y,frontMatter:()=>x,contentTitle:()=>g,toc:()=>v,assets:()=>j});var r=JSON.parse('{"id":"eval-monitor/scorers/llm-judge/response-quality/correctness","title":"Correctness Judge","description":"The Correctness judge assesses whether your GenAI application\'s response is factually correct by comparing it against provided ground truth information (expectedfacts or expectedresponse).","source":"@site/docs/genai/eval-monitor/scorers/llm-judge/response-quality/correctness.mdx","sourceDirName":"eval-monitor/scorers/llm-judge/response-quality","slug":"/eval-monitor/scorers/llm-judge/response-quality/correctness","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/response-quality/correctness","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"genAISidebar","previous":{"title":"Safety","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/response-quality/safety"},"next":{"title":"Tool Call Evaluation with Built-in Judges","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/tool-call/"}}'),s=t(74848),a=t(28453),l=t(77541),o=t(10440),i=t(44471),c=t(42640),d=t(51004),u=t(78010),p=t(57250),h=t(95986),m=t(83884),f=t(55935);let x={},g="Correctness Judge",j={},v=[...m.RM,{value:"Usage examples",id:"usage-examples",level:2},...f.RM,{value:"Interpret results",id:"interpret-results",level:2},{value:"Next steps",id:"next-steps",level:2}];function w(e){let n={admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"correctness-judge",children:"Correctness Judge"})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"Correctness"})," judge assesses whether your GenAI application's response is factually correct by comparing it against provided ground truth information (",(0,s.jsx)(n.code,{children:"expected_facts"})," or ",(0,s.jsx)(n.code,{children:"expected_response"}),")."]}),"\n",(0,s.jsx)(n.p,{children:"This built-in LLM judge is designed for evaluating application responses against known correct answers."}),"\n",(0,s.jsx)(m.Ay,{}),"\n",(0,s.jsx)(n.h2,{id:"usage-examples",children:"Usage examples"}),"\n",(0,s.jsx)(h.A,{children:(0,s.jsxs)(u.A,{groupId:"invocation-method",children:[(0,s.jsx)(p.A,{value:"direct",label:"Invoke directly",default:!0,children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from mlflow.genai.scorers import Correctness\n\ncorrectness_judge = Correctness()\n\n# Example 1: Response contains expected facts\nfeedback = correctness_judge(\n    inputs={"request": "What is MLflow?"},\n    outputs={\n        "response": "MLflow is an open-source platform for managing the ML lifecycle."\n    },\n    expectations={\n        "expected_facts": [\n            "MLflow is open-source",\n            "MLflow is a platform for ML lifecycle",\n        ]\n    },\n)\n\n# Example 2: Response missing or contradicting facts\nfeedback = correctness_judge(\n    inputs={"request": "When was MLflow released?"},\n    outputs={"response": "MLflow was released in 2017."},\n    expectations={"expected_facts": ["MLflow was released in June 2018"]},\n)\n\n# Example 3: Using expected_response instead of expected_facts\nfeedback = correctness_judge(\n    inputs={"request": "What is the capital of France?"},\n    outputs={"response": "The capital of France is Paris."},\n    expectations={"expected_response": "Paris is the capital of France."},\n)\n'})})}),(0,s.jsx)(p.A,{value:"evaluate",label:"Invoke with evaluate()",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom mlflow.genai.scorers import Correctness\n\n# Create evaluation dataset with ground truth\neval_dataset = [\n    # Example 1: Response contains expected facts\n    {\n        "inputs": {"request": "What is MLflow?"},\n        "outputs": {\n            "response": "MLflow is an open-source platform for managing the ML lifecycle."\n        },\n        "expectations": {\n            "expected_facts": [\n                "MLflow is open-source",\n                "MLflow is a platform for ML lifecycle",\n            ]\n        },\n    },\n    # Example 2: Response missing or contradicting facts\n    {\n        "inputs": {"request": "When was MLflow released?"},\n        "outputs": {"response": "MLflow was released in 2017."},\n        "expectations": {"expected_facts": ["MLflow was released in June 2018"]},\n    },\n    # Example 3: Using expected_response instead of expected_facts\n    {\n        "inputs": {"request": "What is the capital of France?"},\n        "outputs": {"response": "The capital of France is Paris."},\n        "expectations": {"expected_response": "Paris is the capital of France."},\n    },\n]\n\n# Run evaluation with Correctness judge\neval_results = mlflow.genai.evaluate(\n    data=eval_dataset,\n    scorers=[\n        Correctness(\n            model="openai:/gpt-4o-mini",  # Optional.\n        )\n    ],\n)\n'})})})]})}),"\n",(0,s.jsx)(n.admonition,{type:"tip",children:(0,s.jsxs)(n.p,{children:["Use ",(0,s.jsx)(n.code,{children:"expected_facts"})," rather than ",(0,s.jsx)(n.code,{children:"expected_response"})," for more flexible evaluation - the response doesn't need to match word-for-word, just contain the key facts."]})}),"\n",(0,s.jsx)(f.Ay,{}),"\n",(0,s.jsx)(n.h2,{id:"interpret-results",children:"Interpret results"}),"\n",(0,s.jsx)(n.p,{children:"The judge returns a Feedback object with:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"value"}),': "yes" if response is correct, "no" if incorrect']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"rationale"}),": Detailed explanation of which facts are supported or missing"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next steps"}),"\n",(0,s.jsxs)(o.A,{children:[(0,s.jsx)(l.A,{icon:i.A,title:"Explore other built-in judges",description:"Learn about other built-in quality evaluation judges",href:"/genai/eval-monitor/scorers/llm-judge/predefined/#available-judges"}),(0,s.jsx)(l.A,{icon:c.A,title:"Create custom judges",description:"Build domain-specific evaluation judges",href:"/genai/eval-monitor/scorers/llm-judge/custom-judges"}),(0,s.jsx)(l.A,{icon:d.A,title:"Build evaluation datasets",description:"Create test cases with ground truth for testing",href:"/genai/datasets/"})]})]})}function y(e={}){let{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(w,{...e})}):w(e)}},83884(e,n,t){t.d(n,{Ay:()=>o,RM:()=>a});var r=t(74848),s=t(28453);let a=[{value:"Prerequisites for running the examples",id:"prerequisites-for-running-the-examples",level:2}];function l(e){let n={a:"a",code:"code",h2:"h2",li:"li",ol:"ol",p:"p",pre:"pre",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h2,{id:"prerequisites-for-running-the-examples",children:"Prerequisites for running the examples"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Install MLflow and required packages"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"pip install --upgrade mlflow\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Create an MLflow experiment by following the ",(0,r.jsx)(n.a,{href:"/genai/getting-started/connect-environment/",children:"setup your environment quickstart"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["(Optional, if using OpenAI models) Use the native OpenAI SDK to connect to OpenAI-hosted models. Select a model from the ",(0,r.jsx)(n.a,{href:"https://platform.openai.com/docs/models",children:"available OpenAI models"}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport os\nimport openai\n\n# Ensure your OPENAI_API_KEY is set in your environment\n# os.environ["OPENAI_API_KEY"] = "<YOUR_API_KEY>" # Uncomment and set if not globally configured\n\n# Enable auto-tracing for OpenAI\nmlflow.openai.autolog()\n\n# Create an OpenAI client\nclient = openai.OpenAI()\n\n# Select an LLM\nmodel_name = "gpt-4o-mini"\n'})}),"\n"]}),"\n"]})]})}function o(e={}){let{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}},55935(e,n,t){t.d(n,{Ay:()=>o,RM:()=>a});var r=t(74848),s=t(28453);let a=[{value:"Select the LLM that powers the judge",id:"select-the-llm-that-powers-the-judge",level:2}];function l(e){let n={a:"a",code:"code",h2:"h2",p:"p",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h2,{id:"select-the-llm-that-powers-the-judge",children:"Select the LLM that powers the judge"}),"\n",(0,r.jsxs)(n.p,{children:["You can change the judge model by using the ",(0,r.jsx)(n.code,{children:"model"})," argument in the judge definition. The model must be specified in the format ",(0,r.jsx)(n.code,{children:"<provider>:/<model-name>"}),", where ",(0,r.jsx)(n.code,{children:"<provider>"})," is a LiteLLM-compatible model provider."]}),"\n",(0,r.jsxs)(n.p,{children:["For a list of supported models, see ",(0,r.jsx)(n.a,{href:"/genai/eval-monitor/scorers/llm-judge/custom-judges/#selecting-judge-models",children:"selecting judge models"}),"."]})]})}function o(e={}){let{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}},75689(e,n,t){t.d(n,{A:()=>i});var r=t(96540);let s=e=>{let n=e.replace(/^([A-Z])|[\s-_]+(\w)/g,(e,n,t)=>t?t.toUpperCase():n.toLowerCase());return n.charAt(0).toUpperCase()+n.slice(1)},a=(...e)=>e.filter((e,n,t)=>!!e&&""!==e.trim()&&t.indexOf(e)===n).join(" ").trim();var l={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};let o=(0,r.forwardRef)(({color:e="currentColor",size:n=24,strokeWidth:t=2,absoluteStrokeWidth:s,className:o="",children:i,iconNode:c,...d},u)=>(0,r.createElement)("svg",{ref:u,...l,width:n,height:n,stroke:e,strokeWidth:s?24*Number(t)/Number(n):t,className:a("lucide",o),...!i&&!(e=>{for(let n in e)if(n.startsWith("aria-")||"role"===n||"title"===n)return!0})(d)&&{"aria-hidden":"true"},...d},[...c.map(([e,n])=>(0,r.createElement)(e,n)),...Array.isArray(i)?i:[i]])),i=(e,n)=>{let t=(0,r.forwardRef)(({className:t,...l},i)=>(0,r.createElement)(o,{ref:i,iconNode:n,className:a(`lucide-${s(e).replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()}`,`lucide-${e}`,t),...l}));return t.displayName=s(e),t}},42640(e,n,t){t.d(n,{A:()=>r});let r=(0,t(75689).A)("bot",[["path",{d:"M12 8V4H8",key:"hb8ula"}],["rect",{width:"16",height:"12",x:"4",y:"8",rx:"2",key:"enze0r"}],["path",{d:"M2 14h2",key:"vft8re"}],["path",{d:"M20 14h2",key:"4cs60a"}],["path",{d:"M15 13v2",key:"1xurst"}],["path",{d:"M9 13v2",key:"rq6x2g"}]])},44471(e,n,t){t.d(n,{A:()=>r});let r=(0,t(75689).A)("circle-check-big",[["path",{d:"M21.801 10A10 10 0 1 1 17 3.335",key:"yps3ct"}],["path",{d:"m9 11 3 3L22 4",key:"1pflzl"}]])},51004(e,n,t){t.d(n,{A:()=>r});let r=(0,t(75689).A)("database",[["ellipse",{cx:"12",cy:"5",rx:"9",ry:"3",key:"msslwz"}],["path",{d:"M3 5V19A9 3 0 0 0 21 19V5",key:"1wlel7"}],["path",{d:"M3 12A9 3 0 0 0 21 12",key:"mv7ke4"}]])},57250(e,n,t){t.d(n,{A:()=>a});var r=t(74848);t(96540);var s=t(34164);function a({children:e,hidden:n,className:t}){return(0,r.jsx)("div",{role:"tabpanel",className:(0,s.A)("tabItem_Ymn6",t),hidden:n,children:e})}},78010(e,n,t){t.d(n,{A:()=>v});var r=t(74848),s=t(96540),a=t(34164),l=t(88287),o=t(28584),i=t(56347),c=t(99989),d=t(96629),u=t(80618),p=t(41367);function h(e){return s.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,s.isValidElement)(e)&&function(e){let{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function m({value:e,tabValues:n}){return n.some(n=>n.value===e)}var f=t(19863);function x({className:e,block:n,selectedValue:t,selectValue:s,tabValues:l}){let i=[],{blockElementScrollPositionUntilNextRender:c}=(0,o.a_)(),d=e=>{let n=e.currentTarget,r=l[i.indexOf(n)].value;r!==t&&(c(n),s(r))},u=e=>{let n=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{let t=i.indexOf(e.currentTarget)+1;n=i[t]??i[0];break}case"ArrowLeft":{let t=i.indexOf(e.currentTarget)-1;n=i[t]??i[i.length-1]}}n?.focus()};return(0,r.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,a.A)("tabs",{"tabs--block":n},e),children:l.map(({value:e,label:n,attributes:s})=>(0,r.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{i.push(e)},onKeyDown:u,onClick:d,...s,className:(0,a.A)("tabs__item","tabItem_LNqP",s?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function g({lazy:e,children:n,selectedValue:t}){let l=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){let e=l.find(e=>e.props.value===t);return e?(0,s.cloneElement)(e,{className:(0,a.A)("margin-top--md",e.props.className)}):null}return(0,r.jsx)("div",{className:"margin-top--md",children:l.map((e,n)=>(0,s.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function j(e){let n=function(e){let n,{defaultValue:t,queryString:r=!1,groupId:a}=e,l=function(e){let{values:n,children:t}=e;return(0,s.useMemo)(()=>{let e=n??h(t).map(({props:{value:e,label:n,attributes:t,default:r}})=>({value:e,label:n,attributes:t,default:r})),r=(0,u.XI)(e,(e,n)=>e.value===n.value);if(r.length>0)throw Error(`Docusaurus error: Duplicate values "${r.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`);return e},[n,t])}(e),[o,f]=(0,s.useState)(()=>(function({defaultValue:e,tabValues:n}){if(0===n.length)throw Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!m({value:e,tabValues:n}))throw Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}let t=n.find(e=>e.default)??n[0];if(!t)throw Error("Unexpected error: 0 tabValues");return t.value})({defaultValue:t,tabValues:l})),[x,g]=function({queryString:e=!1,groupId:n}){let t=(0,i.W6)(),r=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,d.aZ)(r),(0,s.useCallback)(e=>{if(!r)return;let n=new URLSearchParams(t.location.search);n.set(r,e),t.replace({...t.location,search:n.toString()})},[r,t])]}({queryString:r,groupId:a}),[j,v]=function({groupId:e}){let n=e?`docusaurus.tab.${e}`:null,[t,r]=(0,p.Dv)(n);return[t,(0,s.useCallback)(e=>{n&&r.set(e)},[n,r])]}({groupId:a}),w=m({value:n=x??j,tabValues:l})?n:null;return(0,c.A)(()=>{w&&f(w)},[w]),{selectedValue:o,selectValue:(0,s.useCallback)(e=>{if(!m({value:e,tabValues:l}))throw Error(`Can't select invalid tab value=${e}`);f(e),g(e),v(e)},[g,v,l]),tabValues:l}}(e);return(0,r.jsxs)("div",{className:(0,a.A)(l.G.tabs.container,"tabs-container","tabList__CuJ"),children:[(0,r.jsx)(x,{...n,...e}),(0,r.jsx)(g,{...n,...e})]})}function v(e){let n=(0,f.A)();return(0,r.jsx)(j,{...e,children:h(e.children)},String(n))}},95986(e,n,t){t.d(n,{A:()=>s});var r=t(74848);t(96540);function s({children:e}){return(0,r.jsx)("div",{className:"wrapper_sf5q",children:e})}},77541(e,n,t){t.d(n,{A:()=>c});var r=t(74848);t(96540);var s=t(95310),a=t(34164);let l="tileImage_O4So";var o=t(66497),i=t(92802);function c({icon:e,image:n,imageDark:t,imageWidth:c,imageHeight:d,iconSize:u=32,containerHeight:p,title:h,description:m,href:f,linkText:x="Learn more \u2192",className:g}){if(!e&&!n)throw Error("TileCard requires either an icon or image prop");let j=p?{height:`${p}px`}:{},v={};return c&&(v.width=`${c}px`),d&&(v.height=`${d}px`),(0,r.jsxs)(s.A,{href:f,className:(0,a.A)("tileCard_NHsj",g),children:[(0,r.jsx)("div",{className:"tileIcon_pyoR",style:j,children:e?(0,r.jsx)(e,{size:u}):t?(0,r.jsx)(i.A,{sources:{light:(0,o.default)(n),dark:(0,o.default)(t)},alt:h,className:l,style:v}):(0,r.jsx)("img",{src:(0,o.default)(n),alt:h,className:l,style:v})}),(0,r.jsx)("h3",{children:h}),(0,r.jsx)("p",{children:m}),(0,r.jsx)("div",{className:"tileLink_iUbu",children:x})]})}},10440(e,n,t){t.d(n,{A:()=>a});var r=t(74848);t(96540);var s=t(34164);function a({children:e,className:n}){return(0,r.jsx)("div",{className:(0,s.A)("tilesGrid_hB9N",n),children:e})}},28453(e,n,t){t.d(n,{R:()=>l,x:()=>o});var r=t(96540);let s={},a=r.createContext(s);function l(e){let n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);