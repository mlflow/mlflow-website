"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7779],{7715:(e,n,l)=>{l.r(n),l.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>h,frontMatter:()=>t,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"deep-learning/tensorflow/guide/index","title":"TensorFlow within MLflow","description":"TensorFlow is a powerful end-to-end open source platform for machine learning that has revolutionized how developers build and deploy ML solutions. With its comprehensive ecosystem of tools and libraries, TensorFlow empowers everyone from beginners to experts to create sophisticated models for diverse applications.","source":"@site/docs/classic-ml/deep-learning/tensorflow/guide/index.mdx","sourceDirName":"deep-learning/tensorflow/guide","slug":"/deep-learning/tensorflow/guide/","permalink":"/docs/latest/ml/deep-learning/tensorflow/guide/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"classicMLSidebar","previous":{"title":"Quickstart","permalink":"/docs/latest/ml/deep-learning/tensorflow/quickstart/quickstart-tensorflow"},"next":{"title":"MLflow Transformers Flavor","permalink":"/docs/latest/ml/deep-learning/transformers/"}}');var r=l(74848),i=l(28453),s=l(49374);const t={},a="TensorFlow within MLflow",d={},c=[{value:"Complete ML Ecosystem",id:"complete-ml-ecosystem",level:4},{value:"Powerful Core Features",id:"powerful-core-features",level:4},{value:"Why MLflow + TensorFlow?",id:"why-mlflow--tensorflow",level:2},{value:"Autologging TensorFlow Experiments",id:"autologging-tensorflow-experiments",level:2},{value:"Requirements",id:"requirements",level:4},{value:"Limitations",id:"limitations",level:4},{value:"What Gets Automatically Logged",id:"what-gets-automatically-logged",level:3},{value:"Model Information",id:"model-information",level:4},{value:"Training Parameters",id:"training-parameters",level:4},{value:"Optimizer Configuration",id:"optimizer-configuration",level:4},{value:"Dataset Information",id:"dataset-information",level:4},{value:"Training Metrics",id:"training-metrics",level:4},{value:"Artifacts",id:"artifacts",level:4},{value:"Logging to MLflow with Keras Callback",id:"logging-to-mlflow-with-keras-callback",level:2},{value:"Using the Predefined Callback",id:"using-the-predefined-callback",level:3},{value:"Customizing MLflow Logging",id:"customizing-mlflow-logging",level:3},{value:"Saving Your TensorFlow Model to MLflow",id:"saving-your-tensorflow-model-to-mlflow",level:2},{value:"Basic Model Saving",id:"basic-model-saving",level:3},{value:"Model Formats",id:"model-formats",level:3},{value:"TensorFlow SavedModel (Default)",id:"tensorflow-savedmodel-default",level:4},{value:"H5 Format",id:"h5-format",level:4},{value:"Keras Format",id:"keras-format",level:4},{value:"Model Signatures",id:"model-signatures",level:3},{value:"Advanced TensorFlow Integration",id:"advanced-tensorflow-integration",level:2},{value:"Complex Model Tracking",id:"complex-model-tracking",level:3},{value:"Hyperparameter Optimization",id:"hyperparameter-optimization",level:3},{value:"Deployment Preparation",id:"deployment-preparation",level:3},{value:"Real-World Applications",id:"real-world-applications",level:2},{value:"Conclusion",id:"conclusion",level:2}];function m(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components},{Details:o}=n;return o||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"tensorflow-within-mlflow",children:"TensorFlow within MLflow"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"TensorFlow"})," is a powerful end-to-end open source platform for machine learning that has revolutionized how developers build and deploy ML solutions. With its comprehensive ecosystem of tools and libraries, TensorFlow empowers everyone from beginners to experts to create sophisticated models for diverse applications."]}),"\n",(0,r.jsx)(n.p,{children:"TensorFlow's Keras API provides an intuitive interface for building and training deep learning models, while its powerful backend enables efficient computation on CPUs, GPUs, and TPUs."}),"\n",(0,r.jsxs)(o,{children:[(0,r.jsx)("summary",{children:"Why TensorFlow Leads the Industry"}),(0,r.jsx)(n.h4,{id:"complete-ml-ecosystem",children:"Complete ML Ecosystem"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\ud83c\udfd7\ufe0f ",(0,r.jsx)(n.strong,{children:"Production-Ready"}),": End-to-end platform from experimentation to deployment"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udcf1 ",(0,r.jsx)(n.strong,{children:"Multi-Platform Deployment"}),": Run models on browsers, mobile devices, edge hardware, and servers"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udd2c ",(0,r.jsx)(n.strong,{children:"Research Flexibility"}),": High-level and low-level APIs for both beginners and experts"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udcca ",(0,r.jsx)(n.strong,{children:"TensorBoard Integration"}),": Rich visualization of model architecture and training metrics"]}),"\n"]}),(0,r.jsx)(n.h4,{id:"powerful-core-features",children:"Powerful Core Features"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u26a1 ",(0,r.jsx)(n.strong,{children:"Graph Execution"}),": Optimized execution for maximum performance"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udd04 ",(0,r.jsx)(n.strong,{children:"Eager Execution"}),": Immediate evaluation for intuitive debugging"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83e\udde9 ",(0,r.jsx)(n.strong,{children:"Modular Design"}),": Customize any part of your ML pipeline"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83c\udf10 ",(0,r.jsx)(n.strong,{children:"Global Community"}),": Extensive resources, tutorials, and pre-trained models"]}),"\n"]})]}),"\n",(0,r.jsx)(n.h2,{id:"why-mlflow--tensorflow",children:"Why MLflow + TensorFlow?"}),"\n",(0,r.jsx)(n.p,{children:"The integration of MLflow with TensorFlow creates a powerful workflow for machine learning practitioners:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\ud83d\udcca ",(0,r.jsx)(n.strong,{children:"One-Line Autologging"}),": Enable comprehensive tracking with just ",(0,r.jsx)(n.code,{children:"mlflow.tensorflow.autolog()"})]}),"\n",(0,r.jsxs)(n.li,{children:["\u2699\ufe0f ",(0,r.jsx)(n.strong,{children:"Zero-Code Integration"}),": Your existing TensorFlow training code works unchanged"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udd04 ",(0,r.jsx)(n.strong,{children:"Complete Reproducibility"}),": Every parameter, metric, and model is captured automatically"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udcc8 ",(0,r.jsx)(n.strong,{children:"Training Visualization"}),": Monitor performance through the MLflow UI"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udc65 ",(0,r.jsx)(n.strong,{children:"Collaborative Development"}),": Share experiments and results with team members"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\ude80 ",(0,r.jsx)(n.strong,{children:"Streamlined Deployment"}),": Package models for deployment across different environments"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"autologging-tensorflow-experiments",children:"Autologging TensorFlow Experiments"}),"\n",(0,r.jsxs)(n.p,{children:["MLflow can automatically log metrics, parameters, and models from your TensorFlow training runs. Simply call ",(0,r.jsx)(s.B,{fn:"mlflow.tensorflow.autolog"})," or ",(0,r.jsx)(s.B,{fn:"mlflow.autolog"})," before your training code:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import mlflow\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Enable autologging\nmlflow.tensorflow.autolog()\n\n# Prepare sample data\ndata = np.random.uniform(size=[20, 28, 28, 3])\nlabel = np.random.randint(2, size=20)\n\n# Define model\nmodel = keras.Sequential(\n    [\n        keras.Input([28, 28, 3]),\n        keras.layers.Conv2D(8, 2),\n        keras.layers.MaxPool2D(2),\n        keras.layers.Flatten(),\n        keras.layers.Dense(2),\n        keras.layers.Softmax(),\n    ]\n)\n\nmodel.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(),\n    optimizer=keras.optimizers.Adam(0.001),\n    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)\n\n# Training with automatic logging\nwith mlflow.start_run():\n    model.fit(data, label, batch_size=5, epochs=2)\n"})}),"\n",(0,r.jsxs)(o,{children:[(0,r.jsx)("summary",{children:"Autologging Requirements and Limitations"}),(0,r.jsx)(n.h4,{id:"requirements",children:"Requirements"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"TensorFlow Version"}),": Only TensorFlow >= 2.3.0 is supported"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Training API"}),": Must use the ",(0,r.jsx)(n.code,{children:"model.fit()"})," Keras API"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Run Context"}),": Works both with and without an active MLflow run"]}),"\n"]}),(0,r.jsx)(n.h4,{id:"limitations",children:"Limitations"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u274c ",(0,r.jsx)(n.strong,{children:"Custom Training Loops"}),": Not supported (use manual logging instead)"]}),"\n",(0,r.jsxs)(n.li,{children:["\u274c ",(0,r.jsx)(n.strong,{children:"Older TensorFlow Versions"}),": Not supported (use manual logging instead)"]}),"\n",(0,r.jsxs)(n.li,{children:["\u274c ",(0,r.jsx)(n.strong,{children:"Non-Keras TensorFlow"}),": Not supported (use manual logging instead)"]}),"\n"]}),(0,r.jsx)(n.admonition,{title:"attention",type:"warning",children:(0,r.jsxs)(n.p,{children:["Autologging is only supported when you are using the ",(0,r.jsx)(n.code,{children:"model.fit()"})," Keras API to train\nthe model. Additionally, only TensorFlow >= 2.3.0 is supported. If you are using an older version\nof TensorFlow or TensorFlow without Keras, please use manual logging."]})})]}),"\n",(0,r.jsx)(n.h3,{id:"what-gets-automatically-logged",children:"What Gets Automatically Logged"}),"\n",(0,r.jsxs)(o,{children:[(0,r.jsx)("summary",{children:"Comprehensive Autologging Details"}),(0,r.jsx)(n.h4,{id:"model-information",children:"Model Information"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\ud83d\udccb ",(0,r.jsx)(n.strong,{children:"Model Summary"}),": Complete architecture overview as returned by ",(0,r.jsx)(n.code,{children:"model.summary()"})]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83e\udde9 ",(0,r.jsx)(n.strong,{children:"Layer Configuration"}),": Details of each layer in the model"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udcd0 ",(0,r.jsx)(n.strong,{children:"Parameter Count"}),": Total number of trainable and non-trainable parameters"]}),"\n"]}),(0,r.jsx)(n.h4,{id:"training-parameters",children:"Training Parameters"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u2699\ufe0f ",(0,r.jsx)(n.strong,{children:"Batch Size"}),": Number of samples per gradient update"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udd22 ",(0,r.jsx)(n.strong,{children:"Epochs"}),": Number of complete passes through the training dataset"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83e\uddee ",(0,r.jsx)(n.strong,{children:"Steps Per Epoch"}),": Number of batch iterations per epoch"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udccf ",(0,r.jsx)(n.strong,{children:"Validation Steps"}),": Number of batch iterations for validation"]}),"\n"]}),(0,r.jsx)(n.h4,{id:"optimizer-configuration",children:"Optimizer Configuration"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\ud83e\udde0 ",(0,r.jsx)(n.strong,{children:"Optimizer Name"}),": Type of optimizer used (Adam, SGD, etc.)"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udcc9 ",(0,r.jsx)(n.strong,{children:"Learning Rate"}),": Step size for gradient updates"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83c\udfaf ",(0,r.jsx)(n.strong,{children:"Epsilon"}),": Small constant for numerical stability"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udd04 ",(0,r.jsx)(n.strong,{children:"Other Optimizer Parameters"}),": Beta values, momentum, etc."]}),"\n"]}),(0,r.jsx)(n.h4,{id:"dataset-information",children:"Dataset Information"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\ud83d\udcca ",(0,r.jsx)(n.strong,{children:"Dataset Shape"}),": Input and output dimensions"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udd22 ",(0,r.jsx)(n.strong,{children:"Sample Count"}),": Number of training and validation samples"]}),"\n"]}),(0,r.jsx)(n.h4,{id:"training-metrics",children:"Training Metrics"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\ud83d\udcc9 ",(0,r.jsx)(n.strong,{children:"Training Loss"}),": Loss value for each epoch"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udcc8 ",(0,r.jsx)(n.strong,{children:"Validation Loss"}),": Loss on validation data"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83c\udfaf ",(0,r.jsx)(n.strong,{children:"Custom Metrics"}),": Any metrics specified in ",(0,r.jsx)(n.code,{children:"model.compile()"})]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udd04 ",(0,r.jsx)(n.strong,{children:"Early Stopping Metrics"}),": ",(0,r.jsx)(n.code,{children:"stopped_epoch"}),", ",(0,r.jsx)(n.code,{children:"restored_epoch"}),", etc."]}),"\n"]}),(0,r.jsx)(n.h4,{id:"artifacts",children:"Artifacts"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\ud83e\udd16 ",(0,r.jsx)(n.strong,{children:"Saved Model"}),": Complete model in TensorFlow SavedModel format"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udcca ",(0,r.jsx)(n.strong,{children:"TensorBoard Logs"}),": Training and validation metrics"]}),"\n"]})]}),"\n",(0,r.jsxs)(n.p,{children:["You can customize autologging behavior by passing arguments to ",(0,r.jsx)(s.B,{fn:"mlflow.tensorflow.autolog"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"mlflow.tensorflow.autolog(\n    log_models=True,\n    log_input_examples=True,\n    log_model_signatures=True,\n    log_dataset_info=True,\n    log_every_n_steps=1,\n)\n"})}),"\n",(0,r.jsxs)(o,{children:[(0,r.jsx)("summary",{children:"How TensorFlow Autologging Works"}),(0,r.jsx)(n.p,{children:"MLflow's TensorFlow autologging uses a custom Keras callback attached to your model via monkey patching. This callback:"}),(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Captures Initial State"}),": At training start, logs model architecture, hyperparameters, and optimizer settings"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Monitors Training"}),": Tracks metrics at each epoch or at specified intervals"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Records Completion"}),": Saves the final trained model when training completes"]}),"\n"]}),(0,r.jsx)(n.p,{children:"This approach integrates seamlessly with TensorFlow's existing callback system, ensuring compatibility with your other callbacks like early stopping or learning rate scheduling."})]}),"\n",(0,r.jsx)(n.h2,{id:"logging-to-mlflow-with-keras-callback",children:"Logging to MLflow with Keras Callback"}),"\n",(0,r.jsx)(n.p,{children:"For more control over what gets logged, you can use MLflow's built-in Keras callback or create your own custom callback."}),"\n",(0,r.jsx)(n.h3,{id:"using-the-predefined-callback",children:"Using the Predefined Callback"}),"\n",(0,r.jsxs)(n.p,{children:["MLflow provides ",(0,r.jsx)(s.B,{fn:"mlflow.tensorflow.MlflowCallback",children:(0,r.jsx)(n.code,{children:"mlflow.tensorflow.MlflowCallback"})})," that offers the same functionality as autologging but with more explicit control:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import mlflow\nfrom tensorflow import keras\n\n# Define and compile your model\nmodel = keras.Sequential([...])\nmodel.compile(...)\n\n# Create an MLflow run and add the callback\nwith mlflow.start_run() as run:\n    model.fit(\n        data,\n        labels,\n        batch_size=32,\n        epochs=10,\n        callbacks=[mlflow.tensorflow.MlflowCallback(run)],\n    )\n"})}),"\n",(0,r.jsxs)(o,{children:[(0,r.jsx)("summary",{children:"Callback Configuration Options"}),(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"MlflowCallback"})," accepts several parameters to customize logging behavior:"]}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"mlflow.tensorflow.MlflowCallback(\n    run=None,  # MLflow run object (current run used if None)\n    log_models=True,  # Whether to log models\n    log_every_epoch=True,  # Log metrics at the end of each epoch\n    log_every_n_steps=None,  # Log metrics every N steps (overrides log_every_epoch)\n)\n"})}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Epoch-based Logging"}),": Set ",(0,r.jsx)(n.code,{children:"log_every_epoch=True"})," (default) to log at the end of each epoch"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Batch-based Logging"}),": Set ",(0,r.jsx)(n.code,{children:"log_every_n_steps=N"})," to log every N batches"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Selective Model Logging"}),": Set ",(0,r.jsx)(n.code,{children:"log_models=False"})," to disable model saving"]}),"\n"]})]}),"\n",(0,r.jsx)(n.h3,{id:"customizing-mlflow-logging",children:"Customizing MLflow Logging"}),"\n",(0,r.jsxs)(n.p,{children:["You can create your own callback by subclassing ",(0,r.jsx)(n.code,{children:"keras.callbacks.Callback"})," to implement custom logging logic:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from tensorflow import keras\nimport math\nimport mlflow\n\n\nclass CustomMlflowCallback(keras.callbacks.Callback):\n    def on_epoch_begin(self, epoch, logs=None):\n        mlflow.log_metric("current_epoch", epoch)\n\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        # Log metrics in log scale\n        for k, v in logs.items():\n            if v > 0:  # Avoid log(0) or log(negative)\n                mlflow.log_metric(f"log_{k}", math.log(v), step=epoch)\n            mlflow.log_metric(k, v, step=epoch)\n\n    def on_train_end(self, logs=None):\n        # Log final model weights statistics\n        weights = self.model.get_weights()\n        mlflow.log_metric("total_parameters", sum(w.size for w in weights))\n        mlflow.log_metric(\n            "average_weight",\n            sum(w.sum() for w in weights) / sum(w.size for w in weights),\n        )\n'})}),"\n",(0,r.jsxs)(o,{children:[(0,r.jsx)("summary",{children:"Keras Callback Lifecycle Hooks"}),(0,r.jsx)(n.p,{children:"Keras callbacks provide various hooks into the training process:"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Training Setup"}),": ",(0,r.jsx)(n.code,{children:"on_train_begin"}),", ",(0,r.jsx)(n.code,{children:"on_train_end"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Epoch Progress"}),": ",(0,r.jsx)(n.code,{children:"on_epoch_begin"}),", ",(0,r.jsx)(n.code,{children:"on_epoch_end"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Batch Progress"}),": ",(0,r.jsx)(n.code,{children:"on_batch_begin"}),", ",(0,r.jsx)(n.code,{children:"on_batch_end"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Validation"}),": ",(0,r.jsx)(n.code,{children:"on_test_begin"}),", ",(0,r.jsx)(n.code,{children:"on_test_end"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Prediction"}),": ",(0,r.jsx)(n.code,{children:"on_predict_begin"}),", ",(0,r.jsx)(n.code,{children:"on_predict_end"})]}),"\n"]}),(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"logs"})," dictionary passed to these methods contains metrics like:"]}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"loss"}),": Training loss"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"val_loss"}),": Validation loss"]}),"\n",(0,r.jsxs)(n.li,{children:["Any custom metrics defined in ",(0,r.jsx)(n.code,{children:"model.compile()"})]}),"\n"]}),(0,r.jsxs)(n.p,{children:["For full documentation, see ",(0,r.jsx)(n.a,{href:"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback",children:"keras.callbacks.Callback"}),"."]})]}),"\n",(0,r.jsx)(n.h2,{id:"saving-your-tensorflow-model-to-mlflow",children:"Saving Your TensorFlow Model to MLflow"}),"\n",(0,r.jsx)(n.h3,{id:"basic-model-saving",children:"Basic Model Saving"}),"\n",(0,r.jsxs)(n.p,{children:["If you haven't enabled autologging (which saves models automatically), you can manually save your TensorFlow model using ",(0,r.jsx)(s.B,{fn:"mlflow.tensorflow.log_model"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Define model\nmodel = keras.Sequential(\n    [\n        keras.Input([28, 28, 3]),\n        keras.layers.Conv2D(8, 2),\n        keras.layers.MaxPool2D(2),\n        keras.layers.Flatten(),\n        keras.layers.Dense(2),\n        keras.layers.Softmax(),\n    ]\n)\n\n# Train model (code omitted for brevity)\n\n# Log the model to MLflow\nmodel_info = mlflow.tensorflow.log_model(model, name="model")\n\n# Later, load the model for inference\nloaded_model = mlflow.tensorflow.load_model(model_info.model_uri)\npredictions = loaded_model.predict(tf.random.uniform([1, 28, 28, 3]))\n'})}),"\n",(0,r.jsxs)(o,{children:[(0,r.jsx)("summary",{children:"Understanding MLflow Model Saving"}),(0,r.jsx)(n.p,{children:"When you save a TensorFlow model with MLflow:"}),(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Format Conversion"}),": The model is converted to a generic MLflow ",(0,r.jsx)(n.code,{children:"pyfunc"})," model to support deployment, loaded via ",(0,r.jsx)(n.code,{children:"mlflow.pyfunc.load_model()"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Preservation of Original Format"}),": The model is still capable of being loaded as a native TensorFlow object via ",(0,r.jsx)(n.code,{children:"mlflow.tensorflow.load_model()"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Metadata Creation"}),": Model metadata is stored, including dependencies and signature"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Artifact Storage"}),": The model is saved to the MLflow artifact store"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Loading Capability"}),": The model can be loaded back as either a native TensorFlow model or a generic ",(0,r.jsx)(n.code,{children:"pyfunc"})," model"]}),"\n"]}),(0,r.jsx)(n.p,{children:"This approach enables consistent model management regardless of the framework used."})]}),"\n",(0,r.jsx)(n.h3,{id:"model-formats",children:"Model Formats"}),"\n",(0,r.jsx)(n.p,{children:"By default, MLflow saves TensorFlow models in the TensorFlow SavedModel format (compiled graph), which is ideal for deployment. You can also save in other formats:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Save in H5 format (weights only)\nmlflow.tensorflow.log_model(\n    model, name="model", keras_model_kwargs={"save_format": "h5"}\n)\n\n# Save in native Keras format\nmlflow.tensorflow.log_model(\n    model, name="model", keras_model_kwargs={"save_format": "keras"}\n)\n'})}),"\n",(0,r.jsxs)(o,{children:[(0,r.jsx)("summary",{children:"Comparing Model Formats"}),(0,r.jsx)(n.h4,{id:"tensorflow-savedmodel-default",children:"TensorFlow SavedModel (Default)"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Complete Serialization"}),": Includes model architecture, weights, and compilation information"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Deployment Ready"}),": Optimized for production environments"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"TensorFlow Serving"}),": Compatible with TensorFlow Serving"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Cross-Platform"}),": Can be deployed across different platforms"]}),"\n"]}),(0,r.jsx)(n.h4,{id:"h5-format",children:"H5 Format"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Weights Storage"}),": Efficiently stores model weights"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Smaller Size"}),": Generally smaller than SavedModel format"]}),"\n",(0,r.jsxs)(n.li,{children:["\u274c ",(0,r.jsx)(n.strong,{children:"Limited Information"}),": Doesn't include the full computation graph"]}),"\n",(0,r.jsxs)(n.li,{children:["\u274c ",(0,r.jsx)(n.strong,{children:"Deployment Limitations"}),": Not ideal for certain deployment scenarios"]}),"\n"]}),(0,r.jsx)(n.h4,{id:"keras-format",children:"Keras Format"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Native Keras"}),": Uses Keras' native serialization"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Compatibility"}),": Works well with newer Keras versions"]}),"\n",(0,r.jsxs)(n.li,{children:["\u274c ",(0,r.jsx)(n.strong,{children:"Deployment"}),": May require additional steps for deployment"]}),"\n"]}),(0,r.jsxs)(n.p,{children:["For most production use cases, the default SavedModel format is recommended. For more details, see ",(0,r.jsx)(n.a,{href:"https://www.tensorflow.org/guide/keras/save_and_serialize",children:"TensorFlow Save and Load Guide"}),"."]})]}),"\n",(0,r.jsx)(n.h3,{id:"model-signatures",children:"Model Signatures"}),"\n",(0,r.jsx)(n.p,{children:"A model signature describes the expected input and output formats of your model. While optional, it's a best practice for better model understanding and validation. The easiest way to add a signature is using automatic inference:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom mlflow.models import infer_signature\nimport tensorflow as tf\nimport numpy as np\n\n# Sample input data\nsample_input = np.random.uniform(size=[2, 28, 28, 3])\n\n# Get predictions\nsample_output = model.predict(sample_input)\n\n# Infer signature from data\nsignature = infer_signature(sample_input, sample_output)\n\n# Log model with inferred signature\nmodel_info = mlflow.tensorflow.log_model(model, name="model", signature=signature)\n'})}),"\n",(0,r.jsxs)(n.p,{children:["When autologging is enabled with ",(0,r.jsx)(n.code,{children:"log_input_examples=True"})," and ",(0,r.jsx)(n.code,{children:"log_model_signatures=True"}),", MLflow automatically infers and logs the signature from your training data."]}),"\n",(0,r.jsx)(n.p,{children:"The signature appears in the MLflow UI:"}),"\n",(0,r.jsx)("div",{className:"center-div",style:{width:"90%"},children:(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"TensorFlow Model Signature",src:l(18700).A+"",width:"3410",height:"1604"})})}),"\n",(0,r.jsxs)(o,{children:[(0,r.jsx)("summary",{children:"Manual Signature Definition"}),(0,r.jsx)(n.p,{children:"For complete control over your model signature, you can manually define the input and output schemas:"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow import keras\nfrom mlflow.types import Schema, TensorSpec\nfrom mlflow.models import ModelSignature\n\n# Define model\nmodel = keras.Sequential(\n    [\n        keras.Input([28, 28, 3]),\n        keras.layers.Conv2D(8, 2),\n        keras.layers.MaxPool2D(2),\n        keras.layers.Flatten(),\n        keras.layers.Dense(2),\n        keras.layers.Softmax(),\n    ]\n)\n\n# Define input schema\ninput_schema = Schema(\n    [\n        TensorSpec(np.dtype(np.float32), (-1, 28, 28, 3), "input"),\n    ]\n)\n\n# Create signature with input schema\nsignature = ModelSignature(inputs=input_schema)\n\n# Log model with signature\nmodel_info = mlflow.tensorflow.log_model(model, name="model", signature=signature)\n'})}),(0,r.jsx)(n.p,{children:"Manual definition is useful when:"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"You need precise control over tensor specifications"}),"\n",(0,r.jsx)(n.li,{children:"Working with complex input/output structures"}),"\n",(0,r.jsx)(n.li,{children:"The automatic inference doesn't capture your intended schema"}),"\n",(0,r.jsx)(n.li,{children:"You want to specify exact data types and shapes upfront"}),"\n"]})]}),"\n",(0,r.jsx)(n.h2,{id:"advanced-tensorflow-integration",children:"Advanced TensorFlow Integration"}),"\n",(0,r.jsx)(n.h3,{id:"complex-model-tracking",children:"Complex Model Tracking"}),"\n",(0,r.jsx)(n.p,{children:"For more sophisticated models, you might want to track additional information:"}),"\n",(0,r.jsxs)(o,{children:[(0,r.jsx)("summary",{children:"Tracking Transfer Learning"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n# Load pre-trained model\nbase_model = tf.keras.applications.MobileNetV2(\n    input_shape=(224, 224, 3), include_top=False, weights="imagenet"\n)\n\n# Freeze base model\nbase_model.trainable = False\n\n# Create new model head\ninputs = tf.keras.Input(shape=(224, 224, 3))\nx = base_model(inputs, training=False)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dense(256, activation="relu")(x)\noutputs = tf.keras.layers.Dense(10, activation="softmax")(x)\nmodel = tf.keras.Model(inputs, outputs)\n\nwith mlflow.start_run() as run:\n    # Log base model information\n    mlflow.log_param("base_model", "MobileNetV2")\n    mlflow.log_param("base_model_trainable", False)\n    mlflow.log_param("new_layers", "GlobalAveragePooling2D, Dense(256), Dense(10)")\n\n    # Log base model summary\n    with open("base_model_summary.txt", "w") as f:\n        base_model.summary(print_fn=lambda x: f.write(x + "\\n"))\n    mlflow.log_artifact("base_model_summary.txt")\n\n    # Log model visualization\n    tf.keras.utils.plot_model(model, to_file="model_architecture.png", show_shapes=True)\n    mlflow.log_artifact("model_architecture.png")\n\n    # Continue with normal training...\n'})})]}),"\n",(0,r.jsxs)(o,{children:[(0,r.jsx)("summary",{children:"Tracking Multi-Model Experiments"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import mlflow\n\n# Main experiment run\nwith mlflow.start_run(run_name="ensemble_experiment") as parent_run:\n    mlflow.log_param("experiment_type", "ensemble")\n\n    # Train first model\n    with mlflow.start_run(run_name="model_1", nested=True) as child_run_1:\n        model_1 = create_model_1()\n        # Train model_1\n        mlflow.tensorflow.log_model(model_1, name="model_1")\n        mlflow.log_metric("accuracy", accuracy_1)\n\n    # Train second model\n    with mlflow.start_run(run_name="model_2", nested=True) as child_run_2:\n        model_2 = create_model_2()\n        # Train model_2\n        mlflow.tensorflow.log_model(model_2, name="model_2")\n        mlflow.log_metric("accuracy", accuracy_2)\n\n    # Create and log ensemble model\n    ensemble_model = create_ensemble([model_1, model_2])\n    mlflow.tensorflow.log_model(ensemble_model, name="ensemble_model")\n    mlflow.log_metric("ensemble_accuracy", ensemble_accuracy)\n'})})]}),"\n",(0,r.jsx)(n.h3,{id:"hyperparameter-optimization",children:"Hyperparameter Optimization"}),"\n",(0,r.jsx)(n.p,{children:"Combine TensorFlow with hyperparameter tuning tools while tracking everything in MLflow:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport tensorflow as tf\nfrom tensorflow import keras\nimport optuna\n\n\ndef create_model(trial):\n    # Define hyperparameters to tune\n    learning_rate = trial.suggest_float("learning_rate", 1e-5, 1e-1, log=True)\n    units = trial.suggest_int("units", 32, 512)\n    dropout = trial.suggest_float("dropout", 0.1, 0.5)\n\n    # Create model with suggested hyperparameters\n    model = keras.Sequential(\n        [\n            keras.layers.Input(shape=(28, 28, 3)),\n            keras.layers.Flatten(),\n            keras.layers.Dense(units, activation="relu"),\n            keras.layers.Dropout(dropout),\n            keras.layers.Dense(10, activation="softmax"),\n        ]\n    )\n\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n        loss="sparse_categorical_crossentropy",\n        metrics=["accuracy"],\n    )\n\n    return model\n\n\ndef objective(trial):\n    # Start nested run for this trial\n    with mlflow.start_run(nested=True):\n        # Log hyperparameters\n        params = {\n            "learning_rate": trial.params["learning_rate"],\n            "units": trial.params["units"],\n            "dropout": trial.params["dropout"],\n        }\n        mlflow.log_params(params)\n\n        # Create and train model\n        model = create_model(trial)\n        history = model.fit(\n            x_train, y_train, validation_data=(x_val, y_val), epochs=5, verbose=0\n        )\n\n        # Get validation accuracy\n        val_accuracy = max(history.history["val_accuracy"])\n        mlflow.log_metric("val_accuracy", val_accuracy)\n\n        # Log model\n        mlflow.tensorflow.log_model(model, name="model")\n\n        return val_accuracy\n\n\n# Main experiment run\nwith mlflow.start_run(run_name="hyperparameter_optimization"):\n    # Log study parameters\n    mlflow.log_params(\n        {\n            "optimization_framework": "optuna",\n            "n_trials": 20,\n            "direction": "maximize",\n            "metric": "val_accuracy",\n        }\n    )\n\n    # Create and run study\n    study = optuna.create_study(direction="maximize")\n    study.optimize(objective, n_trials=20)\n\n    # Log best parameters and score\n    mlflow.log_params({f"best_{k}": v for k, v in study.best_params.items()})\n    mlflow.log_metric("best_val_accuracy", study.best_value)\n\n    # Train final model with best parameters\n    final_model = create_model(study.best_trial)\n    final_model.fit(x_train, y_train, epochs=10)\n    mlflow.tensorflow.log_model(final_model, name="best_model")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"deployment-preparation",children:"Deployment Preparation"}),"\n",(0,r.jsx)(n.p,{children:"Once you've trained and logged your TensorFlow model with MLflow, deploying it locally is straightforward with a single command using the MLflow CLI:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"mlflow models serve -m models:/<model_id> -p 5000\n"})}),"\n",(0,r.jsx)(n.p,{children:"Test your deployed model:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import requests\nimport json\n\n# Prepare test data\ntest_data = {"inputs": sample_input.numpy().tolist()}\n\n# Make prediction request\nresponse = requests.post(\n    "http://localhost:5000/invocations",\n    data=json.dumps(test_data),\n    headers={"Content-Type": "application/json"},\n)\n\npredictions = response.json()\nprint("Predictions:", predictions)\n'})}),"\n",(0,r.jsxs)(o,{children:[(0,r.jsx)("summary",{children:"Advanced Deployment Options"}),(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"mlflow models serve"})," command supports several options for customization:"]}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Specify environment manager\nmlflow models serve -m models:/<model_id> -p 5000 --env-manager conda\n\n# Enable MLServer for enhanced inference capabilities\nmlflow models serve -m models:/<model_id> -p 5000 --enable-mlserver\n\n# Set custom host\nmlflow models serve -m models:/<model_id> -p 5000 --host 0.0.0.0\n"})}),(0,r.jsx)(n.p,{children:"For production deployments, consider:"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Using MLServer (",(0,r.jsx)(n.code,{children:"--enable-mlserver"}),") for better performance and additional features"]}),"\n",(0,r.jsxs)(n.li,{children:["Building Docker images with ",(0,r.jsx)(n.code,{children:"mlflow models build-docker"})]}),"\n",(0,r.jsx)(n.li,{children:"Deploying to cloud platforms like Azure ML or Amazon SageMaker"}),"\n",(0,r.jsx)(n.li,{children:"Setting up proper environment management and dependency isolation"}),"\n"]})]}),"\n",(0,r.jsx)(n.h2,{id:"real-world-applications",children:"Real-World Applications"}),"\n",(0,r.jsx)(n.p,{children:"The MLflow-TensorFlow integration excels in scenarios such as:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\ud83d\uddbc\ufe0f ",(0,r.jsx)(n.strong,{children:"Computer Vision"}),": Track CNN architectures, data augmentation strategies, and training dynamics for image classification, object detection, and segmentation"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udcdd ",(0,r.jsx)(n.strong,{children:"Natural Language Processing"}),": Monitor transformer models, embeddings, and fine-tuning for language understanding, translation, and generation"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udcca ",(0,r.jsx)(n.strong,{children:"Time Series Analysis"}),": Log RNN and LSTM models for forecasting, anomaly detection, and sequence prediction"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83c\udfed ",(0,r.jsx)(n.strong,{children:"Production ML Systems"}),": Version models from development to deployment with complete lineage tracking"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83c\udf93 ",(0,r.jsx)(n.strong,{children:"Educational Projects"}),": Document learning progression from simple to complex models"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83e\uddea ",(0,r.jsx)(n.strong,{children:"Experimental Research"}),": Compare novel architectures and training techniques with established baselines"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,r.jsx)(n.p,{children:"The MLflow-TensorFlow integration provides a comprehensive solution for tracking, managing, and deploying machine learning experiments. By combining TensorFlow's powerful computation capabilities with MLflow's experiment tracking, you create a workflow that is:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\ud83d\udd0d ",(0,r.jsx)(n.strong,{children:"Transparent"}),": Every aspect of model training is documented"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udd04 ",(0,r.jsx)(n.strong,{children:"Reproducible"}),": Experiments can be recreated exactly"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udcca ",(0,r.jsx)(n.strong,{children:"Comparable"}),": Different approaches can be evaluated side-by-side"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udcc8 ",(0,r.jsx)(n.strong,{children:"Scalable"}),": From simple prototypes to complex production models"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udc65 ",(0,r.jsx)(n.strong,{children:"Collaborative"}),": Team members can share and build upon each other's work"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Whether you're a researcher exploring new model architectures or an engineer deploying models to production, the MLflow-TensorFlow integration provides the foundation for organized, reproducible, and scalable machine learning development."})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(m,{...e})}):m(e)}},18700:(e,n,l)=>{l.d(n,{A:()=>o});const o=l.p+"assets/images/tensorflow-model-signature-b99a17dca0d6d45fc0e0663f41824bf1.png"},28453:(e,n,l)=>{l.d(n,{R:()=>s,x:()=>t});var o=l(96540);const r={},i=o.createContext(r);function s(e){const n=o.useContext(i);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),o.createElement(i.Provider,{value:n},e.children)}},49374:(e,n,l)=>{l.d(n,{B:()=>a});l(96540);const o=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var r=l(86025),i=l(28774),s=l(74848);const t=e=>{const n=e.split(".");for(let l=n.length;l>0;l--){const e=n.slice(0,l).join(".");if(o[e])return e}return null};function a({fn:e,children:n}){const l=t(e);if(!l)return(0,s.jsx)(s.Fragment,{children:n});const a=(0,r.Ay)(`/${o[l]}#${e}`);return(0,s.jsx)(i.A,{to:a,target:"_blank",children:n??(0,s.jsxs)("code",{children:[e,"()"]})})}}}]);