"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[3318],{799:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>m,contentTitle:()=>d,default:()=>w,frontMatter:()=>h,metadata:()=>a,toc:()=>u});const a=JSON.parse('{"id":"tracing/quickstart/typescript-openai","title":"Tracing Quickstart (TS/JS)","description":"The Python quickstart is available here.","source":"@site/docs/genai/tracing/quickstart/typescript-openai.mdx","sourceDirName":"tracing/quickstart","slug":"/tracing/quickstart/typescript-openai","permalink":"/mlflow-website/docs/latest/genai/tracing/quickstart/typescript-openai","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"genAISidebar","previous":{"title":"Getting Started (Python)","permalink":"/mlflow-website/docs/latest/genai/tracing/quickstart/python-openai"},"next":{"title":"Instrument Your App with MLflow Tracing","permalink":"/mlflow-website/docs/latest/genai/tracing/app-instrumentation/"}}');var r=n(74848),l=n(28453),o=n(11470),i=n(19365),s=(n(49374),n(66927)),c=n(47020),p=n(51307);const h={},d="Tracing Quickstart (TS/JS)",m={},u=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Step 1: Set up your environment",id:"step-1-set-up-your-environment",level:2},{value:"Connect to MLflow",id:"connect-to-mlflow",level:3},...p.RM,{value:"Create a new MLflow Experiment",id:"create-a-new-mlflow-experiment",level:3},{value:"Initialize the Tracing SDK",id:"initialize-the-tracing-sdk",level:3},{value:"Set OpenAI API Key (or other LLM providers)",id:"set-openai-api-key-or-other-llm-providers",level:3},{value:"Step 2: Trace a single LLM call",id:"step-2-trace-a-single-llm-call",level:2},{value:"Step 3: Trace a tool calling agent",id:"step-3-trace-a-tool-calling-agent",level:2},{value:"Step 4: Explore Traces in the UI",id:"step-4-explore-traces-in-the-ui",level:2},{value:"Step 5: Attach Feedbacks on Traces",id:"step-5-attach-feedbacks-on-traces",level:2},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2}];function f(e){const t={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components},{Details:n}=t;return n||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"tracing-quickstart-tsjs",children:"Tracing Quickstart (TS/JS)"})}),"\n",(0,r.jsx)(t.admonition,{type:"info",children:(0,r.jsxs)(t.p,{children:["The Python quickstart is available ",(0,r.jsx)("ins",{children:(0,r.jsx)(t.a,{href:"/genai/tracing/quickstart/python-openai",children:"here"})}),"."]})}),"\n",(0,r.jsx)(t.p,{children:"This quickstart guide will walk you through setting up a simple GenAI application with MLflow Tracing. In less than 10 minutes, you'll enable tracing, run a basic application, and explore the generated traces in the MLflow UI."}),"\n",(0,r.jsx)(t.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsx)(t.p,{children:"Install the required packages by running the following command:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"npm install mlflow-openai\n"})}),"\n",(0,r.jsxs)(t.admonition,{type:"info",children:[(0,r.jsx)(t.p,{children:"The code example in this guide uses the OpenAI SDK; however, the contents of this guide are applicable to any other LLM providers, such as Anthropic, Google, Bedrock, and more."}),(0,r.jsxs)(t.p,{children:["For other LLM providers that are not natively integrated with auto-tracing, install the ",(0,r.jsx)(t.code,{children:"mlflow-tracing"})," package and wrap the LLM call with the ",(0,r.jsx)(t.code,{children:"mlflow.trace"})," wrapper function instead."]}),(0,r.jsxs)(n,{children:[(0,r.jsx)("summary",{children:"Example of wrapping Anthropic API calls to generate a trace"}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-typescript",children:'import * as mlflow from "mlflow-tracing";\nimport Anthropic from \'@anthropic-ai/sdk\';\n\n// Instantiate the Anthropic client\nconst anthropic = new Anthropic({\n  apiKey: process.env.ANTHROPIC_API_KEY,\n});\n\n// Define a traced function that wraps the Anthropic API call.\nconst generate = mlflow.trace(\n    (prompt: string) => {\n        return anthropic.messages.create({\n            model: "claude-sonnet-4-latest",\n            max_tokens: 1024,\n            messages: [{ role: "user", content: prompt }],\n        });\n    },\n    { spanType: mlflow.SpanType.LLM }\n);\n\n// Call the wrapped function as usual.\nconst response = await generate("Hello, Claude");\n'})})]})]}),"\n",(0,r.jsx)(t.h2,{id:"step-1-set-up-your-environment",children:"Step 1: Set up your environment"}),"\n",(0,r.jsx)(t.h3,{id:"connect-to-mlflow",children:"Connect to MLflow"}),"\n",(0,r.jsx)(t.p,{children:"MLflow logs Traces in a tracking server. Connect your application to the tracking server by one of the following methods."}),"\n",(0,r.jsx)(p.Ay,{}),"\n",(0,r.jsx)(t.h3,{id:"create-a-new-mlflow-experiment",children:"Create a new MLflow Experiment"}),"\n",(0,r.jsx)(t.p,{children:"Create a new MLflow experiment in the MLflow UI, or choose an existing experiment."}),"\n",(0,r.jsx)(s.A,{src:"/images/llms/tracing/quickstart/mlflow-ui-new-experiment.png",alt:"New Experiment",width:"80%"}),"\n",(0,r.jsxs)(t.ol,{children:["\n",(0,r.jsxs)(t.li,{children:["Navigate to the MLflow UI in your browser. For example, if you started a local MLflow server at port 5000, you can navigate to ",(0,r.jsx)(t.a,{href:"http://127.0.0.1:5000",children:"http://127.0.0.1:5000"}),"."]}),"\n",(0,r.jsxs)(t.li,{children:["Click on the ",(0,r.jsx)("div",{className:"inline-flex rounded-sm bg-sky-700 px-2 py-1.5 text-sm font-semibold text-white",children:"Create"})," button on the top right."]}),"\n",(0,r.jsx)(t.li,{children:'Enter a name for the experiment and click on "Create".'}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsxs)(t.em,{children:["You can leave the ",(0,r.jsx)(t.code,{children:"Artifact Location"})," field blank for now. It is an advanced configuration to override where MLflow stores experiment data."]})}),"\n",(0,r.jsx)(t.h3,{id:"initialize-the-tracing-sdk",children:"Initialize the Tracing SDK"}),"\n",(0,r.jsx)(c.A,{children:(0,r.jsxs)(o.A,{children:[(0,r.jsxs)(i.A,{value:"self-hosted",label:"Self Host",default:!0,children:[(0,r.jsxs)(t.p,{children:["Call the ",(0,r.jsx)(t.code,{children:"init"})," function with the tracking URI (e.g., ",(0,r.jsx)(t.code,{children:"http://127.0.0.1:5000"}),") and the experiment ID. You can find the experiment ID by hovering over the ",(0,r.jsx)("div",{className:"inline-flex items-center justify-center w-5 h-5 rounded-full border border-gray-400 text-sm font-semibold text-gray-600",children:"!"})," icon next to the experiment name within the MLflow UI."]}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-typescript",children:'import { init } from "mlflow-tracing";\n\ninit({\n    trackingUri: "<your-tracking-server-uri>",\n    experimentId: "<your-experiment-id>",\n});\n'})})]}),(0,r.jsxs)(i.A,{value:"remote",label:"Remote MLflow Server",children:[(0,r.jsxs)(t.p,{children:["Call the ",(0,r.jsx)(t.code,{children:"init"})," function with the URI of your remote MLflow server and the experiment ID. You can find the experiment ID by hovering over the ",(0,r.jsx)("div",{className:"inline-flex items-center justify-center w-5 h-5 rounded-full border border-gray-400 text-sm font-semibold text-gray-600",children:"!"})," icon next to the experiment name within the MLflow UI."]}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-typescript",children:'import { init } from "mlflow-tracing";\n\ninit({\n    trackingUri: "<remote-tracking-server-uri>",\n    experimentId: "<your-experiment-id>",\n});\n'})})]}),(0,r.jsxs)(i.A,{value:"databricks",label:"Databricks",children:[(0,r.jsxs)(t.p,{children:["Call the ",(0,r.jsx)(t.code,{children:"init"})," function with the URI of your remote MLflow server and the experiment ID. You can find the experiment ID by hovering over the ",(0,r.jsx)("div",{className:"inline-flex items-center justify-center w-5 h-5 rounded-full border border-gray-400 text-sm font-semibold text-gray-600",children:"!"})," icon next to the experiment name within the MLflow UI."]}),(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"Method 1: Use Databricks config file for authentication."})}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-typescript",children:'import { init } from "mlflow-tracing";\n\ninit({\n    trackingUri: "databricks",\n    experimentId: "<your-experiment-id>",\n    // Optional: Set the Databricks config file path if it is not in the default location\n    configPath: "<your-databricks-config-file-path>",\n});\n'})}),(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"Method 2: Use environment variables"})}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"export DATABRICKS_HOST=<your-databricks-host>\nexport DATABRICKS_TOKEN=<your-databricks-personal-access-token>\n"})}),(0,r.jsxs)(t.p,{children:["or create a ",(0,r.jsx)(t.code,{children:".env"})," file in the root directory of your project and add the following:"]}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"DATABRICKS_HOST=<your-databricks-host>\nDATABRICKS_TOKEN=<your-databricks-personal-access-token>\n"})}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-typescript",children:"// Load environment variables from .env file\nimport 'dotenv/config';\n"})}),(0,r.jsxs)(t.p,{children:["The ",(0,r.jsx)(t.code,{children:"init"})," function will automatically load the above environment variables when tracking URI is set to ",(0,r.jsx)(t.code,{children:"databricks"}),"."]}),(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-typescript",children:'import { init } from "mlflow-tracing";\n\ninit({\n    trackingUri: "databricks",\n    experimentId: "<your-experiment-id>",\n});\n'})})]})]})}),"\n",(0,r.jsx)(t.h3,{id:"set-openai-api-key-or-other-llm-providers",children:"Set OpenAI API Key (or other LLM providers)"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:'export OPENAI_API_KEY="your-api-key-here"  # Replace with your actual API key\n'})}),"\n",(0,r.jsx)(t.h2,{id:"step-2-trace-a-single-llm-call",children:"Step 2: Trace a single LLM call"}),"\n",(0,r.jsxs)(t.p,{children:["Let's start with a simple example of tracing a single LLM call. We first wrap the OpenAI client with the ",(0,r.jsx)(t.code,{children:"tracedOpenAI"})," function. After that, every call to OpenAI API will generate a trace span, capturing the input, output, latency, token counts, and other metadata."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-typescript",children:'import { OpenAI } from "openai";\nimport { tracedOpenAI } from "mlflow-openai";\n\n// Wrap the OpenAI client with the tracedOpenAI function\nconst client = tracedOpenAI(new OpenAI());\n\n// Invoke the client as usual\n// If you are running this tutorial as a script, remove the `await` keyword.\nawait client.chat.completions.create({\n    model: "o4-mini",\n    messages: [\n        {"role": "system", "content": "You are a helpful weather assistant."},\n        {"role": "user", "content": "What\'s the weather like in Seattle?"},\n    ],\n})\n'})}),"\n",(0,r.jsx)(t.p,{children:'After running the code above, go to the MLflow UI and select the "Traces" tab. It should show the newly created trace.'}),"\n",(0,r.jsx)(s.A,{src:"/images/llms/tracing/quickstart/single-openai-trace-list.png",alt:"Single Trace"}),"\n",(0,r.jsx)(t.p,{children:"The table view shows the primary metadata of the trace, such as the trace ID, execution duration, token count, source system and status. You can add or remove displayed columns by selecting the columns in the drop down."}),"\n",(0,r.jsx)(t.p,{children:"By clicking on the request row (the linked request text), you can view the detailed spans in the trace."}),"\n",(0,r.jsx)(s.A,{src:"/images/llms/tracing/quickstart/single-openai-trace-detail.png",alt:"Single Trace Detail",width:"80%"}),"\n",(0,r.jsx)(t.p,{children:'The "Chat" view in the above screenshot shows the full chat messages exchanged between the user and the model. By clicking other tables such as "Inputs / Outputs" or "Attributes", you can see different aspects of the trace, including the raw input payload, token usage breakdown, and more.'}),"\n",(0,r.jsx)(t.h2,{id:"step-3-trace-a-tool-calling-agent",children:"Step 3: Trace a tool calling agent"}),"\n",(0,r.jsxs)(t.p,{children:["Next, let's add a bit more complexity to the application. To get the real-time weather information, we will use an external weather API as a tool. The application will include a tool calling flow, not only a simple LLM call. To instrument that custom Python flow, we will use the ",(0,r.jsx)(t.code,{children:"mlflow.trace"})," wrapper function."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-typescript",children:"import * as mlflow from \"mlflow-tracing\";\n\n// Wrap the tool function with the `mlflow.trace` wrapper. The wrapped function will be automatically traced and logged to MLflow.\nconst getWeather = mlflow.trace(\n    // A tool function that fetches the weather information from a weather API\n    async function getWeather(latitude: number, longitude: number) {\n        const response = await fetch(`https://api.open-meteo.com/v1/forecast?latitude=${latitude}&longitude=${longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m`);\n        const data = await response.json();\n        return data['current']['temperature_2m'];\n    },\n     // Set the span type to TOOL. You can also set other span configuration here.\n    { spanType: mlflow.SpanType.TOOL }\n);\n"})}),"\n",(0,r.jsx)(t.p,{children:"To pass the function as a tool to the LLM, we need to define the JSON schema for the function."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-typescript",children:'const tools = [{\n    type: "function",\n    function: {\n        name: "get_weather" as const,\n        description: "Get current temperature for provided coordinates in celsius.",\n        parameters: {\n            type: "object",\n            properties: {\n                latitude: { type: "number" },\n                longitude: { type: "number" }\n            },\n            required: ["latitude", "longitude"],\n            additionalProperties: false\n        },\n        strict: true\n    }\n}];\n'})}),"\n",(0,r.jsxs)(t.p,{children:["Lastly, define a simple flow that first asks the LLM to get instructions for calling the tool, then invokes the tool function, and lastly returns the result to the LLM.. This example uses the ",(0,r.jsx)(t.code,{children:"mlflow.withSpan"})," API to create a parent span for the agent flow, but you can also achieve the same by using the ",(0,r.jsx)(t.code,{children:"mlflow.trace"})," API like the previous example."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-typescript",children:'async function runToolAgent(question: string) {\n    console.log(`\\n\ud83e\udd16 Running tool agent with question: "${question}"`);\n\n    return await mlflow.withSpan(\n        async () => {\n            const client = tracedOpenAI(new OpenAI());\n            const messages: any[] = [{"role": "user", "content": question}];\n\n            // First LLM call to get tool instructions\n            const response = await client.chat.completions.create({\n                model: "o4-mini",\n                messages: messages,\n                tools: tools,\n            });\n\n            const aiMsg = response.choices[0].message;\n            messages.push(aiMsg);\n\n            // If the model requests tool call(s), invoke the function\n            if (aiMsg.tool_calls && aiMsg.tool_calls.length > 0) {\n                for (const toolCall of aiMsg.tool_calls) {\n                    const functionName = toolCall.function.name;\n\n                    if (functionName === "get_weather") {\n                        // Invoke the tool function with the provided arguments\n                        const args = JSON.parse(toolCall.function.arguments);\n                        const toolResult = await getWeather(args.latitude, args.longitude);\n                        messages.push({\n                            "role": "tool",\n                            "tool_call_id": toolCall.id,\n                            "content": String(toolResult),\n                        });\n                    } else {\n                        throw new Error(`Invalid tool returned: ${functionName}`);\n                    }\n                }\n\n                // Second LLM call with tool results\n                const finalResponse = await client.chat.completions.create({\n                    model: "o4-mini",\n                    messages: messages\n                });\n                return finalResponse.choices[0].message.content;\n            }\n            return aiMsg.content;\n        },\n        {\n            name: "run_tool_agent",\n            spanType: mlflow.SpanType.AGENT,\n        }\n    );\n}\n\n'})}),"\n",(0,r.jsx)(t.p,{children:"Now we can run the application."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-typescript",children:'// If you are running this tutorial as a script, remove the `await` keyword.\nawait runToolAgent("What\'s the weather like in Seattle?")\n'})}),"\n",(0,r.jsx)(t.h2,{id:"step-4-explore-traces-in-the-ui",children:"Step 4: Explore Traces in the UI"}),"\n",(0,r.jsx)(t.p,{children:"After running the application, you can explore the traces in the MLflow UI."}),"\n",(0,r.jsx)(s.A,{src:"/images/llms/tracing/quickstart/openai-tool-calling-trace-detail.png",alt:"Tool Calling Trace",width:"90%"}),"\n",(0,r.jsx)(t.p,{children:"The trace shows all LLM invocations and tool calls, organized in a tree structure. You can also inspect the timeline breakdown by clicking the timeline icon next to the tree view. This helps you understand where the time is spent in the application."}),"\n",(0,r.jsx)(s.A,{src:"/images/llms/tracing/quickstart/openai-tool-calling-trace-timeline.png",alt:"Tool Calling Trace Timeline",width:"90%"}),"\n",(0,r.jsx)(t.h2,{id:"step-5-attach-feedbacks-on-traces",children:"Step 5: Attach Feedbacks on Traces"}),"\n",(0,r.jsx)(t.p,{children:"As a last step of this quickstart, let's attach feedback on the generated traces. In real world development, human feedback is critical to improve the quality of any LLM-powered application."}),"\n",(0,r.jsx)(t.p,{children:'To add a feedback to a trace, you can open the trace detail page and click the "Add new Assessment" button on the top right. It will open an input form where you can provide various feedback values and metadata. For example, we can add feedback called "Quality" with an integer value (1~5), indicating how good the answer is. We can also put the detailed rationale behind the score for future reference.'}),"\n",(0,r.jsx)(s.A,{src:"/images/llms/tracing/quickstart/openai-trace-feedback-input.png",alt:"Feedback Input Form",width:"90%"}),"\n",(0,r.jsx)(t.p,{children:'When you submit the form with "Create" button, the feedback will be attached to the trace.'}),"\n",(0,r.jsx)(s.A,{src:"/images/llms/tracing/quickstart/openai-trace-feedback-record.png",alt:"Feedback List",width:"90%"}),"\n",(0,r.jsx)(t.p,{children:"The aggregated score in the experiment can be seen in the Trace list. You can do slice-and-dice by various criteria, such as timestamp, source, tags, and it will update the aggregated score in real-time."}),"\n",(0,r.jsx)(s.A,{src:"/images/llms/tracing/quickstart/openai-trace-feedback-aggregate.png",alt:"Feedback Aggregated",width:"90%"}),"\n",(0,r.jsx)(t.h2,{id:"summary",children:"Summary"}),"\n",(0,r.jsx)(t.p,{children:"Congratulations! You've successfully:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"\u2705 Set up MLflow Tracing for a GenAI application"}),"\n",(0,r.jsx)(t.li,{children:"\u2705 Enabled automatic tracing for OpenAI API calls"}),"\n",(0,r.jsx)(t.li,{children:"\u2705 Generated and explored traces in the MLflow UI"}),"\n",(0,r.jsx)(t.li,{children:"\u2705 Learned how to add custom tracing using decorators"}),"\n",(0,r.jsx)(t.li,{children:"\u2705 Learned how to attach feedback on traces"}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:"MLflow Tracing provides powerful observability for your GenAI applications, helping you monitor performance, debug issues, and understand user interactions. Continue exploring the advanced features to get the most out of your tracing setup!"}),"\n",(0,r.jsx)(t.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsx)(t.p,{children:"Now that you have basic tracing working, explore these advanced features:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.a,{href:"/genai/tracing/app-instrumentation/typescript-sdk",children:"Typescript SDK Guide"}),": Learn more about how to use the Typescript SDK."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.a,{href:"/genai/eval-monitor",children:"Automatic Evaluation"}),": Learn how to set up automatic evaluation for traces using MLflow's GenAI evaluation feature."]}),"\n"]})]})}function w(e={}){const{wrapper:t}={...(0,l.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(f,{...e})}):f(e)}},11470:(e,t,n)=>{n.d(t,{A:()=>v});var a=n(96540),r=n(34164),l=n(23104),o=n(56347),i=n(205),s=n(57485),c=n(31682),p=n(70679);function h(e){return a.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function d(e){const{values:t,children:n}=e;return(0,a.useMemo)(()=>{const e=t??function(e){return h(e).map(({props:{value:e,label:t,attributes:n,default:a}})=>({value:e,label:t,attributes:n,default:a}))}(n);return function(e){const t=(0,c.XI)(e,(e,t)=>e.value===t.value);if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[t,n])}function m({value:e,tabValues:t}){return t.some(t=>t.value===e)}function u({queryString:e=!1,groupId:t}){const n=(0,o.W6)(),r=function({queryString:e=!1,groupId:t}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:e,groupId:t});return[(0,s.aZ)(r),(0,a.useCallback)(e=>{if(!r)return;const t=new URLSearchParams(n.location.search);t.set(r,e),n.replace({...n.location,search:t.toString()})},[r,n])]}function f(e){const{defaultValue:t,queryString:n=!1,groupId:r}=e,l=d(e),[o,s]=(0,a.useState)(()=>function({defaultValue:e,tabValues:t}){if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!m({value:e,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${t.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const n=t.find(e=>e.default)??t[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:t,tabValues:l})),[c,h]=u({queryString:n,groupId:r}),[f,w]=function({groupId:e}){const t=function(e){return e?`docusaurus.tab.${e}`:null}(e),[n,r]=(0,p.Dv)(t);return[n,(0,a.useCallback)(e=>{t&&r.set(e)},[t,r])]}({groupId:r}),g=(()=>{const e=c??f;return m({value:e,tabValues:l})?e:null})();(0,i.A)(()=>{g&&s(g)},[g]);return{selectedValue:o,selectValue:(0,a.useCallback)(e=>{if(!m({value:e,tabValues:l}))throw new Error(`Can't select invalid tab value=${e}`);s(e),h(e),w(e)},[h,w,l]),tabValues:l}}var w=n(92303);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var x=n(74848);function y({className:e,block:t,selectedValue:n,selectValue:a,tabValues:o}){const i=[],{blockElementScrollPositionUntilNextRender:s}=(0,l.a_)(),c=e=>{const t=e.currentTarget,r=i.indexOf(t),l=o[r].value;l!==n&&(s(t),a(l))},p=e=>{let t=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const n=i.indexOf(e.currentTarget)+1;t=i[n]??i[0];break}case"ArrowLeft":{const n=i.indexOf(e.currentTarget)-1;t=i[n]??i[i.length-1];break}}t?.focus()};return(0,x.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":t},e),children:o.map(({value:e,label:t,attributes:a})=>(0,x.jsx)("li",{role:"tab",tabIndex:n===e?0:-1,"aria-selected":n===e,ref:e=>{i.push(e)},onKeyDown:p,onClick:c,...a,className:(0,r.A)("tabs__item",g.tabItem,a?.className,{"tabs__item--active":n===e}),children:t??e},e))})}function b({lazy:e,children:t,selectedValue:n}){const l=(Array.isArray(t)?t:[t]).filter(Boolean);if(e){const e=l.find(e=>e.props.value===n);return e?(0,a.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,x.jsx)("div",{className:"margin-top--md",children:l.map((e,t)=>(0,a.cloneElement)(e,{key:t,hidden:e.props.value!==n}))})}function j(e){const t=f(e);return(0,x.jsxs)("div",{className:(0,r.A)("tabs-container",g.tabList),children:[(0,x.jsx)(y,{...t,...e}),(0,x.jsx)(b,{...t,...e})]})}function v(e){const t=(0,w.A)();return(0,x.jsx)(j,{...e,children:h(e.children)},String(t))}},19365:(e,t,n)=>{n.d(t,{A:()=>o});n(96540);var a=n(34164);const r={tabItem:"tabItem_Ymn6"};var l=n(74848);function o({children:e,hidden:t,className:n}){return(0,l.jsx)("div",{role:"tabpanel",className:(0,a.A)(r.tabItem,n),hidden:t,children:e})}},28453:(e,t,n)=>{n.d(t,{R:()=>o,x:()=>i});var a=n(96540);const r={},l=a.createContext(r);function o(e){const t=a.useContext(l);return a.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),a.createElement(l.Provider,{value:t},e.children)}},47020:(e,t,n)=>{n.d(t,{A:()=>l});n(96540);const a={wrapper:"wrapper_sf5q"};var r=n(74848);function l({children:e}){return(0,r.jsx)("div",{className:a.wrapper,children:e})}},49374:(e,t,n)=>{n.d(t,{B:()=>i});n(96540);const a=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}');var r=n(86025),l=n(74848);const o=e=>{const t=e.split(".");for(let n=t.length;n>0;n--){const e=t.slice(0,n).join(".");if(a[e])return e}return null};function i({fn:e,children:t,hash:n}){const i=o(e);if(!i)return(0,l.jsx)(l.Fragment,{children:t});const s=(0,r.Ay)(`/${a[i]}#${n??e}`);return(0,l.jsx)("a",{href:s,target:"_blank",children:t??(0,l.jsxs)("code",{children:[e,"()"]})})}},51307:(e,t,n)=>{n.d(t,{Ay:()=>p,RM:()=>s});var a=n(74848),r=n(28453),l=n(11470),o=n(19365),i=n(47020);const s=[];function c(e){const t={a:"a",admonition:"admonition",code:"code",p:"p",pre:"pre",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(i.A,{children:(0,a.jsxs)(l.A,{children:[(0,a.jsxs)(o.A,{value:"local",label:"Local (pip)",default:!0,children:[(0,a.jsxs)(t.p,{children:["For the fastest setup, you can install the ",(0,a.jsx)(t.a,{href:"https://pypi.org/project/mlflow/",children:"mlflow"})," Python package and run MLflow locally:"]}),(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:"mlflow ui --backend-store-uri sqlite:///mlflow.db --port 5000\n"})}),(0,a.jsxs)(t.p,{children:["This will start the server at port 5000 on your local machine. Connect your notebook/IDE to the server by setting the tracking URI. You can also access to the MLflow UI at ",(0,a.jsx)(t.a,{href:"http://localhost:5000",children:"http://localhost:5000"}),"."]}),(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'import mlflow\n\nmlflow.set_tracking_uri("http://localhost:5000")\n'})}),(0,a.jsxs)(t.p,{children:["You can also brows the MLflow UI at ",(0,a.jsx)(t.a,{href:"http://localhost:5000",children:"http://localhost:5000"}),"."]})]}),(0,a.jsxs)(o.A,{value:"docker",label:"Local (docker)",children:[(0,a.jsx)(t.p,{children:"MLflow provides a Docker Compose file to start a local MLflow server with a postgres database and a minio server."}),(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:"git clone https://github.com/mlflow/mlflow.git\ncd docker-compose\ncp .env.dev.example .env\ndocker compose up -d\n"})}),(0,a.jsxs)(t.p,{children:["This will start the server at port 5000 on your local machine. Connect your notebook/IDE to the server by setting the tracking URI. You can also access to the MLflow UI at ",(0,a.jsx)(t.a,{href:"http://localhost:5000",children:"http://localhost:5000"}),"."]}),(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'import mlflow\n\nmlflow.set_tracking_uri("http://localhost:5000")\n'})}),(0,a.jsxs)(t.p,{children:["Refer to the ",(0,a.jsx)(t.a,{href:"https://github.com/mlflow/mlflow/tree/master/docker-compose/README.md",children:"instruction"})," for more details, e.g., overriding the default environment variables."]})]}),(0,a.jsxs)(o.A,{value:"remote",label:"Remote MLflow Server",children:[(0,a.jsx)(t.p,{children:"If you have a remote MLflow tracking server, configure the connection:"}),(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'import os\nimport mlflow\n\n# Set your MLflow tracking URI\nos.environ["MLFLOW_TRACKING_URI"] = "http://your-mlflow-server:5000"\n# Or directly in code\nmlflow.set_tracking_uri("http://your-mlflow-server:5000")\n'})})]}),(0,a.jsxs)(o.A,{value:"databricks",label:"Databricks",children:[(0,a.jsx)(t.p,{children:"If you have a Databricks account, configure the connection:"}),(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:"import mlflow\n\nmlflow.login()\n"})}),(0,a.jsx)(t.p,{children:"This will prompt you for your configuration details (Databricks Host url and a PAT)."})]})]})}),"\n",(0,a.jsx)(t.admonition,{type:"tip",children:(0,a.jsxs)(t.p,{children:["If you are unsure about how to set up an MLflow tracking server, you can start with the cloud-based MLflow powered by Databricks: ",(0,a.jsx)("ins",{children:(0,a.jsx)(t.a,{href:"https://login.databricks.com/?destination_url=%2Fml%2Fexperiments-signup%3Fsource%3DTRY_MLFLOW&dbx_source=TRY_MLFLOW&signup_experience_step=EXPRESS&provider=MLFLOW&utm_source=mlflow_org&tuuid=a9534f33-78bf-4b81-becc-4334e993251d&rl_aid=e6685d78-9f85-4fed-b64f-08e247f53547&intent=SIGN_UP",children:"Sign up for free \u2192"})})]})})]})}function p(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},66927:(e,t,n)=>{n.d(t,{A:()=>o});n(96540);const a={container:"container_JwLF",imageWrapper:"imageWrapper_RfGN",image:"image_bwOA",caption:"caption_jo2G"};var r=n(86025),l=n(74848);function o({src:e,alt:t,width:n,caption:o,className:i}){return(0,l.jsxs)("div",{className:`${a.container} ${i||""}`,children:[(0,l.jsx)("div",{className:a.imageWrapper,style:n?{width:n}:{},children:(0,l.jsx)("img",{src:(0,r.Ay)(e),alt:t,className:a.image})}),o&&(0,l.jsx)("p",{className:a.caption,children:o})]})}}}]);