/*! For license information please see 8852b4af.48f9e19e.js.LICENSE.txt */
"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7341],{6789:(e,l,n)=>{n.d(l,{A:()=>c});n(96540);var t=n(28774),r=n(34164);const o={tileCard:"tileCard_NHsj",tileIcon:"tileIcon_pyoR",tileLink:"tileLink_iUbu",tileImage:"tileImage_O4So"};var i=n(86025),a=n(21122),s=n(74848);function c({icon:e,image:l,imageDark:n,imageWidth:c,imageHeight:m,iconSize:p=32,containerHeight:h,title:d,description:f,href:u,linkText:g="Learn more \u2192",className:w}){if(!e&&!l)throw new Error("TileCard requires either an icon or image prop");const _=h?{height:`${h}px`}:{},y={};return c&&(y.width=`${c}px`),m&&(y.height=`${m}px`),(0,s.jsxs)(t.A,{href:u,className:(0,r.A)(o.tileCard,w),children:[(0,s.jsx)("div",{className:o.tileIcon,style:_,children:e?(0,s.jsx)(e,{size:p}):n?(0,s.jsx)(a.A,{sources:{light:(0,i.Ay)(l),dark:(0,i.Ay)(n)},alt:d,className:o.tileImage,style:y}):(0,s.jsx)("img",{src:(0,i.Ay)(l),alt:d,className:o.tileImage,style:y})}),(0,s.jsx)("h3",{children:d}),(0,s.jsx)("p",{children:f}),(0,s.jsx)("div",{className:o.tileLink,children:g})]})}},28453:(e,l,n)=>{n.d(l,{R:()=>i,x:()=>a});var t=n(96540);const r={},o=t.createContext(r);function i(e){const l=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(l):{...l,...e}},[l,e])}function a(e){let l;return l=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),t.createElement(o.Provider,{value:l},e.children)}},30045:(e,l,n)=>{n.r(l),n.d(l,{assets:()=>u,contentTitle:()=>f,default:()=>_,frontMatter:()=>d,metadata:()=>t,toc:()=>g});const t=JSON.parse('{"id":"eval-monitor/scorers/llm-judge/guidelines","title":"Create Custom LLM Scorers","description":"While MLflow\'s predefined LLM judge scorers offer excellent starting points for common quality dimensions in simpler applications, you\'ll need to create custom LLM judges as your application becomes more complex and to tune your evaluation criteria to meet the specific, nuanced business requirements of your use case and align with your domain expert\'s judgment. MLflow provides robust and flexible ways to create custom LLM judges tailored to these unique requirements.","source":"@site/docs/genai/eval-monitor/scorers/llm-judge/guidelines.mdx","sourceDirName":"eval-monitor/scorers/llm-judge","slug":"/eval-monitor/scorers/llm-judge/guidelines","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/guidelines","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"genAISidebar","previous":{"title":"Evaluating Agent Behavior","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/agent-behavior-patterns"},"next":{"title":"Predefined Scorers","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/predefined"}}');var r=n(74848),o=n(28453),i=n(49374),a=n(66927),s=n(6789),c=n(65592),m=n(42640),p=n(61878),h=n(47504);const d={},f="Create Custom LLM Scorers",u={},g=[{value:"Guidelines (<em>we suggest starting here</em>)",id:"guidelines-we-suggest-starting-here",level:2},{value:"Example usage",id:"example-usage",level:3},{value:"Selecting Judge Models",id:"selecting-judge-models",level:2},{value:"Bring Your Own Prompt (full control)",id:"bring-your-own-prompt-full-control",level:2},{value:"Next Steps",id:"next-steps",level:2}];function w(e){const l={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(l.header,{children:(0,r.jsx)(l.h1,{id:"create-custom-llm-scorers",children:"Create Custom LLM Scorers"})}),"\n",(0,r.jsxs)(l.p,{children:["While MLflow's predefined LLM judge scorers offer excellent starting points for common quality dimensions in simpler applications, you'll need to create custom LLM judges as your application becomes more complex and to tune your evaluation criteria to meet the specific, nuanced business requirements of your use case and align with your domain expert's judgment. MLflow provides robust and flexible ways to create ",(0,r.jsx)(l.strong,{children:"custom LLM judges"})," tailored to these unique requirements."]}),"\n",(0,r.jsxs)(l.h2,{id:"guidelines-we-suggest-starting-here",children:["Guidelines (",(0,r.jsx)(l.em,{children:"we suggest starting here"}),")"]}),"\n",(0,r.jsxs)(l.p,{children:[(0,r.jsx)(i.B,{fn:"mlflow.genai.scorers.Guidelines",children:"Guidelines"})," is a powerful scorer class designed to let you quickly and easily customize evaluation by defining natural language criteria that are framed as pass/fail conditions. It is ideal for checking compliance with rules, style guides, or information inclusion/exclusion."]}),"\n",(0,r.jsx)(l.p,{children:'Guidelines have the distinct advantage of being easy to explain to business stakeholders ("we are evaluating if the app delivers upon this set of rules") and, as such, can often be directly written by domain experts.'}),"\n",(0,r.jsx)(l.h3,{id:"example-usage",children:"Example usage"}),"\n",(0,r.jsx)(l.p,{children:"First, define the guidelines as a simple string:"}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-python",children:'tone = "The response must maintain a courteous, respectful tone throughout.  It must show empathy for customer concerns."\neasy_to_understand = "The response must use clear, concise language and structure responses logically. It must avoid jargon or explain technical terms when used."\nbanned_topics = "If the request is a question about product pricing, the response must politely decline to answer and refer the user to the pricing page."\n'})}),"\n",(0,r.jsxs)(l.p,{children:["Then pass each guideline to the ",(0,r.jsx)(l.code,{children:"Guidelines"})," class to create a scorer and run evaluation:"]}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-python",children:'import mlflow\n\neval_dataset = [\n    {\n        "inputs": {"question": "I\'m having trouble with my account.  I can\'t log in."},\n        "outputs": "I\'m sorry to hear that you\'re having trouble logging in. Please provide me with your username and the specific issue you\'re experiencing, and I\'ll be happy to help you resolve it.",\n    },\n    {\n        "inputs": {"question": "How much does a microwave cost?"},\n        "outputs": "The microwave costs $100.",\n    },\n    {\n        "inputs": {"question": "How does a refrigerator work?"},\n        "outputs": "A refrigerator operates via thermodynamic vapor-compression cycles utilizing refrigerant phase transitions. The compressor pressurizes vapor which condenses externally, then expands through evaporator coils to absorb internal heat through endothermic vaporization.",\n    },\n]\n\nmlflow.genai.evaluate(\n    data=eval_dataset,\n    scorers=[\n        # Create a scorer for each guideline\n        Guidelines(name="tone", guidelines=tone),\n        Guidelines(name="easy_to_understand", guidelines=easy_to_understand),\n        Guidelines(name="banned_topics", guidelines=banned_topics),\n    ],\n)\n'})}),"\n",(0,r.jsx)(a.A,{src:"/images/mlflow-3/eval-monitor/scorers/guideline-scorers-results.png",alt:"Guidelines scorers result"}),"\n",(0,r.jsx)(l.h2,{id:"selecting-judge-models",children:"Selecting Judge Models"}),"\n",(0,r.jsx)(l.p,{children:"MLflow supports all major LLM providers, such as OpenAI, Anthropic, Google, xAI, and more."}),"\n",(0,r.jsxs)(l.p,{children:["See ",(0,r.jsx)(l.a,{href:"/genai/eval-monitor/scorers/llm-judge#supported-models",children:"Supported Models"})," for more details."]}),"\n",(0,r.jsx)(l.h2,{id:"bring-your-own-prompt-full-control",children:"Bring Your Own Prompt (full control)"}),"\n",(0,r.jsxs)(l.p,{children:["While ",(0,r.jsx)(l.code,{children:"Guidelines"})," scorers have the distinct advantage of being easy to write and maintain, you may need more control or can't write your evaluation criteria as pass/fail guidelines."]}),"\n",(0,r.jsxs)(l.admonition,{title:"Recommendation: Use make_judge Instead",type:"note",children:[(0,r.jsxs)(l.p,{children:["We recommend using the ",(0,r.jsx)(i.B,{fn:"mlflow.genai.judges.make_judge",children:"make_judge"})," API instead of ",(0,r.jsx)(l.code,{children:"custom_prompt_judge"}),". The ",(0,r.jsx)(l.code,{children:"make_judge"})," API provides:"]}),(0,r.jsxs)(l.ul,{children:["\n",(0,r.jsx)(l.li,{children:"More flexible template-based instructions"}),"\n",(0,r.jsx)(l.li,{children:"Better version control and collaboration features"}),"\n",(0,r.jsx)(l.li,{children:"Support for both field-based and Agent-as-a-Judge evaluation"}),"\n",(0,r.jsx)(l.li,{children:"Alignment capabilities with human feedback"}),"\n"]}),(0,r.jsxs)(l.p,{children:["See the ",(0,r.jsx)(l.a,{href:"/genai/eval-monitor/scorers/llm-judge/make-judge",children:"make_judge documentation"})," for complete details."]})]}),"\n",(0,r.jsxs)(l.p,{children:["The ",(0,r.jsx)(i.B,{fn:"mlflow.genai.judges.custom_prompt_judge",children:"custom_prompt_judge"})," API allows you to define a full prompt for the judge, while still letting MLflow handle complexities like response parsing."]}),"\n",(0,r.jsxs)(l.p,{children:["See ",(0,r.jsx)(l.a,{href:"/genai/eval-monitor/scorers/llm-judge/prompt",children:"Bring Your Own Prompt"})," for more details."]}),"\n",(0,r.jsx)(l.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsxs)(c.A,{children:[(0,r.jsx)(s.A,{icon:m.A,title:"Evaluate Agents",description:"Learn how to evaluate AI agents with specialized techniques and scorers",href:"/genai/eval-monitor/running-evaluation/agents"}),(0,r.jsx)(s.A,{icon:p.A,title:"Evaluate Traces",description:"Evaluate production traces to understand and improve your AI application's behavior",href:"/genai/eval-monitor/running-evaluation/traces"}),(0,r.jsx)(s.A,{icon:h.A,title:"Collect User Feedback",description:"Integrate user feedback to continuously improve your evaluation criteria and model performance",href:"/genai/assessments/feedback/"})]})]})}function _(e={}){const{wrapper:l}={...(0,o.R)(),...e.components};return l?(0,r.jsx)(l,{...e,children:(0,r.jsx)(w,{...e})}):w(e)}},42640:(e,l,n)=>{n.d(l,{A:()=>t});const t=(0,n(84722).A)("bot",[["path",{d:"M12 8V4H8",key:"hb8ula"}],["rect",{width:"16",height:"12",x:"4",y:"8",rx:"2",key:"enze0r"}],["path",{d:"M2 14h2",key:"vft8re"}],["path",{d:"M20 14h2",key:"4cs60a"}],["path",{d:"M15 13v2",key:"1xurst"}],["path",{d:"M9 13v2",key:"rq6x2g"}]])},47504:(e,l,n)=>{n.d(l,{A:()=>t});const t=(0,n(84722).A)("message-square",[["path",{d:"M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z",key:"1lielz"}]])},49374:(e,l,n)=>{n.d(l,{B:()=>a});n(96540);const t=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}');var r=n(86025),o=n(74848);const i=e=>{const l=e.split(".");for(let n=l.length;n>0;n--){const e=l.slice(0,n).join(".");if(t[e])return e}return null};function a({fn:e,children:l,hash:n}){const a=i(e);if(!a)return(0,o.jsx)(o.Fragment,{children:l});const s=(0,r.Ay)(`/${t[a]}#${n??e}`);return(0,o.jsx)("a",{href:s,target:"_blank",children:l??(0,o.jsxs)("code",{children:[e,"()"]})})}},61878:(e,l,n)=>{n.d(l,{A:()=>t});const t=(0,n(84722).A)("git-branch",[["line",{x1:"6",x2:"6",y1:"3",y2:"15",key:"17qcm7"}],["circle",{cx:"18",cy:"6",r:"3",key:"1h7g24"}],["circle",{cx:"6",cy:"18",r:"3",key:"fqmcym"}],["path",{d:"M18 9a9 9 0 0 1-9 9",key:"n2h4wq"}]])},65592:(e,l,n)=>{n.d(l,{A:()=>i});n(96540);var t=n(34164);const r={tilesGrid:"tilesGrid_hB9N"};var o=n(74848);function i({children:e,className:l}){return(0,o.jsx)("div",{className:(0,t.A)(r.tilesGrid,l),children:e})}},66927:(e,l,n)=>{n.d(l,{A:()=>i});n(96540);const t={container:"container_JwLF",imageWrapper:"imageWrapper_RfGN",image:"image_bwOA",caption:"caption_jo2G"};var r=n(86025),o=n(74848);function i({src:e,alt:l,width:n,caption:i,className:a}){return(0,o.jsxs)("div",{className:`${t.container} ${a||""}`,children:[(0,o.jsx)("div",{className:t.imageWrapper,style:n?{width:n}:{},children:(0,o.jsx)("img",{src:(0,r.Ay)(e),alt:l,className:t.image})}),i&&(0,o.jsx)("p",{className:t.caption,children:i})]})}},84722:(e,l,n)=>{n.d(l,{A:()=>c});var t=n(96540);const r=e=>{const l=(e=>e.replace(/^([A-Z])|[\s-_]+(\w)/g,(e,l,n)=>n?n.toUpperCase():l.toLowerCase()))(e);return l.charAt(0).toUpperCase()+l.slice(1)},o=(...e)=>e.filter((e,l,n)=>Boolean(e)&&""!==e.trim()&&n.indexOf(e)===l).join(" ").trim(),i=e=>{for(const l in e)if(l.startsWith("aria-")||"role"===l||"title"===l)return!0};var a={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};const s=(0,t.forwardRef)(({color:e="currentColor",size:l=24,strokeWidth:n=2,absoluteStrokeWidth:r,className:s="",children:c,iconNode:m,...p},h)=>(0,t.createElement)("svg",{ref:h,...a,width:l,height:l,stroke:e,strokeWidth:r?24*Number(n)/Number(l):n,className:o("lucide",s),...!c&&!i(p)&&{"aria-hidden":"true"},...p},[...m.map(([e,l])=>(0,t.createElement)(e,l)),...Array.isArray(c)?c:[c]])),c=(e,l)=>{const n=(0,t.forwardRef)(({className:n,...i},a)=>{return(0,t.createElement)(s,{ref:a,iconNode:l,className:o(`lucide-${c=r(e),c.replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()}`,`lucide-${e}`,n),...i});var c});return n.displayName=r(e),n}}}]);