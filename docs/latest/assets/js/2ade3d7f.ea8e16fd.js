"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["6928"],{96218(e,n,t){t.r(n),t.d(n,{metadata:()=>l,default:()=>A,frontMatter:()=>v,contentTitle:()=>x,toc:()=>j,assets:()=>y});var l=JSON.parse('{"id":"eval-monitor/running-evaluation/agents","title":"Evaluating Agents","description":"AI Agents are an emerging pattern of GenAI applications that can use tools, make decisions, and execute multi-step workflows. However, evaluating the performance of those complex agents is challenging. MLflow provides a powerful toolkit to systematically evaluate the agent behavior precisely using traces and scorers.","source":"@site/docs/genai/eval-monitor/running-evaluation/agents.mdx","sourceDirName":"eval-monitor/running-evaluation","slug":"/eval-monitor/running-evaluation/agents","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/running-evaluation/agents","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"genAISidebar","previous":{"title":"Evaluate Prompts","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/running-evaluation/prompts"},"next":{"title":"Evaluate Traces","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/running-evaluation/traces"}}'),a=t(74848),o=t(28453),i=t(54725),r=t(46077),s=t(81956),c=t(10440),p=t(77541),h=t(42640),m=t(51004),d=t(47792),f=t(85731),u=t(93164),g=t(96844),w=t(47504),_=t(74990);let v={},x="Evaluating Agents",y={},j=[{value:"Workflow",id:"workflow",level:2},{value:"Example: Evaluating a Tool-Calling Agent",id:"example-evaluating-a-tool-calling-agent",level:2},{value:"Prerequisites",id:"prerequisites",level:3},..._.RM,{value:"Step 1: Build an agent",id:"step-1-build-an-agent",level:3},{value:"Step 2: Create evaluation dataset",id:"step-2-create-evaluation-dataset",level:3},{value:"Step 3: Define scorers",id:"step-3-define-scorers",level:3},{value:"Step 4: Run the evaluation",id:"step-4-run-the-evaluation",level:3},{value:"Configure parallelization",id:"configure-parallelization",level:2},{value:"Evaluating MLflow Models",id:"evaluating-mlflow-models",level:2},{value:"Next steps",id:"next-steps",level:2}];function b(e){let n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"evaluating-agents",children:"Evaluating Agents"})}),"\n",(0,a.jsx)(n.p,{children:"AI Agents are an emerging pattern of GenAI applications that can use tools, make decisions, and execute multi-step workflows. However, evaluating the performance of those complex agents is challenging. MLflow provides a powerful toolkit to systematically evaluate the agent behavior precisely using traces and scorers."}),"\n",(0,a.jsx)(r.A,{src:"/images/mlflow-3/eval-monitor/agent-evaluation-hero.png",alt:"Agent Evaluation",width:"95%"}),"\n",(0,a.jsx)(n.h2,{id:"workflow",children:"Workflow"}),"\n",(0,a.jsx)(s.A,{steps:[{icon:h.A,title:"Build your agent",description:"Create an AI agent with tools, instructions, and capabilities for your specific use case."},{icon:m.A,title:"Create evaluation dataset",description:"Design test cases with inputs and expectations for both outputs and agent behaviors like tool usage."},{icon:d.A,title:"Define agent-specific scorers",description:"Create scorers that evaluate multi-step agent behaviors using traces."},{icon:f.A,title:"Run evaluation",description:"Execute the evaluation and analyze both final outputs and intermediate agent behaviors in MLflow UI."}]}),"\n",(0,a.jsx)(n.h2,{id:"example-evaluating-a-tool-calling-agent",children:"Example: Evaluating a Tool-Calling Agent"}),"\n",(0,a.jsx)(n.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,a.jsx)(n.p,{children:"First, install the required packages by running the following command:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"pip install --upgrade 'mlflow[genai]>=3.3' openai\n"})}),"\n",(0,a.jsx)(n.p,{children:"MLflow stores evaluation results in a tracking server. Connect your local environment to the tracking server by one of the following methods."}),"\n",(0,a.jsx)(_.Ay,{}),"\n",(0,a.jsx)(n.h3,{id:"step-1-build-an-agent",children:"Step 1: Build an agent"}),"\n",(0,a.jsxs)(n.p,{children:["Create a math agent that can use tools to answer questions. We use ",(0,a.jsx)(n.a,{href:"/genai/tracing/integrations/listing/openai-agent",children:"OpenAI Agents"})," to build the tool-calling agent in a few lines of code."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from agents import Agent, Runner, function_tool\n\n\n@function_tool\ndef add(a: float, b: float) -> float:\n    """Adds two numbers."""\n    return a + b\n\n\n@function_tool\ndef multiply(a: float, b: float) -> float:\n    """Multiply two numbers."""\n    return a * b\n\n\n@function_tool\ndef modular(a: int, b: int) -> int:\n    """Modular arithmetic"""\n    return a % b\n\n\nagent = Agent(\n    name="Math Agent",\n    instructions=(\n        "You will be given a math question. Calculate the answer using the given calculator tools. "\n        "Return the final number only as an integer."\n    ),\n    tools=[add, multiply, modular],\n)\n'})}),"\n",(0,a.jsx)(n.p,{children:"Make sure you can run the agent locally."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from agents import Runner\n\nresult = await Runner.run(agent, "What is 15% of 240?")\nprint(result.final_output)\n# 36\n'})}),"\n",(0,a.jsx)(n.p,{children:"Lastly, let's wrap it in a function that MLflow can call. Note that MLflow runs each prediction in a threadpool,\nso using a synchronous function does not slow down the evaluation."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from openai import OpenAI\n\n# If you are using Jupyter Notebook, you need to apply nest_asyncio.\n# import nest_asyncio\n# nest_asyncio.apply()\n\n\ndef predict_fn(question: str) -> str:\n    return Runner.run_sync(agent, question).final_output\n"})}),"\n",(0,a.jsxs)(n.admonition,{type:"tip",children:[(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Async Functions are Supported!"})}),(0,a.jsx)(n.p,{children:"If your agent library provides an async API, you can use it directly without converting to sync. MLflow automatically detects and handles async functions:"}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"async def predict_fn(question: str) -> str:\n    result = await Runner.run(agent, question)\n    return result.final_output\n\n\nmlflow.genai.evaluate(\n    data=eval_dataset, predict_fn=predict_fn, scorers=[exact_match, uses_correct_tools]\n)\n"})}),(0,a.jsxs)(n.p,{children:["By default, async functions have a 5-minute timeout. Configure this using the ",(0,a.jsx)(n.code,{children:"MLFLOW_GENAI_EVAL_ASYNC_TIMEOUT"})," environment variable:"]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"export MLFLOW_GENAI_EVAL_ASYNC_TIMEOUT=600  # 10 minutes\n"})})]}),"\n",(0,a.jsx)(n.h3,{id:"step-2-create-evaluation-dataset",children:"Step 2: Create evaluation dataset"}),"\n",(0,a.jsxs)(n.p,{children:["Design test cases as a list of dictionaries, each with an ",(0,a.jsx)(n.code,{children:"inputs"}),", ",(0,a.jsx)(n.code,{children:"expectations"}),", and an optional ",(0,a.jsx)(n.code,{children:"tags"})," field."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'eval_dataset = [\n    {\n        "inputs": {"task": "What is 15% of 240?"},\n        "expectations": {"answer": 36},\n        "tags": {"topic": "math"},\n    },\n    {\n        "inputs": {\n            "task": "I have 8 cookies and 3 friends. How many more cookies should I buy to share equally?"\n        },\n        "expectations": {"answer": 1},\n        "tags": {"topic": "math"},\n    },\n    {\n        "inputs": {\n            "task": "I bought 2 shares of stock at $100 each. It\'s now worth $150. How much profit did I make?"\n        },\n        "expectations": {"answer": 100},\n        "tags": {"topic": "math"},\n    },\n]\n'})}),"\n",(0,a.jsx)(n.h3,{id:"step-3-define-scorers",children:"Step 3: Define scorers"}),"\n",(0,a.jsx)(n.p,{children:"We'll define a custom scorer to evaluate the correctness of the final output."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from mlflow.genai import scorer\n\n\n@scorer\ndef exact_match(outputs, expectations) -> bool:\n    return int(outputs) == expectations["answer"]\n'})}),"\n",(0,a.jsxs)(n.admonition,{type:"tip",children:[(0,a.jsx)(n.p,{children:"MLflow provides built-in scorers for evaluating agent tool usage:"}),(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(i.B,{fn:"mlflow.genai.scorers.ToolCallCorrectness",children:"ToolCallCorrectness"}),": Evaluates if tool calls and arguments are correct for the user query"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(i.B,{fn:"mlflow.genai.scorers.ToolCallEfficiency",children:"ToolCallEfficiency"}),": Evaluates if tool calls are efficient without redundancy"]}),"\n"]}),(0,a.jsxs)(n.p,{children:["These scorers automatically analyze traces to assess tool usage patterns. See the ",(0,a.jsx)("ins",{children:(0,a.jsx)(n.a,{href:"/genai/eval-monitor/scorers/llm-judge/predefined",children:"Built-in Judges"})})," guide for more details."]}),(0,a.jsxs)(n.p,{children:["For custom evaluation patterns, you can create your own scorers that parse traces. See the ",(0,a.jsx)("ins",{children:(0,a.jsx)(n.a,{href:"/genai/eval-monitor/scorers/custom",children:"Custom Scorers"})})," guide."]})]}),"\n",(0,a.jsx)(n.h3,{id:"step-4-run-the-evaluation",children:"Step 4: Run the evaluation"}),"\n",(0,a.jsx)(n.p,{children:"Now we are ready to run the evaluation!"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from mlflow.genai.scorers import ToolCallCorrectness, ToolCallEfficiency\n\nresults = mlflow.genai.evaluate(\n    data=eval_dataset,\n    predict_fn=predict_fn,\n    scorers=[\n        exact_match,\n        ToolCallCorrectness(),\n        ToolCallEfficiency(),\n    ],\n)\n"})}),"\n",(0,a.jsx)(n.p,{children:"Once the evaluation is done, open the MLflow UI in your browser and navigate to the experiment page. You should see MLflow creates a new Run and logs the evaluation results."}),"\n",(0,a.jsx)(r.A,{src:"/images/mlflow-3/eval-monitor/agent-evaluation-result.png",alt:"Agent Evaluation",width:"95%"}),"\n",(0,a.jsxs)(n.p,{children:["It seems the agent does not call tools in the correct order for the second test case. Let's click on the row to ",(0,a.jsx)(n.strong,{children:"open the trace and inspect what happened under the hood"}),"."]}),"\n",(0,a.jsx)(r.A,{src:"/images/mlflow-3/eval-monitor/agent-evaluation-trace.png",alt:"Agent Evaluation",width:"95%"}),"\n",(0,a.jsx)(n.p,{children:"By looking at the trace, we can figure out the agent computes the answer in three steps (1) compute 100 _ 2 (2) compute 150 _ 2 (3) subtract the two results. However, the more effective way is (1) subtract 100 from 150 (2) multiply the result by 2. In the next version, we can update the system instruction to use tools in a more effective way."}),"\n",(0,a.jsx)(n.h2,{id:"configure-parallelization",children:"Configure parallelization"}),"\n",(0,a.jsxs)(n.p,{children:["Running a complex agent can take a long time. MLflow by default uses background threadpool to speed up the evaluation process. You can configure the number of workers to use by setting the ",(0,a.jsx)(n.code,{children:"MLFLOW_GENAI_EVAL_MAX_WORKERS"})," environment variable."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"export MLFLOW_GENAI_EVAL_MAX_WORKERS=10\n"})}),"\n",(0,a.jsx)(n.h2,{id:"evaluating-mlflow-models",children:"Evaluating MLflow Models"}),"\n",(0,a.jsxs)(n.p,{children:["In MLflow 2.x, you can pass the model URI directly to the ",(0,a.jsx)(n.code,{children:"model"})," argument of the legacy ",(0,a.jsx)(i.B,{fn:"mlflow.evaluate"})," API (deprecated). The new GenAI evaluation API in MLflow ",(0,a.jsx)(n.strong,{children:"3.x"})," still support evaluating MLflow Models, but the workflow is slightly different."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\n\n# Load the model **outside** the prediction function.\nmodel = mlflow.pyfunc.load_model("models:/math_agent/1")\n\n\n# Wrap the model in a function that MLflow can call.\ndef predict_fn(question: str) -> str:\n    return model.predict(question)\n\n\n# Run the evaluation as usual.\nmlflow.genai.evaluate(\n    data=eval_dataset, predict_fn=predict_fn, scorers=[exact_match, uses_correct_tools]\n)\n'})}),"\n",(0,a.jsx)(n.h2,{id:"next-steps",children:"Next steps"}),"\n",(0,a.jsxs)(c.A,{children:[(0,a.jsx)(p.A,{icon:u.A,iconSize:48,title:"Customize Scorers",description:"Build advanced evaluation criteria and metrics specifically designed for agent behaviors and tool usage patterns.",href:"/genai/eval-monitor/scorers",linkText:"Create custom scorers \u2192",containerHeight:64}),(0,a.jsx)(p.A,{icon:g.A,iconSize:48,title:"Evaluate Production Traces",description:"Analyze real agent executions in production environments to understand performance and identify improvement opportunities.",href:"/genai/eval-monitor/running-evaluation/traces",linkText:"Analyze traces \u2192",containerHeight:64}),(0,a.jsx)(p.A,{icon:w.A,iconSize:48,title:"Collect User Feedback",description:"Gather human feedback on agent performance to create training data and improve evaluation accuracy.",href:"/genai/assessments/feedback",linkText:"Start collecting \u2192",containerHeight:64})]})]})}function A(e={}){let{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(b,{...e})}):b(e)}},74990(e,n,t){t.d(n,{Ay:()=>p,RM:()=>s});var l=t(74848),a=t(28453),o=t(78010),i=t(57250),r=t(95986);let s=[];function c(e){let n={a:"a",code:"code",p:"p",pre:"pre",strong:"strong",...(0,a.R)(),...e.components};return(0,l.jsx)(r.A,{children:(0,l.jsxs)(o.A,{children:[(0,l.jsxs)(i.A,{value:"uv",label:"Local (uv)",default:!0,children:[(0,l.jsxs)(n.p,{children:["Install the Python package manager ",(0,l.jsx)(n.a,{href:"https://docs.astral.sh/uv/getting-started/installation/",children:"uv"}),"\n(that will also install ",(0,l.jsxs)(n.a,{href:"https://docs.astral.sh/uv/guides/tools/",children:[(0,l.jsx)(n.code,{children:"uvx"})," command"]})," to invoke Python tools without installing them)."]}),(0,l.jsx)(n.p,{children:"Start a MLflow server locally."}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-shell",children:"uvx mlflow server\n"})})]}),(0,l.jsxs)(i.A,{value:"local",label:"Local (pip)",children:[(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Python Environment"}),": Python 3.10+"]}),(0,l.jsxs)(n.p,{children:["Install the ",(0,l.jsx)(n.code,{children:"mlflow"})," Python package via ",(0,l.jsx)(n.code,{children:"pip"})," and start a MLflow server locally."]}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-shell",children:"pip install --upgrade 'mlflow[genai]'\nmlflow server\n"})})]}),(0,l.jsxs)(i.A,{value:"docker",label:"Local (docker)",children:[(0,l.jsx)(n.p,{children:"MLflow provides a Docker Compose file to start a local MLflow server with a PostgreSQL database and a MinIO server."}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-shell",children:"git clone --depth 1 --filter=blob:none --sparse https://github.com/mlflow/mlflow.git\ncd mlflow\ngit sparse-checkout set docker-compose\ncd docker-compose\ncp .env.dev.example .env\ndocker compose up -d\n"})}),(0,l.jsxs)(n.p,{children:["Refer to the ",(0,l.jsx)(n.a,{href:"https://github.com/mlflow/mlflow/tree/master/docker-compose/README.md",children:"instruction"})," for more details (e.g., overriding the default environment variables)."]})]})]})})}function p(e={}){let{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(c,{...e})}):c(e)}},54725(e,n,t){t.d(n,{B:()=>i});var l=t(74848);t(96540);var a=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}'),o=t(66497);function i({fn:e,children:n,hash:t}){let i=(e=>{let n=e.split(".");for(let e=n.length;e>0;e--){let t=n.slice(0,e).join(".");if(a[t])return t}return null})(e);if(!i)return(0,l.jsx)(l.Fragment,{children:n});let r=(0,o.default)(`/${a[i]}#${t??e}`);return(0,l.jsx)("a",{href:r,target:"_blank",children:n??(0,l.jsxs)("code",{children:[e,"()"]})})}},46077(e,n,t){t.d(n,{A:()=>o});var l=t(74848);t(96540);var a=t(66497);function o({src:e,alt:n,width:t,caption:o,className:i}){return(0,l.jsxs)("div",{className:`container_JwLF ${i||""}`,children:[(0,l.jsx)("div",{className:"imageWrapper_RfGN",style:t?{width:t}:{},children:(0,l.jsx)("img",{src:(0,a.default)(e),alt:n,className:"image_bwOA"})}),o&&(0,l.jsx)("p",{className:"caption_jo2G",children:o})]})}},95986(e,n,t){t.d(n,{A:()=>a});var l=t(74848);t(96540);function a({children:e}){return(0,l.jsx)("div",{className:"wrapper_sf5q",children:e})}},77541(e,n,t){t.d(n,{A:()=>c});var l=t(74848);t(96540);var a=t(95310),o=t(34164);let i="tileImage_O4So";var r=t(66497),s=t(92802);function c({icon:e,image:n,imageDark:t,imageWidth:c,imageHeight:p,iconSize:h=32,containerHeight:m,title:d,description:f,href:u,linkText:g="Learn more \u2192",className:w}){if(!e&&!n)throw Error("TileCard requires either an icon or image prop");let _=m?{height:`${m}px`}:{},v={};return c&&(v.width=`${c}px`),p&&(v.height=`${p}px`),(0,l.jsxs)(a.A,{href:u,className:(0,o.A)("tileCard_NHsj",w),children:[(0,l.jsx)("div",{className:"tileIcon_pyoR",style:_,children:e?(0,l.jsx)(e,{size:h}):t?(0,l.jsx)(s.A,{sources:{light:(0,r.default)(n),dark:(0,r.default)(t)},alt:d,className:i,style:v}):(0,l.jsx)("img",{src:(0,r.default)(n),alt:d,className:i,style:v})}),(0,l.jsx)("h3",{children:d}),(0,l.jsx)("p",{children:f}),(0,l.jsx)("div",{className:"tileLink_iUbu",children:g})]})}},10440(e,n,t){t.d(n,{A:()=>o});var l=t(74848);t(96540);var a=t(34164);function o({children:e,className:n}){return(0,l.jsx)("div",{className:(0,a.A)("tilesGrid_hB9N",n),children:e})}},81956(e,n,t){t.d(n,{A:()=>o});var l=t(74848);t(96540);var a=t(46077);let o=({steps:e,title:n,screenshot:t,width:o="normal"})=>(0,l.jsxs)("div",{className:"workflowContainer__N1v",children:[n&&(0,l.jsx)("h3",{className:"workflowTitle_QrAr",children:n}),t&&(0,l.jsx)("div",{className:"screenshotContainer_OwzZ",children:(0,l.jsx)(a.A,{src:t.src,alt:t.alt,width:t.width||"90%"})}),(0,l.jsx)("div",{className:"stepsContainer_IGeu",style:{maxWidth:"wide"===o?"850px":"700px"},children:e.map((n,t)=>(0,l.jsxs)("div",{className:"stepItem_GyHJ",children:[(0,l.jsxs)("div",{className:"stepIndicator_U2Wb",children:[(0,l.jsx)("div",{className:"stepNumber_vINc",children:n.icon?(0,l.jsx)(n.icon,{size:16}):(0,l.jsx)("span",{className:"stepNumberText_eLd7",children:t+1})}),t<e.length-1&&(0,l.jsx)("div",{className:"stepConnector_Si86"})]}),(0,l.jsxs)("div",{className:"stepContent_D0CA",children:[(0,l.jsx)("h4",{className:"stepTitle_wujx",children:n.title}),(0,l.jsx)("p",{className:"stepDescription_PIaE",children:n.description})]})]},t))})]})}}]);