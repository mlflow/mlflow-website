"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["1332"],{91410(e,t,n){n.r(t),n.d(t,{metadata:()=>l,default:()=>v,frontMatter:()=>x,contentTitle:()=>y,toc:()=>j,assets:()=>_});var l=JSON.parse('{"id":"tracing/integrations/listing/anthropic","title":"Tracing Anthropic","description":"MLflow Tracing provides automatic tracing capability for Anthropic LLMs. By enabling auto tracing","source":"@site/docs/genai/tracing/integrations/listing/anthropic.mdx","sourceDirName":"tracing/integrations/listing","slug":"/tracing/integrations/listing/anthropic","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/anthropic","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"sidebar_position":8,"sidebar_label":"Anthropic"},"sidebar":"genAISidebar","previous":{"title":"Watsonx Orchestrate","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/watsonx-orchestrate"},"next":{"title":"Bedrock","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/bedrock"}}'),a=n(74848),r=n(28453),o=n(54725),i=n(78010),s=n(57250),c=n(95986),p=n(89001),h=n(8060),d=n(10440),m=n(77541),f=n(46077),u=n(93893),g=n(60665),w=n(43975);let x={sidebar_position:8,sidebar_label:"Anthropic"},y="Tracing Anthropic",_={},j=[{value:"Getting Started",id:"getting-started",level:2},...h.RM,{value:"Supported APIs",id:"supported-apis",level:2},{value:"Async",id:"async",level:2},{value:"Advanced Example: Tool Calling Agent",id:"advanced-example-tool-calling-agent",level:2},{value:"Token usage",id:"token-usage",level:2},{value:"Supported APIs:",id:"supported-apis-1",level:4},{value:"Disable auto-tracing",id:"disable-auto-tracing",level:2},{value:"Next steps",id:"next-steps",level:2}];function A(e){let t={a:"a",code:"code",h1:"h1",h2:"h2",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.header,{children:(0,a.jsx)(t.h1,{id:"tracing-anthropic",children:"Tracing Anthropic"})}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.a,{href:"/genai/tracing",children:"MLflow Tracing"})," provides automatic tracing capability for Anthropic LLMs. By enabling auto tracing\nfor Anthropic by calling the ",(0,a.jsx)(o.B,{fn:"mlflow.anthropic.autolog"})," function, MLflow will capture nested traces and log them to the active MLflow Experiment upon invocation of Anthropic Python SDK."]}),"\n",(0,a.jsx)(f.A,{src:"/images/llms/anthropic/anthropic-tracing.png",alt:"Anthropic Tracing via autolog"}),"\n",(0,a.jsx)(t.p,{children:"MLflow trace automatically captures the following information about Anthropic calls:"}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:"Prompts and completion responses"}),"\n",(0,a.jsx)(t.li,{children:"Latencies"}),"\n",(0,a.jsx)(t.li,{children:"Model name"}),"\n",(0,a.jsxs)(t.li,{children:["Additional metadata such as ",(0,a.jsx)(t.code,{children:"temperature"}),", ",(0,a.jsx)(t.code,{children:"max_tokens"}),", if specified."]}),"\n",(0,a.jsx)(t.li,{children:"Function calling if returned in the response"}),"\n",(0,a.jsx)(t.li,{children:"Token usage information"}),"\n",(0,a.jsx)(t.li,{children:"Any exception if raised"}),"\n",(0,a.jsx)(t.li,{children:"and more..."}),"\n"]}),"\n",(0,a.jsx)(t.h2,{id:"getting-started",children:"Getting Started"}),"\n",(0,a.jsx)(p.A,{number:1,title:"Install Dependencies"}),"\n",(0,a.jsx)(c.A,{children:(0,a.jsxs)(i.A,{children:[(0,a.jsx)(s.A,{value:"python",label:"Python",default:!0,children:(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:"pip install 'mlflow[genai]' anthropic\n"})})}),(0,a.jsx)(s.A,{value:"typescript",label:"JS / TS",children:(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:"npm install mlflow-anthropic @anthropic-ai/sdk\n"})})})]})}),"\n",(0,a.jsx)(p.A,{number:2,title:"Start MLflow Server"}),"\n",(0,a.jsx)(h.Ay,{}),"\n",(0,a.jsx)(p.A,{number:3,title:"Enable Tracing and Make API Calls"}),"\n",(0,a.jsx)(c.A,{children:(0,a.jsxs)(i.A,{children:[(0,a.jsxs)(s.A,{value:"python",label:"Chat Completion API",default:!0,children:[(0,a.jsxs)(t.p,{children:["Enable tracing with ",(0,a.jsx)(t.code,{children:"mlflow.anthropic.autolog()"})," and make API calls as usual."]}),(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'import anthropic\nimport mlflow\n\n# Enable auto-tracing for Anthropic\nmlflow.anthropic.autolog()\n\n# Set a tracking URI and an experiment\nmlflow.set_tracking_uri("http://localhost:5000")\nmlflow.set_experiment("Anthropic")\n\n# Invoke the Anthropic model as usual.\n# Make sure your API key is set via the ANTHROPIC_API_KEY environment variable.\nclient = anthropic.Anthropic()\n\nmessage = client.messages.create(\n    model="claude-sonnet-4-5-2025092",\n    max_tokens=512,\n    messages=[\n        {"role": "user", "content": "Hello, Claude"},\n    ],\n)\n'})})]}),(0,a.jsxs)(s.A,{value:"typescript",label:"JS / TS",children:[(0,a.jsxs)(t.p,{children:["Wrap the Anthropic client with the ",(0,a.jsx)(t.code,{children:"tracedAnthropic"})," function and make API calls as usual."]}),(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-typescript",children:'import Anthropic from "@anthropic-ai/sdk";\nimport { tracedAnthropic } from "mlflow-anthropic";\n\n// Wrap the Anthropic client with the tracedAnthropic function\nconst client = tracedAnthropic(new Anthropic());\n\n// Invoke the client as usual\nconst message = await client.messages.create({\n  model: "claude-3-7-sonnet-20250219",\n  max_tokens: 512,\n  messages: [\n    { role: "user", content: "Hello, Claude" },\n  ],\n});\n'})})]})]})}),"\n",(0,a.jsx)(p.A,{number:4,title:"View Traces in MLflow UI"}),"\n",(0,a.jsxs)(t.p,{children:["Browse to the MLflow UI at ",(0,a.jsx)(t.a,{href:"http://localhost:5000",children:"http://localhost:5000"})," (or your MLflow server URL) and you should see the traces for the Anthropic API calls."]}),"\n",(0,a.jsx)(f.A,{src:"/images/llms/anthropic/anthropic-basic-tracing.png",alt:"Anthropic Tracing"}),"\n",(0,a.jsx)(t.h2,{id:"supported-apis",children:"Supported APIs"}),"\n",(0,a.jsx)(t.p,{children:"MLflow supports automatic tracing for the following Anthropic APIs:"}),"\n",(0,a.jsxs)(t.table,{children:[(0,a.jsx)(t.thead,{children:(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.th,{style:{textAlign:"center"},children:"Chat Completion"}),(0,a.jsx)(t.th,{style:{textAlign:"center"},children:"Function Calling"}),(0,a.jsx)(t.th,{style:{textAlign:"center"},children:"Streaming"}),(0,a.jsx)(t.th,{style:{textAlign:"center"},children:"Async"}),(0,a.jsx)(t.th,{style:{textAlign:"center"},children:"Image"}),(0,a.jsx)(t.th,{style:{textAlign:"center"},children:"Batch"})]})}),(0,a.jsx)(t.tbody,{children:(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.td,{style:{textAlign:"center"},children:"\u2705"}),(0,a.jsx)(t.td,{style:{textAlign:"center"},children:"\u2705"}),(0,a.jsx)(t.td,{style:{textAlign:"center"},children:"-"}),(0,a.jsx)(t.td,{style:{textAlign:"center"},children:"\u2705 (*1)"}),(0,a.jsx)(t.td,{style:{textAlign:"center"},children:"-"}),(0,a.jsx)(t.td,{style:{textAlign:"center"},children:"-"})]})})]}),"\n",(0,a.jsx)("div",{style:{fontSize:"0.9em",marginTop:"10px"},children:(0,a.jsx)(t.p,{children:"(*1) Async support was added in MLflow 2.21.0."})}),"\n",(0,a.jsxs)(t.p,{children:["To request support for additional APIs, please open a ",(0,a.jsx)(t.a,{href:"https://github.com/mlflow/mlflow/issues",children:"feature request"})," on GitHub."]}),"\n",(0,a.jsx)(t.h2,{id:"async",children:"Async"}),"\n",(0,a.jsx)(t.p,{children:"MLflow Tracing has supported the asynchronous API of the Anthropic SDK since MLflow 2.21.0. Its usage is the same as the synchronous API."}),"\n",(0,a.jsxs)(i.A,{children:[(0,a.jsx)(s.A,{value:"python",label:"Python",default:!0,children:(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'import anthropic\n\n# Enable trace logging\nmlflow.anthropic.autolog()\n\nclient = anthropic.AsyncAnthropic()\n\nresponse = await client.messages.create(\n    model="claude-3-5-sonnet-20241022",\n    max_tokens=1024,\n    messages=[\n        {"role": "user", "content": "Hello, Claude"},\n    ],\n)\n'})})}),(0,a.jsx)(s.A,{value:"typescript",label:"JS / TS",children:(0,a.jsx)(t.p,{children:"Anthropic Typescript / Javascript SDK is natively async. See the Getting Started example above."})})]}),"\n",(0,a.jsx)(t.h2,{id:"advanced-example-tool-calling-agent",children:"Advanced Example: Tool Calling Agent"}),"\n",(0,a.jsxs)(t.p,{children:["MLflow Tracing automatically captures tool calling response from Anthropic models. The function instruction in the response will be highlighted in the trace UI. Moreover, you can annotate the tool function with the ",(0,a.jsx)(t.code,{children:"@mlflow.trace"})," decorator to create a span for the tool execution."]}),"\n",(0,a.jsx)(t.p,{children:"The following example implements a simple function calling agent using Anthropic Tool Calling and MLflow Tracing for Anthropic. The example further uses the asynchronous Anthropic SDK so that the agent can handle concurrent invocations without blocking."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'import json\nimport anthropic\nimport mlflow\nimport asyncio\nfrom mlflow.entities import SpanType\n\nclient = anthropic.AsyncAnthropic()\nmodel_name = "claude-sonnet-4-5-20250929"\n\n\n# Define the tool function. Decorate it with `@mlflow.trace` to create a span for its execution.\n@mlflow.trace(span_type=SpanType.TOOL)\nasync def get_weather(city: str) -> str:\n    if city == "Tokyo":\n        return "sunny"\n    elif city == "Paris":\n        return "rainy"\n    return "unknown"\n\n\ntools = [\n    {\n        "name": "get_weather",\n        "description": "Returns the weather condition of a given city.",\n        "input_schema": {\n            "type": "object",\n            "properties": {"city": {"type": "string"}},\n            "required": ["city"],\n        },\n    }\n]\n\n_tool_functions = {"get_weather": get_weather}\n\n\n# Define a simple tool calling agent\n@mlflow.trace(span_type=SpanType.AGENT)\nasync def run_tool_agent(question: str):\n    messages = [{"role": "user", "content": question}]\n\n    # Invoke the model with the given question and available tools\n    ai_msg = await client.messages.create(\n        model=model_name,\n        messages=messages,\n        tools=tools,\n        max_tokens=2048,\n    )\n    messages.append({"role": "assistant", "content": ai_msg.content})\n\n    # If the model requests tool call(s), invoke the function with the specified arguments\n    tool_calls = [c for c in ai_msg.content if c.type == "tool_use"]\n    for tool_call in tool_calls:\n        if tool_func := _tool_functions.get(tool_call.name):\n            tool_result = await tool_func(**tool_call.input)\n        else:\n            raise RuntimeError("An invalid tool is returned from the assistant!")\n\n        messages.append(\n            {\n                "role": "user",\n                "content": [\n                    {\n                        "type": "tool_result",\n                        "tool_use_id": tool_call.id,\n                        "content": tool_result,\n                    }\n                ],\n            }\n        )\n\n    # Send the tool results to the model and get a new response\n    response = await client.messages.create(\n        model=model_name,\n        messages=messages,\n        max_tokens=2048,\n    )\n\n    return response.content[-1].text\n\n\n# Run the tool calling agent\ncities = ["Tokyo", "Paris", "Sydney"]\nquestions = [f"What\'s the weather like in {city} today?" for city in cities]\nanswers = await asyncio.gather(*(run_tool_agent(q) for q in questions))\n\nfor city, answer in zip(cities, answers):\n    print(f"{city}: {answer}")\n'})}),"\n",(0,a.jsx)(t.h2,{id:"token-usage",children:"Token usage"}),"\n",(0,a.jsxs)(t.p,{children:["MLflow >= 3.2.0 supports token usage tracking for Anthropic. The token usage for each LLM call will be logged in the ",(0,a.jsx)(t.code,{children:"mlflow.chat.tokenUsage"})," attribute. The total token usage throughout the trace will be\navailable in the ",(0,a.jsx)(t.code,{children:"token_usage"})," field of the trace info object."]}),"\n",(0,a.jsxs)(i.A,{children:[(0,a.jsx)(s.A,{value:"python",label:"Python",default:!0,children:(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'import json\nimport anthropic\nimport mlflow\n\nmlflow.anthropic.autolog()\n\nclient = anthropic.Anthropic()\nmessage = client.messages.create(\n    model="claude-3-5-sonnet-20241022",\n    max_tokens=1024,\n    messages=[{"role": "user", "content": "Hello"}],\n)\n\n# Get the trace object just created\nlast_trace_id = mlflow.get_last_active_trace_id()\ntrace = mlflow.get_trace(trace_id=last_trace_id)\n\n# Print the token usage\ntotal_usage = trace.info.token_usage\nprint("== Total token usage: ==")\nprint(f"  Input tokens: {total_usage[\'input_tokens\']}")\nprint(f"  Output tokens: {total_usage[\'output_tokens\']}")\nprint(f"  Total tokens: {total_usage[\'total_tokens\']}")\n\n# Print the token usage for each LLM call\nprint("\\n== Detailed usage for each LLM call: ==")\nfor span in trace.data.spans:\n    if usage := span.get_attribute("mlflow.chat.tokenUsage"):\n        print(f"{span.name}:")\n        print(f"  Input tokens: {usage[\'input_tokens\']}")\n        print(f"  Output tokens: {usage[\'output_tokens\']}")\n        print(f"  Total tokens: {usage[\'total_tokens\']}")\n'})})}),(0,a.jsx)(s.A,{value:"typescript",label:"JS / TS",children:(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-typescript",children:'import * as mlflow from "mlflow-tracing";\n\n// After your Anthropic call completes, flush and fetch the trace\nawait mlflow.flushTraces();\nconst lastTraceId = mlflow.getLastActiveTraceId();\n\nif (lastTraceId) {\n  const client = new mlflow.MlflowClient({ trackingUri: "http://localhost:5000" });\n  const trace = await client.getTrace(lastTraceId);\n\n  // Total token usage on the trace\n  console.log("== Total token usage: ==");\n  console.log(trace.info.tokenUsage); // { input_tokens, output_tokens, total_tokens }\n\n  // Per-span usage (if provided by the provider)\n  console.log("\\n== Detailed usage for each LLM call: ==");\n  for (const span of trace.data.spans) {\n    const usage = span.attributes?.["mlflow.chat.tokenUsage"];\n    if (usage) {\n      console.log(`${span.name}:`, usage);\n    }\n  }\n}\n'})})})]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:"== Total token usage: ==\n  Input tokens: 8\n  Output tokens: 12\n  Total tokens: 20\n\n== Detailed usage for each LLM call: ==\nMessages.create:\n  Input tokens: 8\n  Output tokens: 12\n  Total tokens: 20\n"})}),"\n",(0,a.jsx)(t.h4,{id:"supported-apis-1",children:"Supported APIs:"}),"\n",(0,a.jsx)(t.p,{children:"Token usage tracking is supported for the following Anthropic APIs:"}),"\n",(0,a.jsxs)(t.table,{children:[(0,a.jsx)(t.thead,{children:(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.th,{style:{textAlign:"center"},children:"Chat Completion"}),(0,a.jsx)(t.th,{style:{textAlign:"center"},children:"Function Calling"}),(0,a.jsx)(t.th,{style:{textAlign:"center"},children:"Streaming"}),(0,a.jsx)(t.th,{style:{textAlign:"center"},children:"Async"}),(0,a.jsx)(t.th,{style:{textAlign:"center"},children:"Image"}),(0,a.jsx)(t.th,{style:{textAlign:"center"},children:"Batch"})]})}),(0,a.jsx)(t.tbody,{children:(0,a.jsxs)(t.tr,{children:[(0,a.jsx)(t.td,{style:{textAlign:"center"},children:"\u2705"}),(0,a.jsx)(t.td,{style:{textAlign:"center"},children:"\u2705"}),(0,a.jsx)(t.td,{style:{textAlign:"center"},children:"-"}),(0,a.jsx)(t.td,{style:{textAlign:"center"},children:"\u2705 (*1)"}),(0,a.jsx)(t.td,{style:{textAlign:"center"},children:"-"}),(0,a.jsx)(t.td,{style:{textAlign:"center"},children:"-"})]})})]}),"\n",(0,a.jsx)("div",{style:{fontSize:"0.9em",marginTop:"10px"},children:(0,a.jsx)(t.p,{children:"(*1) Async support was added in MLflow 2.21.0."})}),"\n",(0,a.jsx)(t.h2,{id:"disable-auto-tracing",children:"Disable auto-tracing"}),"\n",(0,a.jsxs)(t.p,{children:["Auto tracing for Anthropic can be disabled globally by calling ",(0,a.jsx)(t.code,{children:"mlflow.anthropic.autolog(disable=True)"})," or ",(0,a.jsx)(t.code,{children:"mlflow.autolog(disable=True)"}),"."]}),"\n",(0,a.jsx)(t.h2,{id:"next-steps",children:"Next steps"}),"\n",(0,a.jsxs)(d.A,{children:[(0,a.jsx)(m.A,{icon:u.A,iconSize:48,title:"Track User Feedback",description:"Record user feedback on traces for tracking user satisfaction.",href:"/genai/tracing/collect-user-feedback",linkText:"Learn about feedback \u2192",containerHeight:64}),(0,a.jsx)(m.A,{icon:g.A,iconSize:48,title:"Manage Prompts",description:"Learn how to manage prompts with MLflow's prompt registry.",href:"/genai/prompt-registry",linkText:"Manage prompts \u2192",containerHeight:64}),(0,a.jsx)(m.A,{icon:w.A,iconSize:48,title:"Evaluate Traces",description:"Evaluate traces with LLM judges to understand and improve your AI application's behavior.",href:"/genai/eval-monitor/running-evaluation/traces",linkText:"Evaluate traces \u2192",containerHeight:64})]})]})}function v(e={}){let{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(A,{...e})}):A(e)}},8060(e,t,n){n.d(t,{Ay:()=>p,RM:()=>s});var l=n(74848),a=n(28453),r=n(78010),o=n(57250),i=n(95986);let s=[];function c(e){let t={a:"a",code:"code",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,l.jsx)(i.A,{children:(0,l.jsxs)(r.A,{children:[(0,l.jsxs)(o.A,{value:"local",label:"Local (pip)",default:!0,children:[(0,l.jsxs)(t.p,{children:["If you have a local Python environment >= 3.10, you can start the MLflow server locally using the ",(0,l.jsx)(t.code,{children:"mlflow"})," CLI command."]}),(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-bash",children:"mlflow server\n"})})]}),(0,l.jsxs)(o.A,{value:"docker",label:"Local (docker)",children:[(0,l.jsx)(t.p,{children:"MLflow also provides a Docker Compose file to start a local MLflow server with a postgres database and a minio server."}),(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-bash",children:"git clone --depth 1 --filter=blob:none --sparse https://github.com/mlflow/mlflow.git\ncd mlflow\ngit sparse-checkout set docker-compose\ncd docker-compose\ncp .env.dev.example .env\ndocker compose up -d\n"})}),(0,l.jsxs)(t.p,{children:["Refer to the ",(0,l.jsx)(t.a,{href:"https://github.com/mlflow/mlflow/tree/master/docker-compose/README.md",children:"instruction"})," for more details, e.g., overriding the default environment variables."]})]})]})})}function p(e={}){let{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,l.jsx)(t,{...e,children:(0,l.jsx)(c,{...e})}):c(e)}},75689(e,t,n){n.d(t,{A:()=>s});var l=n(96540);let a=e=>{let t=e.replace(/^([A-Z])|[\s-_]+(\w)/g,(e,t,n)=>n?n.toUpperCase():t.toLowerCase());return t.charAt(0).toUpperCase()+t.slice(1)},r=(...e)=>e.filter((e,t,n)=>!!e&&""!==e.trim()&&n.indexOf(e)===t).join(" ").trim();var o={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};let i=(0,l.forwardRef)(({color:e="currentColor",size:t=24,strokeWidth:n=2,absoluteStrokeWidth:a,className:i="",children:s,iconNode:c,...p},h)=>(0,l.createElement)("svg",{ref:h,...o,width:t,height:t,stroke:e,strokeWidth:a?24*Number(n)/Number(t):n,className:r("lucide",i),...!s&&!(e=>{for(let t in e)if(t.startsWith("aria-")||"role"===t||"title"===t)return!0})(p)&&{"aria-hidden":"true"},...p},[...c.map(([e,t])=>(0,l.createElement)(e,t)),...Array.isArray(s)?s:[s]])),s=(e,t)=>{let n=(0,l.forwardRef)(({className:n,...o},s)=>(0,l.createElement)(i,{ref:s,iconNode:t,className:r(`lucide-${a(e).replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()}`,`lucide-${e}`,n),...o}));return n.displayName=a(e),n}},60665(e,t,n){n.d(t,{A:()=>l});let l=(0,n(75689).A)("book-open",[["path",{d:"M12 7v14",key:"1akyts"}],["path",{d:"M3 18a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h5a4 4 0 0 1 4 4 4 4 0 0 1 4-4h5a1 1 0 0 1 1 1v13a1 1 0 0 1-1 1h-6a3 3 0 0 0-3 3 3 3 0 0 0-3-3z",key:"ruj8y"}]])},43975(e,t,n){n.d(t,{A:()=>l});let l=(0,n(75689).A)("scale",[["path",{d:"m16 16 3-8 3 8c-.87.65-1.92 1-3 1s-2.13-.35-3-1Z",key:"7g6ntu"}],["path",{d:"m2 16 3-8 3 8c-.87.65-1.92 1-3 1s-2.13-.35-3-1Z",key:"ijws7r"}],["path",{d:"M7 21h10",key:"1b0cd5"}],["path",{d:"M12 3v18",key:"108xh3"}],["path",{d:"M3 7h2c2 0 5-1 7-2 2 1 5 2 7 2h2",key:"3gwbw2"}]])},93893(e,t,n){n.d(t,{A:()=>l});let l=(0,n(75689).A)("users",[["path",{d:"M16 21v-2a4 4 0 0 0-4-4H6a4 4 0 0 0-4 4v2",key:"1yyitq"}],["path",{d:"M16 3.128a4 4 0 0 1 0 7.744",key:"16gr8j"}],["path",{d:"M22 21v-2a4 4 0 0 0-3-3.87",key:"kshegd"}],["circle",{cx:"9",cy:"7",r:"4",key:"nufk8"}]])},57250(e,t,n){n.d(t,{A:()=>r});var l=n(74848);n(96540);var a=n(34164);function r({children:e,hidden:t,className:n}){return(0,l.jsx)("div",{role:"tabpanel",className:(0,a.A)("tabItem_Ymn6",n),hidden:t,children:e})}},78010(e,t,n){n.d(t,{A:()=>y});var l=n(74848),a=n(96540),r=n(34164),o=n(88287),i=n(28584),s=n(56347),c=n(99989),p=n(96629),h=n(80618),d=n(41367);function m(e){return a.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,a.isValidElement)(e)&&function(e){let{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function f({value:e,tabValues:t}){return t.some(t=>t.value===e)}var u=n(19863);function g({className:e,block:t,selectedValue:n,selectValue:a,tabValues:o}){let s=[],{blockElementScrollPositionUntilNextRender:c}=(0,i.a_)(),p=e=>{let t=e.currentTarget,l=o[s.indexOf(t)].value;l!==n&&(c(t),a(l))},h=e=>{let t=null;switch(e.key){case"Enter":p(e);break;case"ArrowRight":{let n=s.indexOf(e.currentTarget)+1;t=s[n]??s[0];break}case"ArrowLeft":{let n=s.indexOf(e.currentTarget)-1;t=s[n]??s[s.length-1]}}t?.focus()};return(0,l.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":t},e),children:o.map(({value:e,label:t,attributes:a})=>(0,l.jsx)("li",{role:"tab",tabIndex:n===e?0:-1,"aria-selected":n===e,ref:e=>{s.push(e)},onKeyDown:h,onClick:p,...a,className:(0,r.A)("tabs__item","tabItem_LNqP",a?.className,{"tabs__item--active":n===e}),children:t??e},e))})}function w({lazy:e,children:t,selectedValue:n}){let o=(Array.isArray(t)?t:[t]).filter(Boolean);if(e){let e=o.find(e=>e.props.value===n);return e?(0,a.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,l.jsx)("div",{className:"margin-top--md",children:o.map((e,t)=>(0,a.cloneElement)(e,{key:t,hidden:e.props.value!==n}))})}function x(e){let t=function(e){let t,{defaultValue:n,queryString:l=!1,groupId:r}=e,o=function(e){let{values:t,children:n}=e;return(0,a.useMemo)(()=>{let e=t??m(n).map(({props:{value:e,label:t,attributes:n,default:l}})=>({value:e,label:t,attributes:n,default:l})),l=(0,h.XI)(e,(e,t)=>e.value===t.value);if(l.length>0)throw Error(`Docusaurus error: Duplicate values "${l.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`);return e},[t,n])}(e),[i,u]=(0,a.useState)(()=>(function({defaultValue:e,tabValues:t}){if(0===t.length)throw Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!f({value:e,tabValues:t}))throw Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${t.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}let n=t.find(e=>e.default)??t[0];if(!n)throw Error("Unexpected error: 0 tabValues");return n.value})({defaultValue:n,tabValues:o})),[g,w]=function({queryString:e=!1,groupId:t}){let n=(0,s.W6)(),l=function({queryString:e=!1,groupId:t}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!t)throw Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:e,groupId:t});return[(0,p.aZ)(l),(0,a.useCallback)(e=>{if(!l)return;let t=new URLSearchParams(n.location.search);t.set(l,e),n.replace({...n.location,search:t.toString()})},[l,n])]}({queryString:l,groupId:r}),[x,y]=function({groupId:e}){let t=e?`docusaurus.tab.${e}`:null,[n,l]=(0,d.Dv)(t);return[n,(0,a.useCallback)(e=>{t&&l.set(e)},[t,l])]}({groupId:r}),_=f({value:t=g??x,tabValues:o})?t:null;return(0,c.A)(()=>{_&&u(_)},[_]),{selectedValue:i,selectValue:(0,a.useCallback)(e=>{if(!f({value:e,tabValues:o}))throw Error(`Can't select invalid tab value=${e}`);u(e),w(e),y(e)},[w,y,o]),tabValues:o}}(e);return(0,l.jsxs)("div",{className:(0,r.A)(o.G.tabs.container,"tabs-container","tabList__CuJ"),children:[(0,l.jsx)(g,{...t,...e}),(0,l.jsx)(w,{...t,...e})]})}function y(e){let t=(0,u.A)();return(0,l.jsx)(x,{...e,children:m(e.children)},String(t))}},54725(e,t,n){n.d(t,{B:()=>o});var l=n(74848);n(96540);var a=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}'),r=n(66497);function o({fn:e,children:t,hash:n}){let o=(e=>{let t=e.split(".");for(let e=t.length;e>0;e--){let n=t.slice(0,e).join(".");if(a[n])return n}return null})(e);if(!o)return(0,l.jsx)(l.Fragment,{children:t});let i=(0,r.default)(`/${a[o]}#${n??e}`);return(0,l.jsx)("a",{href:i,target:"_blank",children:t??(0,l.jsxs)("code",{children:[e,"()"]})})}},46077(e,t,n){n.d(t,{A:()=>r});var l=n(74848);n(96540);var a=n(66497);function r({src:e,alt:t,width:n,caption:r,className:o}){return(0,l.jsxs)("div",{className:`container_JwLF ${o||""}`,children:[(0,l.jsx)("div",{className:"imageWrapper_RfGN",style:n?{width:n}:{},children:(0,l.jsx)("img",{src:(0,a.default)(e),alt:t,className:"image_bwOA"})}),r&&(0,l.jsx)("p",{className:"caption_jo2G",children:r})]})}},89001(e,t,n){n.d(t,{A:()=>a});var l=n(74848);n(96540);let a=({number:e,title:t})=>(0,l.jsxs)("div",{className:"stepHeader_RqmM",children:[(0,l.jsx)("div",{className:"stepNumber_exmH",children:e}),(0,l.jsx)("h3",{className:"stepTitle_SzBx",children:t})]})},95986(e,t,n){n.d(t,{A:()=>a});var l=n(74848);n(96540);function a({children:e}){return(0,l.jsx)("div",{className:"wrapper_sf5q",children:e})}},77541(e,t,n){n.d(t,{A:()=>c});var l=n(74848);n(96540);var a=n(95310),r=n(34164);let o="tileImage_O4So";var i=n(66497),s=n(92802);function c({icon:e,image:t,imageDark:n,imageWidth:c,imageHeight:p,iconSize:h=32,containerHeight:d,title:m,description:f,href:u,linkText:g="Learn more \u2192",className:w}){if(!e&&!t)throw Error("TileCard requires either an icon or image prop");let x=d?{height:`${d}px`}:{},y={};return c&&(y.width=`${c}px`),p&&(y.height=`${p}px`),(0,l.jsxs)(a.A,{href:u,className:(0,r.A)("tileCard_NHsj",w),children:[(0,l.jsx)("div",{className:"tileIcon_pyoR",style:x,children:e?(0,l.jsx)(e,{size:h}):n?(0,l.jsx)(s.A,{sources:{light:(0,i.default)(t),dark:(0,i.default)(n)},alt:m,className:o,style:y}):(0,l.jsx)("img",{src:(0,i.default)(t),alt:m,className:o,style:y})}),(0,l.jsx)("h3",{children:m}),(0,l.jsx)("p",{children:f}),(0,l.jsx)("div",{className:"tileLink_iUbu",children:g})]})}},10440(e,t,n){n.d(t,{A:()=>r});var l=n(74848);n(96540);var a=n(34164);function r({children:e,className:t}){return(0,l.jsx)("div",{className:(0,a.A)("tilesGrid_hB9N",t),children:e})}},28453(e,t,n){n.d(t,{R:()=>o,x:()=>i});var l=n(96540);let a={},r=l.createContext(a);function o(e){let t=l.useContext(r);return l.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),l.createElement(r.Provider,{value:t},e.children)}}}]);