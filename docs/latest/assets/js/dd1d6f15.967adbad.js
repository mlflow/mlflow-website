/*! For license information please see dd1d6f15.967adbad.js.LICENSE.txt */
"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[2554],{6789:(e,n,t)=>{t.d(n,{A:()=>c});t(96540);var a=t(28774),r=t(34164);const l={tileCard:"tileCard_NHsj",tileIcon:"tileIcon_pyoR",tileLink:"tileLink_iUbu",tileImage:"tileImage_O4So"};var i=t(86025),o=t(15626),s=t(74848);function c({icon:e,image:n,imageDark:t,imageWidth:c,imageHeight:d,iconSize:p=32,containerHeight:h,title:u,description:m,href:f,linkText:g="Learn more \u2192",className:w}){if(!e&&!n)throw new Error("TileCard requires either an icon or image prop");const _=h?{height:`${h}px`}:{},j={};return c&&(j.width=`${c}px`),d&&(j.height=`${d}px`),(0,s.jsxs)(a.A,{href:f,className:(0,r.A)(l.tileCard,w),children:[(0,s.jsx)("div",{className:l.tileIcon,style:_,children:e?(0,s.jsx)(e,{size:p}):t?(0,s.jsx)(o.A,{sources:{light:(0,i.default)(n),dark:(0,i.default)(t)},alt:u,className:l.tileImage,style:j}):(0,s.jsx)("img",{src:(0,i.default)(n),alt:u,className:l.tileImage,style:j})}),(0,s.jsx)("h3",{children:u}),(0,s.jsx)("p",{children:m}),(0,s.jsx)("div",{className:l.tileLink,children:g})]})}},11470:(e,n,t)=>{t.d(n,{A:()=>b});var a=t(96540),r=t(34164),l=t(17559),i=t(23104),o=t(56347),s=t(205),c=t(57485),d=t(31682),p=t(70679);function h(e){return a.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function u(e){const{values:n,children:t}=e;return(0,a.useMemo)(()=>{const e=n??function(e){return h(e).map(({props:{value:e,label:n,attributes:t,default:a}})=>({value:e,label:n,attributes:t,default:a}))}(t);return function(e){const n=(0,d.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,t])}function m({value:e,tabValues:n}){return n.some(n=>n.value===e)}function f({queryString:e=!1,groupId:n}){const t=(0,o.W6)(),r=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,c.aZ)(r),(0,a.useCallback)(e=>{if(!r)return;const n=new URLSearchParams(t.location.search);n.set(r,e),t.replace({...t.location,search:n.toString()})},[r,t])]}function g(e){const{defaultValue:n,queryString:t=!1,groupId:r}=e,l=u(e),[i,o]=(0,a.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!m({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const t=n.find(e=>e.default)??n[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:l})),[c,d]=f({queryString:t,groupId:r}),[h,g]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[t,r]=(0,p.Dv)(n);return[t,(0,a.useCallback)(e=>{n&&r.set(e)},[n,r])]}({groupId:r}),w=(()=>{const e=c??h;return m({value:e,tabValues:l})?e:null})();(0,s.A)(()=>{w&&o(w)},[w]);return{selectedValue:i,selectValue:(0,a.useCallback)(e=>{if(!m({value:e,tabValues:l}))throw new Error(`Can't select invalid tab value=${e}`);o(e),d(e),g(e)},[d,g,l]),tabValues:l}}var w=t(92303);const _={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var j=t(74848);function x({className:e,block:n,selectedValue:t,selectValue:a,tabValues:l}){const o=[],{blockElementScrollPositionUntilNextRender:s}=(0,i.a_)(),c=e=>{const n=e.currentTarget,r=o.indexOf(n),i=l[r].value;i!==t&&(s(n),a(i))},d=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=o.indexOf(e.currentTarget)+1;n=o[t]??o[0];break}case"ArrowLeft":{const t=o.indexOf(e.currentTarget)-1;n=o[t]??o[o.length-1];break}}n?.focus()};return(0,j.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":n},e),children:l.map(({value:e,label:n,attributes:a})=>(0,j.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{o.push(e)},onKeyDown:d,onClick:c,...a,className:(0,r.A)("tabs__item",_.tabItem,a?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function y({lazy:e,children:n,selectedValue:t}){const l=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=l.find(e=>e.props.value===t);return e?(0,a.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,j.jsx)("div",{className:"margin-top--md",children:l.map((e,n)=>(0,a.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function v(e){const n=g(e);return(0,j.jsxs)("div",{className:(0,r.A)(l.G.tabs.container,"tabs-container",_.tabList),children:[(0,j.jsx)(x,{...n,...e}),(0,j.jsx)(y,{...n,...e})]})}function b(e){const n=(0,w.A)();return(0,j.jsx)(v,{...e,children:h(e.children)},String(n))}},19365:(e,n,t)=>{t.d(n,{A:()=>i});t(96540);var a=t(34164);const r={tabItem:"tabItem_Ymn6"};var l=t(74848);function i({children:e,hidden:n,className:t}){return(0,l.jsx)("div",{role:"tabpanel",className:(0,a.A)(r.tabItem,t),hidden:n,children:e})}},25358:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/llm-judge-vs-agent-judge-64ca5835fdfc045c406055ab2510218a.png"},28453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>o});var a=t(96540);const r={},l=a.createContext(r);function i(e){const n=a.useContext(l);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),a.createElement(l.Provider,{value:n},e.children)}},46816:(e,n,t)=>{t.d(n,{A:()=>a});const a=(0,t(84722).A)("wrench",[["path",{d:"M14.7 6.3a1 1 0 0 0 0 1.4l1.6 1.6a1 1 0 0 0 1.4 0l3.77-3.77a6 6 0 0 1-7.94 7.94l-6.91 6.91a2.12 2.12 0 0 1-3-3l6.91-6.91a6 6 0 0 1 7.94-7.94l-3.76 3.76z",key:"cbrjhi"}]])},47020:(e,n,t)=>{t.d(n,{A:()=>l});t(96540);const a={wrapper:"wrapper_sf5q"};var r=t(74848);function l({children:e}){return(0,r.jsx)("div",{className:a.wrapper,children:e})}},49374:(e,n,t)=>{t.d(n,{B:()=>o});t(96540);const a=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}');var r=t(86025),l=t(74848);const i=e=>{const n=e.split(".");for(let t=n.length;t>0;t--){const e=n.slice(0,t).join(".");if(a[e])return e}return null};function o({fn:e,children:n,hash:t}){const o=i(e);if(!o)return(0,l.jsx)(l.Fragment,{children:n});const s=(0,r.default)(`/${a[o]}#${t??e}`);return(0,l.jsx)("a",{href:s,target:"_blank",children:n??(0,l.jsxs)("code",{children:[e,"()"]})})}},65592:(e,n,t)=>{t.d(n,{A:()=>i});t(96540);var a=t(34164);const r={tilesGrid:"tilesGrid_hB9N"};var l=t(74848);function i({children:e,className:n}){return(0,l.jsx)("div",{className:(0,a.A)(r.tilesGrid,n),children:e})}},66927:(e,n,t)=>{t.d(n,{A:()=>i});t(96540);const a={container:"container_JwLF",imageWrapper:"imageWrapper_RfGN",image:"image_bwOA",caption:"caption_jo2G"};var r=t(86025),l=t(74848);function i({src:e,alt:n,width:t,caption:i,className:o}){return(0,l.jsxs)("div",{className:`${a.container} ${o||""}`,children:[(0,l.jsx)("div",{className:a.imageWrapper,style:t?{width:t}:{},children:(0,l.jsx)("img",{src:(0,r.default)(e),alt:n,className:a.image})}),i&&(0,l.jsx)("p",{className:a.caption,children:i})]})}},72271:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>_,contentTitle:()=>w,default:()=>y,frontMatter:()=>g,metadata:()=>a,toc:()=>j});const a=JSON.parse('{"id":"eval-monitor/scorers/llm-judge/agentic-overview","title":"Agent-based Scorers (Agent-as-a-Judge)","description":"Understanding how judges become autonomous agents for deep trace analysis","source":"@site/docs/genai/eval-monitor/scorers/llm-judge/agentic-overview.mdx","sourceDirName":"eval-monitor/scorers/llm-judge","slug":"/eval-monitor/scorers/llm-judge/agentic-overview","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/agentic-overview","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Agent-based Scorers (Agent-as-a-Judge)","description":"Understanding how judges become autonomous agents for deep trace analysis"},"sidebar":"genAISidebar","previous":{"title":"Guidelines-based","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/guidelines"},"next":{"title":"Code-based Scorers","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/custom"}}');var r=t(74848),l=t(28453),i=t(49374),o=t(11470),s=t(19365),c=t(66927),d=t(47020),p=t(65592),h=t(6789),u=t(46816),m=t(93893),f=t(87073);const g={title:"Agent-based Scorers (Agent-as-a-Judge)",description:"Understanding how judges become autonomous agents for deep trace analysis"},w="Agent-based Scorer (aka. Agent-as-a-Judge)",_={},j=[{value:"How it works",id:"how-it-works",level:2},{value:"Comparison with LLM-as-a-Judge",id:"comparison-with-llm-as-a-judge",level:2},{value:"When to use Agent-as-a-Judge?",id:"when-to-use-agent-as-a-judge",level:3},{value:"When to use LLM-as-a-Judge?",id:"when-to-use-llm-as-a-judge",level:3},{value:"Quickstart",id:"quickstart",level:2},{value:"Running the Judge against Batch Traces",id:"running-the-judge-against-batch-traces",level:2},{value:"Advanced Examples",id:"advanced-examples",level:2},{value:"Debugging Agent Judges",id:"debugging-agent-judges",level:2},{value:"Next Steps",id:"next-steps",level:2}];function x(e){const n={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"agent-based-scorer-aka-agent-as-a-judge",children:"Agent-based Scorer (aka. Agent-as-a-Judge)"})}),"\n",(0,r.jsxs)(n.p,{children:["Agent-as-a-Judge represents a paradigm shift in LLM evaluation. Instead of simply assessing inputs and outputs, these judges act as ",(0,r.jsx)(n.strong,{children:"autonomous agents"})," equipped with tools to investigate your application's execution in depth."]}),"\n",(0,r.jsx)(n.h2,{id:"how-it-works",children:"How it works"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:t(25358).A+"",width:"898",height:"518"})}),"\n",(0,r.jsx)(n.p,{children:"Agent-as-a-Judge uses the following tools to investigate traces logged to the MLflow backend. These tools enable the judge to act like an experienced debugger, systematically exploring your application's execution."}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Tool"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"GetTraceInfo"})}),(0,r.jsx)(n.td,{children:"Retrieves high-level information about a trace including timing, status, and metadata."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"ListSpans"})}),(0,r.jsx)(n.td,{children:"Lists all spans in a trace with their hierarchy, timing, and basic attributes."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"GetSpan"})}),(0,r.jsx)(n.td,{children:"Fetches detailed information about a specific span including inputs, outputs, and custom attributes."})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"SearchTraceRegex"})}),(0,r.jsx)(n.td,{children:"Searches for patterns across all span data using regular expressions."})]})]})]}),"\n",(0,r.jsx)(n.admonition,{title:"Why not directly pass a trace to LLM?",type:"info",children:(0,r.jsx)(n.p,{children:"While it works for simple cases, traces from real-world applications are often large and complex. Passing the entire trace to LLM will quickly run into context window limit and degrade the judge accuracy. Agentic-approach uses tools to explore the trace structure and fetch the necessary details without eating up the context window."})}),"\n",(0,r.jsx)(n.h2,{id:"comparison-with-llm-as-a-judge",children:"Comparison with LLM-as-a-Judge"}),"\n",(0,r.jsx)(n.p,{children:"Understanding when to use each approach depends on where you are in your development lifecycle:"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Aspect"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"Agent-as-a-Judge"})}),(0,r.jsx)(n.th,{children:(0,r.jsx)(n.strong,{children:"LLM-as-a-Judge"})})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Ease of setup"})}),(0,r.jsx)(n.td,{children:"Simple - just describe what to investigate"}),(0,r.jsx)(n.td,{children:"Requires careful prompt engineering and refinement"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"What they evaluate"})}),(0,r.jsx)(n.td,{children:"Complete execution traces and trajectory"}),(0,r.jsx)(n.td,{children:"Specific inputs and outputs fields"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Performance"})}),(0,r.jsx)(n.td,{children:"Slower (explores trace in detail)"}),(0,r.jsx)(n.td,{children:"Fast execution"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Cost"})}),(0,r.jsx)(n.td,{children:"Higher (more context and tool usage)"}),(0,r.jsx)(n.td,{children:"Lower (less context)"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"when-to-use-agent-as-a-judge",children:"When to use Agent-as-a-Judge?"}),"\n",(0,r.jsxs)(n.p,{children:["Agent-as-a-Judge is suitable for ",(0,r.jsx)(n.strong,{children:"bootstrapping"})," the evaluation flywheel."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Getting started with a new application"}),"\n",(0,r.jsx)(n.li,{children:"Revising and refining your agent"}),"\n",(0,r.jsx)(n.li,{children:"Identifying failure patterns"}),"\n",(0,r.jsx)(n.li,{children:"Understanding unexpected behavior"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"when-to-use-llm-as-a-judge",children:"When to use LLM-as-a-Judge?"}),"\n",(0,r.jsxs)(n.p,{children:["LLM-as-a-Judge is more efficient for evaluating a particular criteria, therefore suitable for ",(0,r.jsx)(n.strong,{children:"continuous evaluation"})," and ",(0,r.jsx)(n.strong,{children:"production use"}),"."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Production monitoring"}),"\n",(0,r.jsx)(n.li,{children:"Regression testing"}),"\n",(0,r.jsx)(n.li,{children:"Final validation before deployment"}),"\n",(0,r.jsx)(n.li,{children:"Meeting specific quality expectations"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"quickstart",children:"Quickstart"}),"\n",(0,r.jsxs)(n.p,{children:["To create an Agent-as-a-Judge, simply call the ",(0,r.jsx)(n.code,{children:"make_judge"})," API and pass an instruction with the ",(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"{{ trace }}"})})," template variable:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom mlflow.genai.judges import make_judge\nfrom typing import Literal\nimport time\n\nperformance_judge = make_judge(\n    name="performance_analyzer",\n    instructions=(\n        "Analyze the {{ trace }} for performance issues.\\n\\n"\n        "Check for:\\n"\n        "- Operations taking longer than 2 seconds\\n"\n        "- Redundant API calls or database queries\\n"\n        "- Inefficient data processing patterns\\n"\n        "- Proper use of caching mechanisms\\n\\n"\n        "Rate as: \'optimal\', \'acceptable\', or \'needs_improvement\'"\n    ),\n    feedback_value_type=Literal["optimal", "acceptable", "needs_improvement"],\n    model="openai:/gpt-5",\n    # model="anthropic:/claude-opus-4-1-20250805",\n)\n'})}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsxs)(n.p,{children:["The usage of ",(0,r.jsx)(n.code,{children:"{{ trace }}"})," template variable is important. If the template does not contain ",(0,r.jsx)(n.code,{children:"{{ trace }}"}),", MLflow assumes the scorer is a normal LLM-as-a-Judge and does not use MCP tools."]})}),"\n",(0,r.jsx)(n.p,{children:"Then, generate a trace from your application and pass it to the scorer:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'@mlflow.trace\ndef slow_data_processor(query: str):\n    """Example application with performance bottlenecks."""\n    with mlflow.start_span("fetch_data") as span:\n        time.sleep(2.5)\n        span.set_inputs({"query": query})\n        span.set_outputs({"data": ["item1", "item2", "item3"]})\n\n    with mlflow.start_span("process_data") as span:\n        for i in range(3):\n            with mlflow.start_span(f"redundant_api_call_{i}"):\n                time.sleep(0.5)\n        span.set_outputs({"processed": "results"})\n\n    return "Processing complete"\n\n\nresult = slow_data_processor("SELECT * FROM users")\ntrace_id = mlflow.get_last_active_trace_id()\ntrace = mlflow.get_trace(trace_id)\n\nfeedback = performance_judge(trace=trace)\n\nprint(f"Performance Rating: {feedback.value}")\nprint(f"Analysis: {feedback.rationale}")\n'})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Performance Rating: needs_improvement\nAnalysis: Found critical performance issues:\n1. The 'fetch_data' span took 2.5 seconds, exceeding the 2-second threshold\n2. Detected 3 redundant API calls (redundant_api_call_0, redundant_api_call_1,\n   redundant_api_call_2) that appear to be duplicate operations\n3. Total execution time of 4 seconds could be optimized by parallelizing\n   the redundant operations or implementing caching\n"})}),"\n",(0,r.jsx)(c.A,{src:"/images/mlflow-3/eval-monitor/scorers/agentic-judge-result.png",alt:"Agent-as-a-Judge Evaluation Results"}),"\n",(0,r.jsx)(n.h2,{id:"running-the-judge-against-batch-traces",children:"Running the Judge against Batch Traces"}),"\n",(0,r.jsxs)(n.p,{children:["To apply the scorer to a batch of traces, use the ",(0,r.jsx)(i.B,{fn:"mlflow.genai.evaluate",children:"mlflow.genai.evaluate"})," API."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import mlflow\n\n# Retrieve traces from MLflow\ntraces = mlflow.search_traces(filter_string="timestamp > 1727174400000")\n\n# Run evaluation with Agent-as-a-Judge\nresults = mlflow.genai.evaluate(\n    data=traces,\n    scorers=[performance_judge],\n)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"advanced-examples",children:"Advanced Examples"}),"\n",(0,r.jsx)(d.A,{children:(0,r.jsxs)(o.A,{children:[(0,r.jsx)(s.A,{value:"tool_usage",label:"Tool Usage Analysis",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'tool_optimization_judge = make_judge(\n    name="tool_optimizer",\n    instructions=(\n        "Analyze tool usage patterns in {{ trace }}.\\n\\n"\n        "Check for:\\n"\n        "1. Unnecessary tool calls (could be answered without tools)\\n"\n        "2. Wrong tool selection (better tool available)\\n"\n        "3. Inefficient sequencing (could parallelize or reorder)\\n"\n        "4. Missing tool usage (should have used a tool)\\n\\n"\n        "Provide specific optimization suggestions.\\n"\n        "Rate efficiency as: \'optimal\', \'good\', \'suboptimal\', or \'poor\'"\n    ),\n    feedback_value_type=Literal["optimal", "good", "suboptimal", "poor"],\n    model="anthropic:/claude-opus-4-1-20250805",\n)\n'})})}),(0,r.jsx)(s.A,{value:"loop_detection",label:"Loop Detection",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'loop_detector_judge = make_judge(\n    name="loop_detector",\n    instructions=(\n        "Detect problematic loops in {{ trace }}.\\n\\n"\n        "Identify:\\n"\n        "1. Infinite loop risks\\n"\n        "2. Unnecessary iterations\\n"\n        "3. Circular reasoning patterns\\n"\n        "4. Recursive calls without proper termination\\n\\n"\n        "Report specific span patterns that indicate issues.\\n"\n        "Classify as: \'clean\', \'warning\', or \'critical\'"\n    ),\n    feedback_value_type=Literal["clean", "warning", "critical"],\n    model="anthropic:/claude-opus-4-1-20250805",\n)\n'})})}),(0,r.jsx)(s.A,{value:"reasoning_chain",label:"Reasoning Analysis",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'reasoning_judge = make_judge(\n    name="reasoning_validator",\n    instructions=(\n        "Evaluate the reasoning chain in {{ trace }}.\\n\\n"\n        "Analysis criteria:\\n"\n        "1. Logical Progression: Does each step follow logically from the previous?\\n"\n        "2. Assumption Validity: Are assumptions reasonable and stated?\\n"\n        "3. Evidence Usage: Is evidence properly cited and used?\\n"\n        "4. Conclusion Soundness: Does the conclusion follow from the premises?\\n\\n"\n        "Identify specific reasoning flaws with span IDs.\\n"\n        "Score 1-100 for reasoning quality."\n    ),\n    feedback_value_type=int,\n    model="anthropic:/claude-opus-4-1-20250805",\n)\n'})})}),(0,r.jsx)(s.A,{value:"rag",label:"RAG Agent Evaluation",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'rag_judge = make_judge(\n    name="rag_evaluator",\n    instructions=(\n        "Evaluate the RAG agent\'s behavior in {{ trace }}.\\n\\n"\n        "Check for:\\n"\n        "1. Were the right documents retrieved?\\n"\n        "2. Is the response grounded in the retrieved context?\\n"\n        "3. Are sources properly cited?\\n\\n"\n        "Rate as: \'good\', \'acceptable\', or \'poor\'"\n    ),\n    feedback_value_type=Literal["good", "acceptable", "poor"],\n    model="anthropic:/claude-opus-4-1-20250805",\n)\n\n\n# Use with your RAG pipeline\n@mlflow.trace\ndef rag_pipeline(query):\n    docs = retrieve_documents(query)\n    response = generate_with_context(query, docs)\n    return response\n\n\nresult = rag_pipeline("What is MLflow?")\ntrace = mlflow.get_last_active_trace()\nevaluation = rag_judge(trace=trace)\n'})})}),(0,r.jsx)(s.A,{value:"error_handling",label:"Error Handling Assessment",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'error_handling_judge = make_judge(\n    name="error_handler_checker",\n    instructions=(\n        "Analyze error handling in the {{ trace }}.\\n\\n"\n        "Look for:\\n"\n        "1. Spans with error status or exceptions\\n"\n        "2. Retry attempts and their patterns\\n"\n        "3. Fallback mechanisms\\n"\n        "4. Error propagation and recovery\\n\\n"\n        "Identify specific error scenarios and how they were handled.\\n"\n        "Rate as: \'robust\', \'adequate\', or \'fragile\'"\n    ),\n    feedback_value_type=Literal["robust", "adequate", "fragile"],\n    model="anthropic:/claude-opus-4-1-20250805",\n)\n'})})})]})}),"\n",(0,r.jsx)(n.h2,{id:"debugging-agent-judges",children:"Debugging Agent Judges"}),"\n",(0,r.jsx)(n.p,{children:"To see the actual MCP tool calls that the Agent-as-a-Judge makes while analyzing your trace, enable debug logging:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import logging\n\n# Enable debug logging to see agent tool calls\nlogging.basicConfig(level=logging.DEBUG)\nlogger = logging.getLogger("mlflow.genai.judges")\nlogger.setLevel(logging.DEBUG)\n\n# Now when you run the judge, you\'ll see detailed tool usage\nfeedback = performance_judge(trace=trace)\n'})}),"\n",(0,r.jsx)(n.p,{children:"With debug logging enabled, you'll see output like:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'DEBUG:mlflow.genai.judges:Calling tool: GetTraceInfo\nDEBUG:mlflow.genai.judges:Tool response: {"trace_id": "abc123", "duration_ms": 4000, ...}\nDEBUG:mlflow.genai.judges:Calling tool: ListSpans\nDEBUG:mlflow.genai.judges:Tool response: [{"span_id": "def456", "name": "fetch_data", ...}]\nDEBUG:mlflow.genai.judges:Calling tool: GetSpan with span_id=def456\nDEBUG:mlflow.genai.judges:Tool response: {"duration_ms": 2500, "inputs": {"query": "SELECT * FROM users"}, ...}\n'})}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsxs)(p.A,{children:[(0,r.jsx)(h.A,{icon:u.A,title:"Evaluation Quickstart",description:"Get started with MLflow's evaluation framework.",href:"/genai/eval-monitor/quickstart",linkText:"Start evaluating \u2192"}),(0,r.jsx)(h.A,{icon:m.A,title:"Collect Human Feedback",description:"Learn how to collect human feedback for evaluation.",href:"/genai/assessments/feedback",linkText:"Collect feedback \u2192"}),(0,r.jsx)(h.A,{icon:f.A,title:"Aligning Judges with Human Feedback",description:"Learn how to align your scorer with human feedback.",href:"/genai/eval-monitor/scorers/llm-judge/alignment",linkText:"Learn alignment \u2192"})]})]})}function y(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(x,{...e})}):x(e)}},84722:(e,n,t)=>{t.d(n,{A:()=>c});var a=t(96540);const r=e=>{const n=(e=>e.replace(/^([A-Z])|[\s-_]+(\w)/g,(e,n,t)=>t?t.toUpperCase():n.toLowerCase()))(e);return n.charAt(0).toUpperCase()+n.slice(1)},l=(...e)=>e.filter((e,n,t)=>Boolean(e)&&""!==e.trim()&&t.indexOf(e)===n).join(" ").trim(),i=e=>{for(const n in e)if(n.startsWith("aria-")||"role"===n||"title"===n)return!0};var o={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};const s=(0,a.forwardRef)(({color:e="currentColor",size:n=24,strokeWidth:t=2,absoluteStrokeWidth:r,className:s="",children:c,iconNode:d,...p},h)=>(0,a.createElement)("svg",{ref:h,...o,width:n,height:n,stroke:e,strokeWidth:r?24*Number(t)/Number(n):t,className:l("lucide",s),...!c&&!i(p)&&{"aria-hidden":"true"},...p},[...d.map(([e,n])=>(0,a.createElement)(e,n)),...Array.isArray(c)?c:[c]])),c=(e,n)=>{const t=(0,a.forwardRef)(({className:t,...i},o)=>{return(0,a.createElement)(s,{ref:o,iconNode:n,className:l(`lucide-${c=r(e),c.replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()}`,`lucide-${e}`,t),...i});var c});return t.displayName=r(e),t}},87073:(e,n,t)=>{t.d(n,{A:()=>a});const a=(0,t(84722).A)("brain",[["path",{d:"M12 5a3 3 0 1 0-5.997.125 4 4 0 0 0-2.526 5.77 4 4 0 0 0 .556 6.588A4 4 0 1 0 12 18Z",key:"l5xja"}],["path",{d:"M12 5a3 3 0 1 1 5.997.125 4 4 0 0 1 2.526 5.77 4 4 0 0 1-.556 6.588A4 4 0 1 1 12 18Z",key:"ep3f8r"}],["path",{d:"M15 13a4.5 4.5 0 0 1-3-4 4.5 4.5 0 0 1-3 4",key:"1p4c4q"}],["path",{d:"M17.599 6.5a3 3 0 0 0 .399-1.375",key:"tmeiqw"}],["path",{d:"M6.003 5.125A3 3 0 0 0 6.401 6.5",key:"105sqy"}],["path",{d:"M3.477 10.896a4 4 0 0 1 .585-.396",key:"ql3yin"}],["path",{d:"M19.938 10.5a4 4 0 0 1 .585.396",key:"1qfode"}],["path",{d:"M6 18a4 4 0 0 1-1.967-.516",key:"2e4loj"}],["path",{d:"M19.967 17.484A4 4 0 0 1 18 18",key:"159ez6"}]])},93893:(e,n,t)=>{t.d(n,{A:()=>a});const a=(0,t(84722).A)("users",[["path",{d:"M16 21v-2a4 4 0 0 0-4-4H6a4 4 0 0 0-4 4v2",key:"1yyitq"}],["path",{d:"M16 3.128a4 4 0 0 1 0 7.744",key:"16gr8j"}],["path",{d:"M22 21v-2a4 4 0 0 0-3-3.87",key:"kshegd"}],["circle",{cx:"9",cy:"7",r:"4",key:"nufk8"}]])}}]);