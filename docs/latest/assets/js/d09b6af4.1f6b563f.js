"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8291],{11557:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"developer-workflow/index","title":"GenAI Developer Workflow with MLflow","description":"This guide walks you through the complete development lifecycle of GenAI applications and agents, highlighting common challenges and MLflow\'s recommended solutions. We\'ll iteratively build both the development workflow and data flow that enables you to create GenAI applications that reliably deliver high-quality responses at optimal cost and latency.","source":"@site/docs/genai/developer-workflow/index.mdx","sourceDirName":"developer-workflow","slug":"/developer-workflow/","permalink":"/docs/latest/genai/developer-workflow/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"genAISidebar","previous":{"title":"Why use MLflow","permalink":"/docs/latest/genai/overview/why-mlflow"},"next":{"title":"Building & Iterating","permalink":"/docs/latest/genai/developer-workflow/phase1-build-improve"}}');var i=s(74848),l=s(28453);const r={},o="GenAI Developer Workflow with MLflow",a={},d=[{value:"Table of Contents",id:"table-of-contents",level:2},{value:"Workflow Overview",id:"workflow-overview",level:2},{value:"Development Challenges",id:"development-challenges",level:2},{value:"\ud83c\udfaf <strong>Quality Assessment Challenge</strong>",id:"-quality-assessment-challenge",level:4},{value:"\ud83d\udcca <strong>Observability Challenge</strong>",id:"-observability-challenge",level:4},{value:"\ud83d\udd04 <strong>Iteration Speed Challenge</strong>",id:"-iteration-speed-challenge",level:4},{value:"\ud83d\udcb0 <strong>Cost &amp; Performance Challenge</strong>",id:"-cost--performance-challenge",level:4},{value:"Core Components",id:"core-components",level:2},{value:"\ud83d\udcca <strong>MLflow Traces</strong>",id:"-mlflow-traces",level:3},{value:"\ud83e\uddea <strong>Evaluation Harness</strong>",id:"-evaluation-harness",level:3},{value:"\ud83c\udfaf <strong>Automated Scorers</strong>",id:"-automated-scorers",level:3},{value:"\ud83d\udccb <strong>Evaluation Datasets</strong>",id:"-evaluation-datasets",level:3},{value:"Development Phase",id:"development-phase",level:2},{value:"Initial Application Development",id:"initial-application-development",level:3},{value:"Version Development Process",id:"version-development-process",level:3},{value:"Production Phase",id:"production-phase",level:2},{value:"Deployment &amp; Monitoring",id:"deployment--monitoring",level:3},{value:"Production Data Collection",id:"production-data-collection",level:3},{value:"Evaluation &amp; Improvement",id:"evaluation--improvement",level:2},{value:"Systematic Quality Assessment",id:"systematic-quality-assessment",level:3},{value:"Continuous Improvement Cycle",id:"continuous-improvement-cycle",level:3},{value:"Complete Workflow Integration",id:"complete-workflow-integration",level:2},{value:"End-to-End Data Flow",id:"end-to-end-data-flow",level:3},{value:"Benefits &amp; Best Practices",id:"benefits--best-practices",level:2},{value:"\ud83c\udfaf <strong>Quality Assurance Benefits</strong>",id:"-quality-assurance-benefits",level:3},{value:"\ud83d\udcca <strong>Operational Benefits</strong>",id:"-operational-benefits",level:3},{value:"\ud83d\udd04 <strong>Development Benefits</strong>",id:"-development-benefits",level:3},{value:"\ud83d\udca1 <strong>Best Practices</strong>",id:"-best-practices",level:3}];function c(e){const n={a:"a",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",mermaid:"mermaid",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"genai-developer-workflow-with-mlflow",children:"GenAI Developer Workflow with MLflow"})}),"\n",(0,i.jsxs)(n.p,{children:["This guide walks you through the complete development lifecycle of GenAI applications and agents, highlighting common challenges and MLflow's recommended solutions. We'll iteratively build both the development workflow and data flow that enables you to create GenAI applications that ",(0,i.jsx)(n.strong,{children:"reliably deliver high-quality responses"})," at optimal cost and latency."]}),"\n",(0,i.jsx)(n.h2,{id:"table-of-contents",children:"Table of Contents"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#workflow-overview",children:"Workflow Overview"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#development-challenges",children:"Development Challenges"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#core-components",children:"Core Components"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#development-phase",children:"Development Phase"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#production-phase",children:"Production Phase"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#evaluation--improvement",children:"Evaluation & Improvement"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#complete-workflow-integration",children:"Complete Workflow Integration"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#benefits--best-practices",children:"Benefits & Best Practices"})}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"workflow-overview",children:"Workflow Overview"}),"\n",(0,i.jsx)(n.p,{children:"The MLflow GenAI development workflow addresses the unique challenges of building reliable AI applications through systematic observation, evaluation, and improvement cycles."}),"\n",(0,i.jsx)(n.mermaid,{value:"flowchart LR\n    DEV[\ud83d\udd28 <strong>Development</strong><br/>Write & improve<br/>your GenAI app]\n\n    PROD[\ud83d\ude80 <strong>Production</strong><br/>Deploy app<br/>& serve users]\n\n    OBSERVE[\ud83d\udc41\ufe0f <strong>Observation</strong><br/>Collect traces<br/>& monitor quality]\n\n    EVAL[\u2696\ufe0f <strong>Evaluation</strong><br/>Test changes<br/>systematically]\n\n    IMPROVE[\ud83d\udca1 <strong>Improvement</strong><br/>Analyze issues<br/>& iterate]\n\n    DEV --\x3e PROD\n    PROD --\x3e OBSERVE\n    OBSERVE --\x3e IMPROVE\n    IMPROVE --\x3e EVAL\n    EVAL --\x3e DEV\n\n    classDef phaseStyle fill:#e3f2fd,stroke:#1976d2,stroke-width:3px,color:#000\n\n    class DEV,PROD,OBSERVE,EVAL,IMPROVE phaseStyle"}),"\n",(0,i.jsx)(n.h2,{id:"development-challenges",children:"Development Challenges"}),"\n",(0,i.jsx)(n.p,{children:"Building reliable GenAI applications presents unique challenges that traditional software development practices don't address:"}),"\n",(0,i.jsxs)(n.h4,{id:"-quality-assessment-challenge",children:["\ud83c\udfaf ",(0,i.jsx)(n.strong,{children:"Quality Assessment Challenge"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Problem"}),": Unlike traditional software, GenAI outputs are subjective and context-dependent"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"MLflow Solution"}),": Systematic evaluation with automated scorers and human expert feedback"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Future Benefit"}),": Consistent quality measurement across development and production"]}),"\n"]}),"\n",(0,i.jsxs)(n.h4,{id:"-observability-challenge",children:["\ud83d\udcca ",(0,i.jsx)(n.strong,{children:"Observability Challenge"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Problem"}),": Understanding why GenAI applications fail or produce poor results"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"MLflow Solution"}),": Comprehensive tracing of execution flow, inputs, outputs, and context"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Future Benefit"}),": Detailed debugging capabilities and performance optimization insights"]}),"\n"]}),"\n",(0,i.jsxs)(n.h4,{id:"-iteration-speed-challenge",children:["\ud83d\udd04 ",(0,i.jsx)(n.strong,{children:"Iteration Speed Challenge"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Problem"}),": Testing changes against diverse scenarios is time-consuming and manual"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"MLflow Solution"}),": Automated evaluation harness with curated datasets from production traffic"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Future Benefit"}),": Rapid validation of improvements with confidence in quality maintenance"]}),"\n"]}),"\n",(0,i.jsxs)(n.h4,{id:"-cost--performance-challenge",children:["\ud83d\udcb0 ",(0,i.jsx)(n.strong,{children:"Cost & Performance Challenge"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Problem"}),": Balancing response quality with latency and API costs"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"MLflow Solution"}),": Performance monitoring and cost tracking across different configurations"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Future Benefit"}),": Data-driven optimization of cost-performance trade-offs"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"core-components",children:"Core Components"}),"\n",(0,i.jsxs)(n.h3,{id:"-mlflow-traces",children:["\ud83d\udcca ",(0,i.jsx)(n.strong,{children:"MLflow Traces"})]}),"\n",(0,i.jsx)(n.p,{children:"Capture complete execution details of every request, providing:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Input/output tracking"}),": Full visibility into data transformations"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Performance metrics"}),": Latency, token usage, and cost attribution"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Error analysis"}),": Detailed failure context for debugging"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Contextual metadata"}),": User, session, and environment information"]}),"\n"]}),"\n",(0,i.jsxs)(n.h3,{id:"-evaluation-harness",children:["\ud83e\uddea ",(0,i.jsx)(n.strong,{children:"Evaluation Harness"})]}),"\n",(0,i.jsx)(n.p,{children:"Systematic testing framework that:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Runs new versions"})," against historical production scenarios"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Applies consistent scoring"})," using automated metrics and LLM judges"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Compares performance"})," across different application versions"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Validates quality"})," before production deployment"]}),"\n"]}),"\n",(0,i.jsxs)(n.h3,{id:"-automated-scorers",children:["\ud83c\udfaf ",(0,i.jsx)(n.strong,{children:"Automated Scorers"})]}),"\n",(0,i.jsx)(n.p,{children:"AI-powered quality assessment that provides:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Consistent evaluation"}),": Same criteria applied across development and production"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Scalable feedback"}),": Automated assessment of large volumes of interactions"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Expert-aligned ratings"}),": LLM judges trained on domain expert preferences"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Real-time monitoring"}),": Continuous quality assessment in production"]}),"\n"]}),"\n",(0,i.jsxs)(n.h3,{id:"-evaluation-datasets",children:["\ud83d\udccb ",(0,i.jsx)(n.strong,{children:"Evaluation Datasets"})]}),"\n",(0,i.jsx)(n.p,{children:"Curated collections of test scenarios that:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Represent real usage"}),": Built from actual production traffic patterns"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Include expert annotations"}),": Ground truth labels from domain experts"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Enable regression testing"}),": Consistent benchmarks across versions"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Support iterative improvement"}),": Growing collection of edge cases and scenarios"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"development-phase",children:"Development Phase"}),"\n",(0,i.jsx)(n.h3,{id:"initial-application-development",children:"Initial Application Development"}),"\n",(0,i.jsx)(n.mermaid,{value:"flowchart LR\n    subgraph DEV_DETAIL[\ud83d\udd28 Development Workflow]\n        direction TB\n\n        START[\ud83d\udcdd Write Application Code]\n        INSTRUMENT[\ud83d\udd27 Add MLflow Tracing]\n        TEST[\ud83e\uddea Local Testing]\n        DEBUG[\ud83d\udd0d Debug with Traces]\n        REFINE[\u2728 Refine Implementation]\n\n        START --\x3e INSTRUMENT\n        INSTRUMENT --\x3e TEST\n        TEST --\x3e DEBUG\n        DEBUG --\x3e REFINE\n        REFINE --\x3e TEST\n    end\n\n    classDef devStep fill:#e3f2fd,stroke:#1976d2,stroke-width:2px\n    class START,INSTRUMENT,TEST,DEBUG,REFINE devStep"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Key Activities:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Instrument your code"})," with MLflow tracing decorators"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Capture development traces"})," to understand execution flow"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Iterate rapidly"})," using trace data to identify issues"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Build initial evaluation datasets"})," from development scenarios"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"version-development-process",children:"Version Development Process"}),"\n",(0,i.jsx)(n.mermaid,{value:"flowchart TB\n    ISSUE[\ud83d\udea8 Identified Issue/Improvement]\n    CODE_CHANGE[\ud83d\udcdd Implement Code Changes]\n    LOCAL_EVAL[\ud83e\uddea Local Evaluation]\n    COMPARE[\ud83d\udcca Compare Against Baseline]\n    READY[\u2705 Ready for Production Testing]\n\n    ISSUE --\x3e CODE_CHANGE\n    CODE_CHANGE --\x3e LOCAL_EVAL\n    LOCAL_EVAL --\x3e COMPARE\n    COMPARE --\x3e READY\n\n    classDef processStep fill:#fff3e0,stroke:#f57c00,stroke-width:2px\n    class ISSUE,CODE_CHANGE,LOCAL_EVAL,COMPARE,READY processStep"}),"\n",(0,i.jsx)(n.h2,{id:"production-phase",children:"Production Phase"}),"\n",(0,i.jsx)(n.h3,{id:"deployment--monitoring",children:"Deployment & Monitoring"}),"\n",(0,i.jsx)(n.mermaid,{value:"flowchart LR\n    subgraph PROD_DETAIL[\ud83d\ude80 Production Operations]\n        direction TB\n\n        DEPLOY[\ud83c\udf10 Deploy Application]\n        SERVE[\ud83d\udd04 Serve User Requests]\n        LOG[\ud83d\udcca Log All Traces]\n        MONITOR[\ud83d\udcc8 Monitor Performance]\n        ALERT[\ud83d\udea8 Quality Alerts]\n\n        DEPLOY --\x3e SERVE\n        SERVE --\x3e LOG\n        LOG --\x3e MONITOR\n        MONITOR --\x3e ALERT\n    end\n\n    classDef prodStep fill:#e8f5e8,stroke:#388e3c,stroke-width:2px\n    class DEPLOY,SERVE,LOG,MONITOR,ALERT prodStep"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Key Capabilities:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Automatic trace collection"})," from all production requests"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Real-time quality monitoring"})," using automated scorers"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Performance tracking"})," including latency and cost metrics"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"User feedback integration"})," for quality assessment"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"production-data-collection",children:"Production Data Collection"}),"\n",(0,i.jsx)(n.p,{children:"Production traces provide valuable insights:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Data Type"}),(0,i.jsx)(n.th,{children:"Purpose"}),(0,i.jsx)(n.th,{children:"Usage"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Request/Response Pairs"})}),(0,i.jsx)(n.td,{children:"Quality assessment"}),(0,i.jsx)(n.td,{children:"Evaluation dataset creation"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Performance Metrics"})}),(0,i.jsx)(n.td,{children:"Optimization"}),(0,i.jsx)(n.td,{children:"Cost and latency analysis"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Error Patterns"})}),(0,i.jsx)(n.td,{children:"Debugging"}),(0,i.jsx)(n.td,{children:"Issue identification and resolution"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"User Feedback"})}),(0,i.jsx)(n.td,{children:"Quality validation"}),(0,i.jsx)(n.td,{children:"Expert annotation and scorer training"})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"evaluation--improvement",children:"Evaluation & Improvement"}),"\n",(0,i.jsx)(n.h3,{id:"systematic-quality-assessment",children:"Systematic Quality Assessment"}),"\n",(0,i.jsx)(n.mermaid,{value:"flowchart TB\n    subgraph EVAL_PROCESS[\u2696\ufe0f Evaluation Process]\n        direction TB\n\n        COLLECT[\ud83d\udcca Collect Production Data]\n        CURATE[\ud83c\udfaf Curate Test Scenarios]\n        ANNOTATE[\ud83d\udc68\u200d\ud83d\udcbc Expert Annotation]\n        SCORE[\ud83e\udd16 Automated Scoring]\n        COMPARE[\ud83d\udcc8 Version Comparison]\n        DECIDE[\u2705 Deployment Decision]\n\n        COLLECT --\x3e CURATE\n        CURATE --\x3e ANNOTATE\n        ANNOTATE --\x3e SCORE\n        SCORE --\x3e COMPARE\n        COMPARE --\x3e DECIDE\n    end\n\n    classDef evalStep fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px\n    class COLLECT,CURATE,ANNOTATE,SCORE,COMPARE,DECIDE evalStep"}),"\n",(0,i.jsx)(n.h3,{id:"continuous-improvement-cycle",children:"Continuous Improvement Cycle"}),"\n",(0,i.jsx)(n.p,{children:"The evaluation framework enables systematic improvement:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Issue Identification"}),": Use production traces and monitoring to identify quality or performance issues"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Root Cause Analysis"}),": Examine detailed trace data to understand failure patterns"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Solution Development"}),": Create targeted improvements based on data insights"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Systematic Testing"}),": Validate changes using evaluation harness with representative scenarios"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Quality Assurance"}),": Ensure new versions don't introduce regressions"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Confident Deployment"}),": Deploy validated improvements with quality guarantees"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"complete-workflow-integration",children:"Complete Workflow Integration"}),"\n",(0,i.jsx)(n.h3,{id:"end-to-end-data-flow",children:"End-to-End Data Flow"}),"\n",(0,i.jsx)(n.mermaid,{value:"flowchart TB\n    subgraph WORKFLOW[\ud83c\udf1f Complete MLflow GenAI Workflow]\n        direction TB\n\n        %% User interaction\n        USER[\ud83d\udc65 End Users]\n        APP[\ud83d\ude80 Production App]\n\n        %% Data collection\n        TRACES[\ud83d\udcca Trace Collection]\n        MONITOR[\ud83d\udcc8 Monitoring & Alerts]\n\n        %% Analysis & improvement\n        ANALYSIS[\ud83d\udd0d Issue Analysis]\n        DATASETS[\ud83d\udccb Evaluation Datasets]\n\n        %% Development & testing\n        DEV[\ud83d\udc68\u200d\ud83d\udcbb Developer]\n        VERSION[\ud83d\udd04 New Version]\n        EVAL[\ud83e\uddea Evaluation Harness]\n        SCORERS[\ud83c\udfaf Automated Scorers]\n\n        %% Expert input\n        EXPERT[\ud83d\udc68\u200d\ud83d\udcbc Domain Experts]\n        FEEDBACK[\ud83d\udcac Quality Feedback]\n\n        %% Results & deployment\n        RESULTS[\ud83d\udcca Evaluation Results]\n        DEPLOY[\ud83d\ude80 Deployment]\n\n        %% Flow connections\n        USER --\x3e APP\n        APP --\x3e TRACES\n        TRACES --\x3e MONITOR\n        MONITOR --\x3e ANALYSIS\n        ANALYSIS --\x3e DEV\n        DEV --\x3e VERSION\n        VERSION --\x3e EVAL\n\n        TRACES --\x3e DATASETS\n        EXPERT --\x3e DATASETS\n        EXPERT --\x3e FEEDBACK\n\n        DATASETS --\x3e EVAL\n        SCORERS --\x3e EVAL\n        SCORERS --\x3e TRACES\n\n        EVAL --\x3e RESULTS\n        RESULTS --\x3e DEPLOY\n        DEPLOY --\x3e APP\n\n        FEEDBACK --\x3e ANALYSIS\n    end\n\n    classDef userStyle fill:#e8f5e8,stroke:#388e3c,stroke-width:2px\n    classDef systemStyle fill:#e3f2fd,stroke:#1976d2,stroke-width:2px\n    classDef processStyle fill:#fff3e0,stroke:#f57c00,stroke-width:2px\n    classDef expertStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px\n\n    class USER,APP userStyle\n    class TRACES,MONITOR,DATASETS,RESULTS systemStyle\n    class ANALYSIS,DEV,VERSION,EVAL,DEPLOY processStyle\n    class EXPERT,FEEDBACK,SCORERS expertStyle"}),"\n",(0,i.jsx)(n.h2,{id:"benefits--best-practices",children:"Benefits & Best Practices"}),"\n",(0,i.jsxs)(n.h3,{id:"-quality-assurance-benefits",children:["\ud83c\udfaf ",(0,i.jsx)(n.strong,{children:"Quality Assurance Benefits"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Consistent evaluation"}),": Same quality criteria across development and production"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Expert alignment"}),": Automated scorers trained on domain expert preferences"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Regression prevention"}),": Systematic testing prevents quality degradation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Continuous monitoring"}),": Real-time quality assessment in production"]}),"\n"]}),"\n",(0,i.jsxs)(n.h3,{id:"-operational-benefits",children:["\ud83d\udcca ",(0,i.jsx)(n.strong,{children:"Operational Benefits"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Complete observability"}),": Full visibility into application behavior"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Performance optimization"}),": Data-driven cost and latency improvements"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Rapid debugging"}),": Detailed trace data accelerates issue resolution"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Scalable monitoring"}),": Automated quality assessment for high-volume applications"]}),"\n"]}),"\n",(0,i.jsxs)(n.h3,{id:"-development-benefits",children:["\ud83d\udd04 ",(0,i.jsx)(n.strong,{children:"Development Benefits"})]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Faster iteration"}),": Automated evaluation accelerates improvement cycles"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Confident deployment"}),": Quality validation before production release"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Data-driven decisions"}),": Evidence-based approach to application improvements"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Systematic improvement"}),": Structured approach to quality enhancement"]}),"\n"]}),"\n",(0,i.jsxs)(n.h3,{id:"-best-practices",children:["\ud83d\udca1 ",(0,i.jsx)(n.strong,{children:"Best Practices"})]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Start Simple, Scale Systematically:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Begin with basic tracing and monitoring"}),"\n",(0,i.jsx)(n.li,{children:"Gradually add evaluation datasets and automated scorers"}),"\n",(0,i.jsx)(n.li,{children:"Implement systematic workflows as your application matures"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Align Scorers with Business Goals:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Train automated scorers on domain expert preferences"}),"\n",(0,i.jsx)(n.li,{children:"Regularly validate scorer performance against human judgment"}),"\n",(0,i.jsx)(n.li,{children:"Update scoring criteria as business requirements evolve"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Leverage Production Data:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Use real user interactions to build evaluation datasets"}),"\n",(0,i.jsx)(n.li,{children:"Identify quality issues through production trace analysis"}),"\n",(0,i.jsx)(n.li,{children:"Create test scenarios from actual usage patterns"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Implement Continuous Feedback Loops:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Collect user feedback systematically"}),"\n",(0,i.jsx)(n.li,{children:"Monitor quality trends over time"}),"\n",(0,i.jsx)(n.li,{children:"Iterate based on data insights rather than assumptions"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"This comprehensive workflow enables you to build, deploy, and continuously improve GenAI applications with confidence in their quality, performance, and reliability."}),"\n",(0,i.jsx)(n.p,{children:"MLflow's GenAI developer workflow provides the foundation for building reliable, high-quality AI applications that deliver consistent value to your users."})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},28453:(e,n,s)=>{s.d(n,{R:()=>r,x:()=>o});var t=s(96540);const i={},l=t.createContext(i);function r(e){const n=t.useContext(l);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),t.createElement(l.Provider,{value:n},e.children)}}}]);