"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["4295"],{97008(e,n,s){s.r(n),s.d(n,{metadata:()=>l,default:()=>k,frontMatter:()=>_,contentTitle:()=>j,toc:()=>y,assets:()=>x});var l=JSON.parse('{"id":"eval-monitor/running-evaluation/multi-turn","title":"Evaluate Conversations","description":"Conversation evaluation enables you to assess entire conversation sessions rather than individual turns. This is essential for evaluating conversational AI systems where quality emerges over multiple interactions, such as user frustration patterns, conversation completeness, or overall dialogue coherence.","source":"@site/docs/genai/eval-monitor/running-evaluation/multi-turn.mdx","sourceDirName":"eval-monitor/running-evaluation","slug":"/eval-monitor/running-evaluation/multi-turn","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/running-evaluation/multi-turn","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"genAISidebar","previous":{"title":"Evaluate Traces","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/running-evaluation/traces"},"next":{"title":"Automatic Evaluation","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/automatic-evaluations/"}}'),t=s(74848),i=s(28453),r=s(54725),o=s(46077),a=s(81956),c=s(10440),m=s(77541),d=s(47504),p=s(93893),h=s(47792),u=s(85731),f=s(60665),w=s(96844),g=s(93164),v=s(74990);let _={},j="Evaluate Conversations",x={},y=[{value:"Workflow",id:"workflow",level:2},{value:"Overview",id:"overview",level:2},{value:"Prerequisites",id:"prerequisites",level:2},...v.RM,{value:"Quick Start",id:"quick-start",level:2},{value:"Multi-Turn Judges",id:"multi-turn-judges",level:2},{value:"Built-in Judges",id:"built-in-judges",level:3},{value:"Custom Judges",id:"custom-judges",level:3},{value:"Combining Single-Turn and Multi-Turn Judges",id:"combining-single-turn-and-multi-turn-judges",level:3},{value:"Working with Specific Sessions",id:"working-with-specific-sessions",level:2},{value:"Limitations",id:"limitations",level:2},{value:"Next Steps",id:"next-steps",level:2}];function b(e){let n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"evaluate-conversations",children:"Evaluate Conversations"})}),"\n",(0,t.jsx)(n.p,{children:"Conversation evaluation enables you to assess entire conversation sessions rather than individual turns. This is essential for evaluating conversational AI systems where quality emerges over multiple interactions, such as user frustration patterns, conversation completeness, or overall dialogue coherence."}),"\n",(0,t.jsx)(n.admonition,{title:"Experimental Feature",type:"info",children:(0,t.jsx)(n.p,{children:"Multi-turn evaluation is experimental in MLflow 3.7.0. The API and behavior may change in future releases."})}),"\n",(0,t.jsx)(n.h2,{id:"workflow",children:"Workflow"}),"\n",(0,t.jsx)(a.A,{steps:[{icon:d.A,title:"Tag traces with session IDs",description:"Add session metadata to your traces to group related conversation turns together."},{icon:p.A,title:"Search and retrieve session traces",description:"Collect traces from your tracking server and MLflow will automatically group them by session."},{icon:h.A,title:"Define conversation judges",description:"Use built-in multi-turn judges or create custom ones to evaluate full conversations."},{icon:u.A,title:"Run evaluation",description:"Execute evaluation and analyze session-level metrics alongside individual turn metrics in MLflow UI."}]}),"\n",(0,t.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(n.p,{children:"Traditional single-turn evaluation assesses each agent response independently. However, many important qualities can only be evaluated by examining the full conversation:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"User Frustration"}),": Did the user become frustrated? Was it resolved?"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Conversation Completeness"}),": Were all user questions answered by the end of the conversation?"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Dialogue Coherence"}),": Does the conversation flow naturally?"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Multi-turn evaluation addresses these needs by grouping traces into conversation sessions and applying judges that analyze the entire conversation history."}),"\n",(0,t.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,t.jsx)(n.p,{children:"First, install the required packages by running the following command:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"pip install --upgrade 'mlflow[genai]>=3.7'\n"})}),"\n",(0,t.jsx)(n.p,{children:"MLflow stores evaluation results in a tracking server. Connect your local environment to the tracking server by one of the following methods."}),"\n",(0,t.jsx)(v.Ay,{}),"\n",(0,t.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,t.jsxs)(n.p,{children:["Multi-turn evaluation works by grouping traces into conversation sessions using the ",(0,t.jsx)(n.code,{children:"mlflow.trace.session"})," metadata. When building your agent, you can set session IDs on traces to group them into conversations:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import mlflow\n\n\n@mlflow.trace\ndef my_chatbot(question, session_id):\n    mlflow.update_current_trace(metadata={"mlflow.trace.session": session_id})\n    return generate_response(question)\n'})}),"\n",(0,t.jsx)(o.A,{src:"/images/genai/sessions-view-ui.png",alt:"Sessions View UI",width:"95%"}),"\n",(0,t.jsxs)(n.p,{children:["To evaluate conversations, ",(0,t.jsx)(n.a,{href:"/genai/tracing/search-traces/",children:"get traces from your experiment"})," and pass them to ",(0,t.jsx)(n.code,{children:"mlflow.genai.evaluate"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from mlflow.genai.scorers import ConversationCompleteness, UserFrustration\n\n# Get all traces\ntraces = mlflow.search_traces(\n    experiment_ids=["<your-experiment-id>"],\n    return_type="list",\n)\n\n# Evaluate all sessions - MLflow automatically groups by session ID\nresults = mlflow.genai.evaluate(\n    data=traces,\n    scorers=[\n        ConversationCompleteness(),\n        UserFrustration(),\n    ],\n)\n'})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"How it works:"})," MLflow automatically groups traces by their ",(0,t.jsx)(n.code,{children:"mlflow.trace.session"})," metadata and sorts them chronologically by timestamp within each session. Multi-turn judges run once per session and analyze the complete conversation history. Multi-turn assessments are logged to the first trace (chronologically) in each session. You can use the Sessions tab to view session-level metrics for the entire conversation as well as trace-level metrics for individual turns."]}),"\n",(0,t.jsx)(n.h2,{id:"multi-turn-judges",children:"Multi-Turn Judges"}),"\n",(0,t.jsx)(n.h3,{id:"built-in-judges",children:"Built-in Judges"}),"\n",(0,t.jsx)(n.p,{children:"MLflow provides built-in judges for evaluating conversations:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(r.B,{fn:"mlflow.genai.scorers.ConversationCompleteness",children:"ConversationCompleteness"})}),': Evaluates whether the agent addressed all user questions throughout the conversation (returns "yes" or "no")']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(r.B,{fn:"mlflow.genai.scorers.ConversationalGuidelines",children:"ConversationalGuidelines"})}),': Evaluates whether the assistant\'s responses throughout the conversation comply with provided guidelines (returns "yes" or "no")']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(r.B,{fn:"mlflow.genai.scorers.KnowledgeRetention",children:"KnowledgeRetention"})}),': Evaluates whether the assistant correctly retains information from earlier user inputs without contradiction or distortion (returns "yes" or "no")']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(r.B,{fn:"mlflow.genai.scorers.UserFrustration",children:"UserFrustration"})}),': Detects and tracks user frustration patterns (returns "none", "resolved", or "unresolved")']}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["See the ",(0,t.jsx)(n.a,{href:"/genai/eval-monitor/scorers/llm-judge/predefined#multi-turn",children:"Built-in Judges"})," page for detailed usage examples and API documentation."]}),"\n",(0,t.jsx)(n.h3,{id:"custom-judges",children:"Custom Judges"}),"\n",(0,t.jsxs)(n.p,{children:["You can create custom multi-turn judges using ",(0,t.jsx)(r.B,{fn:"mlflow.genai.judges.make_judge",children:"make_judge"})," with the ",(0,t.jsx)(n.code,{children:"{{ conversation }}"})," template variable:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from mlflow.genai.judges import make_judge\nfrom typing import Literal\n\n# Create a custom multi-turn judge\npoliteness_judge = make_judge(\n    name="conversation_politeness",\n    instructions=(\n        "Analyze the {{ conversation }} and determine if the agent maintains "\n        "a polite and professional tone throughout all interactions. "\n        "Rate as \'consistently_polite\', \'mostly_polite\', or \'impolite\'."\n    ),\n    feedback_value_type=Literal["consistently_polite", "mostly_polite", "impolite"],\n    model="openai:/gpt-4o",\n)\n\n# Use in evaluation\nresults = mlflow.genai.evaluate(\n    data=traces,\n    scorers=[politeness_judge],\n)\n'})}),"\n",(0,t.jsxs)(n.admonition,{title:"Conversation Template Variable",type:"note",children:[(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"{{ conversation }}"})," variable injects the complete conversation history in a structured format."]}),(0,t.jsxs)(n.p,{children:["The variable can only be used with ",(0,t.jsx)(n.code,{children:"{{ expectations }}"}),", not with ",(0,t.jsx)(n.code,{children:"{{ inputs }}"}),", ",(0,t.jsx)(n.code,{children:"{{ outputs }}"}),", or ",(0,t.jsx)(n.code,{children:"{{ trace }}"}),"."]})]}),"\n",(0,t.jsx)(n.h3,{id:"combining-single-turn-and-multi-turn-judges",children:"Combining Single-Turn and Multi-Turn Judges"}),"\n",(0,t.jsx)(n.p,{children:"You can use both single-turn and multi-turn judges in the same evaluation:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from mlflow.genai.scorers import (\n    ConversationCompleteness,\n    UserFrustration,\n    RelevanceToQuery,  # Single-turn scorer\n)\n\nresults = mlflow.genai.evaluate(\n    data=traces,\n    scorers=[\n        # Single-turn: evaluates each trace individually\n        RelevanceToQuery(),\n        # Multi-turn: evaluates entire sessions\n        ConversationCompleteness(),\n        UserFrustration(),\n    ],\n)\n"})}),"\n",(0,t.jsx)(n.p,{children:"Single-turn judges run on every trace individually, while multi-turn judges run once per session and analyze the complete conversation history."}),"\n",(0,t.jsx)(n.h2,{id:"working-with-specific-sessions",children:"Working with Specific Sessions"}),"\n",(0,t.jsx)(n.p,{children:"If you need to evaluate specific sessions or filter traces, you can extract session IDs and retrieve traces for each:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import mlflow\n\n# Get all traces from your experiment\nall_traces = mlflow.search_traces(\n    experiment_ids=["<your-experiment-id>"],\n    return_type="list",\n)\n\n# Extract unique session IDs\nsession_ids = set()\nfor trace in all_traces:\n    session_id = trace.info.trace_metadata.get("mlflow.trace.session")\n    if session_id:\n        session_ids.add(session_id)\n\n# Get traces for each session and combine\nall_session_traces = []\nfor session_id in session_ids:\n    session_traces = mlflow.search_traces(\n        experiment_ids=["<your-experiment-id>"],\n        filter_string=f"metadata.`mlflow.trace.session` = \'{session_id}\'",\n        return_type="list",\n    )\n    all_session_traces.extend(session_traces)\n\n# Evaluate all sessions\nresults = mlflow.genai.evaluate(\n    data=all_session_traces,\n    scorers=[ConversationCompleteness(), UserFrustration()],\n)\n'})}),"\n",(0,t.jsx)(n.h2,{id:"limitations",children:"Limitations"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsxs)(n.strong,{children:["No ",(0,t.jsx)(n.code,{children:"predict_fn"})," support"]}),": Multi-turn judges currently work only with pre-collected traces. You cannot use them with ",(0,t.jsx)(n.code,{children:"predict_fn"})," in ",(0,t.jsx)(n.code,{children:"mlflow.genai.evaluate"}),"."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsxs)(c.A,{children:[(0,t.jsx)(m.A,{icon:f.A,iconSize:48,title:"Session Tracing Guide",description:"Learn how to track users and sessions in your conversational AI applications for better evaluation.",href:"/genai/tracing/track-users-sessions/",linkText:"Learn about sessions \u2192",containerHeight:64}),(0,t.jsx)(m.A,{icon:w.A,iconSize:48,title:"Built-in Multi-Turn Judges",description:"Explore built-in judges for conversation completeness, user frustration, and other multi-turn metrics.",href:"/genai/eval-monitor/scorers/llm-judge/predefined#multi-turn",linkText:"View judges \u2192",containerHeight:64}),(0,t.jsx)(m.A,{icon:g.A,iconSize:48,title:"Create Custom Multi-Turn Judges",description:"Build custom LLM judges using make_judge to evaluate conversation-specific criteria and patterns.",href:"/genai/eval-monitor/scorers/llm-judge/custom-judges",linkText:"Create custom judges \u2192",containerHeight:64})]})]})}function k(e={}){let{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(b,{...e})}):b(e)}},74990(e,n,s){s.d(n,{Ay:()=>m,RM:()=>a});var l=s(74848),t=s(28453),i=s(78010),r=s(57250),o=s(95986);let a=[];function c(e){let n={a:"a",code:"code",p:"p",pre:"pre",strong:"strong",...(0,t.R)(),...e.components};return(0,l.jsx)(o.A,{children:(0,l.jsxs)(i.A,{children:[(0,l.jsxs)(r.A,{value:"uv",label:"Local (uv)",default:!0,children:[(0,l.jsxs)(n.p,{children:["Install the Python package manager ",(0,l.jsx)(n.a,{href:"https://docs.astral.sh/uv/getting-started/installation/",children:"uv"}),"\n(that will also install ",(0,l.jsxs)(n.a,{href:"https://docs.astral.sh/uv/guides/tools/",children:[(0,l.jsx)(n.code,{children:"uvx"})," command"]})," to invoke Python tools without installing them)."]}),(0,l.jsx)(n.p,{children:"Start a MLflow server locally."}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-shell",children:"uvx mlflow server\n"})})]}),(0,l.jsxs)(r.A,{value:"local",label:"Local (pip)",children:[(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Python Environment"}),": Python 3.10+"]}),(0,l.jsxs)(n.p,{children:["Install the ",(0,l.jsx)(n.code,{children:"mlflow"})," Python package via ",(0,l.jsx)(n.code,{children:"pip"})," and start a MLflow server locally."]}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-shell",children:"pip install --upgrade 'mlflow[genai]'\nmlflow server\n"})})]}),(0,l.jsxs)(r.A,{value:"docker",label:"Local (docker)",children:[(0,l.jsx)(n.p,{children:"MLflow provides a Docker Compose file to start a local MLflow server with a PostgreSQL database and a MinIO server."}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-shell",children:"git clone --depth 1 --filter=blob:none --sparse https://github.com/mlflow/mlflow.git\ncd mlflow\ngit sparse-checkout set docker-compose\ncd docker-compose\ncp .env.dev.example .env\ndocker compose up -d\n"})}),(0,l.jsxs)(n.p,{children:["Refer to the ",(0,l.jsx)(n.a,{href:"https://github.com/mlflow/mlflow/tree/master/docker-compose/README.md",children:"instruction"})," for more details (e.g., overriding the default environment variables)."]})]})]})})}function m(e={}){let{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(c,{...e})}):c(e)}},54725(e,n,s){s.d(n,{B:()=>r});var l=s(74848);s(96540);var t=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}'),i=s(66497);function r({fn:e,children:n,hash:s}){let r=(e=>{let n=e.split(".");for(let e=n.length;e>0;e--){let s=n.slice(0,e).join(".");if(t[s])return s}return null})(e);if(!r)return(0,l.jsx)(l.Fragment,{children:n});let o=(0,i.default)(`/${t[r]}#${s??e}`);return(0,l.jsx)("a",{href:o,target:"_blank",children:n??(0,l.jsxs)("code",{children:[e,"()"]})})}},46077(e,n,s){s.d(n,{A:()=>i});var l=s(74848);s(96540);var t=s(66497);function i({src:e,alt:n,width:s,caption:i,className:r}){return(0,l.jsxs)("div",{className:`container_JwLF ${r||""}`,children:[(0,l.jsx)("div",{className:"imageWrapper_RfGN",style:s?{width:s}:{},children:(0,l.jsx)("img",{src:(0,t.default)(e),alt:n,className:"image_bwOA"})}),i&&(0,l.jsx)("p",{className:"caption_jo2G",children:i})]})}},95986(e,n,s){s.d(n,{A:()=>t});var l=s(74848);s(96540);function t({children:e}){return(0,l.jsx)("div",{className:"wrapper_sf5q",children:e})}},77541(e,n,s){s.d(n,{A:()=>c});var l=s(74848);s(96540);var t=s(95310),i=s(34164);let r="tileImage_O4So";var o=s(66497),a=s(92802);function c({icon:e,image:n,imageDark:s,imageWidth:c,imageHeight:m,iconSize:d=32,containerHeight:p,title:h,description:u,href:f,linkText:w="Learn more \u2192",className:g}){if(!e&&!n)throw Error("TileCard requires either an icon or image prop");let v=p?{height:`${p}px`}:{},_={};return c&&(_.width=`${c}px`),m&&(_.height=`${m}px`),(0,l.jsxs)(t.A,{href:f,className:(0,i.A)("tileCard_NHsj",g),children:[(0,l.jsx)("div",{className:"tileIcon_pyoR",style:v,children:e?(0,l.jsx)(e,{size:d}):s?(0,l.jsx)(a.A,{sources:{light:(0,o.default)(n),dark:(0,o.default)(s)},alt:h,className:r,style:_}):(0,l.jsx)("img",{src:(0,o.default)(n),alt:h,className:r,style:_})}),(0,l.jsx)("h3",{children:h}),(0,l.jsx)("p",{children:u}),(0,l.jsx)("div",{className:"tileLink_iUbu",children:w})]})}},10440(e,n,s){s.d(n,{A:()=>i});var l=s(74848);s(96540);var t=s(34164);function i({children:e,className:n}){return(0,l.jsx)("div",{className:(0,t.A)("tilesGrid_hB9N",n),children:e})}},81956(e,n,s){s.d(n,{A:()=>i});var l=s(74848);s(96540);var t=s(46077);let i=({steps:e,title:n,screenshot:s,width:i="normal"})=>(0,l.jsxs)("div",{className:"workflowContainer__N1v",children:[n&&(0,l.jsx)("h3",{className:"workflowTitle_QrAr",children:n}),s&&(0,l.jsx)("div",{className:"screenshotContainer_OwzZ",children:(0,l.jsx)(t.A,{src:s.src,alt:s.alt,width:s.width||"90%"})}),(0,l.jsx)("div",{className:"stepsContainer_IGeu",style:{maxWidth:"wide"===i?"850px":"700px"},children:e.map((n,s)=>(0,l.jsxs)("div",{className:"stepItem_GyHJ",children:[(0,l.jsxs)("div",{className:"stepIndicator_U2Wb",children:[(0,l.jsx)("div",{className:"stepNumber_vINc",children:n.icon?(0,l.jsx)(n.icon,{size:16}):(0,l.jsx)("span",{className:"stepNumberText_eLd7",children:s+1})}),s<e.length-1&&(0,l.jsx)("div",{className:"stepConnector_Si86"})]}),(0,l.jsxs)("div",{className:"stepContent_D0CA",children:[(0,l.jsx)("h4",{className:"stepTitle_wujx",children:n.title}),(0,l.jsx)("p",{className:"stepDescription_PIaE",children:n.description})]})]},s))})]})}}]);