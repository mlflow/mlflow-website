"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["4777"],{55072(e,n,t){t.r(n),t.d(n,{metadata:()=>a,default:()=>h,frontMatter:()=>s,contentTitle:()=>p,toc:()=>c,assets:()=>m});var a=JSON.parse('{"id":"tracing/integrations/listing/dspy","title":"Tracing DSPy\u{1F9E9}","description":"DSPy is an open-source framework for building modular AI systems and offers algorithms for optimizing their prompts and weights.","source":"@site/docs/genai/tracing/integrations/listing/dspy.mdx","sourceDirName":"tracing/integrations/listing","slug":"/tracing/integrations/listing/dspy","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/dspy","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"sidebar_label":"DSPy"},"sidebar":"genAISidebar","previous":{"title":"CrewAI","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/crewai"},"next":{"title":"Google ADK","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/google-adk"}}'),l=t(74848),o=t(28453),i=t(66497),r=t(54725);let s={sidebar_position:5,sidebar_label:"DSPy"},p="Tracing DSPy\u{1F9E9}",m={},c=[{value:"Example Usage",id:"example-usage",level:3},{value:"Tracing during Evaluation",id:"tracing-during-evaluation",level:3},{value:"Tracing during Compilation (Optimization)",id:"tracing-during-compilation-optimization",level:3},{value:"Token usage",id:"token-usage",level:3},{value:"Disable auto-tracing",id:"disable-auto-tracing",level:3}];function f(e){let n={a:"a",admonition:"admonition",code:"code",h1:"h1",h3:"h3",header:"header",p:"p",pre:"pre",strong:"strong",...(0,o.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.header,{children:(0,l.jsx)(n.h1,{id:"tracing-dspy",children:"Tracing DSPy\u{1F9E9}"})}),"\n",(0,l.jsx)("video",{src:(0,i.default)("/images/llms/tracing/dspy-tracing.mp4"),controls:!0,loop:!0,autoPlay:!0,muted:!0,"aria-label":"DSPy Tracing via autolog"}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.a,{href:"https://dspy.ai/",children:"DSPy"})," is an open-source framework for building modular AI systems and offers algorithms for optimizing their prompts and weights."]}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.a,{href:"../../",children:"MLflow Tracing"})," provides automatic tracing capability for DSPy. You can enable tracing\nfor DSPy by calling the ",(0,l.jsx)(r.B,{fn:"mlflow.dspy.autolog"})," function, and nested traces are automatically logged to the active MLflow Experiment upon invocation of DSPy modules."]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"import mlflow\n\nmlflow.dspy.autolog()\n"})}),"\n",(0,l.jsx)(n.admonition,{type:"tip",children:(0,l.jsxs)(n.p,{children:["MLflow DSPy integration is not only about tracing. MLflow offers full tracking experience for DSPy, including model tracking, index management, and evaluation. Please see the ",(0,l.jsx)(n.strong,{children:(0,l.jsx)(n.a,{href:"/genai/flavors/dspy",children:"MLflow DSPy Flavor"})})," to learn more!"]})}),"\n",(0,l.jsx)(n.h3,{id:"example-usage",children:"Example Usage"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'import dspy\nimport mlflow\n\n# Enabling tracing for DSPy\nmlflow.dspy.autolog()\n\n# Optional: Set a tracking URI and an experiment\nmlflow.set_tracking_uri("http://localhost:5000")\nmlflow.set_experiment("DSPy")\n\n# Define a simple ChainOfThought model and run it\nlm = dspy.LM("openai/gpt-4o-mini")\ndspy.configure(lm=lm)\n\n\n# Define a simple summarizer model and run it\nclass SummarizeSignature(dspy.Signature):\n    """Given a passage, generate a summary."""\n\n    passage: str = dspy.InputField(desc="a passage to summarize")\n    summary: str = dspy.OutputField(desc="a one-line summary of the passage")\n\n\nclass Summarize(dspy.Module):\n    def __init__(self):\n        self.summarize = dspy.ChainOfThought(SummarizeSignature)\n\n    def forward(self, passage: str):\n        return self.summarize(passage=passage)\n\n\nsummarizer = Summarize()\nsummarizer(\n    passage=(\n        "MLflow Tracing is a feature that enhances LLM observability in your Generative AI (GenAI) applications "\n        "by capturing detailed information about the execution of your application\'s services. Tracing provides "\n        "a way to record the inputs, outputs, and metadata associated with each intermediate step of a request, "\n        "enabling you to easily pinpoint the source of bugs and unexpected behaviors."\n    )\n)\n'})}),"\n",(0,l.jsx)(n.h3,{id:"tracing-during-evaluation",children:"Tracing during Evaluation"}),"\n",(0,l.jsx)(n.p,{children:"Evaluating DSPy models is an important step in the development of AI systems. MLflow Tracing can help you track the performance of your programs after the evaluation, by providing detailed information about the execution of your programs for each input."}),"\n",(0,l.jsxs)(n.p,{children:["When MLflow auto-tracing is enabled for DSPy, traces will be automatically generated when you execute DSPy's ",(0,l.jsx)(n.a,{href:"https://dspy.ai/learn/evaluation/overview/",children:"built-in evaluation suites"}),". The following example demonstrates how to run evaluation and review traces in MLflow:"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'import dspy\nfrom dspy.evaluate.metrics import answer_exact_match\n\nimport mlflow\n\n# Enabling tracing for DSPy evaluation\nmlflow.dspy.autolog(log_traces_from_eval=True)\n\n# Define a simple evaluation set\neval_set = [\n    dspy.Example(\n        question="How many \'r\'s are in the word \'strawberry\'?", answer="3"\n    ).with_inputs("question"),\n    dspy.Example(\n        question="How many \'a\'s are in the word \'banana\'?", answer="3"\n    ).with_inputs("question"),\n    dspy.Example(\n        question="How many \'e\'s are in the word \'elephant\'?", answer="2"\n    ).with_inputs("question"),\n]\n\n\n# Define a program\nclass Counter(dspy.Signature):\n    question: str = dspy.InputField()\n    answer: str = dspy.OutputField(\n        desc="Should only contain a single number as an answer"\n    )\n\n\ncot = dspy.ChainOfThought(Counter)\n\n# Evaluate the programs\nwith mlflow.start_run(run_name="CoT Evaluation"):\n    evaluator = dspy.evaluate.Evaluate(\n        devset=eval_set,\n        return_all_scores=True,\n        return_outputs=True,\n        show_progress=True,\n    )\n    aggregated_score, outputs, all_scores = evaluator(cot, metric=answer_exact_match)\n\n    # Log the aggregated score\n    mlflow.log_metric("exact_match", aggregated_score)\n    # Log the detailed evaluation results as a table\n    mlflow.log_table(\n        {\n            "question": [example.question for example in eval_set],\n            "answer": [example.answer for example in eval_set],\n            "output": outputs,\n            "exact_match": all_scores,\n        },\n        artifact_file="eval_results.json",\n    )\n'})}),"\n",(0,l.jsxs)(n.p,{children:['If you open the MLflow UI and go to the "CoT Evaluation" run, you will see the evaluation result, and the list of traces generated during the evaluation on the ',(0,l.jsx)(n.code,{children:"Traces"})," tab."]}),"\n",(0,l.jsx)(n.admonition,{type:"note",children:(0,l.jsxs)(n.p,{children:["You can disable tracing for these steps by calling the ",(0,l.jsx)(r.B,{fn:"mlflow.dspy.autolog"})," function with the ",(0,l.jsx)(n.code,{children:"log_traces_from_eval"})," parameters set to ",(0,l.jsx)(n.code,{children:"False"}),"."]})}),"\n",(0,l.jsx)(n.h3,{id:"tracing-during-compilation-optimization",children:"Tracing during Compilation (Optimization)"}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.a,{href:"https://dspy.ai/learn/optimization/overview/",children:"Compilation (optimization)"})," is the core concept of DSPy. Through compilation, DSPy automatically optimizes the prompts and weights of your DSPy program to achieve the best performance."]}),"\n",(0,l.jsxs)(n.p,{children:["By default, MLflow does ",(0,l.jsx)(n.strong,{children:"NOT"})," generate traces during complication, because complication can trigger hundreds or thousands of invocations of DSPy modules. To enable tracing for compilation, you can call the ",(0,l.jsx)(r.B,{fn:"mlflow.dspy.autolog"})," function with the ",(0,l.jsx)(n.code,{children:"log_traces_from_compile"})," parameter set to ",(0,l.jsx)(n.code,{children:"True"}),"."]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'import dspy\nimport mlflow\n\n# Enable auto-tracing for compilation\nmlflow.dspy.autolog(log_traces_from_compile=True)\n\n# Optimize the DSPy program as usual\ntp = dspy.MIPROv2(metric=metric, auto="medium", num_threads=24)\noptimized = tp.compile(cot, trainset=trainset)\n'})}),"\n",(0,l.jsx)(n.h3,{id:"token-usage",children:"Token usage"}),"\n",(0,l.jsxs)(n.p,{children:["MLflow >= 3.5.0 supports token usage tracking for dspy. The token usage call will be logged in the ",(0,l.jsx)(n.code,{children:"mlflow.chat.tokenUsage"})," attribute. The total token usage throughout the trace will be\navailable in the ",(0,l.jsx)(n.code,{children:"token_usage"})," field of the trace info object."]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'import dspy\nimport mlflow\n\nmlflow.dspy.autolog()\n\ndspy.settings.configure(lm=dspy.LM("openai/gpt-4o-mini"))\n\ntask = dspy.Predict("instruction -> response")\nresult = task(instruction="Translate \'hello\' to French.")\n\nlast_trace_id = mlflow.get_last_active_trace_id()\ntrace = mlflow.get_trace(trace_id=last_trace_id)\n\n# Print the token usage\ntotal_usage = trace.info.token_usage\nprint("== Total token usage: ==")\nprint(f"  Input tokens: {total_usage[\'input_tokens\']}")\nprint(f"  Output tokens: {total_usage[\'output_tokens\']}")\nprint(f"  Total tokens: {total_usage[\'total_tokens\']}")\n\n# Print the token usage for each LLM call\nprint("\\n== Detailed usage for each LLM call: ==")\nfor span in trace.data.spans:\n    if usage := span.get_attribute("mlflow.chat.tokenUsage"):\n        print(f"{span.name}:")\n        print(f"  Input tokens: {usage[\'input_tokens\']}")\n        print(f"  Output tokens: {usage[\'output_tokens\']}")\n        print(f"  Total tokens: {usage[\'total_tokens\']}")\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"== Total token usage: ==\n  Input tokens: 143\n  Output tokens: 12\n  Total tokens: 155\n\n== Detailed usage for each LLM call: ==\nLM.__call__:\n  Input tokens: 143\n  Output tokens: 12\n  Total tokens: 155\n"})}),"\n",(0,l.jsx)(n.h3,{id:"disable-auto-tracing",children:"Disable auto-tracing"}),"\n",(0,l.jsxs)(n.p,{children:["Auto tracing for DSPy can be disabled globally by calling ",(0,l.jsx)(n.code,{children:"mlflow.dspy.autolog(disable=True)"})," or ",(0,l.jsx)(n.code,{children:"mlflow.autolog(disable=True)"}),"."]})]})}function h(e={}){let{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(f,{...e})}):f(e)}},54725(e,n,t){t.d(n,{B:()=>i});var a=t(74848);t(96540);var l=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}'),o=t(66497);function i({fn:e,children:n,hash:t}){let i=(e=>{let n=e.split(".");for(let e=n.length;e>0;e--){let t=n.slice(0,e).join(".");if(l[t])return t}return null})(e);if(!i)return(0,a.jsx)(a.Fragment,{children:n});let r=(0,o.default)(`/${l[i]}#${t??e}`);return(0,a.jsx)("a",{href:r,target:"_blank",children:n??(0,a.jsxs)("code",{children:[e,"()"]})})}},28453(e,n,t){t.d(n,{R:()=>i,x:()=>r});var a=t(96540);let l={},o=a.createContext(l);function i(e){let n=a.useContext(o);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:i(e.components),a.createElement(o.Provider,{value:n},e.children)}}}]);