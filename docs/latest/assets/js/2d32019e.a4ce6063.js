"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["1646"],{57761(e,n,a){a.r(n),a.d(n,{metadata:()=>r,default:()=>y,frontMatter:()=>x,contentTitle:()=>_,toc:()=>v,assets:()=>w});var r=JSON.parse('{"id":"traditional-ml/sparkml/index","title":"MLflow Spark MLlib Integration","description":"Apache Spark MLlib provides distributed machine learning algorithms for processing large-scale datasets across clusters. MLflow integrates with Spark MLlib to track distributed ML pipelines, manage models, and enable flexible deployment from cluster training to standalone inference.","source":"@site/docs/classic-ml/traditional-ml/sparkml/index.mdx","sourceDirName":"traditional-ml/sparkml","slug":"/traditional-ml/sparkml/","permalink":"/mlflow-website/docs/latest/ml/traditional-ml/sparkml/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"classicMLSidebar","previous":{"title":"XGBoost","permalink":"/mlflow-website/docs/latest/ml/traditional-ml/xgboost/"},"next":{"title":"Prophet","permalink":"/mlflow-website/docs/latest/ml/traditional-ml/prophet/"}}'),i=a(74848),t=a(28453),l=a(78010),o=a(57250),s=a(33508),d=a(10440),c=a(77541),m=a(51004),p=a(61878),g=a(22356),h=a(99653),u=a(17133),f=a(56064),k=a(60665);let x={},_="MLflow Spark MLlib Integration",w={},v=[{value:"Why MLflow + Spark MLlib?",id:"why-mlflow--spark-mllib",level:2},{value:"Basic Model Logging",id:"basic-model-logging",level:2},{value:"Model Formats and Loading",id:"model-formats-and-loading",level:2},{value:"Datasource Autologging",id:"datasource-autologging",level:2},{value:"Model Signatures",id:"model-signatures",level:2},{value:"ONNX Conversion",id:"onnx-conversion",level:2},{value:"Model Registry",id:"model-registry",level:2},{value:"Learn More",id:"learn-more",level:2}];function j(e){let n={code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"mlflow-spark-mllib-integration",children:"MLflow Spark MLlib Integration"})}),"\n",(0,i.jsx)(n.p,{children:"Apache Spark MLlib provides distributed machine learning algorithms for processing large-scale datasets across clusters. MLflow integrates with Spark MLlib to track distributed ML pipelines, manage models, and enable flexible deployment from cluster training to standalone inference."}),"\n",(0,i.jsx)(n.h2,{id:"why-mlflow--spark-mllib",children:"Why MLflow + Spark MLlib?"}),"\n",(0,i.jsx)(s.A,{features:[{icon:m.A,title:"Pipeline Tracking",description:"Automatically log Spark ML pipelines with all stages, transformers, and estimators. Track parameters from each pipeline component and maintain complete lineage."},{icon:p.A,title:"Format Flexibility",description:"Save models in native Spark format for distributed batch processing or PyFunc format for inference outside a Spark cluster with automatic DataFrame conversion."},{icon:g.A,title:"Datasource Autologging",description:"Track data sources automatically with paths, formats, and versions. Maintain complete data lineage for distributed ML workflows."},{icon:h.A,title:"Cross-Platform Deployment",description:"Deploy Spark models with PyFunc wrappers for REST APIs and edge computing, or convert to ONNX for platform-independent inference."}]}),"\n",(0,i.jsx)(n.h2,{id:"basic-model-logging",children:"Basic Model Logging"}),"\n",(0,i.jsxs)(n.p,{children:["Log Spark MLlib models with ",(0,i.jsx)(n.code,{children:"mlflow.spark.log_model()"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport mlflow.spark\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import Tokenizer, HashingTF\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql import SparkSession\n\n# Initialize Spark session\nspark = SparkSession.builder.appName("MLflowSparkExample").getOrCreate()\n\n# Prepare training data\ntraining = spark.createDataFrame(\n    [\n        (0, "a b c d e spark", 1.0),\n        (1, "b d", 0.0),\n        (2, "spark f g h", 1.0),\n        (3, "hadoop mapreduce", 0.0),\n    ],\n    ["id", "text", "label"],\n)\n\n# Create ML Pipeline\ntokenizer = Tokenizer(inputCol="text", outputCol="words")\nhashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol="features")\nlr = LogisticRegression(maxIter=10, regParam=0.001)\npipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n\n# Train and log the model\nwith mlflow.start_run():\n    model = pipeline.fit(training)\n\n    # Log the entire pipeline\n    model_info = mlflow.spark.log_model(\n        spark_model=model, artifact_path="spark-pipeline"\n    )\n\n    # Log parameters manually\n    mlflow.log_params(\n        {\n            "max_iter": lr.getMaxIter(),\n            "reg_param": lr.getRegParam(),\n            "num_features": hashingTF.getNumFeatures(),\n        }\n    )\n\nprint(f"Model logged with URI: {model_info.model_uri}")\n'})}),"\n",(0,i.jsx)(n.p,{children:"Automatically logs the complete pipeline with all stages, parameters, and model in both Spark native and PyFunc formats."}),"\n",(0,i.jsx)(n.h2,{id:"model-formats-and-loading",children:"Model Formats and Loading"}),"\n",(0,i.jsxs)(l.A,{children:[(0,i.jsxs)(o.A,{value:"native",label:"Native Spark Format",children:[(0,i.jsx)(n.p,{children:"Preserves full Spark ML functionality for distributed processing:"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Load as native Spark model (requires Spark session)\nspark_model = mlflow.spark.load_model(model_info.model_uri)\n\n# Use for distributed batch scoring\ntest_data = spark.createDataFrame(\n    [(4, "spark i j k"), (5, "l m n"), (6, "spark hadoop spark"), (7, "apache hadoop")],\n    ["id", "text"],\n)\n\npredictions = spark_model.transform(test_data)\npredictions.show()\n'})})]}),(0,i.jsxs)(o.A,{value:"pyfunc",label:"PyFunc Format",children:[(0,i.jsx)(n.p,{children:"Enables inference outside a Spark cluster:"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import pandas as pd\n\n# Load as PyFunc model\npyfunc_model = mlflow.pyfunc.load_model(model_info.model_uri)\n\n# Use with pandas DataFrame\ntest_data = pd.DataFrame(\n    {"text": ["spark machine learning", "hadoop distributed computing"]}\n)\n\npredictions = pyfunc_model.predict(test_data)\nprint(predictions)\n'})}),(0,i.jsx)(n.p,{children:"PyFunc automatically converts pandas DataFrames to Spark format and creates a local Spark session for inference. Note that the Apache Spark library is still required as a dependency."})]})]}),"\n",(0,i.jsx)(n.h2,{id:"datasource-autologging",children:"Datasource Autologging"}),"\n",(0,i.jsx)(n.p,{children:"Track data sources automatically during model training:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import mlflow.spark\n\nmlflow.spark.autolog()\n\nwith mlflow.start_run():\n    raw_data = spark.read.parquet("s3://my-bucket/training-data/")\n    model = pipeline.fit(raw_data)\n    mlflow.spark.log_model(model, artifact_path="model")\n'})}),"\n",(0,i.jsx)(n.p,{children:"Requires Spark 3.0+, MLflow-Spark JAR configuration, and is not supported on Databricks shared/serverless clusters. Logs paths, formats, and versions for all datasource reads."}),"\n",(0,i.jsx)(n.h2,{id:"model-signatures",children:"Model Signatures"}),"\n",(0,i.jsx)(n.p,{children:"Infer signatures automatically for Spark ML models:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from mlflow.models import infer_signature\nfrom pyspark.ml.functions import array_to_vector\n\nvector_data = spark.createDataFrame(\n    [([3.0, 4.0], 0.0), ([5.0, 6.0], 1.0)], ["features_array", "label"]\n).select(array_to_vector("features_array").alias("features"), "label")\n\nlr = LogisticRegression(featuresCol="features", labelCol="label")\nmodel = lr.fit(vector_data)\n\npredictions = model.transform(vector_data)\n\n# Infer signature from pandas DataFrames\nsignature = infer_signature(\n    vector_data.limit(2).toPandas(),\n    predictions.select("prediction").limit(2).toPandas(),\n)\n\nwith mlflow.start_run():\n    mlflow.spark.log_model(\n        spark_model=model,\n        artifact_path="vector_model",\n        signature=signature,\n    )\n'})}),"\n",(0,i.jsx)(n.h2,{id:"onnx-conversion",children:"ONNX Conversion"}),"\n",(0,i.jsx)(n.p,{children:"Convert Spark models to ONNX (experimental):"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import onnxmltools\n\nwith mlflow.start_run():\n    model = pipeline.fit(training_data)\n    mlflow.spark.log_model(spark_model=model, artifact_path="spark_model")\n\n    onnx_model = onnxmltools.convert_sparkml(model, name="SparkMLPipeline")\n    onnxmltools.utils.save_model(onnx_model, "model.onnx")\n    mlflow.log_artifact("model.onnx")\n'})}),"\n",(0,i.jsx)(n.h2,{id:"model-registry",children:"Model Registry"}),"\n",(0,i.jsx)(n.p,{children:"Register and promote Spark models:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from mlflow import MlflowClient\n\nclient = MlflowClient()\n\nwith mlflow.start_run():\n    model = pipeline.fit(train_data)\n\n    mlflow.spark.log_model(\n        spark_model=model,\n        artifact_path="production_candidate",\n        registered_model_name="CustomerSegmentationModel",\n    )\n\n    mlflow.set_tags(\n        {\n            "validation_passed": "true",\n            "deployment_target": "batch_scoring",\n        }\n    )\n\nmodel_version = client.get_latest_versions(\n    "CustomerSegmentationModel", stages=["None"]\n)[0]\n\nclient.transition_model_version_stage(\n    name="CustomerSegmentationModel", version=model_version.version, stage="Staging"\n)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"learn-more",children:"Learn More"}),"\n",(0,i.jsxs)(d.A,{children:[(0,i.jsx)(c.A,{icon:u.A,iconSize:48,title:"Model Registry",description:"Manage model versions, aliases, and lifecycle stages for production deployment workflows.",href:"/ml/model-registry",linkText:"View registry docs \u2192",containerHeight:64}),(0,i.jsx)(c.A,{icon:f.A,iconSize:48,title:"Model Signatures",description:"Define input and output schemas for model validation and type checking.",href:"/ml/model/signatures",linkText:"Learn about signatures \u2192",containerHeight:64}),(0,i.jsx)(c.A,{icon:h.A,iconSize:48,title:"Model Deployment",description:"Deploy Spark models with MLflow serving, batch inference, and cloud platforms.",href:"/ml/deployment",linkText:"Deploy models \u2192",containerHeight:64}),(0,i.jsx)(c.A,{icon:k.A,iconSize:48,title:"MLflow Tracking",description:"Track experiments, parameters, metrics, and artifacts across ML workflows.",href:"/ml/tracking",linkText:"View tracking docs \u2192",containerHeight:64})]})]})}function y(e={}){let{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(j,{...e})}):j(e)}},33508(e,n,a){a.d(n,{A:()=>i});var r=a(74848);a(96540);function i({features:e,col:n=2}){return(0,r.jsx)("div",{className:"featureHighlights_Ardf",style:{gridTemplateColumns:`repeat(${n}, 1fr)`},children:e.map((e,n)=>(0,r.jsxs)("div",{className:"highlightItem_XPnN",children:[e.icon&&(0,r.jsx)("div",{className:"highlightIcon_SUR8",children:(0,r.jsx)(e.icon,{size:24})}),(0,r.jsxs)("div",{className:"highlightContent_d0XP",children:[(0,r.jsx)("h4",{children:e.title}),(0,r.jsx)("p",{children:e.description})]})]},n))})}},77541(e,n,a){a.d(n,{A:()=>d});var r=a(74848);a(96540);var i=a(95310),t=a(34164);let l="tileImage_O4So";var o=a(66497),s=a(92802);function d({icon:e,image:n,imageDark:a,imageWidth:d,imageHeight:c,iconSize:m=32,containerHeight:p,title:g,description:h,href:u,linkText:f="Learn more \u2192",className:k}){if(!e&&!n)throw Error("TileCard requires either an icon or image prop");let x=p?{height:`${p}px`}:{},_={};return d&&(_.width=`${d}px`),c&&(_.height=`${c}px`),(0,r.jsxs)(i.A,{href:u,className:(0,t.A)("tileCard_NHsj",k),children:[(0,r.jsx)("div",{className:"tileIcon_pyoR",style:x,children:e?(0,r.jsx)(e,{size:m}):a?(0,r.jsx)(s.A,{sources:{light:(0,o.default)(n),dark:(0,o.default)(a)},alt:g,className:l,style:_}):(0,r.jsx)("img",{src:(0,o.default)(n),alt:g,className:l,style:_})}),(0,r.jsx)("h3",{children:g}),(0,r.jsx)("p",{children:h}),(0,r.jsx)("div",{className:"tileLink_iUbu",children:f})]})}},10440(e,n,a){a.d(n,{A:()=>t});var r=a(74848);a(96540);var i=a(34164);function t({children:e,className:n}){return(0,r.jsx)("div",{className:(0,i.A)("tilesGrid_hB9N",n),children:e})}}}]);