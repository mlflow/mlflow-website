"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[2459],{28453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>i});var r=t(96540);const a={},s=r.createContext(a);function o(e){const n=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),r.createElement(s.Provider,{value:n},e.children)}},41762:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>i,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"llms/rag/index","title":"Retrieval Augmented Generation (RAG)","description":"Retrieval Augmented Generation (RAG) is a powerful and efficient approach to natural","source":"@site/docs/llms/rag/index.mdx","sourceDirName":"llms/rag","slug":"/llms/rag/","permalink":"/docs/latest/llms/rag/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"More Customization","permalink":"/docs/latest/llms/custom-pyfunc-for-llms/"},"next":{"title":"Explore RAG Tutorials","permalink":"/docs/latest/llms/rag/notebooks/"}}');var a=t(74848),s=t(28453),o=t(56289);const i={},l="Retrieval Augmented Generation (RAG)",c={},d=[{value:"Benefits of RAG",id:"benefits-of-rag",level:2},{value:"Understanding the Power of RAG",id:"understanding-the-power-of-rag",level:2},{value:"Explore RAG Tutorials",id:"explore-rag-tutorials",level:2}];function u(e){const n={h1:"h1",h2:"h2",header:"header",li:"li",p:"p",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"retrieval-augmented-generation-rag",children:"Retrieval Augmented Generation (RAG)"})}),"\n",(0,a.jsx)(n.p,{children:"Retrieval Augmented Generation (RAG) is a powerful and efficient approach to natural\nlanguage processing that combines the strength of both pre-trained foundation models and\nretrieval mechanisms. It allows the generative model to access a dataset of documents\nthrough a retrieval mechanism, which enhances generated responses to be more contextually relevant\nand factually accurate. This improvement results in a cost-effective and accessible alternative\nto training custom models for specific use cases."}),"\n",(0,a.jsx)(n.p,{children:"The Retrieval mechanism works by embedding documents and questions in the same latent space, allowing\na user to ask a question and get the most relevant document chunk as a response. This mechanism then passes\nthe contextual chunk to the generative model, resulting in better quality responses with fewer hallucinations."}),"\n",(0,a.jsx)(n.h2,{id:"benefits-of-rag",children:"Benefits of RAG"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Provides LLM access to external knowledge through documents, resulting in contextually accurate and factual responses."}),"\n",(0,a.jsx)(n.li,{children:"RAG is more cost-effective than fine-tuning, since it doesn't require the labeled data and computational resources that come with model training."}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"understanding-the-power-of-rag",children:"Understanding the Power of RAG"}),"\n",(0,a.jsx)(n.p,{children:"In the realm of artificial intelligence, particularly within natural language processing, the ability to generate coherent\nand contextually relevant responses is paramount. Large language models (LLMs) have shown immense promise in this area,\nbut they often operate based on their internal knowledge, which can sometimes lead to inconsistencies or inaccuracies in\ntheir outputs. This is where RAG comes into play."}),"\n",(0,a.jsx)(n.p,{children:"RAG is a groundbreaking framework designed to enhance the capabilities of LLMs. Instead of solely relying on the vast but\nstatic knowledge embedded during their training, RAG empowers these models to actively retrieve and reference information\nfrom external knowledge bases. This dynamic approach ensures that the generated responses are not only rooted in the most\ncurrent and reliable facts but also transparent in their sourcing. In essence, RAG transforms LLMs from closed-book learners,\nrelying on memorized information, to open-book thinkers, capable of actively seeking out and referencing external knowledge."}),"\n",(0,a.jsx)(n.p,{children:"The implications of RAG are profound. By grounding responses in verifiable external sources, it significantly reduces the\nchances of LLMs producing misleading or incorrect information. Furthermore, it offers a more cost-effective solution for\nbusinesses, as there's less need for continuous retraining of the model. With RAG, LLMs can provide answers that are not\nonly more accurate but also more trustworthy, paving the way for a new era of AI-driven insights and interactions."}),"\n",(0,a.jsx)(n.h2,{id:"explore-rag-tutorials",children:"Explore RAG Tutorials"}),"\n",(0,a.jsx)(o.A,{className:"button button--primary",to:"notebooks",children:(0,a.jsx)("span",{children:"View RAG Tutorials"})})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(u,{...e})}):u(e)}}}]);