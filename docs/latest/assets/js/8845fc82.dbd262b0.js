"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[2317],{28453:(e,t,a)=>{a.d(t,{R:()=>s,x:()=>i});var n=a(96540);const l={},o=n.createContext(l);function s(e){const t=n.useContext(o);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:s(e.components),n.createElement(o.Provider,{value:t},e.children)}},29936:(e,t,a)=>{a.d(t,{A:()=>n});const n=a.p+"assets/images/dataset-mlflow-ui-9c475f4c9e28b0c438dafb3b3e8c9db8.png"},46539:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>d,contentTitle:()=>r,default:()=>m,frontMatter:()=>i,metadata:()=>n,toc:()=>c});const n=JSON.parse('{"id":"dataset/index","title":"MLflow Dataset Tracking Tutorial","description":"The mlflow.data module is an integral part of the MLflow ecosystem, designed to enhance your machine learning workflow.","source":"@site/docs/dataset/index.mdx","sourceDirName":"dataset","slug":"/dataset/","permalink":"/docs/latest/dataset/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"sidebar_label":"MLflow Dataset"},"sidebar":"docsSidebar","previous":{"title":"MLflow Tracing UI","permalink":"/docs/latest/tracing/ui"},"next":{"title":"MLflow Model Registry","permalink":"/docs/latest/model-registry/"}}');var l=a(74848),o=a(28453),s=a(67756);const i={sidebar_label:"MLflow Dataset"},r="MLflow Dataset Tracking Tutorial",d={},c=[{value:"Key Interfaces",id:"key-interfaces",level:2},{value:"Dataset",id:"dataset",level:3},{value:"DatasetSource",id:"datasetsource",level:3},{value:"Example Usage",id:"example-usage",level:2},{value:"Using Datasets with other MLflow Features",id:"using-datasets-with-other-mlflow-features",level:2},{value:"How to use a Dataset with MLflow evaluate",id:"how-to-use-a-dataset-with-mlflow-evaluate",level:3}];function h(e){const t={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,o.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(t.header,{children:(0,l.jsx)(t.h1,{id:"mlflow-dataset-tracking-tutorial",children:"MLflow Dataset Tracking Tutorial"})}),"\n",(0,l.jsxs)(t.p,{children:["The ",(0,l.jsx)(t.code,{children:"mlflow.data"})," module is an integral part of the MLflow ecosystem, designed to enhance your machine learning workflow.\nThis module enables you to record and retrieve dataset information during model training and evaluation, leveraging MLflow's tracking capabilities."]}),"\n",(0,l.jsx)(t.h2,{id:"key-interfaces",children:"Key Interfaces"}),"\n",(0,l.jsxs)(t.p,{children:["There are two main abstract components associated with the ",(0,l.jsx)(t.code,{children:"mlflow.data"})," module, ",(0,l.jsx)(t.code,{children:"Dataset"})," and ",(0,l.jsx)(t.code,{children:"DatasetSource"}),":"]}),"\n",(0,l.jsx)(t.h3,{id:"dataset",children:"Dataset"}),"\n",(0,l.jsxs)(t.p,{children:["The ",(0,l.jsx)(t.code,{children:"Dataset"})," abstraction is a metadata tracking object that holds the information about a given logged dataset."]}),"\n",(0,l.jsxs)(t.p,{children:["The information stored within a ",(0,l.jsx)(t.code,{children:"Dataset"})," object includes features, targets, and predictions, along with\nmetadata like the dataset's name, digest (hash), schema, and profile. You can log this metadata using the ",(0,l.jsx)(s.B,{fn:"mlflow.log_input"})," API.\nThe module provides functions to construct ",(0,l.jsx)(s.B,{fn:"mlflow.data.dataset.Dataset",children:(0,l.jsx)(t.code,{children:"mlflow.data.dataset.Dataset"})})," objects from various data types."]}),"\n",(0,l.jsx)(t.p,{children:"There are a number of concrete implementations of this abstract class, including:"}),"\n",(0,l.jsxs)(t.ul,{children:["\n",(0,l.jsxs)(t.li,{children:["\n",(0,l.jsx)(s.B,{fn:"mlflow.data.spark_dataset.SparkDataset",children:(0,l.jsx)(t.code,{children:"mlflow.data.spark_dataset.SparkDataset"})}),"\n"]}),"\n",(0,l.jsxs)(t.li,{children:["\n",(0,l.jsx)(s.B,{fn:"mlflow.data.pandas_dataset.PandasDataset",children:(0,l.jsx)(t.code,{children:"mlflow.data.pandas_dataset.PandasDataset"})}),"\n"]}),"\n",(0,l.jsxs)(t.li,{children:["\n",(0,l.jsx)(s.B,{fn:"mlflow.data.numpy_dataset.NumpyDataset",children:(0,l.jsx)(t.code,{children:"mlflow.data.numpy_dataset.NumpyDataset"})}),"\n"]}),"\n",(0,l.jsxs)(t.li,{children:["\n",(0,l.jsx)(s.B,{fn:"mlflow.data.huggingface_dataset.HuggingFaceDataset",children:(0,l.jsx)(t.code,{children:"mlflow.data.huggingface_dataset.HuggingFaceDataset"})}),"\n"]}),"\n",(0,l.jsxs)(t.li,{children:["\n",(0,l.jsx)(s.B,{fn:"mlflow.data.tensorflow_dataset.TensorFlowDataset",children:(0,l.jsx)(t.code,{children:"mlflow.data.tensorflow_dataset.TensorFlowDataset"})}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(t.p,{children:["The following example demonstrates how to construct a ",(0,l.jsx)(s.B,{fn:"mlflow.data.pandas_dataset.PandasDataset",children:(0,l.jsx)(t.code,{children:"mlflow.data.pandas_dataset.PandasDataset"})})," object from a Pandas DataFrame:"]}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-python",children:'import mlflow.data\nimport pandas as pd\nfrom mlflow.data.pandas_dataset import PandasDataset\n\n\ndataset_source_url = "https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv"\nraw_data = pd.read_csv(dataset_source_url, delimiter=";")\n\n# Create an instance of a PandasDataset\ndataset = mlflow.data.from_pandas(\n    raw_data, source=dataset_source_url, name="wine quality - white", targets="quality"\n)\n'})}),"\n",(0,l.jsx)(t.h3,{id:"datasetsource",children:"DatasetSource"}),"\n",(0,l.jsxs)(t.p,{children:["The ",(0,l.jsx)(t.code,{children:"DatasetSource"})," is a component of a given Dataset object, providing a linked lineage to the original source of the data."]}),"\n",(0,l.jsxs)(t.p,{children:["The ",(0,l.jsx)(t.code,{children:"DatasetSource"})," component of a ",(0,l.jsx)(t.code,{children:"Dataset"})," represents the source of a dataset, such as a directory in S3, a Delta Table, or a URL.\nIt is referenced in the ",(0,l.jsx)(t.code,{children:"Dataset"})," for understanding the origin of the data. The ",(0,l.jsx)(t.code,{children:"DatasetSource"})," of a logged\ndataset can be retrieved either by accessing the ",(0,l.jsx)(t.code,{children:"source"})," property of the ",(0,l.jsx)(t.code,{children:"Dataset"})," object, or through using the ",(0,l.jsx)(t.code,{children:"mlflow.data.get_source()"})," API."]}),"\n",(0,l.jsx)(t.admonition,{type:"tip",children:(0,l.jsx)(t.p,{children:"Many of the supported autologging-enabled flavors within MLflow will automatically log the source of the dataset when logging the dataset itself."})}),"\n",(0,l.jsx)(t.admonition,{type:"note",children:(0,l.jsx)(t.p,{children:"The example shown below is purely for instructive purposes, as logging a dataset outside of a training run is not a common practice."})}),"\n",(0,l.jsx)(t.h2,{id:"example-usage",children:"Example Usage"}),"\n",(0,l.jsxs)(t.p,{children:["The following example demonstrates how to use the ",(0,l.jsx)(t.code,{children:"log_inputs"})," API to log a training dataset, retrieve its information, and fetch the data source:"]}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-python",children:'import mlflow\nimport pandas as pd\nfrom mlflow.data.pandas_dataset import PandasDataset\n\n\ndataset_source_url = "https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv"\nraw_data = pd.read_csv(dataset_source_url, delimiter=";")\n\n# Create an instance of a PandasDataset\ndataset = mlflow.data.from_pandas(\n    raw_data, source=dataset_source_url, name="wine quality - white", targets="quality"\n)\n\n# Log the Dataset to an MLflow run by using the `log_input` API\nwith mlflow.start_run() as run:\n    mlflow.log_input(dataset, context="training")\n\n# Retrieve the run information\nlogged_run = mlflow.get_run(run.info.run_id)\n\n# Retrieve the Dataset object\nlogged_dataset = logged_run.inputs.dataset_inputs[0].dataset\n\n# View some of the recorded Dataset information\nprint(f"Dataset name: {logged_dataset.name}")\nprint(f"Dataset digest: {logged_dataset.digest}")\nprint(f"Dataset profile: {logged_dataset.profile}")\nprint(f"Dataset schema: {logged_dataset.schema}")\n'})}),"\n",(0,l.jsx)(t.p,{children:"The stdout results of the above code snippet are as follows:"}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-bash",children:'Dataset name: wine quality - white\nDataset digest: 2a1e42c4\nDataset profile: {"num_rows": 4898, "num_elements": 58776}\nDataset schema: {"mlflow_colspec": [\n    {"type": "double", "name": "fixed acidity"},\n    {"type": "double", "name": "volatile acidity"},\n    {"type": "double", "name": "citric acid"},\n    {"type": "double", "name": "residual sugar"},\n    {"type": "double", "name": "chlorides"},\n    {"type": "double", "name": "free sulfur dioxide"},\n    {"type": "double", "name": "total sulfur dioxide"},\n    {"type": "double", "name": "density"},\n    {"type": "double", "name": "pH"},\n    {"type": "double", "name": "sulphates"},\n    {"type": "double", "name": "alcohol"},\n    {"type": "long", "name": "quality"}\n    ]}\n'})}),"\n",(0,l.jsx)(t.p,{children:"We can navigate to the MLflow UI to see what this looks like for a logged Dataset as well."}),"\n",(0,l.jsx)(t.p,{children:(0,l.jsx)(t.img,{src:a(29936).A+"",width:"1476",height:"763"})}),"\n",(0,l.jsxs)(t.p,{children:["When we want to load the dataset back from the location that it's stored (calling ",(0,l.jsx)(t.code,{children:"load"})," will download the data locally), we\naccess the Dataset's source via the following API:"]}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-python",children:'# Loading the dataset\'s source\ndataset_source = mlflow.data.get_source(logged_dataset)\n\nlocal_dataset = dataset_source.load()\n\nprint(f"The local file where the data has been downloaded to: {local_dataset}")\n\n# Load the data again\nloaded_data = pd.read_csv(local_dataset, delimiter=";")\n'})}),"\n",(0,l.jsxs)(t.p,{children:["The print statement from above resolves to the local file that was created when calling ",(0,l.jsx)(t.code,{children:"load"}),"."]}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-bash",children:"The local file where the data has been downloaded to:\n/var/folders/cd/n8n0rm2x53l_s0xv_j_xklb00000gp/T/tmpuxwtrul1/winequality-white.csv\n"})}),"\n",(0,l.jsx)(t.h2,{id:"using-datasets-with-other-mlflow-features",children:"Using Datasets with other MLflow Features"}),"\n",(0,l.jsxs)(t.p,{children:["The ",(0,l.jsx)(t.code,{children:"mlflow.data"})," module serves the crucial role of associating datasets with MLflow runs. Aside from the obvious utility of having a record\nassociated with an MLflow run to the dataset that was used during training, there are some integrations within MLflow that allow for direct\nusage of Datasets that have been logged with the ",(0,l.jsx)(s.B,{fn:"mlflow.log_input"})," API."]}),"\n",(0,l.jsx)(t.h3,{id:"how-to-use-a-dataset-with-mlflow-evaluate",children:"How to use a Dataset with MLflow evaluate"}),"\n",(0,l.jsx)(t.admonition,{type:"note",children:(0,l.jsx)(t.p,{children:"The integration of Datasets with MLflow evaluate was introduced in MLflow 2.8.0. Previous versions do not have this functionality."})}),"\n",(0,l.jsx)(t.p,{children:"To see how this integration functions, let's take a look at a fairly simple and typical classification task."}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-python",children:'import pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport xgboost\n\nimport mlflow\nfrom mlflow.data.pandas_dataset import PandasDataset\n\n\ndataset_source_url = "https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv"\nraw_data = pd.read_csv(dataset_source_url, delimiter=";")\n\n# Extract the features and target data separately\ny = raw_data["quality"]\nX = raw_data.drop("quality", axis=1)\n\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.33, random_state=17\n)\n\n# Create a label encoder object\nle = LabelEncoder()\n\n# Fit and transform the target variable\ny_train_encoded = le.fit_transform(y_train)\ny_test_encoded = le.transform(y_test)\n\n# Fit an XGBoost binary classifier on the training data split\nmodel = xgboost.XGBClassifier().fit(X_train, y_train_encoded)\n\n# Build the Evaluation Dataset from the test set\ny_test_pred = model.predict(X=X_test)\n\neval_data = X_test\neval_data["label"] = y_test\n\n# Assign the decoded predictions to the Evaluation Dataset\neval_data["predictions"] = le.inverse_transform(y_test_pred)\n\n# Create the PandasDataset for use in mlflow evaluate\npd_dataset = mlflow.data.from_pandas(\n    eval_data, predictions="predictions", targets="label"\n)\n\nmlflow.set_experiment("White Wine Quality")\n\n# Log the Dataset, model, and execute an evaluation run using the configured Dataset\nwith mlflow.start_run() as run:\n    mlflow.log_input(pd_dataset, context="training")\n\n    mlflow.xgboost.log_model(\n        name="white-wine-xgb", xgb_model=model, input_example=X_test\n    )\n\n    result = mlflow.evaluate(data=pd_dataset, predictions=None, model_type="classifier")\n'})}),"\n",(0,l.jsx)(t.admonition,{type:"note",children:(0,l.jsxs)(t.p,{children:["Using the ",(0,l.jsx)(s.B,{fn:"mlflow.evaluate"})," API will automatically log the dataset used for the evaluation to the MLflow run. An explicit call to\nlog the input is not required."]})}),"\n",(0,l.jsx)(t.p,{children:"Navigating to the MLflow UI, we can see how the Dataset, model, metrics, and a classification-specific confusion matrix are all logged\nto the run."}),"\n",(0,l.jsx)("div",{className:"center-div",style:{width:"80%"},children:(0,l.jsx)(t.p,{children:(0,l.jsx)(t.img,{src:a(67429).A+"",width:"1034",height:"1003"})})})]})}function m(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,l.jsx)(t,{...e,children:(0,l.jsx)(h,{...e})}):h(e)}},67429:(e,t,a)=>{a.d(t,{A:()=>n});const n=a.p+"assets/images/dataset-evaluate-0d449786c6575ea6b14818f6a3a92855.png"},67756:(e,t,a)=>{a.d(t,{B:()=>r});a(96540);const n=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var l=a(29030),o=a(56289),s=a(74848);const i=e=>{const t=e.split(".");for(let a=t.length;a>0;a--){const e=t.slice(0,a).join(".");if(n[e])return e}return null};function r(e){let{fn:t,children:a}=e;const r=i(t);if(!r)return(0,s.jsx)(s.Fragment,{children:a});const d=(0,l.Ay)(`/${n[r]}#${t}`);return(0,s.jsx)(o.A,{to:d,target:"_blank",children:a??(0,s.jsxs)("code",{children:[t,"()"]})})}}}]);