/*! For license information please see 33653567.e399b9b4.js.LICENSE.txt */
"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8591],{6789:(e,n,r)=>{r.d(n,{A:()=>a});r(96540);var t=r(28774),l=r(34164);const o={tileCard:"tileCard_NHsj",tileIcon:"tileIcon_pyoR",tileLink:"tileLink_iUbu",tileImage:"tileImage_O4So"};var s=r(86025),i=r(74848);function a({icon:e,image:n,iconSize:r=32,containerHeight:a,title:c,description:d,href:p,linkText:m="Learn more \u2192",className:h}){if(!e&&!n)throw new Error("TileCard requires either an icon or image prop");const u=a?{height:`${a}px`}:{};return(0,i.jsxs)(t.A,{href:p,className:(0,l.A)(o.tileCard,h),children:[(0,i.jsx)("div",{className:o.tileIcon,style:u,children:e?(0,i.jsx)(e,{size:r}):(0,i.jsx)("img",{src:(0,s.Ay)(n),alt:c,className:o.tileImage})}),(0,i.jsx)("h3",{children:c}),(0,i.jsx)("p",{children:d}),(0,i.jsx)("div",{className:o.tileLink,children:m})]})}},11470:(e,n,r)=>{r.d(n,{A:()=>j});var t=r(96540),l=r(34164),o=r(23104),s=r(56347),i=r(205),a=r(57485),c=r(31682),d=r(70679);function p(e){return t.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,t.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function m(e){const{values:n,children:r}=e;return(0,t.useMemo)((()=>{const e=n??function(e){return p(e).map((({props:{value:e,label:n,attributes:r,default:t}})=>({value:e,label:n,attributes:r,default:t})))}(r);return function(e){const n=(0,c.XI)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,r])}function h({value:e,tabValues:n}){return n.some((n=>n.value===e))}function u({queryString:e=!1,groupId:n}){const r=(0,s.W6)(),l=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,a.aZ)(l),(0,t.useCallback)((e=>{if(!l)return;const n=new URLSearchParams(r.location.search);n.set(l,e),r.replace({...r.location,search:n.toString()})}),[l,r])]}function f(e){const{defaultValue:n,queryString:r=!1,groupId:l}=e,o=m(e),[s,a]=(0,t.useState)((()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!h({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const r=n.find((e=>e.default))??n[0];if(!r)throw new Error("Unexpected error: 0 tabValues");return r.value}({defaultValue:n,tabValues:o}))),[c,p]=u({queryString:r,groupId:l}),[f,g]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[r,l]=(0,d.Dv)(n);return[r,(0,t.useCallback)((e=>{n&&l.set(e)}),[n,l])]}({groupId:l}),w=(()=>{const e=c??f;return h({value:e,tabValues:o})?e:null})();(0,i.A)((()=>{w&&a(w)}),[w]);return{selectedValue:s,selectValue:(0,t.useCallback)((e=>{if(!h({value:e,tabValues:o}))throw new Error(`Can't select invalid tab value=${e}`);a(e),p(e),g(e)}),[p,g,o]),tabValues:o}}var g=r(92303);const w={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var v=r(74848);function x({className:e,block:n,selectedValue:r,selectValue:t,tabValues:s}){const i=[],{blockElementScrollPositionUntilNextRender:a}=(0,o.a_)(),c=e=>{const n=e.currentTarget,l=i.indexOf(n),o=s[l].value;o!==r&&(a(n),t(o))},d=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const r=i.indexOf(e.currentTarget)+1;n=i[r]??i[0];break}case"ArrowLeft":{const r=i.indexOf(e.currentTarget)-1;n=i[r]??i[i.length-1];break}}n?.focus()};return(0,v.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,l.A)("tabs",{"tabs--block":n},e),children:s.map((({value:e,label:n,attributes:t})=>(0,v.jsx)("li",{role:"tab",tabIndex:r===e?0:-1,"aria-selected":r===e,ref:e=>{i.push(e)},onKeyDown:d,onClick:c,...t,className:(0,l.A)("tabs__item",w.tabItem,t?.className,{"tabs__item--active":r===e}),children:n??e},e)))})}function _({lazy:e,children:n,selectedValue:r}){const o=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=o.find((e=>e.props.value===r));return e?(0,t.cloneElement)(e,{className:(0,l.A)("margin-top--md",e.props.className)}):null}return(0,v.jsx)("div",{className:"margin-top--md",children:o.map(((e,n)=>(0,t.cloneElement)(e,{key:n,hidden:e.props.value!==r})))})}function y(e){const n=f(e);return(0,v.jsxs)("div",{className:(0,l.A)("tabs-container",w.tabList),children:[(0,v.jsx)(x,{...n,...e}),(0,v.jsx)(_,{...n,...e})]})}function j(e){const n=(0,g.A)();return(0,v.jsx)(y,{...e,children:p(e.children)},String(n))}},19365:(e,n,r)=>{r.d(n,{A:()=>s});r(96540);var t=r(34164);const l={tabItem:"tabItem_Ymn6"};var o=r(74848);function s({children:e,hidden:n,className:r}){return(0,o.jsx)("div",{role:"tabpanel",className:(0,t.A)(l.tabItem,r),hidden:n,children:e})}},28453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>i});var t=r(96540);const l={},o=t.createContext(l);function s(e){const n=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:s(e.components),t.createElement(o.Provider,{value:n},e.children)}},30684:(e,n,r)=>{r.d(n,{A:()=>t});const t=(0,r(84722).A)("globe",[["circle",{cx:"12",cy:"12",r:"10",key:"1mglay"}],["path",{d:"M12 2a14.5 14.5 0 0 0 0 20 14.5 14.5 0 0 0 0-20",key:"13o1zl"}],["path",{d:"M2 12h20",key:"9i4pu4"}]])},46858:(e,n,r)=>{r.d(n,{A:()=>t});const t=(0,r(84722).A)("zap",[["path",{d:"M4 14a1 1 0 0 1-.78-1.63l9.9-10.2a.5.5 0 0 1 .86.46l-1.92 6.02A1 1 0 0 0 13 10h7a1 1 0 0 1 .78 1.63l-9.9 10.2a.5.5 0 0 1-.86-.46l1.92-6.02A1 1 0 0 0 11 14z",key:"1xq2db"}]])},47020:(e,n,r)=>{r.d(n,{A:()=>o});r(96540);const t={wrapper:"wrapper_sf5q"};var l=r(74848);function o({children:e}){return(0,l.jsx)("div",{className:t.wrapper,children:e})}},49374:(e,n,r)=>{r.d(n,{B:()=>i});r(96540);const t=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}');var l=r(86025),o=r(74848);const s=e=>{const n=e.split(".");for(let r=n.length;r>0;r--){const e=n.slice(0,r).join(".");if(t[e])return e}return null};function i({fn:e,children:n,hash:r}){const i=s(e);if(!i)return(0,o.jsx)(o.Fragment,{children:n});const a=(0,l.Ay)(`/${t[i]}#${r??e}`);return(0,o.jsx)("a",{href:a,target:"_blank",children:n??(0,o.jsxs)("code",{children:[e,"()"]})})}},65592:(e,n,r)=>{r.d(n,{A:()=>s});r(96540);var t=r(34164);const l={tilesGrid:"tilesGrid_hB9N"};var o=r(74848);function s({children:e,className:n}){return(0,o.jsx)("div",{className:(0,t.A)(l.tilesGrid,n),children:e})}},72714:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>x,contentTitle:()=>v,default:()=>j,frontMatter:()=>w,metadata:()=>t,toc:()=>_});const t=JSON.parse('{"id":"serving/index","title":"MLflow Model Serving","description":"Transform your trained models into production-ready inference servers with MLflow\'s comprehensive serving capabilities. Deploy locally, in the cloud, or through managed endpoints with standardized REST APIs.","source":"@site/docs/genai/serving/index.mdx","sourceDirName":"serving","slug":"/serving/","permalink":"/docs/latest/genai/serving/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"genAISidebar","previous":{"title":"Prompt Engineering UI","permalink":"/docs/latest/genai/prompt-version-mgmt/prompt-engineering/"},"next":{"title":"Responses Agent","permalink":"/docs/latest/genai/serving/responses-agent"}}');var l=r(74848),o=r(28453),s=(r(28774),r(11470)),i=r(19365),a=(r(49374),r(47020)),c=r(65592),d=r(6789),p=r(79206),m=r(30684),h=r(93164),u=r(80964),f=r(46858),g=r(93893);const w={},v="MLflow Model Serving",x={},_=[{value:"Quick Start",id:"quick-start",level:2},{value:"How Model Serving Works",id:"how-model-serving-works",level:2},{value:"Server Startup and Model Loading",id:"server-startup-and-model-loading",level:3},{value:"Request Processing Pipeline",id:"request-processing-pipeline",level:3},{value:"Model Prediction and Response",id:"model-prediction-and-response",level:3},{value:"The Flavor System",id:"the-flavor-system",level:3},{value:"Error Handling and Debugging",id:"error-handling-and-debugging",level:3},{value:"Input Format Examples",id:"input-format-examples",level:3},{value:"Key Implementation Concepts",id:"key-implementation-concepts",level:2},{value:"Complete Example: Train to Production",id:"complete-example-train-to-production",level:2},{value:"Next Steps",id:"next-steps",level:2}];function y(e){const n={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.header,{children:(0,l.jsx)(n.h1,{id:"mlflow-model-serving",children:"MLflow Model Serving"})}),"\n",(0,l.jsx)(n.p,{children:"Transform your trained models into production-ready inference servers with MLflow's comprehensive serving capabilities. Deploy locally, in the cloud, or through managed endpoints with standardized REST APIs."}),"\n",(0,l.jsx)(p.A,{concepts:[{icon:m.A,title:"REST API Endpoints",description:"Automatic generation of standardized REST endpoints for model inference with consistent request/response formats."},{icon:h.A,title:"Multi-Framework Support",description:"Serve models from any ML framework through MLflow's flavor system with unified deployment patterns."},{icon:u.A,title:"Custom Applications",description:"Build sophisticated serving applications with custom logic, preprocessing, and business rules."},{icon:f.A,title:"Scalable Deployment",description:"Deploy to various targets from local development servers to cloud platforms and Kubernetes clusters."}]}),"\n",(0,l.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,l.jsx)(n.p,{children:"Get your model serving in minutes with these simple steps:"}),"\n",(0,l.jsx)(a.A,{children:(0,l.jsxs)(s.A,{children:[(0,l.jsxs)(i.A,{value:"serve",label:"1. Serve Model",default:!0,children:[(0,l.jsx)(n.p,{children:"Choose your serving approach:"}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'# Serve a logged model\nmlflow models serve -m "models:/<model-id>" -p 5000\n\n# Serve a registered model\nmlflow models serve -m "models:/<model-name>/<model-version>" -p 5000\n\n# Serve a model from local path\nmlflow models serve -m ./path/to/model -p 5000\n'})}),(0,l.jsxs)(n.p,{children:["Your model will be available at ",(0,l.jsx)(n.code,{children:"http://localhost:5000"})]})]}),(0,l.jsxs)(i.A,{value:"predict",label:"2. Make Predictions",children:[(0,l.jsx)(n.p,{children:"Send prediction requests via HTTP:"}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'curl -X POST http://localhost:5000/invocations \\\n  -H "Content-Type: application/json" \\\n  -d \'{"inputs": [[1, 2, 3, 4]]}\'\n'})}),(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Using Python:"})}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'import requests\nimport json\n\ndata = {\n    "dataframe_split": {\n        "columns": ["feature1", "feature2", "feature3", "feature4"],\n        "data": [[1, 2, 3, 4]],\n    }\n}\n\nresponse = requests.post(\n    "http://localhost:5000/invocations",\n    headers={"Content-Type": "application/json"},\n    data=json.dumps(data),\n)\n\nprint(response.json())\n'})})]})]})}),"\n",(0,l.jsx)(n.h2,{id:"how-model-serving-works",children:"How Model Serving Works"}),"\n",(0,l.jsx)(n.p,{children:"MLflow transforms your trained models into production-ready HTTP servers through a carefully orchestrated process that handles everything from model loading to request processing."}),"\n",(0,l.jsx)(n.h3,{id:"server-startup-and-model-loading",children:"Server Startup and Model Loading"}),"\n",(0,l.jsxs)(n.p,{children:["When you run ",(0,l.jsx)(n.code,{children:"mlflow models serve"}),", MLflow begins by analyzing your model's metadata to determine how to load it. Each model contains an ",(0,l.jsx)(n.code,{children:"MLmodel"}),' file that specifies which "flavor" it uses - whether it\'s scikit-learn, PyTorch, TensorFlow, or a custom PyFunc model.']}),"\n",(0,l.jsx)(n.p,{children:"MLflow downloads the model artifacts to a local directory and creates a FastAPI server with standardized endpoints. The server loads your model using the appropriate flavor-specific loading logic. For example, a scikit-learn model is loaded using pickle, while a PyTorch model loads its state dictionary and model class."}),"\n",(0,l.jsx)(n.p,{children:"The server exposes four key endpoints:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:(0,l.jsx)(n.code,{children:"POST /invocations"})})," - The main prediction endpoint"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:(0,l.jsx)(n.code,{children:"GET /ping"})})," and ",(0,l.jsx)(n.strong,{children:(0,l.jsx)(n.code,{children:"GET /health"})})," - Health checks for monitoring"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:(0,l.jsx)(n.code,{children:"GET /version"})})," - Returns server and model information"]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"request-processing-pipeline",children:"Request Processing Pipeline"}),"\n",(0,l.jsxs)(n.p,{children:["When a prediction request arrives at ",(0,l.jsx)(n.code,{children:"/invocations"}),", MLflow processes it through several validation and transformation steps:"]}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Input Format Detection"}),": MLflow automatically detects which input format you're using. It supports multiple formats to accommodate different use cases:"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"dataframe_split"}),": Pandas DataFrame with separate columns and data arrays"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"dataframe_records"}),": List of dictionaries representing rows"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"instances"}),": TensorFlow Serving format for individual predictions"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.code,{children:"inputs"}),": Named tensor format for more complex inputs"]}),"\n"]}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Schema Validation"}),": If your model includes a signature (input/output schema), MLflow validates the incoming data against it. This catches type mismatches and missing columns before they reach your model."]}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Parameter Extraction"}),": MLflow separates prediction data from optional parameters. Parameters like ",(0,l.jsx)(n.code,{children:"temperature"})," for language models or ",(0,l.jsx)(n.code,{children:"threshold"})," for classifiers are extracted and passed separately to models that support them."]}),"\n",(0,l.jsx)(n.h3,{id:"model-prediction-and-response",children:"Model Prediction and Response"}),"\n",(0,l.jsxs)(n.p,{children:["Once the input is validated and formatted, MLflow calls your model's ",(0,l.jsx)(n.code,{children:"predict()"})," method. The framework automatically detects whether your model accepts parameters and calls it appropriately:"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"# For models that accept parameters\nraw_predictions = model.predict(data, params=params)\n\n# For traditional models\nraw_predictions = model.predict(data)\n"})}),"\n",(0,l.jsxs)(n.p,{children:["MLflow then serializes the predictions back to JSON, handling various data types including NumPy arrays, pandas DataFrames, and Python lists. The response format depends on your input format - traditional requests get wrapped in a ",(0,l.jsx)(n.code,{children:"predictions"})," object, while LLM-style requests return unwrapped results."]}),"\n",(0,l.jsx)(n.h3,{id:"the-flavor-system",children:"The Flavor System"}),"\n",(0,l.jsx)(n.p,{children:"MLflow's flavor system is what makes serving work consistently across different ML frameworks. Each flavor implements framework-specific loading and prediction logic while exposing a unified interface."}),"\n",(0,l.jsxs)(n.p,{children:["When you log a model using ",(0,l.jsx)(n.code,{children:"mlflow.sklearn.log_model()"})," or ",(0,l.jsx)(n.code,{children:"mlflow.pytorch.log_model()"}),", MLflow creates both a flavor-specific representation and a PyFunc wrapper. The PyFunc wrapper provides the standardized ",(0,l.jsx)(n.code,{children:"predict()"})," interface that the serving layer expects, while the flavor handles the framework-specific details like tensor operations or data preprocessing."]}),"\n",(0,l.jsx)(n.p,{children:"This architecture means you can serve scikit-learn, PyTorch, TensorFlow, and custom models using identical serving commands and APIs."}),"\n",(0,l.jsx)(n.h3,{id:"error-handling-and-debugging",children:"Error Handling and Debugging"}),"\n",(0,l.jsx)(n.p,{children:"MLflow's serving infrastructure includes comprehensive error handling to help you debug issues:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Schema Errors"}),": Detailed messages about data type mismatches or missing columns"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Format Errors"}),": Clear guidance when input format is incorrect or ambiguous"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Model Errors"}),": Full stack traces from your model's prediction code"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Server Errors"}),": Timeout and resource-related error handling"]}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:"The server logs all requests and errors, making it easier to diagnose production issues."}),"\n",(0,l.jsx)(n.h3,{id:"input-format-examples",children:"Input Format Examples"}),"\n",(0,l.jsx)(n.p,{children:"Here are the main input formats MLflow accepts:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-json",children:'// dataframe_split format\n{\n  "dataframe_split": {\n    "columns": ["feature1", "feature2", "feature3"],\n    "data": [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]\n  }\n}\n\n// dataframe_records format\n{\n  "dataframe_records": [\n    {"feature1": 1.0, "feature2": 2.0, "feature3": 3.0},\n    {"feature1": 4.0, "feature2": 5.0, "feature3": 6.0}\n  ]\n}\n\n// instances format (for simple models)\n{\n  "instances": [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]\n}\n'})}),"\n",(0,l.jsx)(n.p,{children:"All formats return a consistent response structure with your predictions and any additional metadata your model provides."}),"\n",(0,l.jsx)(n.h2,{id:"key-implementation-concepts",children:"Key Implementation Concepts"}),"\n",(0,l.jsx)(a.A,{children:(0,l.jsxs)(s.A,{children:[(0,l.jsxs)(i.A,{value:"model-preparation",label:"Model Preparation",default:!0,children:[(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Prepare your models for successful serving:"})}),(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Model Signatures"}),": Define input/output schemas for automatic request validation"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Environment Management"}),": Capture dependencies to ensure reproducible deployments"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Model Registry"}),": Use aliases for seamless production updates"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Metadata"}),": Include relevant context for debugging and monitoring"]}),"\n"]}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom mlflow.models.signature import infer_signature\nfrom mlflow.tracking import MlflowClient\n\n# Log model with comprehensive serving metadata\nsignature = infer_signature(X_train, model.predict(X_train))\nmlflow.sklearn.log_model(\n    sk_model=model,\n    name="my_model",\n    signature=signature,\n    registered_model_name="production_model",\n    input_example=X_train[:5],  # Visible example for the MLflow UI\n)\n\n# Use aliases for production deployment\nclient = MlflowClient()\nclient.set_registered_model_alias(\n    name="production_model", alias="production", version="1"\n)\n'})})]}),(0,l.jsxs)(i.A,{value:"serving-config",label:"Server Configuration",children:[(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Configure your serving infrastructure for optimal performance:"})}),(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Request Handling"}),": Set appropriate timeouts and batch sizes"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Resource Allocation"}),": Configure workers based on model complexity and load"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Input Formats"}),": Choose the right format for your data type"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Error Handling"}),": Implement proper logging and monitoring"]}),"\n"]}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'# Configure server for production workloads\nexport MLFLOW_SCORING_SERVER_REQUEST_TIMEOUT=60\nexport GUNICORN_CMD_ARGS="--timeout 60 --workers 4"\n\n# Serve with optimal settings\nmlflow models serve \\\n  --model-uri models:/my_model@production \\\n  --port 5000 \\\n  --env-manager local  # For production, use conda or virtualenv\n'})})]}),(0,l.jsxs)(i.A,{value:"custom-pyfunc",label:"Advanced Patterns",children:[(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Implement advanced serving patterns with custom PyFunc models:"})}),(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Preprocessing Logic"}),": Handle data transformation within the model"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Multi-Model Ensembles"}),": Combine predictions from multiple models"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Business Logic"}),": Integrate validation and post-processing rules"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Performance Optimization"}),": Batch processing and caching strategies"]}),"\n"]}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'import joblib\nimport mlflow\nimport pandas as pd\nimport numpy as np\nfrom typing import Dict, Any\n\n\nclass EnsembleModel(mlflow.pyfunc.PythonModel):\n    def load_context(self, context):\n        """Load multiple models for ensemble prediction"""\n        self.model_a = joblib.load(context.artifacts["model_a"])\n        self.model_b = joblib.load(context.artifacts["model_b"])\n        self.preprocessor = joblib.load(context.artifacts["preprocessor"])\n        # Load ensemble weights from config\n        self.weights = context.model_config.get("weights", [0.5, 0.5])\n\n    def predict(self, model_input: pd.DataFrame) -> np.ndarray:\n        """Combine predictions from multiple models"""\n        # Preprocess input\n        processed = self.preprocessor.transform(model_input)\n\n        # Get predictions from both models\n        pred_a = self.model_a.predict(processed)\n        pred_b = self.model_b.predict(processed)\n\n        # Weighted average ensemble\n        ensemble_pred = self.weights[0] * pred_a + self.weights[1] * pred_b\n\n        return ensemble_pred\n\n\n# Log ensemble model with artifacts\nartifacts = {\n    "model_a": "path/to/model_a.pkl",\n    "model_b": "path/to/model_b.pkl",\n    "preprocessor": "path/to/preprocessor.pkl",\n}\n\nmlflow.pyfunc.log_model(\n    name="ensemble_model",\n    python_model=EnsembleModel(),\n    artifacts=artifacts,\n    model_config={"weights": [0.6, 0.4]},\n    pip_requirements=["scikit-learn", "pandas", "numpy"],\n)\n'})})]})]})}),"\n",(0,l.jsx)(n.h2,{id:"complete-example-train-to-production",children:"Complete Example: Train to Production"}),"\n",(0,l.jsx)(n.p,{children:"Follow this step-by-step guide to go from model training to a deployed REST API:"}),"\n",(0,l.jsx)(a.A,{children:(0,l.jsxs)(s.A,{children:[(0,l.jsxs)(i.A,{value:"train",label:"1. Train & Log",default:!0,children:[(0,l.jsx)(n.p,{children:"Train a simple model with automatic logging:"}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport mlflow.sklearn\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n\n# Load sample data\niris = load_iris()\nX = iris.data\ny = iris.target\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# Enable sklearn autologging with model registration\nmlflow.sklearn.autolog(registered_model_name="iris_classifier")\n\n# Train model - MLflow automatically logs everything\nwith mlflow.start_run() as run:\n    model = RandomForestClassifier(n_estimators=10, random_state=42)\n    model.fit(X_train, y_train)\n\n    # Autologging automatically captures:\n    # - Model artifacts\n    # - Training parameters (n_estimators, random_state, etc.)\n    # - Training metrics (score on training data)\n    # - Model signature (inferred from training data)\n    # - Input example\n\n    # Optional: Log additional custom metrics\n    accuracy = model.score(X_test, y_test)\n    mlflow.log_metric("test_accuracy", accuracy)\n\n    print(f"Run ID: {run.info.run_id}")\n    print("Model automatically logged and registered!")\n'})})]}),(0,l.jsxs)(i.A,{value:"register",label:"2. Promote Model",children:[(0,l.jsx)(n.p,{children:"Set up model alias for production:"}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'from mlflow.tracking import MlflowClient\n\nclient = MlflowClient()\n\n# Get the latest registered version (autologging creates version 1)\nmodel_version = client.get_registered_model("iris_classifier").latest_versions[0]\n\n# Set production alias (replaces deprecated stages)\nclient.set_registered_model_alias(\n    name="iris_classifier", alias="production", version=model_version.version\n)\n\nprint(f"Model version {model_version.version} tagged as \'production\'")\n\n# Model URI for serving (using alias)\nmodel_uri = "models:/iris_classifier@production"\nprint(f"Production model URI: {model_uri}")\n'})})]}),(0,l.jsxs)(i.A,{value:"serve",label:"3. Start Server",children:[(0,l.jsx)(n.p,{children:"Serve the registered model:"}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'# Serve using model alias (MLflow 3.x way)\nmlflow models serve \\\n  --model-uri "models:/iris_classifier@production" \\\n  --port 5000 \\\n  --env-manager local\n\n# Server will start at http://localhost:5000\n# Available endpoints:\n# - POST /invocations (predictions)\n# - GET /ping (health check)\n# - GET /version (model info)\n'})}),(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Alternative serving approaches:"})}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'# Serve by specific version number\nmlflow models serve \\\n  --model-uri "models:/iris_classifier/1" \\\n  --port 5000\n\n# Serve from run URI\nmlflow models serve \\\n  --model-uri "runs:/<run-id>/model" \\\n  --port 5000\n'})})]}),(0,l.jsxs)(i.A,{value:"predict",label:"4. Make Predictions",children:[(0,l.jsx)(n.p,{children:"Send requests to your served model:"}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'import requests\nimport json\nimport pandas as pd\n\n# Prepare test data (same format as training)\ntest_data = {\n    "dataframe_split": {\n        "columns": [\n            "sepal length (cm)",\n            "sepal width (cm)",\n            "petal length (cm)",\n            "petal width (cm)",\n        ],\n        "data": [\n            [5.1, 3.5, 1.4, 0.2],  # setosa\n            [6.2, 2.9, 4.3, 1.3],  # versicolor\n            [7.3, 2.9, 6.3, 1.8],  # virginica\n        ],\n    }\n}\n\n# Make prediction request\nresponse = requests.post(\n    "http://localhost:5000/invocations",\n    headers={"Content-Type": "application/json"},\n    data=json.dumps(test_data),\n)\n\n# Parse response\nif response.status_code == 200:\n    predictions = response.json()\n    print("Predictions:", predictions)\n    # Output: {"predictions": [0, 1, 2]}\nelse:\n    print(f"Error: {response.status_code}, {response.text}")\n\n# Health check\nhealth = requests.get("http://localhost:5000/ping")\nprint("Health status:", health.status_code)  # Should be 200\n\n# Model info\ninfo = requests.get("http://localhost:5000/version")\nprint("Model version info:", info.json())\n'})})]})]})}),"\n",(0,l.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,l.jsx)(n.p,{children:"Ready to build more advanced serving applications? Explore these specialized topics:"}),"\n",(0,l.jsx)(n.admonition,{title:"Get Started",type:"tip",children:(0,l.jsx)(n.p,{children:"The examples in each section are designed to be practical and ready-to-use. Start with the Quick Start above, then explore the use cases that match your deployment needs."})}),"\n",(0,l.jsxs)(c.A,{children:[(0,l.jsx)(d.A,{icon:h.A,title:"Custom Applications",description:"Build sophisticated serving logic with custom preprocessing, routing, and business rules",href:"./custom-apps",linkText:"Build custom apps \u2192"}),(0,l.jsx)(d.A,{icon:g.A,title:"Responses Agents",description:"Handle complex response patterns and multi-step inference workflows",href:"./responses-agent",linkText:"Learn about agents \u2192"})]})]})}function j(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(y,{...e})}):y(e)}},79206:(e,n,r)=>{r.d(n,{A:()=>o});r(96540);const t={conceptOverview:"conceptOverview_x8T_",overviewTitle:"overviewTitle_HyAI",conceptGrid:"conceptGrid_uJNV",conceptCard:"conceptCard_oday",conceptHeader:"conceptHeader_HCk5",conceptIcon:"conceptIcon_gejw",conceptTitle:"conceptTitle_TGMM",conceptDescription:"conceptDescription_ZyDn"};var l=r(74848);function o({concepts:e,title:n}){return(0,l.jsxs)("div",{className:t.conceptOverview,children:[n&&(0,l.jsx)("h3",{className:t.overviewTitle,children:n}),(0,l.jsx)("div",{className:t.conceptGrid,children:e.map(((e,n)=>(0,l.jsxs)("div",{className:t.conceptCard,children:[(0,l.jsxs)("div",{className:t.conceptHeader,children:[e.icon&&(0,l.jsx)("div",{className:t.conceptIcon,children:(0,l.jsx)(e.icon,{size:20})}),(0,l.jsx)("h4",{className:t.conceptTitle,children:e.title})]}),(0,l.jsx)("p",{className:t.conceptDescription,children:e.description})]},n)))})]})}},80964:(e,n,r)=>{r.d(n,{A:()=>t});const t=(0,r(84722).A)("settings",[["path",{d:"M12.22 2h-.44a2 2 0 0 0-2 2v.18a2 2 0 0 1-1 1.73l-.43.25a2 2 0 0 1-2 0l-.15-.08a2 2 0 0 0-2.73.73l-.22.38a2 2 0 0 0 .73 2.73l.15.1a2 2 0 0 1 1 1.72v.51a2 2 0 0 1-1 1.74l-.15.09a2 2 0 0 0-.73 2.73l.22.38a2 2 0 0 0 2.73.73l.15-.08a2 2 0 0 1 2 0l.43.25a2 2 0 0 1 1 1.73V20a2 2 0 0 0 2 2h.44a2 2 0 0 0 2-2v-.18a2 2 0 0 1 1-1.73l.43-.25a2 2 0 0 1 2 0l.15.08a2 2 0 0 0 2.73-.73l.22-.39a2 2 0 0 0-.73-2.73l-.15-.08a2 2 0 0 1-1-1.74v-.5a2 2 0 0 1 1-1.74l.15-.09a2 2 0 0 0 .73-2.73l-.22-.38a2 2 0 0 0-2.73-.73l-.15.08a2 2 0 0 1-2 0l-.43-.25a2 2 0 0 1-1-1.73V4a2 2 0 0 0-2-2z",key:"1qme2f"}],["circle",{cx:"12",cy:"12",r:"3",key:"1v7zrd"}]])},84722:(e,n,r)=>{r.d(n,{A:()=>c});var t=r(96540);const l=e=>{const n=(e=>e.replace(/^([A-Z])|[\s-_]+(\w)/g,((e,n,r)=>r?r.toUpperCase():n.toLowerCase())))(e);return n.charAt(0).toUpperCase()+n.slice(1)},o=(...e)=>e.filter(((e,n,r)=>Boolean(e)&&""!==e.trim()&&r.indexOf(e)===n)).join(" ").trim(),s=e=>{for(const n in e)if(n.startsWith("aria-")||"role"===n||"title"===n)return!0};var i={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};const a=(0,t.forwardRef)((({color:e="currentColor",size:n=24,strokeWidth:r=2,absoluteStrokeWidth:l,className:a="",children:c,iconNode:d,...p},m)=>(0,t.createElement)("svg",{ref:m,...i,width:n,height:n,stroke:e,strokeWidth:l?24*Number(r)/Number(n):r,className:o("lucide",a),...!c&&!s(p)&&{"aria-hidden":"true"},...p},[...d.map((([e,n])=>(0,t.createElement)(e,n))),...Array.isArray(c)?c:[c]]))),c=(e,n)=>{const r=(0,t.forwardRef)((({className:r,...s},i)=>{return(0,t.createElement)(a,{ref:i,iconNode:n,className:o(`lucide-${c=l(e),c.replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()}`,`lucide-${e}`,r),...s});var c}));return r.displayName=l(e),r}},93164:(e,n,r)=>{r.d(n,{A:()=>t});const t=(0,r(84722).A)("code",[["path",{d:"m16 18 6-6-6-6",key:"eg8j8"}],["path",{d:"m8 6-6 6 6 6",key:"ppft3o"}]])},93893:(e,n,r)=>{r.d(n,{A:()=>t});const t=(0,r(84722).A)("users",[["path",{d:"M16 21v-2a4 4 0 0 0-4-4H6a4 4 0 0 0-4 4v2",key:"1yyitq"}],["path",{d:"M16 3.128a4 4 0 0 1 0 7.744",key:"16gr8j"}],["path",{d:"M22 21v-2a4 4 0 0 0-3-3.87",key:"kshegd"}],["circle",{cx:"9",cy:"7",r:"4",key:"nufk8"}]])}}]);