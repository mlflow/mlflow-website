"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[3887],{12823:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/signature-vs-no-signature-6981ed9f06b1c588ccd0a276c350c62a.png"},15059:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>p,contentTitle:()=>m,default:()=>u,frontMatter:()=>d,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"model/signatures/index","title":"MLflow Model Signatures and Input Examples Guide","description":"Introduction to Model Signatures and Input Examples \\\\","source":"@site/docs/model/signatures/index.mdx","sourceDirName":"model/signatures","slug":"/model/signatures/","permalink":"/docs/latest/model/signatures/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_label":"Model Signature","sidebar_position":1},"sidebar":"docsSidebar","previous":{"title":"Overview","permalink":"/docs/latest/model/"},"next":{"title":"Dependency Management","permalink":"/docs/latest/model/dependencies/"}}');var i=t(74848),s=t(28453),o=t(56289),l=t(20723),r=t(67756);const d={sidebar_label:"Model Signature",sidebar_position:1},m="MLflow Model Signatures and Input Examples Guide",p={},c=[{value:"Introduction to Model Signatures and Input Examples",id:"intro-model-signature-input-example",level:2},{value:"Model Signature",id:"model-signature",level:3},{value:"Model Input Example",id:"model-input-example",level:3},{value:"Why are these important?",id:"why-are-these-important",level:2},{value:"Model Signature",id:"model-signature-1",level:2},{value:"Model Signature Components",id:"model-signature-components",level:3},{value:"Signature Playground",id:"signature-playground",level:3},{value:"Required vs. Optional Input fields",id:"required-vs-optional-input-fields",level:3},{value:"Model Signature Types",id:"model-signature-types",level:2},{value:"Column-based Signatures",id:"column-based-signatures",level:3},{value:"Supported Data Types",id:"supported-data-types-column",level:4},{value:"Optional Column",id:"optional-column",level:4},{value:"Tensor-based Signatures",id:"tensor-based-signatures",level:3},{value:"Supported Data Types",id:"supported-data-types-tensor",level:4},{value:"Model Signatures with Inference Params",id:"inference-params",level:3},{value:"Supported Data Types for Params",id:"supported-data-types-params",level:4},{value:"Signature Enforcement",id:"signature-enforcement",level:2},{value:"Name Ordering Enforcement",id:"name-ordering-enforcement",level:3},{value:"Input Type Enforcement",id:"input-type-enforcement",level:3},{value:"Params Type and Shape Enforcement",id:"params-type-and-shape-enforcement",level:3},{value:"Handling Integers With Missing Values",id:"handling-integers-with-missing-values",level:4},{value:"Handling Date and Timestamp",id:"handling-date-and-timestamp",level:4},{value:"Handling Ragged Arrays",id:"handling-ragged-arrays",level:4},{value:"How To Log Models With Signatures",id:"how-to-log-models-with-signatures",level:2},{value:"Column-based Signature Example",id:"column-based-signature-example",level:3},{value:"Tensor-based Signature Example",id:"tensor-based-signature-example",level:3},{value:"Signature with params Example",id:"signature-with-params-example",level:3},{value:"Model signature examples for GenAI flavors",id:"genai-model-signature-example",level:3},{value:"How To Set Signatures on Models",id:"how-to-set-signatures-on-models",level:2},{value:"Setting a Signature on a Logged Model",id:"setting-a-signature-on-a-logged-model",level:3},{value:"Setting a Signature on a Registered Model",id:"set-signature-on-mv",level:2},{value:"Model Input Example",id:"input-example",level:2},{value:"How To Log Model With Column-based Example",id:"how-to-log-model-with-column-based-example",level:3},{value:"How To Log Models With a Tensor-based Example",id:"how-to-log-models-with-a-tensor-based-example",level:3},{value:"How To Log Models Using a JSON Object Example",id:"how-to-log-models-using-a-json-object-example",level:3},{value:"How To Log Model With an Example that Contains Params",id:"how-to-log-model-with-an-example-that-contains-params",level:3},{value:"Model Serving Payload Example",id:"model-serving-payload-example",level:2}];function h(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"mlflow-model-signatures-and-input-examples-guide",children:"MLflow Model Signatures and Input Examples Guide"})}),"\n",(0,i.jsx)(n.h2,{id:"intro-model-signature-input-example",children:"Introduction to Model Signatures and Input Examples"}),"\n",(0,i.jsxs)(n.p,{children:["In MLflow, the concepts of ",(0,i.jsx)(n.em,{children:"Model Signature"})," and ",(0,i.jsx)(n.em,{children:"Model Input Example"})," are essential for effectively working with machine learning models.\nThese components do more than just provide metadata; they establish crucial guidelines for model interaction, enhancing integration and\nusability within MLflow's ecosystem."]}),"\n",(0,i.jsx)(n.h3,{id:"model-signature",children:"Model Signature"}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.a,{href:"#model-signature",children:"Model Signature"})," in MLflow is integral to the clear and accurate operation of models. It defines the expected\nformat for model inputs and outputs, including any additional parameters needed for inference. This specification acts as a\ndefinitive guide, ensuring seamless model integration with MLflow's tools and external services."]}),"\n",(0,i.jsx)(n.h3,{id:"model-input-example",children:"Model Input Example"}),"\n",(0,i.jsxs)(n.p,{children:["Complementing the Model Signature, the ",(0,i.jsx)(n.a,{href:"#input-example",children:"Model Input Example"})," gives a concrete instance of what valid model input\nlooks like. This hands-on example is invaluable for developers, offering a clear understanding of the required data format and structure\nfor effective model testing and real-world application."]}),"\n",(0,i.jsx)(n.h2,{id:"why-are-these-important",children:"Why are these important?"}),"\n",(0,i.jsx)("div",{className:"center=div",style:{width:"90%"},children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(12823).A+"",width:"1589",height:"694"})})}),"\n",(0,i.jsx)(n.p,{children:"Model signatures and input examples are foundational to robust ML workflows, offering a blueprint for model interactions that ensures consistency,\naccuracy, and ease of use. They act as a contract between the model and its users, providing a definitive guide to the expected data format,\nthus preventing miscommunication and errors that can arise from incorrect or unexpected inputs."}),"\n",(0,i.jsx)(n.h2,{id:"model-signature-1",children:"Model Signature"}),"\n",(0,i.jsxs)(n.p,{children:["In MLflow, a model signature precisely defines the schema for model inputs, outputs, and any additional parameters required for effective model\noperation. This definition serves as a uniform interface, guiding users in the appropriate and accurate use of their models. Model signatures are\nintegral to the MLflow ecosystem, enabling both the MLflow Tracking UI and Model Registry UI to clearly display the model's required inputs,\noutputs, and parameters. Additionally, ",(0,i.jsx)(n.a,{href:"/model#built-in-deployment",children:"MLflow model deployment tools"})," utilize these signatures to ensure that\nthe data used at inference aligns with the model's established specifications, thus maintaining the model's integrity and performance. For\nmore insights into how these signatures enforce data accuracy, see the ",(0,i.jsx)(n.a,{href:"#signature-enforcement",children:"Signature enforcement"})," section."]}),"\n",(0,i.jsxs)(n.p,{children:["Embedding a signature in your model is a straightforward process in MLflow. When using functions like ",(0,i.jsx)(r.B,{fn:"mlflow.sklearn.log_model",children:(0,i.jsx)(n.code,{children:"sklearn.log_model()"})}),"\nto log or save a model, simply include a ",(0,i.jsx)(n.a,{href:"#input-example",children:"model input example"}),". This action enables MLflow to ",(0,i.jsx)(n.strong,{children:"automatically infer the model's signature"}),".\nDetailed instructions on this process can be found in the ",(0,i.jsx)(n.a,{href:"#how-to-log-models-with-signatures",children:"How to log models with signatures"})," section.\nThe inferred signatures, along with other essential model metadata, are stored in a JSON format within the ",(0,i.jsx)(o.A,{to:"/api_reference/python_api/mlflow.pyfunc.html#pyfunc-model-config",target:"_blank",children:"MLmodel file"})," of\nyour model artifacts. If there's a need to add a signature to a model that has already been logged or saved,\nthe ",(0,i.jsx)(r.B,{fn:"mlflow.models.set_signature",children:(0,i.jsx)(n.code,{children:"set_signature()"})})," API is available for this purpose. Consult the\n",(0,i.jsx)(n.a,{href:"#how-to-set-signatures-on-models",children:"How to set signatures on models"})," section for a detailed guide on implementing this functionality."]}),"\n",(0,i.jsx)(n.h3,{id:"model-signature-components",children:"Model Signature Components"}),"\n",(0,i.jsxs)(n.p,{children:["The structure of a model signature in MLflow is composed of three distinct schema types: ",(0,i.jsx)(n.strong,{children:"(1) inputs"}),", ",(0,i.jsx)(n.strong,{children:"(2) outputs"}),", and ",(0,i.jsx)(n.strong,{children:"(3) parameters (params)"}),".\nThe ",(0,i.jsx)(n.strong,{children:"inputs"})," and ",(0,i.jsx)(n.strong,{children:"outputs"})," schemas specify the data structure that the model expects to receive and produce, respectively. These can be tailored to handle\na variety of data formats, including columnar data and tensors, as well as Array and Object type inputs, catering to the diverse needs of different models."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Parameters (params)"}),", on the other hand, refer to the additional, often optional, parameters that are crucial during the model's inference stage.\nThese parameters provide added flexibility, allowing for fine-tuning and customization of the inference process."]}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsxs)(n.p,{children:["The capability to handle Objects and Arrays in model signatures was introduced in ",(0,i.jsx)(n.strong,{children:"MLflow version 2.10.0"})," and onwards. In versions prior to 2.10.0,\ncolumn-based signatures were limited to scalar input types and certain conditional types specific to lists and dictionary inputs, with support primarily\nfor the ",(0,i.jsx)(n.a,{href:"/llms/transformers",children:"transformers"})," flavor. This enhancement in later versions significantly broadens the scope of data types and\nstructures that MLflow can seamlessly accommodate."]})}),"\n",(0,i.jsx)(n.h3,{id:"signature-playground",children:"Signature Playground"}),"\n",(0,i.jsxs)(n.p,{children:["In order to aid in understanding how data structures will be automatically inferred as a valid signature, as well as to provide extensive examples of\nvalid signatures, we've created a notebook that you can view, showing different examples and their resulting inferred signatures.\nYou can ",(0,i.jsx)(n.a,{href:"/model/notebooks/signature_examples",children:"view the notebook here"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"Alternatively, if you'd like to download the notebook locally and test it out with your own data structures, you can download it below."}),"\n",(0,i.jsx)(l.O,{href:"https://raw.githubusercontent.com/mlflow/mlflow/master/docs/source/model/notebooks/signature_examples.ipynb",children:(0,i.jsx)("span",{children:"Download the Signature Playground Notebook"})}),"\n",(0,i.jsx)(n.h3,{id:"required-vs-optional-input-fields",children:"Required vs. Optional Input fields"}),"\n",(0,i.jsx)(n.p,{children:"There are certain conditions that determine enforcement of signatures that are important to consider when defining your model signatures. One of the\nmost notable is the concept of required vs. optional with regards to input data."}),"\n",(0,i.jsx)(n.p,{children:"Required fields are those that must be present in the input data in order for the model to be able to make a prediction. If a required field is missing,\nthe signature enforcement validation will raise an exception stating that the required input field is missing."}),"\n",(0,i.jsxs)(n.p,{children:["In order to configure a field as optional, you must pass in a value of ",(0,i.jsx)(n.em,{children:"None"})," or ",(0,i.jsx)(n.em,{children:"np.nan"})," for that field when using the ",(0,i.jsx)(r.B,{fn:"mlflow.models.infer_signature"}),"\nfunction. Alternatively, you can manually define the signature and set the ",(0,i.jsx)(n.em,{children:"required"})," field to ",(0,i.jsx)(n.em,{children:"false"})," for that field."]}),"\n",(0,i.jsx)(n.h2,{id:"model-signature-types",children:"Model Signature Types"}),"\n",(0,i.jsx)(n.p,{children:"MLflow supports two primary types of signatures: a column-based signature for tabular-based data, and a tensor-based signature for tensor data."}),"\n",(0,i.jsx)(n.h3,{id:"column-based-signatures",children:"Column-based Signatures"}),"\n",(0,i.jsxs)(n.p,{children:["Column-based signatures are commonly utilized in traditional machine learning models that require tabular data inputs, such as a Pandas DataFrame.\nThese signatures consist of a series of columns, each potentially having a name and a specified data type. The type of each column in both input\nand output corresponds to one of the ",(0,i.jsx)(n.a,{href:"#supported-data-types-column",children:"supported data types"}),", and columns can be optionally named. Additionally,\ncolumns in the input schema can be designated as ",(0,i.jsx)(n.code,{children:"optional"}),", indicating that their inclusion in the model's input is not mandatory and they can be\nleft out if necessary (see ",(0,i.jsx)(n.a,{href:"#optional-column",children:"Optional Column"})," for more details)."]}),"\n",(0,i.jsx)(n.h4,{id:"supported-data-types-column",children:"Supported Data Types"}),"\n",(0,i.jsxs)(n.p,{children:["Column-based signatures support data primitives defined within the ",(0,i.jsx)(r.B,{fn:"mlflow.types.DataType",children:"MLflow DataType"})," specification:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"string"}),"\n",(0,i.jsxs)(n.li,{children:["integer ",(0,i.jsx)("sup",{children:(0,i.jsx)(n.code,{children:"1"})})]}),"\n",(0,i.jsx)(n.li,{children:"long"}),"\n",(0,i.jsx)(n.li,{children:"float"}),"\n",(0,i.jsx)(n.li,{children:"double"}),"\n",(0,i.jsx)(n.li,{children:"boolean"}),"\n",(0,i.jsx)(n.li,{children:"datetime"}),"\n"]}),"\n",(0,i.jsxs)("table",{children:[(0,i.jsx)("thead",{children:(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"Input (Python)"}),(0,i.jsx)("th",{children:"Inferred Signature"})]})}),(0,i.jsx)("tbody",{children:(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from mlflow.models import infer_signature\n\ninfer_signature(model_input={"long_col": 1, "str_col": "a", "bool_col": True})\n'})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'signature:\n    input: \'[\n        {"name": "long_col", "type": "long",    "required": "true"},\n        {"name": "str_col",  "type": "string",  "required": "true"},\n        {"name": "bool_col", "type": "boolean", "required": "true"}\n    ]\'\n    output: null\n    params: null\n'})})})]})})]}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsxs)(n.p,{children:[(0,i.jsx)("sup",{children:(0,i.jsx)(n.code,{children:"1"})})," Python often represents missing values in integer data as floats, causing type variability in integer columns and potential schema enforcement errors in MLflow. To avoid such issues, particularly when using Python in MLflow for model serving and Spark deployments, define integer columns with missing values as doubles (float64)."]})}),"\n",(0,i.jsx)(n.p,{children:"Column-based signature also support composite data types of these primitives."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Array (list, numpy arrays)"}),"\n",(0,i.jsxs)(n.li,{children:["Spark ML vector (it inherits ",(0,i.jsx)(n.code,{children:"Array[double]"})," type)"]}),"\n",(0,i.jsx)(n.li,{children:"Object (dictionary)"}),"\n",(0,i.jsx)(n.li,{children:"AnyType"}),"\n"]}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsxs)(n.p,{children:["AnyType is a special type that can be used to represent any data type, including None values. If this type is used, input data is not validated at all during schema enforcement process in pyfunc predict.\n",(0,i.jsx)(n.em,{children:"mlflow.models.infer_signature"})," function infers a field as AnyType only if the field is always None (e.g. ",(0,i.jsx)(n.code,{children:"{\"a\": None} --\x3e ['a': Any (optional)]"}),"); if the field has other valid types, the field is inferred\nas optional instead (e.g. ",(0,i.jsx)(n.code,{children:'[{"a": None}, {"a": "abc"}] --\x3e [\'a\': string (optional)]'}),").\nIf one field explicitly accepts multiple valid types (e.g. ",(0,i.jsx)(n.code,{children:'[{"a": "string"}, {"a": 123}]'}),"), ",(0,i.jsx)(n.em,{children:"infer_signature"})," function would fail and you need to manually construct the signature using ",(0,i.jsx)(n.em,{children:"ModelSignature"})," object\nwith ",(0,i.jsx)(n.em,{children:"AnyType"})," type for the field. (e.g. ",(0,i.jsx)(n.code,{children:'ModelSignature(Schema([ColSpec(AnyType(), "a", required=False)]))'}),")"]})}),"\n",(0,i.jsx)(n.admonition,{type:"warning",children:(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Support for Array and Object types was introduced in MLflow version ",(0,i.jsx)(n.strong,{children:"2.10.0"}),". These types will not be recognized in previous versions of MLflow. If you are saving a model that uses these signature types, you should ensure that any other environment that attempts to load these models has a version of MLflow installed that is at least 2.10.0."]}),"\n",(0,i.jsxs)(n.li,{children:["Support for Spark ML vector type was introduced in MLflow version ",(0,i.jsx)(n.strong,{children:"2.15.0"}),", These type will not be recognized in previous versions of MLflow."]}),"\n",(0,i.jsxs)(n.li,{children:["Support for AnyType was introduced in MLflow version ",(0,i.jsx)(n.strong,{children:"2.19.0"}),". This type will not be recognized in previous versions of MLflow."]}),"\n"]})}),"\n",(0,i.jsxs)(n.p,{children:["Additional examples for composite data types can be seen by viewing the ",(0,i.jsx)(n.a,{href:"/model/notebooks/signature_examples",children:"signature examples notebook"}),"."]}),"\n",(0,i.jsxs)("table",{children:[(0,i.jsx)("thead",{children:(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"Input (Python)"}),(0,i.jsx)("th",{children:"Inferred Signature"})]})}),(0,i.jsx)("tbody",{children:(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from mlflow.models import infer_signature\n\ninfer_signature(\n    model_input={\n        # Python list\n        "list_col": ["a", "b", "c"],\n        # Numpy array\n        "numpy_col": np.array([[1, 2], [3, 4]]),\n        # Dictionary\n        "obj_col": {"long_prop": 1, "array_prop": ["a", "b", "c"]},\n    }\n)\n'})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'signature:\n    input: \'[\n        {"list_col": Array(string) (required)},\n        {"numpy_col": Array(Array(long)) (required)},\n        {"obj_col": {array_prop: Array(string) (required), long_prop: long (required)} (required)}}\n    ]\'\n    output: null\n    params: null\n'})})})]})})]}),"\n",(0,i.jsx)(n.h4,{id:"optional-column",children:"Optional Column"}),"\n",(0,i.jsxs)(n.p,{children:["Columns that contain ",(0,i.jsx)(n.em,{children:"None"})," or ",(0,i.jsx)(n.em,{children:"np.nan"})," values within the input data will be inferred as ",(0,i.jsx)(n.em,{children:"optional"})," (i.e. ",(0,i.jsx)(n.em,{children:"required=False"}),")"]}),"\n",(0,i.jsxs)("table",{children:[(0,i.jsx)("thead",{children:(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"Input (Python)"}),(0,i.jsx)("th",{children:"Inferred Signature"})]})}),(0,i.jsx)("tbody",{children:(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from mlflow.models import infer_signature\n\ninfer_signature(model_input=pd.DataFrame({"col": [1.0, 2.0, None]}))\n'})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'signature:\n    input: \'[\n        {"name": "col", "type": "double", "required": false}\n    ]\'\n    output: null\n    params: null\n'})})})]})})]}),"\n",(0,i.jsxs)(n.admonition,{type:"note",children:[(0,i.jsxs)(n.p,{children:["Nested arrays can contain an empty list, and it does not make the column ",(0,i.jsx)(n.em,{children:"optional"})," as it represents an empty set (\u2205). In such case,\nthe schema will be inferred from the other elements of the list, assuming they have homogeneous types. If you want to make a column optional,\npass ",(0,i.jsx)(n.em,{children:"None"})," instead."]}),(0,i.jsxs)("table",{children:[(0,i.jsx)("thead",{children:(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"Input (Python)"}),(0,i.jsx)("th",{children:"Inferred Signature"})]})}),(0,i.jsx)("tbody",{children:(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'infer_signature(\n    model_input={\n        "list_with_empty": [["a", "b"], []],\n        "list_with_none": [["a", "b"], None],\n    }\n)\n'})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'signature:\n    input: \'[\n        {"name": "list_with_empty", "type": "Array(str)", "required": "true" },\n        {"name": "list_with_none" , "type": "Array(str)", "required": "false"},\n    ]\'\n    output: null\n    params: null\n'})})})]})})]})]}),"\n",(0,i.jsx)(n.h3,{id:"tensor-based-signatures",children:"Tensor-based Signatures"}),"\n",(0,i.jsxs)(n.p,{children:["Tensor-based signatures are primarily employed in models that process tensor inputs, commonly found in deep learning applications involving images,\naudio data, and similar formats. These schemas consist of sequences of tensors, each potentially named and defined by a specific\n",(0,i.jsx)(n.a,{href:"https://numpy.org/devdocs/user/basics.types.html",children:"numpy data type"}),"."]}),"\n",(0,i.jsxs)(n.p,{children:["In a tensor-based signature, each input and output tensor is characterized by three attributes: a ",(0,i.jsx)(n.strong,{children:"dtype"})," (data type, aligning with\n",(0,i.jsx)(n.a,{href:"https://numpy.org/devdocs/user/basics.types.html",children:"numpy data types"}),"), a ",(0,i.jsx)(n.strong,{children:"shape"}),", and an optional ",(0,i.jsx)(n.strong,{children:"name"}),". It's important to note that\ntensor-based signatures do not accommodate optional inputs. The shape attribute often uses -1 for any dimension whose size may vary,\ncommonly seen in batch processing."]}),"\n",(0,i.jsxs)(n.p,{children:["Consider a classification model trained on the ",(0,i.jsx)(n.a,{href:"http://yann.lecun.com/exdb/mnist",children:"MNIST dataset"}),". An example of its model signature would feature\nan input tensor representing an image as a 28 \xd7 28 \xd7 1 array of float32 numbers. The model's output might be a tensor signifying the probability\nfor each of the 10 target classes. In such cases, the first dimension, representing the batch size, is typically set to -1, allowing the model\nto handle batches of varying sizes."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'signature:\n  inputs: \'[{"name": "images", "type": "tensor", "tensor-spec": {"dtype": "uint8", "shape": [-1, 28, 28, 1]}}]\'\n  outputs: \'[{"type": "tensor", "tensor-spec": {"shape": [-1, 10], "dtype": "float32"}}]\'\n  params: null\n'})}),"\n",(0,i.jsx)(n.h4,{id:"supported-data-types-tensor",children:"Supported Data Types"}),"\n",(0,i.jsxs)(n.p,{children:["Tensor-based schemas support ",(0,i.jsx)(n.a,{href:"https://numpy.org/devdocs/user/basics.types.html",children:"numpy data types"}),"."]}),"\n",(0,i.jsxs)("table",{children:[(0,i.jsx)("thead",{children:(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"Input (Python)"}),(0,i.jsx)("th",{children:"Inferred Signature"})]})}),(0,i.jsx)("tbody",{children:(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from mlflow.models import infer_signature\n\ninfer_signature(\n    model_input=np.array(\n        [\n            [[1, 2, 3], [4, 5, 6]],\n            [[7, 8, 9], [1, 2, 3]],\n        ]\n    )\n)\n"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'signature:\n    input: \'[{"type": "tensor", "tensor-spec": {"dtype": "int64", "shape": [-1, 2, 3]}}]\'\n    output: None\n    params: None\n'})})})]})})]}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsxs)(n.p,{children:["Tensor-based schemas do not support optional inputs. You can pass an array with ",(0,i.jsx)(n.em,{children:"None"})," or ",(0,i.jsx)(n.em,{children:"np.nan"})," values,\nbut the schema doesn't flag them as optional."]})}),"\n",(0,i.jsx)(n.h3,{id:"inference-params",children:"Model Signatures with Inference Params"}),"\n",(0,i.jsxs)(n.p,{children:["Inference parameters (or 'params') are additional settings passed to models during the inference stage. Common examples include parameters\nlike ",(0,i.jsx)(n.code,{children:"temperature"})," and ",(0,i.jsx)(n.code,{children:"max_length"})," in Language Learning Models (LLMs). These params, not typically required during training, play a crucial role in\ntailoring the behavior of a model at the time of inference. This kind of configuration becomes increasingly important with foundational models,\nas the same model might need different parameter settings for various inference scenarios."]}),"\n",(0,i.jsxs)(n.p,{children:["MLflow's ",(0,i.jsx)(n.strong,{children:"2.6.0"})," release introduced the specification of a dictionary of inference params during model inference. This feature enhances the flexibility\nand control over the inference outcomes, enabling more nuanced model behavior adjustments."]}),"\n",(0,i.jsxs)(n.p,{children:["To leverage params at inference time, they must be incorporated into the ",(0,i.jsx)(n.a,{href:"#model-signature",children:"Model Signature"}),". The schema for params is\ndefined as a sequence of ",(0,i.jsx)(r.B,{fn:"mlflow.types.ParamSpec",children:(0,i.jsx)(n.code,{children:"ParamSpec"})})," elements, each comprising:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"name"}),": The identifier of the parameter, e.g., ",(0,i.jsx)(n.code,{children:"temperature"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"type"}),": The data type of the parameter, which must align with one of the ",(0,i.jsx)(n.a,{href:"#supported-data-types-params",children:"supported data types"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"default"}),": The default value for the parameter, ensuring a fallback option if a specific value isn't provided."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"shape"}),": The shape of the parameter, typically ",(0,i.jsx)(n.code,{children:"None"})," for scalar values and ",(0,i.jsx)(n.code,{children:"(-1,)"})," for lists."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"This feature marks a significant advancement in how MLflow handles model inference, offering a more dynamic and adaptable approach to model parameterization."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'signature:\n    inputs: \'[{"name": "input", "type": "string"}]\'\n    outputs: \'[{"name": "output", "type": "string"}]\'\n    params: \'[\n        {\n            "name": "temperature",\n            "type": "float",\n            "default": 0.5,\n            "shape": null\n        },\n        {\n            "name": "suppress_tokens",\n            "type": "integer",\n            "default": [101, 102],\n              "shape": [-1]\n        }\n    ]\'\n'})}),"\n",(0,i.jsx)(n.p,{children:"The inference parameters are supplied to the model in the form of a dictionary during the inference stage. Each parameter value is subject to\nvalidation to ensure it matches the type specified in the model's signature. The example below illustrates the process of defining parameters\nwithin a model signature and demonstrates their application in model inference."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom mlflow.models import infer_signature\n\n\nclass MyModel(mlflow.pyfunc.PythonModel):\n    def predict(self, context, model_input, params):\n        return list(params.values())\n\n\nparams = {"temperature": 0.5, "suppress_tokens": [101, 102]}\n# params\' default values are saved with ModelSignature\nsignature = infer_signature(["input"], params=params)\n\nwith mlflow.start_run():\n    model_info = mlflow.pyfunc.log_model(\n        python_model=MyModel(), name="my_model", signature=signature\n    )\n\nloaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n\n# Not passing params -- predict with default values\nloaded_predict = loaded_model.predict(["input"])\nassert loaded_predict == [0.5, [101, 102]]\n\n# Passing some params -- override passed-in params\nloaded_predict = loaded_model.predict(["input"], params={"temperature": 0.1})\nassert loaded_predict == [0.1, [101, 102]]\n\n# Passing all params -- override all params\nloaded_predict = loaded_model.predict(\n    ["input"], params={"temperature": 0.5, "suppress_tokens": [103]}\n)\nassert loaded_predict == [0.5, [103]]\n'})}),"\n",(0,i.jsx)(n.h4,{id:"supported-data-types-params",children:"Supported Data Types for Params"}),"\n",(0,i.jsxs)(n.p,{children:["Parameters in MLflow are defined to accept values of the ",(0,i.jsx)(r.B,{fn:"mlflow.types.DataType",children:(0,i.jsx)(n.code,{children:"MLflow DataType"})}),", including a one-dimensional\nlist of these data types. Currently, MLflow supports only 1D lists for parameters."]}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsxs)(n.p,{children:["When validating param values, the values will be converted to python native types.\nFor example, ",(0,i.jsx)(n.code,{children:"np.float32(0.1)"})," will be converted to ",(0,i.jsx)(n.code,{children:"float(0.1)"}),"."]})}),"\n",(0,i.jsx)(n.h2,{id:"signature-enforcement",children:"Signature Enforcement"}),"\n",(0,i.jsxs)(n.p,{children:["MLflow's schema enforcement rigorously validates the provided inputs and parameters against the model's signature. It raises an exception\nif the inputs are incompatible and either issues a warning or raises an exception for incompatible parameters. This enforcement is applied\nprior to invoking the underlying model implementation and throughout the model inference process. Note, however, that this enforcement is\nspecific to scenarios where ",(0,i.jsx)(n.a,{href:"/model#built-in-deployment",children:"MLflow model deployment tools"})," are used or when models are loaded as ",(0,i.jsx)(n.code,{children:"python_function"}),".\nIt does not apply to models loaded in their native format, such as through ",(0,i.jsx)(r.B,{fn:"mlflow.sklearn.load_model"}),"."]}),"\n",(0,i.jsx)("div",{className:"center-div",style:{width:"90%"},children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(79367).A+"",width:"1453",height:"1499"})})}),"\n",(0,i.jsx)(n.h3,{id:"name-ordering-enforcement",children:"Name Ordering Enforcement"}),"\n",(0,i.jsx)(n.p,{children:"In MLflow, input names are verified against the model signature. Missing required inputs trigger an exception, whereas missing optional inputs do\nnot. Inputs not declared in the signature are disregarded. When the input schema in the signature specifies input names, matching is conducted by\nname, and inputs are reordered accordingly. If the schema lacks input names, matching is based on the order of inputs, with MLflow checking only\nthe number of inputs provided."}),"\n",(0,i.jsx)(n.h3,{id:"input-type-enforcement",children:"Input Type Enforcement"}),"\n",(0,i.jsx)(n.p,{children:"MLflow enforces input types as defined in the model's signature. For column-based signature models (such as those using DataFrame inputs), MLflow\nperforms safe type conversions where necessary, allowing only lossless conversions. For example, converting int to long or int to double is\npermissible, but converting long to double is not. In cases where types cannot be made compatible, MLflow will raise an error."}),"\n",(0,i.jsx)(n.p,{children:"For Pyspark DataFrame inputs, MLflow casts a sample of the PySpark DataFrame into a Pandas DataFrame. MLflow will only enforce the schema on a subset of the data rows."}),"\n",(0,i.jsx)(n.p,{children:"For tensor-based signature models, type checking is more stringent. An exception is thrown if the input type does not align with the schema-specified type."}),"\n",(0,i.jsx)(n.h3,{id:"params-type-and-shape-enforcement",children:"Params Type and Shape Enforcement"}),"\n",(0,i.jsxs)(n.p,{children:["In MLflow, the types and shapes of parameters (params) are meticulously checked against the model's signature. During inference, each parameter's type\nand shape are validated to ensure they align with the specifications in the signature. Scalar values are expected to have a shape of ",(0,i.jsx)(n.code,{children:"None"}),", while list\nvalues should have a shape of ",(0,i.jsx)(n.code,{children:"(-1,)"}),". If a parameter's type or shape is found to be incompatible, MLflow raises an exception. Additionally, the parameter's\nvalue undergoes a validation check against its designated type in the signature. If the conversion to the specified type fails, an ",(0,i.jsx)(n.em,{children:"MlflowException"})," is\ntriggered. For a comprehensive list of valid params, refer to the ",(0,i.jsx)(n.a,{href:"#inference-params",children:"Model Inference Params"})," section."]}),"\n",(0,i.jsx)(n.admonition,{title:"important",type:"warning",children:(0,i.jsx)(n.p,{children:"Models with signatures that receive undeclared params during inference will trigger a warning for each request, and any invalid params will be disregarded."})}),"\n",(0,i.jsx)(n.h4,{id:"handling-integers-with-missing-values",children:"Handling Integers With Missing Values"}),"\n",(0,i.jsx)(n.p,{children:"In Python, integer data with missing values is often represented as floats. This leads to variability in the data types of integer columns, potentially\ncausing schema enforcement errors during runtime, as integers and floats are not inherently compatible. For instance, if a column 'c' in your training data\nis entirely integers, it will be recognized as such. However, if a missing value is introduced in 'c', it will be represented as a float. If the model's\nsignature expects 'c' to be an integer, MLflow will raise an error due to the inability to convert float to int. To mitigate this issue, especially since\nMLflow uses Python for model serving and Spark deployments, it's advisable to define integer columns with missing values as doubles (float64)."}),"\n",(0,i.jsx)(n.h4,{id:"handling-date-and-timestamp",children:"Handling Date and Timestamp"}),"\n",(0,i.jsxs)(n.p,{children:["Python's datetime types come with built-in precision, such as ",(0,i.jsx)(n.code,{children:"datetime64[D]"})," for day precision and ",(0,i.jsx)(n.code,{children:"datetime64[ns]"})," for nanosecond precision.\nWhile this precision detail is disregarded in column-based model signatures, it is enforced in tensor-based signatures."]}),"\n",(0,i.jsx)(n.h4,{id:"handling-ragged-arrays",children:"Handling Ragged Arrays"}),"\n",(0,i.jsxs)(n.p,{children:["Ragged arrays in numpy, characterized by a shape of (-1,) and a dtype of object, are automatically managed when using ",(0,i.jsx)(n.code,{children:"infer_signature"}),". This results\nin a signature like ",(0,i.jsx)(n.code,{children:"Tensor('object', (-1,))"}),". For a more detailed representation, a signature can be manually created to reflect the specific nature\nof a ragged array, such as ",(0,i.jsx)(n.code,{children:"Tensor('float64', (-1, -1, -1, 3))"}),". Enforcement is then applied as detailed in the signature, accommodating ragged input arrays."]}),"\n",(0,i.jsx)(n.h2,{id:"how-to-log-models-with-signatures",children:"How To Log Models With Signatures"}),"\n",(0,i.jsxs)(n.p,{children:["Including a signature with your model in MLflow is straightforward. Simply provide a ",(0,i.jsx)(n.a,{href:"#input-example",children:"model input example"})," when making a\ncall to either the log_model or save_model functions, such as with ",(0,i.jsx)(r.B,{fn:"mlflow.sklearn.log_model",children:(0,i.jsx)(n.code,{children:"sklearn.log_model()"})}),". MLflow will then\nautomatically infer the model's signature based on this input example and the model's predicted output for the given example."]}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsxs)(n.p,{children:["Starting MLflow 2.20.0, model signature is automatically inferred when logging a PythonModel with type hints. Check\n",(0,i.jsx)(n.a,{href:"../python_model#model-signature-inference-based-on-type-hints",children:"PythonModel with type hints guidance"})," for more details."]})}),"\n",(0,i.jsxs)(n.p,{children:["Alternatively, you can explicitly attach a signature object to your model. This is done by passing a ",(0,i.jsx)(r.B,{fn:"mlflow.models.ModelSignature",children:(0,i.jsx)(n.code,{children:"signature object"})}),"\nto your log_model or save_model function. You can manually create a model signature object or use the ",(0,i.jsx)(r.B,{fn:"mlflow.models.infer_signature",children:(0,i.jsx)(n.code,{children:"infer_signature"})}),"\nfunction to generate it from datasets with valid model inputs (for instance, a training dataset minus the target column), valid model outputs (such as\npredictions made on the training dataset), and valid model parameters (like a dictionary of parameters used for model inference, commonly seen in\n",(0,i.jsx)(n.a,{href:"https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.GenerationConfig",children:"Generation Configs for transformers"}),")."]}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsxs)(n.p,{children:["Model signatures play a crucial role in ",(0,i.jsx)(n.a,{href:"/model#built-in-deployment",children:"MLflow model deployment tools"}),", particularly for serving models in the Python\nFunction (PyFunc) flavor. Therefore, when attaching a signature to your log_model or save_model call, it's important to ensure that the signature\naccurately reflects the inputs and outputs expected by the model's PyFunc representation. This consideration becomes especially significant if the\nmodel's input schema, when loaded as a PyFunc, differs from that of the dataset used for testing (an example of this scenario is with the\n",(0,i.jsx)(n.a,{href:"/model#pmdarima-flavor",children:"pmdarima model flavor"}),")."]})}),"\n",(0,i.jsx)(n.h3,{id:"column-based-signature-example",children:"Column-based Signature Example"}),"\n",(0,i.jsxs)(n.p,{children:["The following example demonstrates how to store a model signature for a simple classifier trained\non the ",(0,i.jsx)(n.code,{children:"Iris dataset"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import pandas as pd\nfrom sklearn import datasets\nfrom sklearn.ensemble import RandomForestClassifier\nimport mlflow\n\niris = datasets.load_iris()\niris_train = pd.DataFrame(iris.data, columns=iris.feature_names)\nclf = RandomForestClassifier(max_depth=7, random_state=0)\n\nwith mlflow.start_run():\n    clf.fit(iris_train, iris.target)\n    # Take the first row of the training dataset as the model input example.\n    input_example = iris_train.iloc[[0]]\n    # The signature is automatically inferred from the input example and its predicted output.\n    mlflow.sklearn.log_model(clf, name="iris_rf", input_example=input_example)\n'})}),"\n",(0,i.jsx)(n.p,{children:"The same signature can be explicitly created and logged as follows:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from mlflow.models import ModelSignature, infer_signature\nfrom mlflow.types.schema import Schema, ColSpec\n\n# Option 1: Manually construct the signature object\ninput_schema = Schema(\n    [\n        ColSpec("double", "sepal length (cm)"),\n        ColSpec("double", "sepal width (cm)"),\n        ColSpec("double", "petal length (cm)"),\n        ColSpec("double", "petal width (cm)"),\n    ]\n)\noutput_schema = Schema([ColSpec("long")])\nsignature = ModelSignature(inputs=input_schema, outputs=output_schema)\n\n# Option 2: Infer the signature\nsignature = infer_signature(iris_train, clf.predict(iris_train))\n\nwith mlflow.start_run():\n    mlflow.sklearn.log_model(clf, name="iris_rf", signature=signature)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"tensor-based-signature-example",children:"Tensor-based Signature Example"}),"\n",(0,i.jsxs)(n.p,{children:["The following example demonstrates how to store a model signature for a simple classifier trained\non the ",(0,i.jsx)(n.code,{children:"MNIST dataset"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import tensorflow as tf\nimport mlflow\n\nmnist = tf.keras.datasets.mnist\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\nmodel = tf.keras.models.Sequential(\n    [\n        tf.keras.layers.Flatten(input_shape=(28, 28)),\n        tf.keras.layers.Dense(128, activation="relu"),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(10),\n    ]\n)\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nmodel.compile(optimizer="adam", loss=loss_fn, metrics=["accuracy"])\n\nwith mlflow.start_run():\n    model.fit(x_train, y_train, epochs=5)\n    # Take the first three training examples as the model input example.\n    input_example = x_train[:3, :]\n    mlflow.tensorflow.log_model(model, name="mnist_cnn", input_example=input_example)\n'})}),"\n",(0,i.jsx)(n.p,{children:"The same signature can be explicitly created and logged as follows:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import numpy as np\nfrom mlflow.models import ModelSignature, infer_signature\nfrom mlflow.types.schema import Schema, TensorSpec\n\n# Option 1: Manually construct the signature object\ninput_schema = Schema(\n    [\n        TensorSpec(np.dtype(np.float64), (-1, 28, 28, 1)),\n    ]\n)\noutput_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 10))])\nsignature = ModelSignature(inputs=input_schema, outputs=output_schema)\n\n# Option 2: Infer the signature\nsignature = infer_signature(testX, model.predict(testX))\n\nwith mlflow.start_run():\n    mlflow.tensorflow.log_model(model, name="mnist_cnn", signature=signature)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"signature-with-params-example",children:"Signature with params Example"}),"\n",(0,i.jsx)(n.p,{children:"The following example demonstrates how to store a model signature with params\nfor a simple transformers model:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom mlflow.models import infer_signature\nimport transformers\n\narchitecture = "mrm8488/t5-base-finetuned-common_gen"\nmodel = transformers.pipeline(\n    task="text2text-generation",\n    tokenizer=transformers.T5TokenizerFast.from_pretrained(architecture),\n    model=transformers.T5ForConditionalGeneration.from_pretrained(architecture),\n)\ndata = "pencil draw paper"\n\nparams = {\n    "top_k": 2,\n    "num_beams": 5,\n    "max_length": 30,\n    "temperature": 0.62,\n    "top_p": 0.85,\n    "repetition_penalty": 1.15,\n    "begin_suppress_tokens": [1, 2, 3],\n}\n\n# infer signature with params\nsignature = infer_signature(\n    data,\n    mlflow.transformers.generate_signature_output(model, data),\n    params,\n)\n\n# save model with signature\nmlflow.transformers.save_model(\n    model,\n    "text2text",\n    signature=signature,\n)\npyfunc_loaded = mlflow.pyfunc.load_model("text2text")\n\n# predict with params\nresult = pyfunc_loaded.predict(data, params=params)\n'})}),"\n",(0,i.jsx)(n.p,{children:"The same signature can be created explicitly as follows:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from mlflow.models import ModelSignature\nfrom mlflow.types.schema import ColSpec, ParamSchema, ParamSpec, Schema\n\ninput_schema = Schema([ColSpec(type="string")])\noutput_schema = Schema([ColSpec(type="string")])\nparams_schema = ParamSchema(\n    [\n        ParamSpec("top_k", "long", 2),\n        ParamSpec("num_beams", "long", 5),\n        ParamSpec("max_length", "long", 30),\n        ParamSpec("temperature", "double", 0.62),\n        ParamSpec("top_p", "double", 0.85),\n        ParamSpec("repetition_penalty", "double", 1.15),\n        ParamSpec("begin_suppress_tokens", "long", [1, 2, 3], (-1,)),\n    ]\n)\nsignature = ModelSignature(\n    inputs=input_schema, outputs=output_schema, params=params_schema\n)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"genai-model-signature-example",children:"Model signature examples for GenAI flavors"}),"\n",(0,i.jsxs)(n.p,{children:["GenAI flavors such as langchain, OpenAI, and transformers normally require an object (dictionary) based model signature.\nManually defining the structure is complex and error-prone. Instead, you should rely on the ",(0,i.jsx)(n.em,{children:"infer_signature"})," method to automatically\ngenerate the model signature based on an input example."]}),"\n",(0,i.jsxs)(n.p,{children:["When logging a GenAI flavor model, you can pass the input example to the ",(0,i.jsx)(n.em,{children:"input_example"})," parameter of the ",(0,i.jsx)(n.em,{children:"log_model"})," method.\nMLflow will infer the model signature from the provided input and apply it to the logged model. Additionally, this input example\nhelps validate that the model can run predictions successfully, making it ",(0,i.jsx)(n.strong,{children:"strongly recommended to always include an input example when logging a GenAI model"}),"."]}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsxs)(n.p,{children:["By default, fields in the input example are inferred as required. To mark a field as optional, you can provide a list of\ninput examples where some examples contain None values for the optional fields. (e.g. ",(0,i.jsx)(n.em,{children:'[{"str": "a"}, {"str": None}]'}),")"]})}),"\n",(0,i.jsx)(n.p,{children:"Taking a langchain model as an example, you can log a model with signature with 2 simple steps using the models from code feature:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Define the langchain model in a separate python file named ",(0,i.jsx)(n.em,{children:"langchain_model.py"}),":"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["To log a langchain model successfully, ",(0,i.jsx)(n.strong,{children:"it is highly recommended to use"})," ",(0,i.jsx)(n.a,{href:"/model#models-from-code",children:"models from code"})," feature."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import os\nfrom operator import itemgetter\n\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.runnables import RunnableLambda\nfrom langchain_openai import OpenAI\n\nimport mlflow\n\nmlflow.set_experiment("Homework Helper")\n\nmlflow.langchain.autolog()\n\nprompt = PromptTemplate(\n    template="You are a helpful tutor that evaluates my homework assignments and provides suggestions on areas for me to study further."\n    " Here is the question: {question} and my answer which I got wrong: {answer}",\n    input_variables=["question", "answer"],\n)\n\n\ndef get_question(input):\n    default = "What is your name?"\n    if isinstance(input_data[0], dict):\n        return input_data[0].get("content").get("question", default)\n    return default\n\n\ndef get_answer(input):\n    default = "My name is Bobo"\n    if isinstance(input_data[0], dict):\n        return input_data[0].get("content").get("answer", default)\n    return default\n\n\nmodel = OpenAI(temperature=0.95)\n\nchain = (\n    {\n        "question": itemgetter("messages") | RunnableLambda(get_question),\n        "answer": itemgetter("messages") | RunnableLambda(get_answer),\n    }\n    | prompt\n    | model\n    # Add this parser to convert the model output to a string\n    # so that MLflow can correctly infer the output schema\n    | StrOutputParser()\n)\n\nmlflow.models.set_model(chain)\n'})}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsxs)(n.p,{children:["MLflow can only infer model signature for ",(0,i.jsx)(n.a,{href:"#supported-data-types-column",children:"certain data types"}),", so for\na langchain model, it is essential to add a parser such as ",(0,i.jsx)(n.em,{children:"StrOutputParser"})," to parse the output to a format\nthat MLflow accepts."]})}),"\n",(0,i.jsxs)(n.ol,{start:"2",children:["\n",(0,i.jsx)(n.li,{children:"Log the langchain model with a valid input example:"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yarn",children:'input_example = {\n    "messages": [\n        {\n            "role": "user",\n            "content": {\n                "question": "What is the primary function of control rods in a nuclear reactor?",\n                "answer": "To stir the primary coolant so that the neutrons are mixed well.",\n            },\n        },\n    ]\n}\n\nchain_path = "langchain_model.py"\nwith mlflow.start_run():\n    model_info = mlflow.langchain.log_model(\n        lc_model=chain_path, artifact_path="model", input_example=input_example\n    )\n'})}),"\n",(0,i.jsxs)(n.p,{children:["At this stage, the input_example serves multiple purposes: it is used to infer the model signature,\nvalidate that the model functions correctly when reloaded using the PyFunc flavor, and to generate\na corresponding serving_input_example. The generated signature is used to validate the model\u2019s\nfunctionality prior to deployment as well as providing guidance to callers of the model when\nit is deployed if they are making requests with invalid data structures.\nFor more information on the benefits and usage of the input example, refer to the ",(0,i.jsx)(n.a,{href:"#input-example",children:"Model Input Example"})," section.\nTo learn how to validate the model locally before deployment, refer to the ",(0,i.jsx)(n.a,{href:"#model-serving-payload-example",children:"Model Serving Payload Example"})," section."]}),"\n",(0,i.jsx)(n.p,{children:"If your model has an optional input field, you can use below input_example as a reference:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from mlflow.models import infer_signature\n\ninput_example = {\n    "messages": [\n        {\n            # specify name field in the first message\n            "name": "userA",\n            "role": "user",\n            "content": {\n                "question": "What is the primary function of control rods in a nuclear reactor?",\n                "answer": "To stir the primary coolant so that the neutrons are mixed well.",\n            },\n        },\n        {\n            # no name field in the second message, so `name` will be inferred as optional\n            "role": "user",\n            "content": {\n                "question": "What is MLflow?",\n                "answer": "MLflow is an open-source platform",\n            },\n        },\n    ]\n}\n\nprint(infer_signature(input_example))\n'})}),"\n",(0,i.jsx)(n.p,{children:"If your model's output contains None values, these fields will be inferred as AnyType (since MLflow 2.19.0), for example:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from mlflow.models import infer_signature\n\ndata = [\n    {\n        "id": None,\n        "object": "chat.completion",\n        "created": 1731491873,\n        "model": None,\n        "choices": [\n            {\n                "index": 0,\n                "message": {\n                    "role": "assistant",\n                    "content": "MLflow",\n                },\n                "finish_reason": None,\n            }\n        ],\n        "usage": {\n            "prompt_tokens": None,\n            "completion_tokens": None,\n            "total_tokens": None,\n        },\n    }\n]\n\nprint(infer_signature(data))\n# inputs:\n# [\n#     \'id\': Any (optional),\n#     \'object\': string (required),\n#     \'created\': long (required),\n#     \'model\': Any (optional),\n#     \'choices\': Array({\n#         \'finish_reason\': Any (optional),\n#         \'index\': long (required),\n#         \'message\': {\n#             \'content\': string (required),\n#             \'role\': string (required)\n#         } (required)\n#     }) (required),\n#     \'usage\': {\n#         \'completion_tokens\': Any (optional),\n#         \'prompt_tokens\': Any (optional),\n#         \'total_tokens\': Any (optional)\n#     } (required)\n# ]\n# outputs:\n# None\n# params:\n# None\n'})}),"\n",(0,i.jsxs)(n.ol,{start:"3",children:["\n",(0,i.jsx)(n.li,{children:"Load the model back and make predictions:"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\nresult = loaded_model.predict(input_example)\n\nprint(result)\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"A"})," ",(0,i.jsx)(n.a,{href:"https://docs.python.org/3/library/dataclasses.html",children:"Dataclass"})," ",(0,i.jsx)(n.strong,{children:"object is also supported to define a signature. Passing a Dataclass\ninstance to"})," ",(0,i.jsx)(n.em,{children:"infer_signature"})," ",(0,i.jsx)(n.strong,{children:"will generate the corresponding model signature equivalent"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from dataclasses import dataclass\nfrom typing import List\nfrom mlflow.models import infer_signature\n\n\n@dataclass\nclass Message:\n    role: str\n    content: str\n\n\n@dataclass\nclass ChatCompletionRequest:\n    messages: List[Message]\n\n\nchat_request = ChatCompletionRequest(\n    messages=[\n        Message(\n            role="user",\n            content="What is the primary function of control rods in a nuclear reactor?",\n        ),\n        Message(role="user", content="What is MLflow?"),\n    ]\n)\n\nmodel_signature = infer_signature(\n    chat_request,\n    "Sample output as a string",\n)\nprint(model_signature)\n# inputs:\n# [\'messages\': Array({content: string (required), role: string (required)}) (required)]\n# outputs:\n# [string (required)]\n# params:\n# None\n'})}),"\n",(0,i.jsx)(n.h2,{id:"how-to-set-signatures-on-models",children:"How To Set Signatures on Models"}),"\n",(0,i.jsxs)(n.p,{children:["Models can be saved without model signatures or with incorrect ones. To add or update a signature for an existing logged model,\nuse the ",(0,i.jsx)(r.B,{fn:"mlflow.models.set_signature"})," API. Below are some examples demonstrating its usage."]}),"\n",(0,i.jsx)(n.h3,{id:"setting-a-signature-on-a-logged-model",children:"Setting a Signature on a Logged Model"}),"\n",(0,i.jsx)(n.p,{children:"The following example demonstrates how to set a model signature on an already-logged sklearn model.\nSuppose that you've logged a sklearn model without a signature like below:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import pandas as pd\nfrom sklearn import datasets\nfrom sklearn.ensemble import RandomForestClassifier\nimport mlflow\n\nX, y = datasets.load_iris(return_X_y=True, as_frame=True)\nclf = RandomForestClassifier(max_depth=7, random_state=0)\nwith mlflow.start_run() as run:\n    clf.fit(X, y)\n    mlflow.sklearn.log_model(clf, name="iris_rf")\n'})}),"\n",(0,i.jsx)(n.p,{children:"You can set a signature on the logged model as follows:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import pandas as pd\nfrom sklearn import datasets\nimport mlflow\nfrom mlflow.models.model import get_model_info\nfrom mlflow.models import infer_signature, set_signature\n\n# load the logged model\nmodel_uri = f"runs:/{run.info.run_id}/iris_rf"\nmodel = mlflow.pyfunc.load_model(model_uri)\n\n# construct the model signature from test dataset\nX_test, _ = datasets.load_iris(return_X_y=True, as_frame=True)\nsignature = infer_signature(X_test, model.predict(X_test))\n\n# set the signature for the logged model\nset_signature(model_uri, signature)\n\n# now when you load the model again, it will have the desired signature\nassert get_model_info(model_uri).signature == signature\n'})}),"\n",(0,i.jsx)(n.p,{children:"Note that model signatures can also be set on model artifacts saved outside of MLflow Tracking. For instance,\nyou can easily set a signature on a locally saved iris model by altering the model_uri\nvariable in the previous code snippet to point to the model's local directory."}),"\n",(0,i.jsx)(n.h2,{id:"set-signature-on-mv",children:"Setting a Signature on a Registered Model"}),"\n",(0,i.jsxs)(n.p,{children:["As MLflow Model Registry artifacts are meant to be read-only, you cannot directly set a signature on\na model version or model artifacts represented by ",(0,i.jsx)(n.code,{children:"models:/"})," URI schemes. Instead, you should first set\nthe signature on the source model artifacts and generate a new model version using the updated\nmodel artifacts. The following example illustrates how this can be done."]}),"\n",(0,i.jsx)(n.p,{children:"Supposed you have created the following model version without a signature like below:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from sklearn.ensemble import RandomForestClassifier\nimport mlflow\nfrom mlflow.client import MlflowClient\n\nmodel_name = "add_signature_model"\n\nwith mlflow.start_run() as run:\n    mlflow.sklearn.log_model(RandomForestClassifier(), name="sklearn-model")\n\nmodel_uri = f"runs:/{run.info.run_id}/sklearn-model"\nmlflow.register_model(model_uri=model_uri, name=model_name)\n'})}),"\n",(0,i.jsx)(n.p,{children:"To set a signature on the model version, create a duplicate model version with the new signature\nas follows:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from sklearn.ensemble import RandomForestClassifier\nimport mlflow\nfrom mlflow.store.artifact.models_artifact_repo import ModelsArtifactRepository\n\nclient = mlflow.client.MlflowClient()\nmodel_name = "add_signature_model"\nmodel_version = 1\nmv = client.get_model_version(name=model_name, version=model_version)\n\n# set a dummy signature on the model version source\nsignature = infer_signature(np.array([1]))\nset_signature(mv.source, signature)\n\n# create a new model version with the updated source\nclient.create_model_version(name=model_name, source=mv.source, run_id=mv.run_id)\n'})}),"\n",(0,i.jsx)(n.p,{children:"Note that this process overwrites the model artifacts from the source run of model version 1\nwith a new model signature."}),"\n",(0,i.jsx)(n.h2,{id:"input-example",children:"Model Input Example"}),"\n",(0,i.jsxs)(n.p,{children:["A model input example provides an instance of a valid model input. Input examples are stored with\nthe model as separate artifacts and are referenced in the ",(0,i.jsx)(o.A,{to:"/api_reference/python_api/mlflow.pyfunc.html#pyfunc-model-config",target:"_blank",children:"MLmodel file"}),".\nTo include an input example with your model, add it to the appropriate log_model call,\ne.g. ",(0,i.jsx)(r.B,{fn:"mlflow.sklearn.log_model",children:(0,i.jsx)(n.code,{children:"sklearn.log_model()"})}),". Input examples are also used to infer\nmodel signatures in log_model calls when signatures aren't specified."]}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsxs)(n.p,{children:["Including an input example while logging a model offers dual benefits. Firstly, it aids in inferring the model's signature.\nSecondly, and just as importantly, it ",(0,i.jsx)(n.strong,{children:"validates the model's requirements"}),". This input example is utilized to execute a prediction\nusing the model that is about to be logged, thereby enhancing the accuracy in identifying model requirement dependencies.\nIt is ",(0,i.jsx)(n.strong,{children:"highly recommended"})," to always include an input example along with your models when you log them."]})}),"\n",(0,i.jsx)(n.p,{children:"Since MLflow 2.16.0, when logging a model with an input example, there are two files saved into the model's artifacts directory:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"input_example.json"}),": The input example in JSON format."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"serving_input_example.json"}),": The input example in JSON format, with additional transformation to have compatible schema for querying a deployed model REST endpoint."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"The following example demonstrates the difference between the two files:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import mlflow\n\n\nclass MyModel(mlflow.pyfunc.PythonModel):\n    def predict(self, context, model_input, params=None):\n        return model_input\n\n\nwith mlflow.start_run():\n    model_info = mlflow.pyfunc.log_model(\n        python_model=MyModel(),\n        name="model",\n        input_example={"question": "What is MLflow?"},\n    )\n'})}),"\n",(0,i.jsx)(n.p,{children:"Example files logged by MLflow:"}),"\n",(0,i.jsxs)("table",{children:[(0,i.jsx)("thead",{children:(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"File name"}),(0,i.jsx)("th",{children:"Content"}),(0,i.jsx)("th",{children:"Explanation"})]})}),(0,i.jsxs)("tbody",{children:[(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:"input_example.json"}),(0,i.jsx)("td",{children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n  "question": "What is MLflow?"\n}\n'})})}),(0,i.jsx)("td",{children:"The input example in its original format."})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:"serving_input_example.json"}),(0,i.jsx)("td",{children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{\n  "inputs": {\n    "question": "What is MLflow?"\n  }\n}\n'})})}),(0,i.jsxs)("td",{children:["JSON-serialized version of the input example with one of the predefined keys (",(0,i.jsx)(n.code,{children:"dataframe_split"}),", ",(0,i.jsx)(n.code,{children:"instances"}),", ",(0,i.jsx)(n.code,{children:"inputs"})," or ",(0,i.jsx)(n.code,{children:"dataframe_records"}),") that mlflow scoring server requires when ",(0,i.jsx)(n.a,{href:"/deployment/deploy-model-locally#local-inference-server-spec",children:"querying a deployed model endpoint"}),"."]})]})]})]}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsxs)(n.p,{children:["Prior to MLflow 2.16.0, dictionary input example was converted to Pandas DataFrame format when saving. In later versions, the input\nexample is simply saved in its JSON serialized format. For pandas DataFrame, it is converted to dictionary format\nwith ",(0,i.jsx)(n.code,{children:"to_dict(orient='split')"})," and saved into json format."]})}),"\n",(0,i.jsx)(n.p,{children:"Similar to model signatures, model inputs can be column-based (i.e DataFrames), tensor-based\n(i.e numpy.ndarrays) or json object (i.e python dictionary). We offer support for input_example\nwith params by using tuple to combine model inputs and params. See examples below:"}),"\n",(0,i.jsx)(n.h3,{id:"how-to-log-model-with-column-based-example",children:"How To Log Model With Column-based Example"}),"\n",(0,i.jsx)(n.p,{children:"For models accepting column-based inputs, an example can be a single record or a batch of records. The\nsample input can be in the following formats:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Pandas DataFrame"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"The given example will be serialized to json using the Pandas split-oriented\nformat. Bytes are base64-encoded. The following example demonstrates how you can log a column-based\ninput example with your model:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import pandas as pd\n\ninput_example = pd.DataFrame(\n    [\n        {\n            "sepal length (cm)": 5.1,\n            "sepal width (cm)": 3.5,\n            "petal length (cm)": 1.4,\n            "petal width (cm)": 0.2,\n        }\n    ]\n)\nmlflow.sklearn.log_model(..., input_example=input_example)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"how-to-log-models-with-a-tensor-based-example",children:"How To Log Models With a Tensor-based Example"}),"\n",(0,i.jsx)(n.p,{children:"For models accepting tensor-based inputs, an example must be a batch of inputs. By default, the axis 0\nis the batch axis unless specified otherwise in the model signature. The sample input can be passed in\nas any of the following formats:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"numpy ndarray"}),"\n",(0,i.jsxs)(n.li,{children:["Python ",(0,i.jsx)(n.code,{children:"dict"})," mapping a string to a numpy array"]}),"\n",(0,i.jsxs)(n.li,{children:["Scipy ",(0,i.jsx)(n.code,{children:"csr_matrix"})," (sparse matrix)"]}),"\n",(0,i.jsxs)(n.li,{children:["Scipy ",(0,i.jsx)(n.code,{children:"csc_matrix"})," (sparse matrix)"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"The following example demonstrates how you can log a tensor-based input example with your model:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# each input has shape (4, 4)\ninput_example = np.array(\n    [\n        [[0, 0, 0, 0], [0, 134, 25, 56], [253, 242, 195, 6], [0, 93, 82, 82]],\n        [[0, 23, 46, 0], [33, 13, 36, 166], [76, 75, 0, 255], [33, 44, 11, 82]],\n    ],\n    dtype=np.uint8,\n)\nmlflow.tensorflow.log_model(..., input_example=input_example)\n"})}),"\n",(0,i.jsx)(n.h3,{id:"how-to-log-models-using-a-json-object-example",children:"How To Log Models Using a JSON Object Example"}),"\n",(0,i.jsx)(n.p,{children:"We support saving input example as it is if it's a json-serializable format. The input example can be\nin the following formats:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"dict"})," (of scalars, strings, or lists of scalar values)"]}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"list"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.code,{children:"scalars"})}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"The following example demonstrates how you can log a json object input example with your model:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'input_example = {\n    "messages": [\n        {"role": "system", "content": "You are a helpful assistant."},\n        {"role": "assistant", "content": "What would you like to ask?"},\n        {"role": "user", "content": "Who owns MLflow?"},\n    ]\n}\nmlflow.langchain.log_model(..., input_example=input_example)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"how-to-log-model-with-an-example-that-contains-params",children:"How To Log Model With an Example that Contains Params"}),"\n",(0,i.jsxs)(n.p,{children:["For models that require additional parameters during inference, you can include an input_example\ncontaining params when saving or logging the model. To achieve this, the sample input should be\nprovided as a ",(0,i.jsx)(n.code,{children:"tuple"}),". The first element of the tuple is the input data example, and the\nsecond element is a ",(0,i.jsx)(n.code,{children:"dict"})," of params. A comprehensive list of valid params is documented in\n",(0,i.jsx)(n.a,{href:"#inference-params",children:"Model Inference Params"})," section."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Python ",(0,i.jsx)(n.code,{children:"tuple"}),": (input_data, params)"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"The following example demonstrates how to log a model with an example containing params:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# input_example could be column-based or tensor-based example as shown above\n# params must be a valid dictionary of params\ninput_data = "Hello, Dolly!"\nparams = {"temperature": 0.5, "top_k": 1}\ninput_example = (input_data, params)\nmlflow.transformers.log_model(..., input_example=input_example)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"model-serving-payload-example",children:"Model Serving Payload Example"}),"\n",(0,i.jsxs)(n.p,{children:["Once an MLflow model is deployed to a REST endpoint for inference, the request payload will be\nJSON serialized and may have subtle difference from in-memory representation.\nTo validate your model works for inference, you can use the ",(0,i.jsx)(n.code,{children:"serving_input_example.json"})," file.\nIt is automatically logged along with the model when an ",(0,i.jsx)(n.code,{children:"input_example"})," is provided and contains\na json format of the given input example for querying a deployed model endpoint."]}),"\n",(0,i.jsx)(n.p,{children:"The following example demonstrates how to load the serving payload from a logged model:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom mlflow.models.utils import load_serving_example\n\ninput_example = {\n    "messages": [\n        {"role": "system", "content": "You are a helpful assistant."},\n        {"role": "assistant", "content": "What would you like to ask?"},\n        {"role": "user", "content": "Who owns MLflow?"},\n    ]\n}\nmodel_info = mlflow.langchain.log_model(..., input_example=input_example)\nprint(f"model_uri: {model_info.model_uri}")\nserving_example = load_serving_example(model_info.model_uri)\nprint(f"serving_example: {serving_example}")\n'})}),"\n",(0,i.jsx)(n.p,{children:"You can validate the input example works prior to serving:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from mlflow.models import validate_serving_input\n\nresult = validate_serving_input(model_info.model_uri, serving_example)\nprint(f"prediction result: {result}")\n'})}),"\n",(0,i.jsx)(n.p,{children:"Serve the model locally"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'mlflow models serve --model-uri "<YOUR_MODEL_URI>"\n'})}),"\n",(0,i.jsx)(n.p,{children:"Validate model inference with the serving payload example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"curl http://127.0.0.1:5000/invocations -H 'Content-Type: application/json' -d 'YOUR_SERVING_EXAMPLE'\n"})})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},20723:(e,n,t)=>{t.d(n,{O:()=>s});var a=t(96540),i=t(74848);function s(e){let{children:n,href:t}=e;const s=(0,a.useCallback)((async e=>{if(e.preventDefault(),window.gtag)try{window.gtag("event","notebook-download",{href:t})}catch{}const n=await fetch(t),a=await n.blob(),i=window.URL.createObjectURL(a),s=document.createElement("a");s.style.display="none",s.href=i;const o=t.split("/").pop();s.download=o,document.body.appendChild(s),s.click(),window.URL.revokeObjectURL(i),document.body.removeChild(s)}),[t]);return(0,i.jsx)("a",{className:"button button--primary",style:{marginBottom:"1rem",display:"block",width:"min-content"},href:t,download:!0,onClick:s,children:n})}},28453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>l});var a=t(96540);const i={},s=a.createContext(i);function o(e){const n=a.useContext(s);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),a.createElement(s.Provider,{value:n},e.children)}},67756:(e,n,t)=>{t.d(n,{B:()=>r});t(96540);const a=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var i=t(29030),s=t(56289),o=t(74848);const l=e=>{const n=e.split(".");for(let t=n.length;t>0;t--){const e=n.slice(0,t).join(".");if(a[e])return e}return null};function r(e){let{fn:n,children:t}=e;const r=l(n);if(!r)return(0,o.jsx)(o.Fragment,{children:t});const d=(0,i.Ay)(`/${a[r]}#${n}`);return(0,o.jsx)(s.A,{to:d,target:"_blank",children:t??(0,o.jsxs)("code",{children:[n,"()"]})})}},79367:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/signature-enforcement-e5974f544a264396c51cb2511dd158f1.png"}}]);