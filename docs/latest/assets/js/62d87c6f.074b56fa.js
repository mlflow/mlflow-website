"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["694"],{26782(e,l,t){t.r(l),t.d(l,{metadata:()=>n,default:()=>y,frontMatter:()=>f,contentTitle:()=>u,toc:()=>g,assets:()=>w});var n=JSON.parse('{"id":"eval-monitor/scorers/llm-judge/tool-call/index","title":"Tool Call Evaluation with Built-in Judges","description":"AI agents often use tools (functions) to complete tasks - from fetching data to performing calculations. Evaluating tool-calling applications requires assessing whether agents select appropriate tools and provide correct arguments to fulfill user requests.","source":"@site/docs/genai/eval-monitor/scorers/llm-judge/tool-call/index.mdx","sourceDirName":"eval-monitor/scorers/llm-judge/tool-call","slug":"/eval-monitor/scorers/llm-judge/tool-call/","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/tool-call/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"genAISidebar","previous":{"title":"Correctness","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/response-quality/correctness"},"next":{"title":"ToolCallCorrectness","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/tool-call/correctness"}}'),o=t(74848),r=t(28453),a=t(54725),i=t(77541),s=t(10440),c=t(46858),p=t(42640),m=t(47792),h=t(83884),d=t(55935);let f={},u="Tool Call Evaluation with Built-in Judges",w={},g=[{value:"Available Tool Call Judges",id:"available-tool-call-judges",level:2},...h.RM,{value:"Complete Agent Example",id:"complete-agent-example",level:2},{value:"Understanding the Results",id:"understanding-the-results",level:3},...d.RM,{value:"Next Steps",id:"next-steps",level:2}];function _(e){let l={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(l.header,{children:(0,o.jsx)(l.h1,{id:"tool-call-evaluation-with-built-in-judges",children:"Tool Call Evaluation with Built-in Judges"})}),"\n",(0,o.jsx)(l.p,{children:"AI agents often use tools (functions) to complete tasks - from fetching data to performing calculations. Evaluating tool-calling applications requires assessing whether agents select appropriate tools and provide correct arguments to fulfill user requests."}),"\n",(0,o.jsx)(l.p,{children:"MLflow provides built-in judges designed specifically for evaluating tool-calling agents:"}),"\n",(0,o.jsx)(l.h2,{id:"available-tool-call-judges",children:"Available Tool Call Judges"}),"\n",(0,o.jsxs)(l.table,{children:[(0,o.jsx)(l.thead,{children:(0,o.jsxs)(l.tr,{children:[(0,o.jsx)(l.th,{children:"Judge"}),(0,o.jsx)(l.th,{children:"What does it evaluate?"}),(0,o.jsx)(l.th,{children:"Requires ground-truth?"}),(0,o.jsx)(l.th,{children:"Requires traces?"})]})}),(0,o.jsxs)(l.tbody,{children:[(0,o.jsxs)(l.tr,{children:[(0,o.jsx)(l.td,{children:(0,o.jsx)(l.a,{href:"/genai/eval-monitor/scorers/llm-judge/tool-call/correctness",children:"ToolCallCorrectness"})}),(0,o.jsx)(l.td,{children:"Are the tool calls and arguments correct for the user query?"}),(0,o.jsx)(l.td,{children:"No"}),(0,o.jsxs)(l.td,{children:["\u26A0\uFE0F ",(0,o.jsx)(l.strong,{children:"Trace Required"})]})]}),(0,o.jsxs)(l.tr,{children:[(0,o.jsx)(l.td,{children:(0,o.jsx)(l.a,{href:"/genai/eval-monitor/scorers/llm-judge/tool-call/efficiency",children:"ToolCallEfficiency"})}),(0,o.jsx)(l.td,{children:"Are the tool calls efficient without redundancy?"}),(0,o.jsx)(l.td,{children:"No"}),(0,o.jsxs)(l.td,{children:["\u26A0\uFE0F ",(0,o.jsx)(l.strong,{children:"Trace Required"})]})]})]})]}),"\n",(0,o.jsx)(l.admonition,{type:"tip",children:(0,o.jsxs)(l.p,{children:["All tool call judges require MLflow Traces with at least one span marked as ",(0,o.jsx)(l.code,{children:'span_type="TOOL"'}),". Use the ",(0,o.jsx)(a.B,{fn:"mlflow.trace",children:"@mlflow.trace"})," decorator with ",(0,o.jsx)(l.code,{children:'span_type="TOOL"'})," on your tool functions."]})}),"\n",(0,o.jsx)(h.Ay,{}),"\n",(0,o.jsx)(l.h2,{id:"complete-agent-example",children:"Complete Agent Example"}),"\n",(0,o.jsx)(l.p,{children:"Here's a complete example showing how to build a tool-calling agent and evaluate it with the judges:"}),"\n",(0,o.jsx)(l.pre,{children:(0,o.jsx)(l.code,{className:"language-python",children:'import json\nimport mlflow\nimport openai\nfrom mlflow.genai.scorers import ToolCallCorrectness, ToolCallEfficiency\n\nmlflow.openai.autolog()\nclient = openai.OpenAI()\n\n# Define the tool schema for the LLM\ntools = [\n    {\n        "type": "function",\n        "function": {\n            "name": "get_weather",\n            "description": "Get the current weather for a location",\n            "parameters": {\n                "type": "object",\n                "properties": {\n                    "location": {"type": "string", "description": "City and country"},\n                },\n                "required": ["location"],\n            },\n        },\n    },\n]\n\n\n# Define the tool function with proper span type\n@mlflow.trace(span_type="TOOL")\ndef get_weather(location: str) -> dict:\n    # Simulated weather data - in practice, this would call a weather API\n    return {"temperature": 72, "condition": "sunny", "location": location}\n\n\n# Define your agent\n@mlflow.trace\ndef agent(query: str):\n    # Call the LLM with tools\n    response = client.chat.completions.create(\n        model="gpt-4o-mini",\n        messages=[{"role": "user", "content": query}],\n        tools=tools,\n    )\n    message = response.choices[0].message\n    responses = []\n    if message.tool_calls:\n        for tool_call in message.tool_calls:\n            args = json.loads(tool_call.function.arguments)\n            result = get_weather(**args)\n            responses.append(\n                {\n                    "response": f"Weather in {result[\'location\']}: {result[\'condition\']}, {result[\'temperature\']}\xb0F"\n                }\n            )\n\n    return {"response": responses if responses else message.content}\n\n\n# Create evaluation dataset\neval_dataset = [\n    {"inputs": {"query": "What\'s the weather like in Paris?"}},\n    {"inputs": {"query": "How\'s the weather in Tokyo?"}},\n]\n\n# Run evaluation with tool call judges\neval_results = mlflow.genai.evaluate(\n    data=eval_dataset,\n    predict_fn=agent,\n    scorers=[\n        ToolCallCorrectness(model="openai:/gpt-4o-mini"),\n        ToolCallEfficiency(model="openai:/gpt-4o-mini"),\n    ],\n)\n'})}),"\n",(0,o.jsx)(l.h3,{id:"understanding-the-results",children:"Understanding the Results"}),"\n",(0,o.jsx)(l.p,{children:"Each tool call judge evaluates tool spans separately:"}),"\n",(0,o.jsxs)(l.ul,{children:["\n",(0,o.jsxs)(l.li,{children:[(0,o.jsx)(l.strong,{children:"ToolCallCorrectness"}),": Assesses whether the agent selected appropriate tools and provided correct arguments"]}),"\n",(0,o.jsxs)(l.li,{children:[(0,o.jsx)(l.strong,{children:"ToolCallEfficiency"}),": Evaluates whether the agent made redundant or unnecessary tool calls"]}),"\n"]}),"\n",(0,o.jsx)(d.Ay,{}),"\n",(0,o.jsx)(l.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsxs)(s.A,{children:[(0,o.jsx)(i.A,{icon:c.A,title:"ToolCallCorrectness",description:"Evaluate if tool calls and arguments are correct",href:"/genai/eval-monitor/scorers/llm-judge/tool-call/correctness"}),(0,o.jsx)(i.A,{icon:p.A,title:"ToolCallEfficiency",description:"Check for redundant or unnecessary tool calls",href:"/genai/eval-monitor/scorers/llm-judge/tool-call/efficiency"}),(0,o.jsx)(i.A,{icon:m.A,title:"Build evaluation datasets",description:"Create ground truth datasets for testing agents",href:"/genai/datasets/"})]})]})}function y(e={}){let{wrapper:l}={...(0,r.R)(),...e.components};return l?(0,o.jsx)(l,{...e,children:(0,o.jsx)(_,{...e})}):_(e)}},83884(e,l,t){t.d(l,{Ay:()=>i,RM:()=>r});var n=t(74848),o=t(28453);let r=[{value:"Prerequisites for running the examples",id:"prerequisites-for-running-the-examples",level:2}];function a(e){let l={a:"a",code:"code",h2:"h2",li:"li",ol:"ol",p:"p",pre:"pre",...(0,o.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(l.h2,{id:"prerequisites-for-running-the-examples",children:"Prerequisites for running the examples"}),"\n",(0,n.jsxs)(l.ol,{children:["\n",(0,n.jsxs)(l.li,{children:["\n",(0,n.jsx)(l.p,{children:"Install MLflow and required packages"}),"\n",(0,n.jsx)(l.pre,{children:(0,n.jsx)(l.code,{className:"language-bash",children:"pip install --upgrade mlflow\n"})}),"\n"]}),"\n",(0,n.jsxs)(l.li,{children:["\n",(0,n.jsxs)(l.p,{children:["Create an MLflow experiment by following the ",(0,n.jsx)(l.a,{href:"/genai/getting-started/connect-environment/",children:"setup your environment quickstart"}),"."]}),"\n"]}),"\n",(0,n.jsxs)(l.li,{children:["\n",(0,n.jsxs)(l.p,{children:["(Optional, if using OpenAI models) Use the native OpenAI SDK to connect to OpenAI-hosted models. Select a model from the ",(0,n.jsx)(l.a,{href:"https://platform.openai.com/docs/models",children:"available OpenAI models"}),"."]}),"\n",(0,n.jsx)(l.pre,{children:(0,n.jsx)(l.code,{className:"language-python",children:'import mlflow\nimport os\nimport openai\n\n# Ensure your OPENAI_API_KEY is set in your environment\n# os.environ["OPENAI_API_KEY"] = "<YOUR_API_KEY>" # Uncomment and set if not globally configured\n\n# Enable auto-tracing for OpenAI\nmlflow.openai.autolog()\n\n# Create an OpenAI client\nclient = openai.OpenAI()\n\n# Select an LLM\nmodel_name = "gpt-4o-mini"\n'})}),"\n"]}),"\n"]})]})}function i(e={}){let{wrapper:l}={...(0,o.R)(),...e.components};return l?(0,n.jsx)(l,{...e,children:(0,n.jsx)(a,{...e})}):a(e)}},55935(e,l,t){t.d(l,{Ay:()=>i,RM:()=>r});var n=t(74848),o=t(28453);let r=[{value:"Select the LLM that powers the judge",id:"select-the-llm-that-powers-the-judge",level:2}];function a(e){let l={a:"a",code:"code",h2:"h2",p:"p",...(0,o.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(l.h2,{id:"select-the-llm-that-powers-the-judge",children:"Select the LLM that powers the judge"}),"\n",(0,n.jsxs)(l.p,{children:["You can change the judge model by using the ",(0,n.jsx)(l.code,{children:"model"})," argument in the judge definition. The model must be specified in the format ",(0,n.jsx)(l.code,{children:"<provider>:/<model-name>"}),", where ",(0,n.jsx)(l.code,{children:"<provider>"})," is a LiteLLM-compatible model provider."]}),"\n",(0,n.jsxs)(l.p,{children:["For a list of supported models, see ",(0,n.jsx)(l.a,{href:"/genai/eval-monitor/scorers/llm-judge/custom-judges/#selecting-judge-models",children:"selecting judge models"}),"."]})]})}function i(e={}){let{wrapper:l}={...(0,o.R)(),...e.components};return l?(0,n.jsx)(l,{...e,children:(0,n.jsx)(a,{...e})}):a(e)}},75689(e,l,t){t.d(l,{A:()=>s});var n=t(96540);let o=e=>{let l=e.replace(/^([A-Z])|[\s-_]+(\w)/g,(e,l,t)=>t?t.toUpperCase():l.toLowerCase());return l.charAt(0).toUpperCase()+l.slice(1)},r=(...e)=>e.filter((e,l,t)=>!!e&&""!==e.trim()&&t.indexOf(e)===l).join(" ").trim();var a={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};let i=(0,n.forwardRef)(({color:e="currentColor",size:l=24,strokeWidth:t=2,absoluteStrokeWidth:o,className:i="",children:s,iconNode:c,...p},m)=>(0,n.createElement)("svg",{ref:m,...a,width:l,height:l,stroke:e,strokeWidth:o?24*Number(t)/Number(l):t,className:r("lucide",i),...!s&&!(e=>{for(let l in e)if(l.startsWith("aria-")||"role"===l||"title"===l)return!0})(p)&&{"aria-hidden":"true"},...p},[...c.map(([e,l])=>(0,n.createElement)(e,l)),...Array.isArray(s)?s:[s]])),s=(e,l)=>{let t=(0,n.forwardRef)(({className:t,...a},s)=>(0,n.createElement)(i,{ref:s,iconNode:l,className:r(`lucide-${o(e).replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()}`,`lucide-${e}`,t),...a}));return t.displayName=o(e),t}},42640(e,l,t){t.d(l,{A:()=>n});let n=(0,t(75689).A)("bot",[["path",{d:"M12 8V4H8",key:"hb8ula"}],["rect",{width:"16",height:"12",x:"4",y:"8",rx:"2",key:"enze0r"}],["path",{d:"M2 14h2",key:"vft8re"}],["path",{d:"M20 14h2",key:"4cs60a"}],["path",{d:"M15 13v2",key:"1xurst"}],["path",{d:"M9 13v2",key:"rq6x2g"}]])},47792(e,l,t){t.d(l,{A:()=>n});let n=(0,t(75689).A)("target",[["circle",{cx:"12",cy:"12",r:"10",key:"1mglay"}],["circle",{cx:"12",cy:"12",r:"6",key:"1vlfrh"}],["circle",{cx:"12",cy:"12",r:"2",key:"1c9p78"}]])},46858(e,l,t){t.d(l,{A:()=>n});let n=(0,t(75689).A)("zap",[["path",{d:"M4 14a1 1 0 0 1-.78-1.63l9.9-10.2a.5.5 0 0 1 .86.46l-1.92 6.02A1 1 0 0 0 13 10h7a1 1 0 0 1 .78 1.63l-9.9 10.2a.5.5 0 0 1-.86-.46l1.92-6.02A1 1 0 0 0 11 14z",key:"1xq2db"}]])},54725(e,l,t){t.d(l,{B:()=>a});var n=t(74848);t(96540);var o=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}'),r=t(66497);function a({fn:e,children:l,hash:t}){let a=(e=>{let l=e.split(".");for(let e=l.length;e>0;e--){let t=l.slice(0,e).join(".");if(o[t])return t}return null})(e);if(!a)return(0,n.jsx)(n.Fragment,{children:l});let i=(0,r.default)(`/${o[a]}#${t??e}`);return(0,n.jsx)("a",{href:i,target:"_blank",children:l??(0,n.jsxs)("code",{children:[e,"()"]})})}},77541(e,l,t){t.d(l,{A:()=>c});var n=t(74848);t(96540);var o=t(95310),r=t(34164);let a="tileImage_O4So";var i=t(66497),s=t(92802);function c({icon:e,image:l,imageDark:t,imageWidth:c,imageHeight:p,iconSize:m=32,containerHeight:h,title:d,description:f,href:u,linkText:w="Learn more \u2192",className:g}){if(!e&&!l)throw Error("TileCard requires either an icon or image prop");let _=h?{height:`${h}px`}:{},y={};return c&&(y.width=`${c}px`),p&&(y.height=`${p}px`),(0,n.jsxs)(o.A,{href:u,className:(0,r.A)("tileCard_NHsj",g),children:[(0,n.jsx)("div",{className:"tileIcon_pyoR",style:_,children:e?(0,n.jsx)(e,{size:m}):t?(0,n.jsx)(s.A,{sources:{light:(0,i.default)(l),dark:(0,i.default)(t)},alt:d,className:a,style:y}):(0,n.jsx)("img",{src:(0,i.default)(l),alt:d,className:a,style:y})}),(0,n.jsx)("h3",{children:d}),(0,n.jsx)("p",{children:f}),(0,n.jsx)("div",{className:"tileLink_iUbu",children:w})]})}},10440(e,l,t){t.d(l,{A:()=>r});var n=t(74848);t(96540);var o=t(34164);function r({children:e,className:l}){return(0,n.jsx)("div",{className:(0,o.A)("tilesGrid_hB9N",l),children:e})}},28453(e,l,t){t.d(l,{R:()=>a,x:()=>i});var n=t(96540);let o={},r=n.createContext(o);function a(e){let l=n.useContext(r);return n.useMemo(function(){return"function"==typeof e?e(l):{...l,...e}},[l,e])}function i(e){let l;return l=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),n.createElement(r.Provider,{value:l},e.children)}}}]);