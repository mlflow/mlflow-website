"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[2395],{28453:(e,l,n)=>{n.d(l,{R:()=>r,x:()=>i});var t=n(96540);const o={},a=t.createContext(o);function r(e){const l=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(l):{...l,...e}},[l,e])}function i(e){let l;return l=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),t.createElement(a.Provider,{value:l},e.children)}},49374:(e,l,n)=>{n.d(l,{B:()=>i});n(96540);const t=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}');var o=n(86025),a=n(74848);const r=e=>{const l=e.split(".");for(let n=l.length;n>0;n--){const e=l.slice(0,n).join(".");if(t[e])return e}return null};function i({fn:e,children:l,hash:n}){const i=r(e);if(!i)return(0,a.jsx)(a.Fragment,{children:l});const p=(0,o.Ay)(`/${t[i]}#${n??e}`);return(0,a.jsx)("a",{href:p,target:"_blank",children:l??(0,a.jsxs)("code",{children:[e,"()"]})})}},66927:(e,l,n)=>{n.d(l,{A:()=>r});n(96540);const t={container:"container_JwLF",imageWrapper:"imageWrapper_RfGN",image:"image_bwOA",caption:"caption_jo2G"};var o=n(86025),a=n(74848);function r({src:e,alt:l,width:n,caption:r,className:i}){return(0,a.jsxs)("div",{className:`${t.container} ${i||""}`,children:[(0,a.jsx)("div",{className:t.imageWrapper,style:n?{width:n}:{},children:(0,a.jsx)("img",{src:(0,o.Ay)(e),alt:l,className:t.image})}),r&&(0,a.jsx)("p",{className:t.caption,children:r})]})}},93380:(e,l,n)=>{n.r(l),n.d(l,{assets:()=>m,contentTitle:()=>s,default:()=>f,frontMatter:()=>p,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"eval-monitor/faq","title":"Evaluate & Monitor FAQ","description":"This page addresses frequently asked questions about MLflow\'s GenAI evaluation.","source":"@site/docs/genai/eval-monitor/faq.mdx","sourceDirName":"eval-monitor","slug":"/eval-monitor/faq","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/faq","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"genAISidebar","previous":{"title":"LLM Evaluation (Legacy)","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/legacy-llm-evaluation"},"next":{"title":"Prompt Registry","permalink":"/mlflow-website/docs/latest/genai/prompt-registry/"}}');var o=n(74848),a=n(28453),r=n(49374),i=n(66927);const p={},s="Evaluate & Monitor FAQ",m={},c=[{value:"Where can I find the evaluation results in MLflow UI?",id:"where-can-i-find-the-evaluation-results-in-mlflow-ui",level:2},{value:"How to change the concurrency of the evaluation?",id:"how-to-change-the-concurrency-of-the-evaluation",level:2},{value:"Why does MLflow make N+1 predictions during evaluation?",id:"why-does-mlflow-make-n1-predictions-during-evaluation",level:2},{value:"How do I change the name of the evaluation run?",id:"how-do-i-change-the-name-of-the-evaluation-run",level:2},{value:"How do I use Databricks Model Serving endpoints as the predict function?",id:"how-do-i-use-databricks-model-serving-endpoints-as-the-predict-function",level:2}];function h(e){const l={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(l.header,{children:(0,o.jsx)(l.h1,{id:"evaluate--monitor-faq",children:"Evaluate & Monitor FAQ"})}),"\n",(0,o.jsx)(l.p,{children:"This page addresses frequently asked questions about MLflow's GenAI evaluation."}),"\n",(0,o.jsx)(l.h2,{id:"where-can-i-find-the-evaluation-results-in-mlflow-ui",children:"Where can I find the evaluation results in MLflow UI?"}),"\n",(0,o.jsx)(l.p,{children:"After an evaluation completes, you can find the resulting runs on the experiment page. Click the run name to view aggregated metrics and metadata in the overview pane."}),"\n",(0,o.jsxs)(l.p,{children:["To inspect per-row evaluation results, open the ",(0,o.jsx)(l.strong,{children:"Traces"})," tab on the run overview page."]}),"\n",(0,o.jsx)(i.A,{src:"/images/mlflow-3/eval-monitor/quickstart-eval-result.png",alt:"Detailed Evaluation Results",width:"90%"}),"\n",(0,o.jsx)(l.h2,{id:"how-to-change-the-concurrency-of-the-evaluation",children:"How to change the concurrency of the evaluation?"}),"\n",(0,o.jsxs)(l.p,{children:["MLflow uses a thread pool to run the predict function and scorers in parallel. Configure the number of workers by setting the ",(0,o.jsx)(l.code,{children:"MLFLOW_GENAI_EVAL_MAX_WORKERS"})," environment variable (default: ",(0,o.jsx)(l.code,{children:"10"}),")."]}),"\n",(0,o.jsx)(l.pre,{children:(0,o.jsx)(l.code,{className:"language-bash",children:"export MLFLOW_GENAI_EVAL_MAX_WORKERS=5\n"})}),"\n",(0,o.jsx)(l.h2,{id:"why-does-mlflow-make-n1-predictions-during-evaluation",children:"Why does MLflow make N+1 predictions during evaluation?"}),"\n",(0,o.jsxs)(l.p,{children:["MLflow requires the predict function passed through the ",(0,o.jsx)(l.code,{children:"predict_fn"})," parameter to emit a single trace per call. To ensure the function produces a trace, MLflow first runs one additional prediction on a single input."]}),"\n",(0,o.jsxs)(l.p,{children:["If you are confident the predict function already generates traces, skip this validation by setting the ",(0,o.jsx)(l.code,{children:"MLFLOW_GENAI_EVAL_SKIP_TRACE_VALIDATION"})," environment variable to ",(0,o.jsx)(l.code,{children:"true"}),"."]}),"\n",(0,o.jsx)(l.pre,{children:(0,o.jsx)(l.code,{className:"language-bash",children:"export MLFLOW_GENAI_EVAL_SKIP_TRACE_VALIDATION=true\n"})}),"\n",(0,o.jsx)(l.h2,{id:"how-do-i-change-the-name-of-the-evaluation-run",children:"How do I change the name of the evaluation run?"}),"\n",(0,o.jsxs)(l.p,{children:["By default, ",(0,o.jsx)(l.code,{children:"mlflow.genai.evaluate"})," generates a random run name. Set a custom name by wrapping the call with ",(0,o.jsx)(l.code,{children:"mlflow.start_run"}),"."]}),"\n",(0,o.jsx)(l.pre,{children:(0,o.jsx)(l.code,{className:"language-python",children:'with mlflow.start_run(run_name="My Evaluation Run") as run:\n    mlflow.genai.evaluate(...)\n'})}),"\n",(0,o.jsx)(l.h2,{id:"how-do-i-use-databricks-model-serving-endpoints-as-the-predict-function",children:"How do I use Databricks Model Serving endpoints as the predict function?"}),"\n",(0,o.jsxs)(l.p,{children:["MLflow provides ",(0,o.jsx)(r.B,{fn:"mlflow.genai.to_predict_fn"}),", which wraps a Databricks Model Serving endpoint so it behaves like a predict function compatible with GenAI evaluation."]}),"\n",(0,o.jsx)(l.p,{children:"The wrapper:"}),"\n",(0,o.jsxs)(l.ul,{children:["\n",(0,o.jsx)(l.li,{children:"Translates each input sample into the request payload expected by the endpoint."}),"\n",(0,o.jsxs)(l.li,{children:["Injects ",(0,o.jsx)(l.code,{children:'{"databricks_options": {"return_trace": True}}'})," so the endpoint returns a model-generated trace."]}),"\n",(0,o.jsx)(l.li,{children:"Copies the trace into the current experiment so it appears in the MLflow UI."}),"\n"]}),"\n",(0,o.jsx)(l.pre,{children:(0,o.jsx)(l.code,{className:"language-python",children:'import mlflow\nfrom mlflow.genai.scorers import Correctness\n\nmlflow.genai.evaluate(\n    # The {"messages": ...} part must be compatible with the request schema of the endpoint\n    data=[{"inputs": {"messages": [{"role": "user", "content": "What is MLflow?"}]}}],\n    # Your Databricks Model Serving endpoint URI\n    predict_fn=mlflow.genai.to_predict_fn("endpoints:/chat"),\n    scorers=[Correctness()],\n)\n'})})]})}function f(e={}){const{wrapper:l}={...(0,a.R)(),...e.components};return l?(0,o.jsx)(l,{...e,children:(0,o.jsx)(h,{...e})}):h(e)}}}]);