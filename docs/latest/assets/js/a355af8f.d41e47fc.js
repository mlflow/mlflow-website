"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[2154],{28453:(e,l,n)=>{n.d(l,{R:()=>r,x:()=>i});var o=n(96540);const t={},a=o.createContext(t);function r(e){const l=o.useContext(a);return o.useMemo((function(){return"function"==typeof e?e(l):{...l,...e}}),[l,e])}function i(e){let l;return l=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),o.createElement(a.Provider,{value:l},e.children)}},59e3:(e,l,n)=>{n.r(l),n.d(l,{assets:()=>p,contentTitle:()=>m,default:()=>h,frontMatter:()=>s,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"deployment/deploy-model-to-sagemaker/index","title":"Deploy MLflow Model to Amazon SageMaker","description":"Amazon SageMaker is a fully managed service designed for scaling ML inference containers.","source":"@site/docs/deployment/deploy-model-to-sagemaker/index.mdx","sourceDirName":"deployment/deploy-model-to-sagemaker","slug":"/deployment/deploy-model-to-sagemaker/","permalink":"/docs/latest/deployment/deploy-model-to-sagemaker/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"docsSidebar","previous":{"title":"Deploy MLflow Model as a Local Inference Server","permalink":"/docs/latest/deployment/deploy-model-locally/"},"next":{"title":"Deploy MLflow Model to Kubernetes","permalink":"/docs/latest/deployment/deploy-model-to-kubernetes/"}}');var t=n(74848),a=n(28453),r=n(56289),i=n(67756);const s={sidebar_position:2},m="Deploy MLflow Model to Amazon SageMaker",p={},c=[{value:"How it works",id:"how-it-works",level:2},{value:"Deploying Model to SageMaker Endpoint",id:"deploying-model-to-sagemaker-endpoint",level:2},{value:"Step 0: Preparation",id:"step-0-preparation",level:3},{value:"Install Tools",id:"install-tools",level:4},{value:"Permissions Setup",id:"permissions-setup",level:4},{value:"Create an MLflow Model",id:"create-an-mlflow-model",level:4},{value:"Step 1: Test your model locally",id:"step-1-test-your-model-locally",level:3},{value:"Step 2: Build a Docker Image and Push to ECR",id:"step-2-build-a-docker-image-and-push-to-ecr",level:3},{value:"Step 3: Deploy to SageMaker Endpoint",id:"step-3-deploy-to-sagemaker-endpoint",level:3},{value:"API Reference",id:"api-reference",level:2},{value:"Useful Links",id:"deployment-sagemaker-references",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2}];function d(e){const l={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(l.header,{children:(0,t.jsx)(l.h1,{id:"deploy-mlflow-model-to-amazon-sagemaker",children:"Deploy MLflow Model to Amazon SageMaker"})}),"\n",(0,t.jsx)(l.p,{children:"Amazon SageMaker is a fully managed service designed for scaling ML inference containers.\nMLflow simplifies the deployment process by offering easy-to-use commands without the need\nfor writing container definitions."}),"\n",(0,t.jsxs)(l.p,{children:["If you are new to MLflow model deployment, please read ",(0,t.jsx)(l.a,{href:"/deployment",children:"MLflow Deployment"}),"\nfirst to understand the basic concepts of MLflow models and deployments."]}),"\n",(0,t.jsx)(l.h2,{id:"how-it-works",children:"How it works"}),"\n",(0,t.jsxs)(l.p,{children:["SageMaker features a capability called ",(0,t.jsx)(l.a,{href:"https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-byoc-containers.html",children:"Bring Your Own Container (BYOC)"}),",\nwhich allows you to run custom Docker containers on the inference endpoint. These containers must meet specific requirements, such as running a web server\nthat exposes certain REST endpoints, having a designated container entrypoint, setting environment variables, etc. Writing a Dockerfile and serving script\nthat meets these requirements can be a tedious task."]}),"\n",(0,t.jsx)(l.p,{children:"MLflow automates the process by building a Docker image from the MLflow Model on your behalf. Subsequently, it pushed the image to Elastic Container Registry (ECR)\nand creates a SageMaker endpoint using this image. It also uploads the model artifact to an S3 bucket and configures the endpoint to download the model from there."}),"\n",(0,t.jsxs)(l.p,{children:["The container provides the same REST endpoints as a local inference server. For instance, the ",(0,t.jsx)(l.code,{children:"/invocations"})," endpoint accepts CSV and JSON input data and returns\nprediction results. For more details on the endpoints, refer to ",(0,t.jsx)(l.a,{href:"/deployment/deploy-model-locally#local-inference-server-spec",children:"Local Inference Server"}),"."]}),"\n",(0,t.jsx)(l.h2,{id:"deploying-model-to-sagemaker-endpoint",children:"Deploying Model to SageMaker Endpoint"}),"\n",(0,t.jsxs)(l.p,{children:["This section outlines the process of deploying a model to SageMaker using the MLflow CLI. For Python API references and tutorials,\nsee the ",(0,t.jsx)(l.a,{href:"#deployment-sagemaker-references",children:"Useful links"})," section."]}),"\n",(0,t.jsx)(l.h3,{id:"step-0-preparation",children:"Step 0: Preparation"}),"\n",(0,t.jsx)(l.h4,{id:"install-tools",children:"Install Tools"}),"\n",(0,t.jsx)(l.p,{children:"Ensure the installation of the following tools if not already done:"}),"\n",(0,t.jsxs)(l.ul,{children:["\n",(0,t.jsx)(l.li,{children:(0,t.jsx)(l.a,{href:"https://pypi.org/project/mlflow",children:"mlflow"})}),"\n",(0,t.jsx)(l.li,{children:(0,t.jsx)(l.a,{href:"https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html",children:"awscli"})}),"\n",(0,t.jsx)(l.li,{children:(0,t.jsx)(l.a,{href:"https://docs.docker.com/get-docker",children:"docker"})}),"\n"]}),"\n",(0,t.jsx)(l.h4,{id:"permissions-setup",children:"Permissions Setup"}),"\n",(0,t.jsxs)(l.p,{children:["Set up AWS accounts and permissions correctly. You need an IAM role with permissions to create a SageMaker endpoint, access an S3 bucket, and use the ECR repository.\nThis role should also be assumable by the user performing the deployment. Learn more about this setup at\n",(0,t.jsx)(l.a,{href:"https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-role.html",children:"Use an IAM role in the AWS CLI"}),"."]}),"\n",(0,t.jsx)(l.h4,{id:"create-an-mlflow-model",children:"Create an MLflow Model"}),"\n",(0,t.jsxs)(l.p,{children:["Before deploying, you must have an MLflow Model. If you don't have one, you can create a sample scikit-learn model by following the ",(0,t.jsx)(l.a,{href:"/getting-started",children:"MLflow Tracking Quickstart"}),".\nRemember to note down the model URI, such as ",(0,t.jsx)(l.code,{children:"runs:/<run_id>/<artifact_path>"})," (or ",(0,t.jsx)(l.code,{children:"models:/<model_name>/<model_version>"})," if you registered the model in the\n",(0,t.jsx)(l.a,{href:"/model-registry",children:"MLflow Model Registry"}),")."]}),"\n",(0,t.jsx)(l.h3,{id:"step-1-test-your-model-locally",children:"Step 1: Test your model locally"}),"\n",(0,t.jsxs)(l.p,{children:["It's recommended to test your model locally before deploying it to a production environment.\nThe ",(0,t.jsx)(i.B,{fn:"mlflow.sagemaker.run_local",children:(0,t.jsx)(l.code,{children:"mlflow deployments run-local"})})," command deploys\nthe model in a Docker container with an identical image and environment configuration, making it ideal\nfor pre-deployment testing."]}),"\n",(0,t.jsx)(l.pre,{children:(0,t.jsx)(l.code,{className:"language-bash",children:"mlflow deployments run-local -t sagemaker -m runs:/<run_id>/model -p 5000\n"})}),"\n",(0,t.jsx)(l.p,{children:"You can then test the model by sending a POST request to the endpoint:"}),"\n",(0,t.jsx)(l.pre,{children:(0,t.jsx)(l.code,{className:"language-bash",children:'curl -X POST -H "Content-Type:application/json; format=pandas-split" --data \'{"columns":["a","b"],"data":[[1,2]]}\' http://localhost:5000/invocations\n'})}),"\n",(0,t.jsx)(l.h3,{id:"step-2-build-a-docker-image-and-push-to-ecr",children:"Step 2: Build a Docker Image and Push to ECR"}),"\n",(0,t.jsxs)(l.p,{children:["The ",(0,t.jsx)(r.A,{to:"/api_reference/cli.html#mlflow-sagemaker-build-and-push-container",target:"_blank",children:"mlflow sagemaker build-and-push-container"}),"\ncommand builds a Docker image compatible with SageMaker and uploads it to ECR."]}),"\n",(0,t.jsx)(l.pre,{children:(0,t.jsx)(l.code,{className:"language-bash",children:"$ mlflow sagemaker build-and-push-container  -m runs:/<run_id>/model\n"})}),"\n",(0,t.jsxs)(l.p,{children:["Alternatively, you can create a custom Docker image using the\n",(0,t.jsx)(l.a,{href:"/docker",children:"official MLflow Docker image"})," and manually push it to ECR."]}),"\n",(0,t.jsx)(l.h3,{id:"step-3-deploy-to-sagemaker-endpoint",children:"Step 3: Deploy to SageMaker Endpoint"}),"\n",(0,t.jsxs)(l.p,{children:["The ",(0,t.jsx)(i.B,{fn:"mlflow.sagemaker.SageMakerDeploymentClient.create_deployment",children:(0,t.jsx)(l.code,{children:"mlflow deployments create"})}),"\ncommand deploys the model to an Amazon SageMaker endpoint. MLflow uploads the Python Function model to S3 and automatically\ninitiates an Amazon SageMaker endpoint serving the model."]}),"\n",(0,t.jsxs)(l.p,{children:["Various command-line options are available to customize the deployment, such as instance type, count, IAM role, etc.\nRefer to the ",(0,t.jsx)(r.A,{to:"/api_reference/cli.html#mlflow-sagemaker",target:"_blank",children:"CLI reference"})," for a complete list of options."]}),"\n",(0,t.jsx)(l.pre,{children:(0,t.jsx)(l.code,{className:"language-bash",children:'$ mlflow deployments create -t sagemaker -m runs:/<run_id>/model \\\n    -C region_name=<your-region> \\\n    -C instance-type=ml.m4.xlarge \\\n    -C instance-count=1 \\\n    -C env=\'{"DISABLE_NGINX": "true"}\'\'\n'})}),"\n",(0,t.jsx)(l.h2,{id:"api-reference",children:"API Reference"}),"\n",(0,t.jsx)(l.p,{children:"You have two options for deploying a model to SageMaker: using the CLI or the Python API."}),"\n",(0,t.jsxs)(l.ul,{children:["\n",(0,t.jsxs)(l.li,{children:["\n","","\n",(0,t.jsx)(r.A,{to:"/api_reference/cli.html#mlflow-sagemaker",target:"_blank",children:"CLI Reference"}),"\n"]}),"\n",(0,t.jsxs)(l.li,{children:["\n",(0,t.jsx)(i.B,{fn:"mlflow.sagemaker",children:"Python API Documentation"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(l.h2,{id:"deployment-sagemaker-references",children:"Useful Links"}),"\n",(0,t.jsxs)(l.ul,{children:["\n",(0,t.jsxs)(l.li,{children:[(0,t.jsx)(l.a,{href:"https://docs.databricks.com/en/_extras/notebooks/source/mlflow/mlflow-quick-start-deployment-aws.html",children:"MLflow Quickstart Part 2: Serving Models Using Amazon SageMaker"})," -\nThis step-by-step tutorial demonstrates how to deploy a model to SageMaker using MLflow Python APIs from a Databricks notebook."]}),"\n",(0,t.jsxs)(l.li,{children:[(0,t.jsx)(l.a,{href:"https://aws.amazon.com/blogs/machine-learning/managing-your-machine-learning-lifecycle-with-mlflow-and-amazon-sagemaker",children:"Managing Your Machine Learning Lifecycle with MLflow and Amazon SageMaker"})," -\nThis comprehensive tutorial covers integrating the entire MLflow lifecycle with SageMaker, from model training to deployment."]}),"\n"]}),"\n",(0,t.jsx)(l.h2,{id:"troubleshooting",children:"Troubleshooting"})]})}function h(e={}){const{wrapper:l}={...(0,a.R)(),...e.components};return l?(0,t.jsx)(l,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},67756:(e,l,n)=>{n.d(l,{B:()=>s});n(96540);const o=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var t=n(29030),a=n(56289),r=n(74848);const i=e=>{const l=e.split(".");for(let n=l.length;n>0;n--){const e=l.slice(0,n).join(".");if(o[e])return e}return null};function s(e){let{fn:l,children:n}=e;const s=i(l);if(!s)return(0,r.jsx)(r.Fragment,{children:n});const m=(0,t.Ay)(`/${o[s]}#${l}`);return(0,r.jsx)(a.A,{to:m,target:"_blank",children:n??(0,r.jsxs)("code",{children:[l,"()"]})})}}}]);