"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7913],{1407:(e,n,l)=>{l.r(n),l.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>d,frontMatter:()=>i,metadata:()=>a,toc:()=>m});const a=JSON.parse('{"id":"deep-learning/keras/guide/index","title":"Keras within MLflow","description":"In this guide we will walk you through how to use Keras with MLflow. We will demonstrate how to track your Keras experiments and log your Keras models to MLflow using both autologging and manual logging approaches.","source":"@site/docs/classic-ml/deep-learning/keras/guide/index.mdx","sourceDirName":"deep-learning/keras/guide","slug":"/deep-learning/keras/guide/","permalink":"/docs/latest/ml/deep-learning/keras/guide/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"classicMLSidebar","previous":{"title":"Quickstart","permalink":"/docs/latest/ml/deep-learning/keras/quickstart/quickstart-keras"},"next":{"title":"Pytorch","permalink":"/docs/latest/ml/deep-learning/pytorch/"}}');var t=l(74848),o=l(28453),r=l(49374);const i={},s="Keras within MLflow",c={},m=[{value:"Setting Up Keras Backend",id:"setting-up-keras-backend",level:2},{value:"Logging Keras Experiments to MLflow",id:"logging-keras-experiments-to-mlflow",level:2},{value:"Autologging Keras Experiments",id:"autologging-keras-experiments",level:3},{value:"What Gets Automatically Logged",id:"what-gets-automatically-logged",level:4},{value:"Automatic Run Management",id:"automatic-run-management",level:4},{value:"Manually Logging Keras Experiments",id:"manually-logging-keras-experiments",level:3},{value:"Best Practices for Manual Logging",id:"best-practices-for-manual-logging",level:4},{value:"Complete Manual Logging Example",id:"complete-manual-logging-example",level:4},{value:"Using MLflow&#39;s Keras Callback",id:"using-mlflows-keras-callback",level:2},{value:"Advanced Callback Usage",id:"advanced-callback-usage",level:3},{value:"Saving Your Keras Model to MLflow",id:"saving-your-keras-model-to-mlflow",level:2},{value:"Basic Model Saving",id:"basic-model-saving",level:3},{value:"Model Signatures",id:"model-signatures",level:3},{value:"Multi-Backend Support with Keras 3.0",id:"multi-backend-support-with-keras-30",level:2},{value:"Advanced Features",id:"advanced-features",level:2},{value:"Hyperparameter Tuning with Keras and MLflow",id:"hyperparameter-tuning-with-keras-and-mlflow",level:3},{value:"Custom Metrics and Artifacts",id:"custom-metrics-and-artifacts",level:3},{value:"Conclusion",id:"conclusion",level:2}];function p(e){const n={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"keras-within-mlflow",children:"Keras within MLflow"})}),"\n",(0,t.jsx)(n.p,{children:"In this guide we will walk you through how to use Keras with MLflow. We will demonstrate how to track your Keras experiments and log your Keras models to MLflow using both autologging and manual logging approaches."}),"\n",(0,t.jsx)(n.h2,{id:"setting-up-keras-backend",children:"Setting Up Keras Backend"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Keras 3.0"})," is inherently multi-backend, supporting TensorFlow, JAX, and PyTorch. You must set the backend environment variable ",(0,t.jsx)(n.strong,{children:"before"})," importing Keras:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import os\n\n# You can use 'tensorflow', 'torch', or 'jax' as backend\n# Make sure to set the environment variable before importing Keras\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n\nimport keras\nimport numpy as np\nimport mlflow\n"})}),"\n",(0,t.jsx)(n.admonition,{title:"backend-selection",type:"important",children:(0,t.jsx)(n.p,{children:"The backend must be set before importing Keras. Once Keras is imported, the backend cannot be changed within the same Python session."})}),"\n",(0,t.jsx)(n.p,{children:"This multi-backend architecture means your MLflow tracking code works consistently regardless of which backend you choose, giving you the flexibility to optimize for your specific use case without changing your experiment tracking setup."}),"\n",(0,t.jsx)(n.h2,{id:"logging-keras-experiments-to-mlflow",children:"Logging Keras Experiments to MLflow"}),"\n",(0,t.jsx)(n.h3,{id:"autologging-keras-experiments",children:"Autologging Keras Experiments"}),"\n",(0,t.jsxs)(n.p,{children:["MLflow provides seamless autologging integration with Keras/TensorFlow. To enable automatic logging of metrics, parameters, and models, simply call ",(0,t.jsx)(r.B,{fn:"mlflow.tensorflow.autolog"})," or ",(0,t.jsx)(r.B,{fn:"mlflow.autolog"})," before your training code."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import mlflow\nimport mlflow.tensorflow\n\n# Enable autologging for TensorFlow/Keras\nmlflow.tensorflow.autolog()\n\n# Your existing Keras training code works unchanged\nmodel.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10)\n"})}),"\n",(0,t.jsx)(n.admonition,{title:"version-support",type:"note",children:(0,t.jsxs)(n.p,{children:["Only versions of ",(0,t.jsx)(n.code,{children:"tensorflow>=2.3"})," are supported. The autologging feature captures metrics from both ",(0,t.jsx)(n.code,{children:"tf.keras"})," and ",(0,t.jsx)(n.code,{children:"tf.keras.callbacks.EarlyStopping"}),"."]})}),"\n",(0,t.jsx)(n.h4,{id:"what-gets-automatically-logged",children:"What Gets Automatically Logged"}),"\n",(0,t.jsx)(n.p,{children:"Autologging captures comprehensive information about your Keras training:"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Framework"}),(0,t.jsx)(n.th,{children:"Metrics"}),(0,t.jsx)(n.th,{children:"Parameters"}),(0,t.jsx)(n.th,{children:"Artifacts"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"tf.keras"})}),(0,t.jsx)(n.td,{children:"Training loss; validation loss; user-specified metrics"}),(0,t.jsxs)(n.td,{children:[(0,t.jsx)(n.code,{children:"fit()"})," parameters; optimizer name; learning rate; epsilon"]}),(0,t.jsx)(n.td,{children:"Model summary on training start; MLflow Model (Keras model); TensorBoard logs on training end"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"tf.keras.callbacks.EarlyStopping"})}),(0,t.jsxs)(n.td,{children:["Metrics from EarlyStopping callbacks: ",(0,t.jsx)(n.code,{children:"stopped_epoch"}),", ",(0,t.jsx)(n.code,{children:"restored_epoch"}),", ",(0,t.jsx)(n.code,{children:"restore_best_weight"}),", etc"]}),(0,t.jsxs)(n.td,{children:[(0,t.jsx)(n.code,{children:"fit()"})," parameters from EarlyStopping: ",(0,t.jsx)(n.code,{children:"min_delta"}),", ",(0,t.jsx)(n.code,{children:"patience"}),", ",(0,t.jsx)(n.code,{children:"baseline"}),", ",(0,t.jsx)(n.code,{children:"restore_best_weights"}),", etc"]}),(0,t.jsx)(n.td,{children:"--"})]})]})]}),"\n",(0,t.jsx)(n.h4,{id:"automatic-run-management",children:"Automatic Run Management"}),"\n",(0,t.jsx)(n.p,{children:"MLflow intelligently manages runs when using autologging:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"No Active Run"}),": If no active run exists when ",(0,t.jsx)(n.code,{children:"autolog()"})," captures data, MLflow automatically creates a run and ends it once training completes via ",(0,t.jsx)(n.code,{children:"tf.keras.fit()"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Existing Run"}),": If a run already exists, MLflow logs to that run but does not automatically end it - you must manually stop the run if needed"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"manually-logging-keras-experiments",children:"Manually Logging Keras Experiments"}),"\n",(0,t.jsx)(n.p,{children:"For more control over what gets logged, you can manually instrument your Keras training code using MLflow's logging APIs:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(r.B,{fn:"mlflow.log_metric"})," / ",(0,t.jsx)(r.B,{fn:"mlflow.log_metrics"}),": Log metrics such as accuracy and loss during training"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(r.B,{fn:"mlflow.log_param"})," / ",(0,t.jsx)(r.B,{fn:"mlflow.log_params"}),": Log parameters such as learning rate and batch size"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(r.B,{fn:"mlflow.keras.log_model"}),": Save your Keras model to MLflow"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(r.B,{fn:"mlflow.log_artifact"}),": Log artifacts such as model checkpoints and plots"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"best-practices-for-manual-logging",children:"Best Practices for Manual Logging"}),"\n",(0,t.jsx)(n.p,{children:"When manually logging Keras experiments, follow these best practices:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Log training parameters"})," at the beginning of training via ",(0,t.jsx)(r.B,{fn:"mlflow.log_params"}),", including learning rate, batch size, epochs, etc."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Log model architecture"})," at the beginning of training via ",(0,t.jsx)(r.B,{fn:"mlflow.log_artifact"}),". You can save the model summary as a text file"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Log training and validation metrics"})," inside your training loop or callbacks via ",(0,t.jsx)(r.B,{fn:"mlflow.log_metric"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Log your trained model"})," to MLflow via ",(0,t.jsx)(r.B,{fn:"mlflow.keras.log_model"})," at the end of training"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"[Optional] Log model checkpoints"})," during training via ",(0,t.jsx)(r.B,{fn:"mlflow.log_artifact"})," to preserve intermediate training states"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"complete-manual-logging-example",children:"Complete Manual Logging Example"}),"\n",(0,t.jsx)(n.p,{children:"Here's an end-to-end example of manually logging a Keras experiment:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport mlflow.keras\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\n\n# Load and prepare data\n(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\nx_train = x_train.reshape(60000, 784).astype("float32") / 255\nx_test = x_test.reshape(10000, 784).astype("float32") / 255\ny_train = keras.utils.to_categorical(y_train, 10)\ny_test = keras.utils.to_categorical(y_test, 10)\n\n\n# Define model architecture\ndef create_model():\n    model = keras.Sequential(\n        [\n            layers.Dense(512, activation="relu", input_shape=(784,)),\n            layers.Dropout(0.2),\n            layers.Dense(256, activation="relu"),\n            layers.Dropout(0.2),\n            layers.Dense(10, activation="softmax"),\n        ]\n    )\n    return model\n\n\n# Training parameters\nparams = {\n    "epochs": 10,\n    "batch_size": 128,\n    "learning_rate": 0.001,\n    "optimizer": "adam",\n    "loss_function": "categorical_crossentropy",\n    "dropout_rate": 0.2,\n    "hidden_units": [512, 256],\n}\n\nwith mlflow.start_run():\n    # Log training parameters\n    mlflow.log_params(params)\n\n    # Create and compile model\n    model = create_model()\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=params["learning_rate"]),\n        loss=params["loss_function"],\n        metrics=["accuracy"],\n    )\n\n    # Log model architecture\n    with open("model_summary.txt", "w") as f:\n        model.summary(print_fn=lambda x: f.write(x + "\\n"))\n    mlflow.log_artifact("model_summary.txt")\n\n    # Custom callback for logging metrics\n    class MLflowCallback(keras.callbacks.Callback):\n        def on_epoch_end(self, epoch, logs=None):\n            if logs:\n                mlflow.log_metrics(\n                    {\n                        "train_loss": logs.get("loss"),\n                        "train_accuracy": logs.get("accuracy"),\n                        "val_loss": logs.get("val_loss"),\n                        "val_accuracy": logs.get("val_accuracy"),\n                    },\n                    step=epoch,\n                )\n\n    # Train model with custom callback\n    history = model.fit(\n        x_train,\n        y_train,\n        batch_size=params["batch_size"],\n        epochs=params["epochs"],\n        validation_data=(x_test, y_test),\n        callbacks=[MLflowCallback()],\n        verbose=1,\n    )\n\n    # Evaluate model\n    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n    mlflow.log_metrics({"test_loss": test_loss, "test_accuracy": test_accuracy})\n\n    # Log the trained model\n    mlflow.keras.log_model(model, name="model")\n\n    print(f"Test accuracy: {test_accuracy:.4f}")\n'})}),"\n",(0,t.jsx)(n.p,{children:"If you run this code with a local MLflow server, you'll see comprehensive tracking in the MLflow UI."}),"\n",(0,t.jsx)(n.h2,{id:"using-mlflows-keras-callback",children:"Using MLflow's Keras Callback"}),"\n",(0,t.jsxs)(n.p,{children:["MLflow provides a built-in callback for Keras that simplifies experiment tracking. The ",(0,t.jsx)(r.B,{fn:"mlflow.keras.MlflowCallback"})," integrates seamlessly with your Keras training loop:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport mlflow.keras\nfrom mlflow.keras import MlflowCallback\n\n# Create model and prepare data (same as above)\nmodel = create_model()\nmodel.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])\n\nwith mlflow.start_run() as run:\n    # Use MLflow\'s built-in callback\n    mlflow_callback = MlflowCallback(run)\n\n    history = model.fit(\n        x_train,\n        y_train,\n        batch_size=128,\n        epochs=10,\n        validation_data=(x_test, y_test),\n        callbacks=[mlflow_callback],\n        verbose=1,\n    )\n'})}),"\n",(0,t.jsx)(n.h3,{id:"advanced-callback-usage",children:"Advanced Callback Usage"}),"\n",(0,t.jsx)(n.p,{children:"The MlflowCallback supports various configuration options:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Log metrics every 5 batches instead of every epoch\nmlflow_callback = MlflowCallback(run, log_every_epoch=False, log_every_n_steps=5)\n\n\n# Custom callback subclass for specialized logging\nclass CustomMlflowCallback(MlflowCallback):\n    def on_epoch_end(self, epoch, logs=None):\n        # Call parent method\n        super().on_epoch_end(epoch, logs)\n\n        # Add custom logging\n        if logs and epoch % 5 == 0:  # Log every 5 epochs\n            mlflow.log_metric(\n                "learning_rate", self.model.optimizer.learning_rate.numpy()\n            )\n\n    def on_train_end(self, logs=None):\n        # Log final model weights distribution\n        weights = self.model.get_weights()\n        avg_weight = np.mean([np.mean(w) for w in weights])\n        mlflow.log_metric("avg_final_weight", avg_weight)\n'})}),"\n",(0,t.jsx)(n.h2,{id:"saving-your-keras-model-to-mlflow",children:"Saving Your Keras Model to MLflow"}),"\n",(0,t.jsx)(n.h3,{id:"basic-model-saving",children:"Basic Model Saving"}),"\n",(0,t.jsxs)(n.p,{children:["Save your trained Keras model using ",(0,t.jsx)(r.B,{fn:"mlflow.keras.log_model"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport mlflow.keras\nimport numpy as np\n\n# Train your model\nmodel = create_model()\nmodel.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])\nmodel.fit(x_train, y_train, epochs=5)\n\nmodel_info = mlflow.keras.log_model(model, name="model")\n\n# Load and use the model\nloaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n\n# Make predictions\npredictions = loaded_model.predict(x_test[:5])\nprint("Predictions:", predictions)\n'})}),"\n",(0,t.jsx)(n.h3,{id:"model-signatures",children:"Model Signatures"}),"\n",(0,t.jsx)(n.p,{children:"A model signature describes a model's input and output schema. While not required, it's a best practice for better model understanding and validation:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom mlflow.models import infer_signature\nimport numpy as np\n\n# Prepare sample data for signature inference\nsample_input = x_test[:100]\nsample_predictions = model.predict(sample_input)\n\n# Infer signature from sample data\nsignature = infer_signature(sample_input, sample_predictions)\n\n# Log model with signature\nmodel_info = mlflow.keras.log_model(model, name="model", signature=signature)\n'})}),"\n",(0,t.jsx)(n.p,{children:"You can also manually create signatures for more control:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from mlflow.types import Schema, TensorSpec\nfrom mlflow.models import ModelSignature\nimport numpy as np\n\n# Define input and output schemas\ninput_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 784))])\noutput_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 10))])\nsignature = ModelSignature(inputs=input_schema, outputs=output_schema)\n\nmodel_info = mlflow.keras.log_model(model, name="model", signature=signature)\n'})}),"\n",(0,t.jsx)(n.h2,{id:"multi-backend-support-with-keras-30",children:"Multi-Backend Support with Keras 3.0"}),"\n",(0,t.jsx)(n.p,{children:"As mentioned at the start of this guide, Keras 3.0's multi-backend support is one of its most powerful features. MLflow's tracking works seamlessly across all supported backends:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import os\nimport mlflow\n\n# Switch backends easily - MLflow tracking code remains identical\nos.environ["KERAS_BACKEND"] = "jax"  # or "torch" or "tensorflow"\n\nimport keras\nimport mlflow.keras\n\n# Enable autologging (works with any backend)\nmlflow.tensorflow.autolog()\n\n# Your training code is backend-agnostic\nmodel = keras.Sequential(\n    [\n        keras.layers.Dense(64, activation="relu"),\n        keras.layers.Dense(10, activation="softmax"),\n    ]\n)\n\nmodel.compile(\n    optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"]\n)\n\nwith mlflow.start_run():\n    model.fit(x_train, y_train, epochs=5, validation_split=0.2)\n'})}),"\n",(0,t.jsx)(n.p,{children:"This consistency means you can:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Experiment with different backends"})," without changing your MLflow tracking code"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Optimize performance"})," by choosing the best backend for your hardware (JAX for TPUs, PyTorch for research flexibility, TensorFlow for production)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Maintain reproducibility"})," across different computational environments"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"advanced-features",children:"Advanced Features"}),"\n",(0,t.jsx)(n.h3,{id:"hyperparameter-tuning-with-keras-and-mlflow",children:"Hyperparameter Tuning with Keras and MLflow"}),"\n",(0,t.jsx)(n.p,{children:"Combine Keras with hyperparameter tuning libraries while tracking everything in MLflow:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport optuna\nfrom sklearn.model_selection import train_test_split\n\n\ndef objective(trial):\n    # Suggest hyperparameters\n    lr = trial.suggest_float("learning_rate", 1e-5, 1e-1, log=True)\n    batch_size = trial.suggest_categorical("batch_size", [32, 64, 128])\n    hidden_units = trial.suggest_int("hidden_units", 64, 512)\n    dropout_rate = trial.suggest_float("dropout_rate", 0.1, 0.5)\n\n    with mlflow.start_run(nested=True):\n        # Log trial parameters\n        mlflow.log_params(\n            {\n                "learning_rate": lr,\n                "batch_size": batch_size,\n                "hidden_units": hidden_units,\n                "dropout_rate": dropout_rate,\n            }\n        )\n\n        # Create model with suggested parameters\n        model = keras.Sequential(\n            [\n                keras.layers.Dense(hidden_units, activation="relu", input_shape=(784,)),\n                keras.layers.Dropout(dropout_rate),\n                keras.layers.Dense(10, activation="softmax"),\n            ]\n        )\n\n        model.compile(\n            optimizer=keras.optimizers.Adam(learning_rate=lr),\n            loss="categorical_crossentropy",\n            metrics=["accuracy"],\n        )\n\n        # Train model\n        history = model.fit(\n            x_train,\n            y_train,\n            batch_size=batch_size,\n            epochs=10,\n            validation_split=0.2,\n            verbose=0,\n        )\n\n        # Get validation accuracy\n        val_accuracy = max(history.history["val_accuracy"])\n        mlflow.log_metric("val_accuracy", val_accuracy)\n\n        return val_accuracy\n\n\n# Run hyperparameter optimization\nwith mlflow.start_run():\n    mlflow.set_tag("optimization", "optuna")\n    study = optuna.create_study(direction="maximize")\n    study.optimize(objective, n_trials=20)\n\n    # Log best parameters\n    mlflow.log_params(study.best_params)\n    mlflow.log_metric("best_val_accuracy", study.best_value)\n'})}),"\n",(0,t.jsx)(n.h3,{id:"custom-metrics-and-artifacts",children:"Custom Metrics and Artifacts"}),"\n",(0,t.jsx)(n.p,{children:"Log custom visualizations and metrics specific to your use case:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n\ndef log_training_plots(history, run_id):\n    """Log training history plots to MLflow."""\n\n    # Plot training history\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n\n    ax1.plot(history.history["loss"], label="Training Loss")\n    ax1.plot(history.history["val_loss"], label="Validation Loss")\n    ax1.set_title("Model Loss")\n    ax1.set_xlabel("Epoch")\n    ax1.set_ylabel("Loss")\n    ax1.legend()\n\n    ax2.plot(history.history["accuracy"], label="Training Accuracy")\n    ax2.plot(history.history["val_accuracy"], label="Validation Accuracy")\n    ax2.set_title("Model Accuracy")\n    ax2.set_xlabel("Epoch")\n    ax2.set_ylabel("Accuracy")\n    ax2.legend()\n\n    plt.tight_layout()\n    plt.savefig("training_history.png", dpi=300, bbox_inches="tight")\n    mlflow.log_artifact("training_history.png")\n    plt.close()\n\n\ndef log_evaluation_metrics(model, x_test, y_test, class_names):\n    """Log comprehensive evaluation metrics."""\n\n    # Get predictions\n    y_pred = model.predict(x_test)\n    y_pred_classes = np.argmax(y_pred, axis=1)\n    y_true_classes = np.argmax(y_test, axis=1)\n\n    # Confusion matrix\n    cm = confusion_matrix(y_true_classes, y_pred_classes)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(\n        cm,\n        annot=True,\n        fmt="d",\n        cmap="Blues",\n        xticklabels=class_names,\n        yticklabels=class_names,\n    )\n    plt.title("Confusion Matrix")\n    plt.ylabel("True Label")\n    plt.xlabel("Predicted Label")\n    plt.savefig("confusion_matrix.png", dpi=300, bbox_inches="tight")\n    mlflow.log_artifact("confusion_matrix.png")\n    plt.close()\n\n    # Classification report\n    report = classification_report(\n        y_true_classes, y_pred_classes, target_names=class_names, output_dict=True\n    )\n\n    # Log per-class metrics\n    for class_name in class_names:\n        if class_name in report:\n            mlflow.log_metrics(\n                {\n                    f"{class_name}_precision": report[class_name]["precision"],\n                    f"{class_name}_recall": report[class_name]["recall"],\n                    f"{class_name}_f1": report[class_name]["f1-score"],\n                }\n            )\n\n\n# Usage example\nwith mlflow.start_run():\n    # Train model\n    history = model.fit(\n        x_train, y_train, validation_data=(x_test, y_test), epochs=10, verbose=1\n    )\n\n    # Log comprehensive results\n    log_training_plots(history, mlflow.active_run().info.run_id)\n    log_evaluation_metrics(\n        model, x_test, y_test, class_names=[str(i) for i in range(10)]\n    )\n'})}),"\n",(0,t.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,t.jsx)(n.p,{children:"MLflow's integration with Keras provides a comprehensive solution for experiment tracking and model management in deep learning workflows. Whether you choose autologging for simplicity or manual logging for fine-grained control, MLflow captures all the essential information needed for reproducible machine learning research and production deployment."}),"\n",(0,t.jsx)(n.p,{children:"Key benefits of using MLflow with Keras include:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Seamless Integration"}),": One-line autologging setup with comprehensive tracking"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Multi-Backend Support"}),": Consistent tracking across TensorFlow, JAX, and PyTorch backends"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Flexible Logging"}),": Choose between automatic and manual logging approaches"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Production Ready"}),": Built-in model serving and deployment capabilities"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Collaborative Development"}),": Share experiments and models through MLflow's intuitive UI"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Whether you're conducting research experiments or building production ML systems, the MLflow-Keras integration provides the foundation for organized, reproducible, and scalable deep learning workflows."})]})}function d(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(p,{...e})}):p(e)}},28453:(e,n,l)=>{l.d(n,{R:()=>r,x:()=>i});var a=l(96540);const t={},o=a.createContext(t);function r(e){const n=a.useContext(o);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),a.createElement(o.Provider,{value:n},e.children)}},49374:(e,n,l)=>{l.d(n,{B:()=>s});l(96540);const a=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var t=l(86025),o=l(28774),r=l(74848);const i=e=>{const n=e.split(".");for(let l=n.length;l>0;l--){const e=n.slice(0,l).join(".");if(a[e])return e}return null};function s({fn:e,children:n}){const l=i(e);if(!l)return(0,r.jsx)(r.Fragment,{children:n});const s=(0,t.Ay)(`/${a[l]}#${e}`);return(0,r.jsx)(o.A,{to:s,target:"_blank",children:n??(0,r.jsxs)("code",{children:[e,"()"]})})}}}]);