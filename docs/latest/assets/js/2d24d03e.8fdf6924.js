"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[6259],{10493:(e,t,l)=>{l.d(t,{Zp:()=>s,AC:()=>o,WO:()=>p,_C:()=>m,$3:()=>c,jK:()=>h});var a=l(34164);const n={CardGroup:"CardGroup_P84T",NoGap:"NoGap_O9Dj",MaxThreeColumns:"MaxThreeColumns_FO1r",AutofillColumns:"AutofillColumns_fKhQ",Card:"Card_aSCR",CardBordered:"CardBordered_glGF",CardBody:"CardBody_BhRs",TextColor:"TextColor_a8Tp",BoxRoot:"BoxRoot_Etgr",FlexWrapNowrap:"FlexWrapNowrap_f60k",FlexJustifyContentFlexStart:"FlexJustifyContentFlexStart_ZYv5",FlexDirectionRow:"FlexDirectionRow_T2qL",FlexAlignItemsCenter:"FlexAlignItemsCenter_EHVM",FlexFlex:"FlexFlex__JTE",Link:"Link_fVkl",MarginLeft4:"MarginLeft4_YQSJ",MarginTop4:"MarginTop4_jXKN",PaddingBottom4:"PaddingBottom4_O9gt",LogoCardContent:"LogoCardContent_kCQm",LogoCardImage:"LogoCardImage_JdcX",SmallLogoCardContent:"SmallLogoCardContent_LxhV",SmallLogoCardRounded:"SmallLogoCardRounded_X50_",SmallLogoCardImage:"SmallLogoCardImage_tPZl",NewFeatureCardContent:"NewFeatureCardContent_Rq3d",NewFeatureCardHeading:"NewFeatureCardHeading_f6q3",NewFeatureCardHeadingSeparator:"NewFeatureCardHeadingSeparator_pSx8",NewFeatureCardTags:"NewFeatureCardTags_IFHO",NewFeatureCardWrapper:"NewFeatureCardWrapper_NQ0k",TitleCardContent:"TitleCardContent_l9MQ",TitleCardTitle:"TitleCardTitle__K8J",TitleCardSeparator:"TitleCardSeparator_IN2E",Cols1:"Cols1_Gr2U",Cols2:"Cols2_sRvc",Cols3:"Cols3_KjUS",Cols4:"Cols4_dKOj",Cols5:"Cols5_jDmj",Cols6:"Cols6_Q0OR"};var i=l(28774),r=l(74848);const o=({children:e,isSmall:t,cols:l,noGap:i})=>(0,r.jsx)("div",{className:(0,a.A)(n.CardGroup,t?n.AutofillColumns:l?n[`Cols${l}`]:n.MaxThreeColumns,i&&n.NoGap),children:e}),s=({children:e,link:t=""})=>t?(0,r.jsx)(i.A,{className:(0,a.A)(n.Link,n.Card,n.CardBordered),to:t,children:e}):(0,r.jsx)("div",{className:(0,a.A)(n.Card,n.CardBordered),children:e}),m=({headerText:e,link:t,text:l})=>(0,r.jsx)(s,{link:t,children:(0,r.jsxs)("span",{children:[(0,r.jsx)("div",{className:(0,a.A)(n.CardTitle,n.BoxRoot,n.PaddingBottom4),style:{pointerEvents:"none"},children:(0,r.jsx)("div",{className:(0,a.A)(n.BoxRoot,n.FlexFlex,n.FlexAlignItemsCenter,n.FlexDirectionRow,n.FlexJustifyContentFlexStart,n.FlexWrapNowrap),style:{marginLeft:"-4px",marginTop:"-4px"},children:(0,r.jsx)("div",{className:(0,a.A)(n.BoxRoot,n.BoxHideIfEmpty,n.MarginTop4,n.MarginLeft4),style:{pointerEvents:"auto"},children:(0,r.jsx)("span",{className:"",children:e})})})}),(0,r.jsx)("span",{className:(0,a.A)(n.TextColor,n.CardBody),children:(0,r.jsx)("p",{children:l})})]})}),p=({description:e,children:t,link:l})=>(0,r.jsx)(s,{link:l,children:(0,r.jsxs)("div",{className:n.LogoCardContent,children:[(0,r.jsx)("div",{className:n.LogoCardImage,children:t}),(0,r.jsx)("p",{className:n.TextColor,children:e})]})}),c=({children:e,link:t})=>(0,r.jsx)("div",{className:(0,a.A)(n.Card,n.CardBordered,n.SmallLogoCardRounded),children:t?(0,r.jsx)(i.A,{className:(0,a.A)(n.Link),to:t,children:(0,r.jsx)("div",{className:n.SmallLogoCardContent,children:(0,r.jsx)("div",{className:(0,a.A)("max-height-img-container",n.SmallLogoCardImage),children:e})})}):(0,r.jsx)("div",{className:n.SmallLogoCardContent,children:(0,r.jsx)("div",{className:(0,a.A)("max-height-img-container",n.SmallLogoCardImage),children:e})})}),h=({title:e,description:t,link:l=""})=>(0,r.jsx)(s,{link:l,children:(0,r.jsxs)("div",{className:n.TitleCardContent,children:[(0,r.jsx)("div",{className:(0,a.A)(n.TitleCardTitle),style:{textAlign:"left",fontWeight:"bold"},children:e}),(0,r.jsx)("hr",{className:(0,a.A)(n.TitleCardSeparator),style:{margin:"12px 0"}}),(0,r.jsx)("p",{className:(0,a.A)(n.TextColor),children:t})]})})},49374:(e,t,l)=>{l.d(t,{B:()=>o});l(96540);const a=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}');var n=l(86025),i=l(74848);const r=e=>{const t=e.split(".");for(let l=t.length;l>0;l--){const e=t.slice(0,l).join(".");if(a[e])return e}return null};function o({fn:e,children:t,hash:l}){const o=r(e);if(!o)return(0,i.jsx)(i.Fragment,{children:t});const s=(0,n.Ay)(`/${a[o]}#${l??e}`);return(0,i.jsx)("a",{href:s,target:"_blank",children:t??(0,i.jsxs)("code",{children:[e,"()"]})})}},51274:(e,t,l)=>{l.r(t),l.d(t,{assets:()=>p,contentTitle:()=>m,default:()=>d,frontMatter:()=>s,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"tracing/integrations/listing/txtai","title":"Tracing txtai","description":"txtai Tracing via autolog","source":"@site/docs/genai/tracing/integrations/listing/txtai.mdx","sourceDirName":"tracing/integrations/listing","slug":"/tracing/integrations/listing/txtai","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/txtai","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":13,"frontMatter":{"sidebar_position":13,"sidebar_label":"txtai"},"sidebar":"genAISidebar","previous":{"title":"Instructor","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/instructor"},"next":{"title":"Add New Integration","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/contribute"}}');var n=l(74848),i=l(28453),r=(l(49374),l(10493),l(14252),l(11470)),o=l(19365);const s={sidebar_position:13,sidebar_label:"txtai"},m="Tracing txtai",p={},c=[{value:"Examples",id:"examples",level:3},{value:"More Information",id:"more-information",level:3}];function h(e){const t={a:"a",code:"code",h1:"h1",h3:"h3",header:"header",img:"img",p:"p",pre:"pre",...(0,i.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.header,{children:(0,n.jsx)(t.h1,{id:"tracing-txtai",children:"Tracing txtai"})}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"txtai Tracing via autolog",src:l(59255).A+"",width:"1919",height:"1008"})}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.a,{href:"https://github.com/neuml/txtai?tab=readme-ov-file",children:"txtai"})," is an all-in-one embeddings database for semantic search, LLM orchestration and language model workflows."]}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.a,{href:"/genai/tracing",children:"MLflow Tracing"})," provides automatic tracing capability for txtai. Auto tracing for txtai can be enabled by calling the ",(0,n.jsx)(t.code,{children:"mlflow.txtai.autolog"})," function, MLflow will capture traces for LLM invocation, embeddings, vector search, and log them to the active MLflow Experiment."]}),"\n",(0,n.jsxs)(t.p,{children:["To get started, install the ",(0,n.jsx)(t.a,{href:"https://github.com/neuml/mlflow-txtai/tree/master",children:"MLflow txtai extension"}),":"]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-bash",children:"pip install mlflow-txtai\n"})}),"\n",(0,n.jsx)(t.p,{children:"Then, enable autologging in your Python code:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-python",children:"import mlflow\n\nmlflow.txtai.autolog()\n"})}),"\n",(0,n.jsx)(t.h3,{id:"examples",children:"Examples"}),"\n",(0,n.jsxs)(r.A,{children:[(0,n.jsxs)(o.A,{value:"basic",label:"Simple Example",default:!0,children:[(0,n.jsxs)(t.p,{children:["The simplest example to show the tracing integration is to instrument a ",(0,n.jsx)(t.a,{href:"https://neuml.github.io/txtai/pipeline/data/textractor/",children:"Textractor pipeline"}),"."]}),(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-python",children:'import mlflow\nfrom txtai.pipeline import Textractor\n\n# Enable MLflow auto-tracing for txtai\nmlflow.txtai.autolog()\n\n# Optional: Set a tracking URI and an experiment\nmlflow.set_tracking_uri("http://localhost:5000")\nmlflow.set_experiment("txtai")\n\n# Define and run a simple Textractor pipeline.\ntextractor = Textractor()\ntextractor("https://github.com/neuml/txtai")\n'})}),(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"txtai Textractor Tracing via autolog",src:l(83527).A+"",width:"1899",height:"1003"})})]}),(0,n.jsxs)(o.A,{value:"rag",label:"RAG",default:!0,children:[(0,n.jsxs)(t.p,{children:["You can easily trace a ",(0,n.jsx)(t.a,{href:"https://neuml.github.io/txtai/pipeline/text/rag/",children:"RAG pipeline"}),"."]}),(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-python",children:'import mlflow\nfrom txtai import Embeddings, RAG\n\n# Enable MLflow auto-tracing for txtai\nmlflow.txtai.autolog()\n\nwiki = Embeddings()\nwiki.load(provider="huggingface-hub", container="neuml/txtai-wikipedia-slim")\n\n# Define prompt template\ntemplate = """\nAnswer the following question using only the context below. Only include information\nspecifically discussed.\n\nquestion: {question}\ncontext: {context} """\n\n# Create RAG pipeline\nrag = RAG(\n    wiki,\n    "hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4",\n    system="You are a friendly assistant. You answer questions from users.",\n    template=template,\n    context=10,\n)\n\nrag("Tell me about the Roman Empire", maxlength=2048)\n'})}),(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"txtai Rag Tracing via autolog",src:l(59255).A+"",width:"1919",height:"1008"})})]}),(0,n.jsxs)(o.A,{value:"agent",label:"Agent",default:!0,children:[(0,n.jsxs)(t.p,{children:["You can effortlessly trace the internals of a ",(0,n.jsx)(t.a,{href:"https://neuml.github.io/txtai/agent/",children:"txtai agent"})," designed to research questions on astronomy."]}),(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-python",children:'import mlflow\nfrom txtai import Agent, Embeddings\n\n# Enable MLflow auto-tracing for txtai\nmlflow.txtai.autolog()\n\n\ndef search(query):\n    """\n    Searches a database of astronomy data.\n\n    Make sure to call this tool only with a string input, never use JSON.\n\n    Args:\n        query: concepts to search for using similarity search\n\n    Returns:\n        list of search results with for each match\n    """\n\n    return embeddings.search(\n        "SELECT id, text, distance FROM txtai WHERE similar(:query)",\n        10,\n        parameters={"query": query},\n    )\n\n\nembeddings = Embeddings()\nembeddings.load(provider="huggingface-hub", container="neuml/txtai-astronomy")\n\nagent = Agent(\n    tools=[search],\n    llm="hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4",\n    max_iterations=10,\n)\n\nresearcher = """\n{command}\n\nDo the following.\n - Search for results related to the topic.\n - Analyze the results\n - Continue querying until conclusive answers are found\n - Write a Markdown report\n"""\n\nagent(\n    researcher.format(\n        command="""\nWrite a detailed list with explanations of 10 candidate stars that could potentially be habitable to life.\n"""\n    ),\n    maxlength=16000,\n)\n'})}),(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"txtai Agent Tracing via autolog",src:l(88514).A+"",width:"1905",height:"995"})})]})]}),"\n",(0,n.jsx)(t.h3,{id:"more-information",children:"More Information"}),"\n",(0,n.jsxs)(t.p,{children:["For more examples and guidance on using txtai with MLflow, please refer to the ",(0,n.jsx)(t.a,{href:"https://github.com/neuml/mlflow-txtai/tree/master",children:"MLflow txtai extension documentation"})]})]})}function d(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(h,{...e})}):h(e)}},59255:(e,t,l)=>{l.d(t,{A:()=>a});const a=l.p+"assets/images/txtai-rag-tracing-507199b924f1c7ed180e0d940758e2dc.png"},83527:(e,t,l)=>{l.d(t,{A:()=>a});const a=l.p+"assets/images/txtai-textractor-tracing-15f2e1b268fc3fc4921c06e5e9a87cd8.png"},88514:(e,t,l)=>{l.d(t,{A:()=>a});const a=l.p+"assets/images/txtai-agent-tracing-f69f47a9de38c40814ea985887782850.png"}}]);