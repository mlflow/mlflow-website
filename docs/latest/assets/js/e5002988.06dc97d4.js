"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5014],{15706:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>r,default:()=>p,frontMatter:()=>l,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"data-model/experiments","title":"MLflow Experiments Data Model for GenAI","description":"MLflow Experiments serve as the top-level organizational container for all GenAI application development and production activities. An Experiment provides a unified namespace that brings together traces, models, datasets, evaluation runs, and other MLflow entities under a single cohesive framework for your GenAI application lifecycle.","source":"@site/docs/genai/data-model/experiments.mdx","sourceDirName":"data-model","slug":"/data-model/experiments","permalink":"/docs/latest/genai/data-model/experiments","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"genAISidebar","previous":{"title":"MLflow Data Model","permalink":"/docs/latest/genai/data-model/"},"next":{"title":"Logged Model","permalink":"/docs/latest/genai/data-model/logged-model"}}');var s=i(74848),a=i(28453);const l={},r="MLflow Experiments Data Model for GenAI",o={},c=[{value:"Overview",id:"overview",level:2},{value:"The Experiment as Organizational Foundation",id:"the-experiment-as-organizational-foundation",level:2},{value:"\ud83c\udfaf Single Application Focus",id:"-single-application-focus",level:3},{value:"\ud83d\udd17 Unified Entity Management",id:"-unified-entity-management",level:3},{value:"\ud83d\udcca Lifecycle Continuity",id:"-lifecycle-continuity",level:3},{value:"GenAI Entities Within Experiments",id:"genai-entities-within-experiments",level:2},{value:"\ud83d\udcdd Traces: Execution Records",id:"-traces-execution-records",level:3},{value:"\ud83e\udd16 Models: AI System Definitions",id:"-models-ai-system-definitions",level:3},{value:"\ud83d\udccb Datasets: Evaluation Collections",id:"-datasets-evaluation-collections",level:3},{value:"\ud83d\ude80 Evaluation Runs: Systematic Testing",id:"-evaluation-runs-systematic-testing",level:3},{value:"\ud83d\udcca Assessments: Quality Judgments",id:"-assessments-quality-judgments",level:3},{value:"\ud83c\udff7\ufe0f Labeling Sessions: Human Review",id:"\ufe0f-labeling-sessions-human-review",level:3},{value:"Complete Experiment Ecosystem",id:"complete-experiment-ecosystem",level:2},{value:"Benefits of Experiment-Centric Organization",id:"benefits-of-experiment-centric-organization",level:2},{value:"\ud83c\udfaf Unified Context",id:"-unified-context",level:4},{value:"\ud83d\udcca Comprehensive Tracking",id:"-comprehensive-tracking",level:4},{value:"\ud83d\udd04 Streamlined Workflows",id:"-streamlined-workflows",level:4},{value:"\ud83d\udcc8 Data-Driven Insights",id:"-data-driven-insights",level:4},{value:"Experiment Management Best Practices",id:"experiment-management-best-practices",level:2},{value:"\ud83c\udfd7\ufe0f Organizational Structure",id:"\ufe0f-organizational-structure",level:4},{value:"\ud83d\udcca Data Management",id:"-data-management",level:4},{value:"\ud83d\udd04 Workflow Integration",id:"-workflow-integration",level:4},{value:"Getting Started with Experiments",id:"getting-started-with-experiments",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",mermaid:"mermaid",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"mlflow-experiments-data-model-for-genai",children:"MLflow Experiments Data Model for GenAI"})}),"\n",(0,s.jsxs)(n.p,{children:["MLflow ",(0,s.jsx)(n.strong,{children:"Experiments"})," serve as the top-level organizational container for all GenAI application development and production activities. An Experiment provides a unified namespace that brings together traces, models, datasets, evaluation runs, and other MLflow entities under a single cohesive framework for your GenAI application lifecycle."]}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"The Experiment acts as the central hub that connects all aspects of your GenAI application development, from initial prototyping through production deployment and ongoing optimization."}),"\n",(0,s.jsx)(n.mermaid,{value:"graph TD\n    subgraph EXP[\ud83e\uddea MLflow Experiment]\n        direction TB\n        TITLE[\ud83c\udfaf GenAI Application Container]\n\n        subgraph CORE[\ud83d\udcca Core Entities]\n            T[\ud83d\udcdd Traces]\n            M[\ud83e\udd16 Models]\n            D[\ud83d\udccb Datasets]\n            ER[\ud83d\ude80 Evaluation Runs]\n        end\n\n        subgraph ANALYSIS[\ud83d\udcc8 Analysis Entities]\n            A[\ud83d\udcca Assessments]\n            S[\ud83c\udfaf Scorers]\n            LS[\ud83c\udff7\ufe0f Labeling Sessions]\n        end\n\n        TITLE -.-> CORE\n        TITLE -.-> ANALYSIS\n    end\n\n    classDef expStyle fill:#e8f5e8,stroke:#2e7d32,stroke-width:3px,color:#000\n    classDef coreStyle fill:#e3f2fd,stroke:#0277bd,stroke-width:2px,color:#000\n    classDef analysisStyle fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,color:#000\n    classDef titleStyle fill:#f5f5f5,stroke:#424242,stroke-width:2px,color:#000\n\n    class EXP expStyle\n    class CORE,T,M,D,ER coreStyle\n    class ANALYSIS,A,S,LS analysisStyle\n    class TITLE titleStyle"}),"\n",(0,s.jsx)(n.h2,{id:"the-experiment-as-organizational-foundation",children:"The Experiment as Organizational Foundation"}),"\n",(0,s.jsx)(n.h3,{id:"-single-application-focus",children:"\ud83c\udfaf Single Application Focus"}),"\n",(0,s.jsx)(n.p,{children:"Each Experiment represents one distinct GenAI application or service. Whether you're building a chatbot, document summarizer, or code assistant, all related work happens within a single Experiment container."}),"\n",(0,s.jsx)(n.h3,{id:"-unified-entity-management",children:"\ud83d\udd17 Unified Entity Management"}),"\n",(0,s.jsx)(n.p,{children:"All MLflow entities associated with your GenAI application automatically inherit the Experiment context, creating natural relationships and enabling cross-entity analysis."}),"\n",(0,s.jsx)(n.h3,{id:"-lifecycle-continuity",children:"\ud83d\udcca Lifecycle Continuity"}),"\n",(0,s.jsx)(n.p,{children:"From development through production, your Experiment maintains continuity across all phases of your application lifecycle."}),"\n",(0,s.jsx)(n.h2,{id:"genai-entities-within-experiments",children:"GenAI Entities Within Experiments"}),"\n",(0,s.jsx)(n.h3,{id:"-traces-execution-records",children:"\ud83d\udcdd Traces: Execution Records"}),"\n",(0,s.jsx)(n.p,{children:"Traces capture individual runs of your GenAI application and are always associated with an Experiment."}),"\n",(0,s.jsx)(n.mermaid,{value:"graph TB\n    subgraph EXP[\ud83e\uddea Experiment]\n        direction TB\n        T1[\ud83d\udcdd Trace: User Query 1]\n        T2[\ud83d\udcdd Trace: User Query 2]\n        T3[\ud83d\udcdd Trace: User Query 3]\n        T4[\ud83d\udcdd Trace: User Query N...]\n\n        T1 -.-> TRACE_DETAIL\n        T2 -.-> TRACE_DETAIL\n        T3 -.-> TRACE_DETAIL\n        T4 -.-> TRACE_DETAIL\n    end\n\n    subgraph TRACE_DETAIL[\ud83d\udcdd Trace Contents]\n        direction TB\n        TD1[\ud83d\udcac Input/Output Data]\n        TD2[\ud83c\udff7\ufe0f Tags & Metadata]\n        TD3[\u23f1\ufe0f Performance Metrics]\n        TD4[\ud83d\udd04 Span Hierarchy]\n    end\n\n    classDef expStyle fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px,color:#000\n    classDef traceStyle fill:#e3f2fd,stroke:#0277bd,stroke-width:2px,color:#000\n    classDef detailStyle fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,color:#000\n    classDef titleStyle fill:#f5f5f5,stroke:#424242,stroke-width:2px,color:#000\n\n    class T1,T2,T3,T4 traceStyle\n    class TRACE_DETAIL,TD1,TD2,TD3,TD4 detailStyle\n    class TITLE titleStyle"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Relationship to Experiment:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"All traces belong to exactly one Experiment"}),"\n",(0,s.jsx)(n.li,{children:"Traces inherit Experiment-level context and settings"}),"\n",(0,s.jsx)(n.li,{children:"Cross-trace analysis happens within the Experiment scope"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"-models-ai-system-definitions",children:"\ud83e\udd16 Models: AI System Definitions"}),"\n",(0,s.jsx)(n.p,{children:"Models represent the AI systems and configurations used in your GenAI application."}),"\n",(0,s.jsx)(n.mermaid,{value:"graph TB\n    subgraph EXP[\ud83e\uddea Experiment]\n        direction TB\n\n        subgraph MODELS[\ud83e\udd16 Model Versions]\n            M1[v1.0: GPT-3.5 + Custom Prompt]\n            M2[v1.1: GPT-4 + Improved Prompt]\n            M3[v2.0: Claude + RAG Pipeline]\n        end\n\n        subgraph TRACES[\ud83d\udcdd Associated Traces]\n            T1[Traces using Model v1.0]\n            T2[Traces using Model v1.1]\n            T3[Traces using Model v2.0]\n        end\n    end\n\n    M1 -.-> T1\n    M2 -.-> T2\n    M3 -.-> T3\n\n    classDef expStyle fill:#e8f5e8,stroke:#2e7d32,stroke-width:3px,color:#000\n    classDef modelStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000\n    classDef traceStyle fill:#e3f2fd,stroke:#0277bd,stroke-width:2px,color:#000\n\n    class EXP expStyle\n    class MODELS,M1,M2,M3 modelStyle\n    class TRACES,T1,T2,T3 traceStyle"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Relationship to Experiment:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Models are registered within specific Experiments"}),"\n",(0,s.jsx)(n.li,{children:"Model versions track evolution of your GenAI application"}),"\n",(0,s.jsx)(n.li,{children:"Traces reference specific model versions for reproducibility"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"-datasets-evaluation-collections",children:"\ud83d\udccb Datasets: Evaluation Collections"}),"\n",(0,s.jsx)(n.p,{children:"Datasets contain curated examples used for testing and evaluating your GenAI application."}),"\n",(0,s.jsx)(n.mermaid,{value:'graph TB\n    subgraph EXP[" "]\n        direction TB\n        TITLE[\ud83e\uddea Experiment: Document QA System]\n\n        subgraph DATASETS[\ud83d\udccb Evaluation Datasets]\n            D1[\ud83d\udcc4 Customer FAQ Dataset]\n            D2[\ud83d\udcda Technical Documentation Dataset]\n            D3[\ud83e\uddea Edge Case Testing Dataset]\n        end\n\n        subgraph USAGE[\ud83c\udfaf Dataset Usage]\n            U1[Model Training & Fine-tuning]\n            U2[Performance Benchmarking]\n            U3[Regression Testing]\n            U4[Quality Validation]\n        end\n\n        DATASETS --\x3e USAGE\n    end\n\n    classDef expStyle fill:#e8f5e8,stroke:#2e7d32,stroke-width:3px,color:#000\n    classDef dataStyle fill:#f1f8e9,stroke:#388e3c,stroke-width:2px,color:#000\n    classDef usageStyle fill:#fff8e1,stroke:#f57c00,stroke-width:2px,color:#000\n    classDef titleStyle fill:#f5f5f5,stroke:#424242,stroke-width:2px,color:#000\n\n    class EXP expStyle\n    class DATASETS,D1,D2,D3 dataStyle\n    class USAGE,U1,U2,U3,U4 usageStyle\n    class TITLE titleStyle'}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Relationship to Experiment:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Datasets are scoped to specific Experiments"}),"\n",(0,s.jsx)(n.li,{children:"Enable consistent evaluation across model versions"}),"\n",(0,s.jsx)(n.li,{children:"Support systematic testing and validation workflows"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"-evaluation-runs-systematic-testing",children:"\ud83d\ude80 Evaluation Runs: Systematic Testing"}),"\n",(0,s.jsx)(n.p,{children:"Evaluation Runs orchestrate systematic testing of your GenAI application using datasets and scoring functions."}),"\n",(0,s.jsx)(n.mermaid,{value:"graph LR\n    subgraph EXP[\ud83e\uddea Experiment]\n        direction TB\n\n        subgraph EVAL_PROCESS[\ud83d\ude80 Evaluation Run Process]\n            direction LR\n            ER1[\ud83d\udccb Dataset] --\x3e ER2[\ud83e\udd16 Model]\n            ER2 --\x3e ER3[\ud83c\udfaf Scorers]\n            ER3 --\x3e ER4[\ud83d\udcca Results]\n        end\n\n        subgraph OUTPUTS[\ud83d\udcc8 Evaluation Outputs]\n            direction TB\n            O1[\ud83d\udcdd Generated Traces]\n            O2[\ud83d\udcca Performance Metrics]\n            O3[\ud83c\udfaf Quality Scores]\n            O4[\ud83d\udccb Detailed Reports]\n        end\n    end\n\n    EVAL_PROCESS --\x3e OUTPUTS\n\n    classDef expStyle fill:#e8f5e8,stroke:#2e7d32,stroke-width:3px,color:#000\n    classDef processStyle fill:#e3f2fd,stroke:#0277bd,stroke-width:2px,color:#000\n    classDef outputStyle fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,color:#000\n\n    class EXP expStyle\n    class EVAL_PROCESS,ER1,ER2,ER3,ER4 processStyle\n    class OUTPUTS,O1,O2,O3,O4 outputStyle"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Relationship to Experiment:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Evaluation Runs belong to specific Experiments"}),"\n",(0,s.jsx)(n.li,{children:"Generate new Traces that become part of the Experiment"}),"\n",(0,s.jsx)(n.li,{children:"Enable systematic comparison across models and versions"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"-assessments-quality-judgments",children:"\ud83d\udcca Assessments: Quality Judgments"}),"\n",(0,s.jsx)(n.p,{children:"Assessments capture quality evaluations and performance judgments on Traces within your Experiment."}),"\n",(0,s.jsx)(n.mermaid,{value:"graph TB\n    subgraph EXP[\ud83e\uddea Experiment]\n        direction TB\n\n        subgraph ASSESSMENT_FLOW[\ud83d\udcca Assessment Flow]\n            direction LR\n            AF1[\ud83d\udcdd Trace] --\x3e AF2[\ud83c\udfaf Scorer/Human]\n            AF2 --\x3e AF3[\ud83d\udcca Assessment]\n        end\n\n        subgraph ASSESSMENT_TYPES[\ud83d\udccb Assessment Types]\n            direction TB\n            AT1[\ud83d\udc4d Feedback: Quality Ratings]\n            AT2[\u26a1 Feedback: Performance Metrics]\n            AT3[\ud83c\udfaf Expectations: Ground Truth]\n            AT4[\ud83d\udd0d Feedback: Error Analysis]\n        end\n    end\n\n    ASSESSMENT_FLOW --\x3e ASSESSMENT_TYPES\n\n    classDef expStyle fill:#e8f5e8,stroke:#2e7d32,stroke-width:3px,color:#000\n    classDef flowStyle fill:#e3f2fd,stroke:#0277bd,stroke-width:2px,color:#000\n    classDef typeStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000\n\n    class EXP expStyle\n    class ASSESSMENT_FLOW,AF1,AF2,AF3 flowStyle\n    class ASSESSMENT_TYPES,AT1,AT2,AT3,AT4 typeStyle"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Relationship to Experiment:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Assessments are attached to Traces within the Experiment"}),"\n",(0,s.jsx)(n.li,{children:"Enable quality tracking across application versions"}),"\n",(0,s.jsx)(n.li,{children:"Support data-driven improvement decisions"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"\ufe0f-labeling-sessions-human-review",children:"\ud83c\udff7\ufe0f Labeling Sessions: Human Review"}),"\n",(0,s.jsx)(n.p,{children:"Labeling Sessions organize human review workflows for Traces within your Experiment."}),"\n",(0,s.jsx)(n.mermaid,{value:"graph LR\n    subgraph EXP[\ud83e\uddea Experiment]\n        direction TB\n\n        subgraph SESSION[\ud83c\udff7\ufe0f Labeling Session]\n            direction TB\n            S1[\ud83d\udcdd Selected Traces]\n            S2[\ud83d\udc65 Human Reviewers]\n            S3[\ud83d\udccb Review Criteria]\n        end\n\n        subgraph OUTCOMES[\ud83c\udfaf Review Outcomes]\n            direction TB\n            R1[\u2b50 Quality Ratings]\n            R2[\ud83d\udd0d Issue Identification]\n            R3[\ud83d\udca1 Improvement Insights]\n            R4[\u2705 Validation Results]\n        end\n\n        SESSION --\x3e OUTCOMES\n    end\n\n    classDef expStyle fill:#e8f5e8,stroke:#2e7d32,stroke-width:3px,color:#000\n    classDef sessionStyle fill:#e1f5fe,stroke:#0277bd,stroke-width:2px,color:#000\n    classDef outcomeStyle fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,color:#000\n\n    class EXP expStyle\n    class SESSION,S1,S2,S3 sessionStyle\n    class OUTCOMES,R1,R2,R3,R4 outcomeStyle"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Relationship to Experiment:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Labeling Sessions operate on Traces within the Experiment"}),"\n",(0,s.jsx)(n.li,{children:"Generate Assessments that enrich the Experiment data"}),"\n",(0,s.jsx)(n.li,{children:"Enable expert validation of automated evaluations"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"complete-experiment-ecosystem",children:"Complete Experiment Ecosystem"}),"\n",(0,s.jsx)(n.p,{children:"All GenAI entities work together within the Experiment to create a comprehensive development and production environment:"}),"\n",(0,s.jsx)(n.mermaid,{value:'graph TD\n    subgraph EXP[" "]\n        direction TB\n        TITLE[\ud83e\uddea GenAI Application Experiment]\n\n        subgraph DEV[\ud83d\udd28 Development Phase]\n            D1[\ud83e\udd16 Model Development]\n            D2[\ud83d\udcdd Development Traces]\n            D3[\ud83e\uddea Initial Testing]\n        end\n\n        subgraph EVAL[\ud83e\uddea Evaluation Phase]\n            E1[\ud83d\udccb Evaluation Datasets]\n            E2[\ud83d\ude80 Evaluation Runs]\n            E3[\ud83d\udcca Automated Scoring]\n            E4[\ud83c\udff7\ufe0f Human Review]\n        end\n\n        subgraph PROD[\ud83d\ude80 Production Phase]\n            P1[\ud83d\udcdd Production Traces]\n            P2[\ud83d\udcca Live Monitoring]\n            P3[\ud83d\udd04 Continuous Assessment]\n        end\n\n        subgraph INSIGHTS[\ud83d\udca1 Analysis & Insights]\n            I1[\ud83d\udcc8 Performance Trends]\n            I2[\ud83c\udfaf Quality Metrics]\n            I3[\ud83d\udd0d Issue Detection]\n            I4[\ud83d\udccb Improvement Planning]\n        end\n\n        DEV --\x3e EVAL\n        EVAL --\x3e PROD\n        PROD --\x3e INSIGHTS\n        INSIGHTS --\x3e DEV\n    end\n\n    classDef expStyle fill:#e8f5e8,stroke:#2e7d32,stroke-width:3px,color:#000\n    classDef devStyle fill:#e3f2fd,stroke:#0277bd,stroke-width:2px,color:#000\n    classDef evalStyle fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,color:#000\n    classDef prodStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000\n    classDef insightStyle fill:#f1f8e9,stroke:#388e3c,stroke-width:2px,color:#000\n    classDef titleStyle fill:#f5f5f5,stroke:#424242,stroke-width:2px,color:#000\n\n    class EXP expStyle\n    class DEV,D1,D2,D3 devStyle\n    class EVAL,E1,E2,E3,E4 evalStyle\n    class PROD,P1,P2,P3 prodStyle\n    class INSIGHTS,I1,I2,I3,I4 insightStyle\n    class TITLE titleStyle'}),"\n",(0,s.jsx)(n.h2,{id:"benefits-of-experiment-centric-organization",children:"Benefits of Experiment-Centric Organization"}),"\n",(0,s.jsx)(n.h4,{id:"-unified-context",children:"\ud83c\udfaf Unified Context"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"All related entities share common metadata and settings"}),"\n",(0,s.jsx)(n.li,{children:"Cross-entity analysis happens naturally within the Experiment scope"}),"\n",(0,s.jsx)(n.li,{children:"Consistent organization across development and production"}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"-comprehensive-tracking",children:"\ud83d\udcca Comprehensive Tracking"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Complete application lifecycle visibility in one location"}),"\n",(0,s.jsx)(n.li,{children:"Historical continuity from initial development through production"}),"\n",(0,s.jsx)(n.li,{children:"Version comparison and evolution tracking"}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"-streamlined-workflows",children:"\ud83d\udd04 Streamlined Workflows"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Natural integration between development, testing, and production"}),"\n",(0,s.jsx)(n.li,{children:"Automated relationship management between entities"}),"\n",(0,s.jsx)(n.li,{children:"Simplified navigation and discovery of related components"}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"-data-driven-insights",children:"\ud83d\udcc8 Data-Driven Insights"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Holistic view of application performance and quality"}),"\n",(0,s.jsx)(n.li,{children:"Systematic comparison across models, versions, and deployments"}),"\n",(0,s.jsx)(n.li,{children:"Foundation for continuous improvement processes"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"experiment-management-best-practices",children:"Experiment Management Best Practices"}),"\n",(0,s.jsx)(n.h4,{id:"\ufe0f-organizational-structure",children:"\ud83c\udfd7\ufe0f Organizational Structure"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"One Experiment per GenAI application"}),": Maintain clear boundaries between different applications"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Descriptive naming"}),": Use clear, consistent naming conventions for Experiments"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Metadata consistency"}),": Apply consistent tagging and organization patterns"]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"-data-management",children:"\ud83d\udcca Data Management"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Trace organization"}),": Use consistent tagging for effective filtering and analysis"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Dataset curation"}),": Maintain high-quality evaluation datasets within each Experiment"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Assessment strategy"}),": Implement systematic quality measurement approaches"]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"-workflow-integration",children:"\ud83d\udd04 Workflow Integration"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"CI/CD integration"}),": Connect deployment pipelines to Experiment tracking"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Automated evaluation"}),": Set up systematic testing using Evaluation Runs"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Continuous monitoring"}),": Implement ongoing assessment of production performance"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"getting-started-with-experiments",children:"Getting Started with Experiments"}),"\n",(0,s.jsx)(n.p,{children:"Setting up an Experiment for your GenAI application creates the foundation for comprehensive tracking and analysis:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"\ud83e\uddea Create Experiment"}),": Establish the container for your GenAI application"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"\ud83d\udcdd Enable Tracing"}),": Capture execution data from your application runs"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"\ud83d\udccb Add Datasets"}),": Create evaluation collections for systematic testing"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"\ud83d\ude80 Run Evaluations"}),": Implement systematic quality and performance testing"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"\ud83d\udcca Analyze Results"}),": Use the unified view to drive improvements"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The Experiment provides the organizational backbone that makes all other MLflow GenAI capabilities possible, creating a structured approach to developing, testing, and maintaining high-quality GenAI applications."}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/genai/tracing",children:"Trace Management"})}),": Understand how to capture and organize execution data within Experiments"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/genai/eval-monitor",children:"Evaluation Workflows"})}),": Implement systematic testing and quality measurement"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/genai/tracing/observe-with-traces/ui",children:"MLflow UI Navigation"})}),": Master the interface for exploring Experiment data and insights"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"MLflow Experiments provide the essential organizational framework that unifies all aspects of GenAI application development, enabling systematic tracking, evaluation, and improvement of your AI systems."})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>r});var t=i(96540);const s={},a=t.createContext(s);function l(e){const n=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);