"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4021],{23756:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>h,frontMatter:()=>i,metadata:()=>o,toc:()=>p});const o=JSON.parse('{"id":"tracing/integrations/bedrock","title":"Tracing Amazon Bedrock with MLflow","description":"MLflow supports automatic tracing for Amazon Bedrock, a fully managed service on AWS that provides high-performing","source":"@site/docs/tracing/integrations/bedrock.mdx","sourceDirName":"tracing/integrations","slug":"/tracing/integrations/bedrock","permalink":"/docs/latest/tracing/integrations/bedrock","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4.5,"frontMatter":{"sidebar_position":4.5,"sidebar_label":"Bedrock"},"sidebar":"docsSidebar","previous":{"title":"LlamaIndex","permalink":"/docs/latest/tracing/integrations/llama_index"},"next":{"title":"DeepSeek","permalink":"/docs/latest/tracing/integrations/deepseek"}}');var l=t(74848),a=t(28453),r=t(67756);const i={sidebar_position:4.5,sidebar_label:"Bedrock"},s="Tracing Amazon Bedrock with MLflow",c={},p=[{value:"Supported APIs",id:"supported-apis",level:2},{value:"Basic Example",id:"basic-example",level:2},{value:"Raw Inputs and Outputs",id:"raw-inputs-and-outputs",level:2},{value:"Streaming",id:"streaming",level:2},{value:"Function Calling Agent",id:"function-calling-agent",level:2},{value:"Disable auto-tracing",id:"disable-auto-tracing",level:2}];function m(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.header,{children:(0,l.jsx)(n.h1,{id:"tracing-amazon-bedrock-with-mlflow",children:"Tracing Amazon Bedrock with MLflow"})}),"\n",(0,l.jsxs)(n.p,{children:["MLflow supports automatic tracing for Amazon Bedrock, a fully managed service on AWS that provides high-performing\nfoundations from leading AI provides such as Anthropic, Cohere, Meta, Mistral AI, and more. By enabling auto tracing\nfor Amazon Bedrock by calling the ",(0,l.jsx)(r.B,{fn:"mlflow.bedrock.autolog"})," function, MLflow will capture traces for LLM invocation\nand log them to the active MLflow Experiment."]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.img,{alt:"Bedrock DIY Agent Tracing",src:t(82046).A+"",width:"1863",height:"772"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"import mlflow\n\nmlflow.bedrock.autolog()\n"})}),"\n",(0,l.jsx)(n.p,{children:"MLflow trace automatically captures the following information about Amazon Bedrock calls:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Prompts and completion responses"}),"\n",(0,l.jsx)(n.li,{children:"Latencies"}),"\n",(0,l.jsx)(n.li,{children:"Model name"}),"\n",(0,l.jsx)(n.li,{children:"Additional metadata such as temperature, max_tokens, if specified."}),"\n",(0,l.jsx)(n.li,{children:"Function calling if returned in the response"}),"\n",(0,l.jsx)(n.li,{children:"Any exception if raised"}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"supported-apis",children:"Supported APIs"}),"\n",(0,l.jsx)(n.p,{children:"MLflow supports automatic tracing for the following Amazon Bedrock APIs:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime/client/converse.html",children:"converse"})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime/client/converse_stream.html",children:"converse_stream"})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime/client/invoke_model.html",children:"invoke_model"})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime/client/invoke_model_stream.html",children:"invoke_model_with_response_stream"})}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"basic-example",children:"Basic Example"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'import boto3\nimport mlflow\n\n# Enable auto-tracing for Amazon Bedrock\nmlflow.bedrock.autolog()\nmlflow.set_experiment("Bedrock")\n# Create a boto3 client for invoking the Bedrock API\nbedrock = boto3.client(\n    service_name="bedrock-runtime",\n    region_name="<REPLACE_WITH_YOUR_AWS_REGION>",\n)\n# MLflow will log a trace for Bedrock API call in the "Bedrock" experiment created above\nresponse = bedrock.converse(\n    modelId="anthropic.claude-3-5-sonnet-20241022-v2:0",\n    messages=[\n        {\n            "role": "user",\n            "content": "Describe the purpose of a \'hello world\' program in one line.",\n        }\n    ],\n    inferenceConfig={\n        "maxTokens": 512,\n        "temperature": 0.1,\n        "topP": 0.9,\n    },\n)\n'})}),"\n",(0,l.jsxs)(n.p,{children:["The logged trace, associated with the ",(0,l.jsx)(n.code,{children:"Bedrock"})," experiment, can be seen in the MLflow UI."]}),"\n",(0,l.jsx)(n.h2,{id:"raw-inputs-and-outputs",children:"Raw Inputs and Outputs"}),"\n",(0,l.jsxs)(n.p,{children:["By default, MLflow renders the rich chat-like UI for input and output messages in the ",(0,l.jsx)(n.code,{children:"Chat"})," tab. To view the raw input and output payload, including configuration parameters, click on the ",(0,l.jsx)(n.code,{children:"Inputs / Outputs"})," tab in the UI."]}),"\n",(0,l.jsx)(n.admonition,{type:"note",children:(0,l.jsxs)(n.p,{children:["The ",(0,l.jsx)(n.code,{children:"Chat"})," panel is only supported for the ",(0,l.jsx)(n.code,{children:"converse"})," and ",(0,l.jsx)(n.code,{children:"converse_stream"})," APIs. For the other APIs, MLflow only displays the ",(0,l.jsx)(n.code,{children:"Inputs / Outputs"})," tab."]})}),"\n",(0,l.jsx)(n.h2,{id:"streaming",children:"Streaming"}),"\n",(0,l.jsxs)(n.p,{children:["MLflow supports tracing streaming calls to Amazon Bedrock APIs. The generated trace shows the aggregated output message in the ",(0,l.jsx)(n.code,{children:"Chat"})," tab, while the individual chunks are displayed in the ",(0,l.jsx)(n.code,{children:"Events"})," tab."]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'response = bedrock.converse_stream(\n    modelId="anthropic.claude-3-5-sonnet-20241022-v2:0",\n    messages=[\n        {\n            "role": "user",\n            "content": [\n                {"text": "Describe the purpose of a \'hello world\' program in one line."}\n            ],\n        }\n    ],\n    inferenceConfig={\n        "maxTokens": 300,\n        "temperature": 0.1,\n        "topP": 0.9,\n    },\n)\n\nfor chunk in response["stream"]:\n    print(chunk)\n'})}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.img,{alt:"Bedrock Stream Tracing",src:t(89237).A+"",width:"1454",height:"669"})}),"\n",(0,l.jsx)(n.admonition,{type:"warning",children:(0,l.jsxs)(n.p,{children:["MLflow does not create a span immediately when the streaming response is returned. Instead, it creates a span when the streaming chunks are ",(0,l.jsx)(n.strong,{children:"consumed"}),", for example, the for-loop in the code snippet above."]})}),"\n",(0,l.jsx)(n.h2,{id:"function-calling-agent",children:"Function Calling Agent"}),"\n",(0,l.jsxs)(n.p,{children:["MLflow Tracing automatically captures function calling metadata when calling Amazon Bedrock APIs. The function definition and instruction in the response will be highlighted in the ",(0,l.jsx)(n.code,{children:"Chat"})," tab on trace UI."]}),"\n",(0,l.jsxs)(n.p,{children:["Combining this with the manual tracing feature, you can define a function-calling agent (ReAct) and trace its execution. The entire agent implementation might look complicated, but the tracing part is pretty straightforward: (1) add the ",(0,l.jsx)(n.code,{children:"@mlflow.trace"})," decorator to functions to trace and (2) enable auto-tracing for Amazon Bedrock with ",(0,l.jsx)(n.code,{children:"mlflow.bedrock.autolog()"}),". MLflow will take care of the complexity such as resolving call chains and recording execution metadata."]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'import boto3\nimport mlflow\nfrom mlflow.entities import SpanType\n\n# Enable auto-tracing for Amazon Bedrock\nmlflow.bedrock.autolog()\nmlflow.set_experiment("Bedrock")\n# Create a boto3 client for invoking the Bedrock API\nbedrock = boto3.client(\n    service_name="bedrock-runtime",\n    region_name="<REPLACE_WITH_YOUR_AWS_REGION>",\n)\nmodel_id = "anthropic.claude-3-5-sonnet-20241022-v2:0"\n\n\n# Define the tool function. Decorate it with `@mlflow.trace` to create a span for its execution.\n@mlflow.trace(span_type=SpanType.TOOL)\ndef get_weather(city: str) -> str:\n    """ "Get the current weather in a given location"""\n    return "sunny" if city == "San Francisco, CA" else "unknown"\n\n\n# Define the tool configuration passed to Bedrock\ntools = [\n    {\n        "toolSpec": {\n            "name": "get_weather",\n            "description": "Get the current weather in a given location",\n            "inputSchema": {\n                "json": {\n                    "type": "object",\n                    "properties": {\n                        "city": {\n                            "type": "string",\n                            "description": "The city and state, e.g., San Francisco, CA",\n                        },\n                    },\n                    "required": ["city"],\n                }\n            },\n        }\n    }\n]\ntool_functions = {"get_weather": get_weather}\n\n\n# Define a simple tool calling agent\n@mlflow.trace(span_type=SpanType.AGENT)\ndef run_tool_agent(question: str) -> str:\n    messages = [{"role": "user", "content": [{"text": question}]}]\n    # Invoke the model with the given question and available tools\n    response = bedrock.converse(\n        modelId=model_id,\n        messages=messages,\n        toolConfig={"tools": tools},\n    )\n    assistant_message = response["output"]["message"]\n    messages.append(assistant_message)\n    # If the model requests tool call(s), invoke the function with the specified arguments\n    tool_use = next(\n        (c["toolUse"] for c in assistant_message["content"] if "toolUse" in c), None\n    )\n    if tool_use:\n        tool_func = tool_functions[tool_use["name"]]\n        tool_result = tool_func(**tool_use["input"])\n        messages.append(\n            {\n                "role": "user",\n                "content": [\n                    {\n                        "toolResult": {\n                            "toolUseId": tool_use["toolUseId"],\n                            "content": [{"text": tool_result}],\n                        }\n                    }\n                ],\n            }\n        )\n        # Send the tool results to the model and get a new response\n        response = bedrock.converse(\n            modelId=model_id,\n            messages=messages,\n            toolConfig={"tools": tools},\n        )\n    return response["output"]["message"]["content"][0]["text"]\n\n\n# Run the tool calling agent\nquestion = "What\'s the weather like in San Francisco today?"\nanswer = run_tool_agent(question)\n'})}),"\n",(0,l.jsx)(n.p,{children:"Executing the code above will create a single trace that involves all LLM invocations and the tool calls."}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.img,{alt:"Bedrock DIY Agent Tracing",src:t(82046).A+"",width:"1863",height:"772"})}),"\n",(0,l.jsx)(n.h2,{id:"disable-auto-tracing",children:"Disable auto-tracing"}),"\n",(0,l.jsxs)(n.p,{children:["Auto tracing for Amazon Bedrock can be disabled globally by calling ",(0,l.jsx)(n.code,{children:"mlflow.bedrock.autolog(disable=True)"})," or ",(0,l.jsx)(n.code,{children:"mlflow.autolog(disable=True)"}),"."]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(m,{...e})}):m(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>i});var o=t(96540);const l={},a=o.createContext(l);function r(e){const n=o.useContext(a);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:r(e.components),o.createElement(a.Provider,{value:n},e.children)}},67756:(e,n,t)=>{t.d(n,{B:()=>s});t(96540);const o=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var l=t(29030),a=t(56289),r=t(74848);const i=e=>{const n=e.split(".");for(let t=n.length;t>0;t--){const e=n.slice(0,t).join(".");if(o[e])return e}return null};function s(e){let{fn:n,children:t}=e;const s=i(n);if(!s)return(0,r.jsx)(r.Fragment,{children:t});const c=(0,l.Ay)(`/${o[s]}#${n}`);return(0,r.jsx)(a.A,{to:c,target:"_blank",children:t??(0,r.jsxs)("code",{children:[n,"()"]})})}},82046:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/bedrock-tracing-agent-cae1bcf40457074afa5bfde0b05b292e.png"},89237:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/bedrock-tracing-stream-d7219a525c3716936e81512180dc0d69.png"}}]);