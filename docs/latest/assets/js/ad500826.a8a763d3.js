"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4891],{28453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>l});var o=n(96540);const r={},a=o.createContext(r);function i(e){const t=o.useContext(a);return o.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),o.createElement(a.Provider,{value:t},e.children)}},67756:(e,t,n)=>{n.d(t,{B:()=>s});n(96540);const o=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var r=n(29030),a=n(56289),i=n(74848);const l=e=>{const t=e.split(".");for(let n=t.length;n>0;n--){const e=t.slice(0,n).join(".");if(o[e])return e}return null};function s(e){let{fn:t,children:n}=e;const s=l(t);if(!s)return(0,i.jsx)(i.Fragment,{children:n});const c=(0,r.Ay)(`/${o[s]}#${t}`);return(0,i.jsx)(a.A,{to:c,target:"_blank",children:n??(0,i.jsxs)("code",{children:[t,"()"]})})}},90078:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>c,default:()=>f,frontMatter:()=>s,metadata:()=>o,toc:()=>h});const o=JSON.parse('{"id":"tracking/artifacts-stores/index","title":"Artifact Stores","description":"The artifact store is a core component in MLflow Tracking where MLflow stores (typically large) artifacts","source":"@site/docs/tracking/artifacts-stores/index.mdx","sourceDirName":"tracking/artifacts-stores","slug":"/tracking/artifacts-stores/","permalink":"/docs/latest/tracking/artifacts-stores/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"sidebar_label":"Artifact Store"},"sidebar":"docsSidebar","previous":{"title":"Tracking Server","permalink":"/docs/latest/tracking/server/"},"next":{"title":"Backend Store","permalink":"/docs/latest/tracking/backend-stores/"}}');var r=n(74848),a=n(28453),i=n(56289),l=n(67756);const s={sidebar_label:"Artifact Store"},c="Artifact Stores",d={},h=[{value:"Configuring an Artifact Store",id:"configuring-an-artifact-store",level:2},{value:"Managing Artifact Store Access",id:"artifacts-stores-manage-access",level:3},{value:"Setting an access Timeout",id:"setting-an-access-timeout",level:3},{value:"Setting a Default Artifact Location for Logging",id:"setting-a-default-artifact-location-for-logging",level:3},{value:"Supported storage types for the Artifact Store",id:"artifacts-store-supported-storages",level:2},{value:"Amazon S3 and S3-compatible storage",id:"amazon-s3-and-s3-compatible-storage",level:3},{value:"Passing Extra Arguments to S3 Upload",id:"passing-extra-arguments-to-s3-upload",level:4},{value:"Setting Custom S3 Endpoint",id:"setting-custom-s3-endpoint",level:4},{value:"Using Non-TLS Authentication",id:"using-non-tls-authentication",level:4},{value:"Setting Bucket Region",id:"setting-bucket-region",level:4},{value:"Azure Blob Storage",id:"azure-blob-storage",level:2},{value:"Google Cloud Storage",id:"google-cloud-storage",level:2},{value:"FTP server",id:"ftp-server",level:3},{value:"SFTP Server",id:"sftp-server",level:3},{value:"NFS",id:"nfs",level:3},{value:"HDFS",id:"hdfs",level:3},{value:"Deletion Behavior",id:"deletion-behavior",level:2},{value:"Multipart upload for proxied artifact access",id:"multipart-upload-for-proxied-artifact-access",level:2}];function p(e){const t={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"artifact-stores",children:"Artifact Stores"})}),"\n",(0,r.jsxs)(t.p,{children:["The artifact store is a core component in ",(0,r.jsx)(t.a,{href:"/tracking",children:"MLflow Tracking"})," where MLflow stores (typically large) artifacts\nfor each run such as model weights (e.g. a pickled scikit-learn model), images (e.g. ONGs), model and data files (e.g. ",(0,r.jsx)(t.a,{href:"https://parquet.apache.org/",children:"Parquet"})," file).\nNote that metadata like parameters, metrics, and tags are stored in a ",(0,r.jsx)(t.a,{href:"/tracking/backend-stores",children:"backend store"})," (e.g., PostGres, MySQL, or MSSQL Database), the other component of the MLflow Tracking."]}),"\n",(0,r.jsx)(t.h2,{id:"configuring-an-artifact-store",children:"Configuring an Artifact Store"}),"\n",(0,r.jsxs)(t.p,{children:["MLflow by default stores artifacts in local ",(0,r.jsx)(t.code,{children:"./mlruns"})," directory, but also supports various locations suitable for large data:\nAmazon S3, Azure Blob Storage, Google Cloud Storage, SFTP server, and NFS. You can connect those remote storages via the MLflow Tracking server.\nSee ",(0,r.jsx)(t.a,{href:"/tracking/server#tracking-server-artifact-store",children:"tracking server setup"})," and the specific section for your storage in ",(0,r.jsx)(t.a,{href:"/tracking/artifacts-stores#artifacts-store-supported-storages",children:"supported storages"})," for guidance on\nhow to connect to your remote storage of choice."]}),"\n",(0,r.jsx)(t.h3,{id:"artifacts-stores-manage-access",children:"Managing Artifact Store Access"}),"\n",(0,r.jsxs)(t.p,{children:["To allow the server and clients to access the artifact location, you should configure your cloud\nprovider credentials as you would for accessing them in any other capacity. For example, for S3, you can set the ",(0,r.jsx)(t.code,{children:"AWS_ACCESS_KEY_ID"}),"\nand ",(0,r.jsx)(t.code,{children:"AWS_SECRET_ACCESS_KEY"})," environment variables, use an IAM role, or configure a default\nprofile in ",(0,r.jsx)(t.code,{children:"~/.aws/credentials"}),"."]}),"\n",(0,r.jsx)(t.admonition,{title:"important",type:"warning",children:(0,r.jsxs)(t.p,{children:["Access credentials and configuration for the artifact storage location are configured ",(0,r.jsx)(t.strong,{children:"once during server initialization"})," in the place\nof having users handle access credentials for artifact-based operations. Note that ",(0,r.jsx)(t.strong,{children:"all users who have access to the\nTracking Server in this mode will have access to artifacts served through this assumed role"}),"."]})}),"\n",(0,r.jsx)(t.h3,{id:"setting-an-access-timeout",children:"Setting an access Timeout"}),"\n",(0,r.jsxs)(t.p,{children:["You can set an environment variable ",(0,r.jsx)(t.code,{children:"MLFLOW_ARTIFACT_UPLOAD_DOWNLOAD_TIMEOUT"})," (in seconds) to configure the timeout for artifact uploads and downloads.\nIf it's not set, MLflow will use the default timeout for the underlying storage client library (e.g. boto3 for S3).\nNote that this is experimental feature, may be changed or removed."]}),"\n",(0,r.jsx)(t.h3,{id:"setting-a-default-artifact-location-for-logging",children:"Setting a Default Artifact Location for Logging"}),"\n",(0,r.jsxs)(t.p,{children:["MLflow automatically records the ",(0,r.jsx)(t.code,{children:"artifact_uri"})," property as a part of ",(0,r.jsx)(l.B,{fn:"mlflow.entities.RunInfo",children:(0,r.jsx)(t.code,{children:"mlflow.entities.RunInfo"})}),", so you can\nretrieve the location of the artifacts for historical runs using the ",(0,r.jsx)(l.B,{fn:"mlflow.get_artifact_uri"})," API.\nAlso, ",(0,r.jsx)(t.code,{children:"artifact_location"})," is a property recorded on ",(0,r.jsx)(l.B,{fn:"mlflow.entities.Experiment",children:(0,r.jsx)(t.code,{children:"mlflow.entities.Experiment"})})," for setting the\ndefault location to store artifacts for all runs in a given experiment."]}),"\n",(0,r.jsx)(t.admonition,{title:"important",type:"warning",children:(0,r.jsxs)(t.p,{children:["If you do not specify a ",(0,r.jsx)(t.code,{children:"--default-artifact-root"})," or an artifact URI when creating the experiment\n(for example, ",(0,r.jsx)(t.code,{children:"mlflow experiments create --artifact-location s3://<my-bucket>"}),"), the artifact root\nwill be set as a path inside the local file store (the hard drive of the computer executing your run). Typically this is not an appropriate location, as the client and\nserver probably refer to different physical locations (that is, the same path on different disks)."]})}),"\n",(0,r.jsx)(t.h2,{id:"artifacts-store-supported-storages",children:"Supported storage types for the Artifact Store"}),"\n",(0,r.jsx)(t.h3,{id:"amazon-s3-and-s3-compatible-storage",children:"Amazon S3 and S3-compatible storage"}),"\n",(0,r.jsxs)(t.p,{children:["To store artifacts in S3 (whether on Amazon S3 or on an S3-compatible alternative, such as\n",(0,r.jsx)(t.a,{href:"https://min.io/",children:"MinIO"})," or ",(0,r.jsx)(t.a,{href:"https://www.digitalocean.com/products/spaces",children:"Digital Ocean Spaces"}),", specify a URI of the form ",(0,r.jsx)(t.code,{children:"s3://<bucket>/<path>"}),". MLflow obtains\ncredentials to access S3 from your machine's IAM role, a profile in ",(0,r.jsx)(t.code,{children:"~/.aws/credentials"}),", or\nthe environment variables ",(0,r.jsx)(t.code,{children:"AWS_ACCESS_KEY_ID"})," and ",(0,r.jsx)(t.code,{children:"AWS_SECRET_ACCESS_KEY"})," depending on which of\nthese are available. For more information on how to set credentials, see\n",(0,r.jsx)(t.a,{href:"https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/setup-credentials.html",children:"Set up AWS Credentials and Region for Development"}),"."]}),"\n",(0,r.jsxs)(t.p,{children:["Followings are commonly used environment variables for configuring S3 storage access. The complete list of configurable parameters for an S3 client is available in the\n",(0,r.jsx)(t.a,{href:"https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html#configuration",children:"boto3 documentation"}),"."]}),"\n",(0,r.jsx)(t.h4,{id:"passing-extra-arguments-to-s3-upload",children:"Passing Extra Arguments to S3 Upload"}),"\n",(0,r.jsxs)(t.p,{children:["To add S3 file upload extra arguments, set ",(0,r.jsx)(t.code,{children:"MLFLOW_S3_UPLOAD_EXTRA_ARGS"})," to a JSON object of key/value pairs.\nFor example, if you want to upload to a KMS Encrypted bucket using the KMS Key 1234:"]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:'export MLFLOW_S3_UPLOAD_EXTRA_ARGS=\'{"ServerSideEncryption": "aws:kms", "SSEKMSKeyId": "1234"}\'\n'})}),"\n",(0,r.jsxs)(t.p,{children:["For a list of available extra args see ",(0,r.jsx)(t.a,{href:"https://github.com/boto/boto3/blob/develop/docs/source/guide/s3-uploading-files.rst#the-extraargs-parameter",children:"Boto3 ExtraArgs Documentation"}),"."]}),"\n",(0,r.jsx)(t.h4,{id:"setting-custom-s3-endpoint",children:"Setting Custom S3 Endpoint"}),"\n",(0,r.jsxs)(t.p,{children:["To store artifacts in a custom endpoint, set the ",(0,r.jsx)(t.code,{children:"MLFLOW_S3_ENDPOINT_URL"})," to your endpoint's URL. For example, if you are using Digital Ocean Spaces:"]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"export MLFLOW_S3_ENDPOINT_URL=https://<region>.digitaloceanspaces.com\n"})}),"\n",(0,r.jsx)(t.p,{children:"If you have a MinIO server at 1.2.3.4 on port 9000:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"export MLFLOW_S3_ENDPOINT_URL=http://1.2.3.4:9000\n"})}),"\n",(0,r.jsx)(t.h4,{id:"using-non-tls-authentication",children:"Using Non-TLS Authentication"}),"\n",(0,r.jsxs)(t.p,{children:["If the MinIO server is configured with using SSL self-signed or signed using some internal-only CA certificate, you could set ",(0,r.jsx)(t.code,{children:"MLFLOW_S3_IGNORE_TLS"})," or ",(0,r.jsx)(t.code,{children:"AWS_CA_BUNDLE"})," variables (not both at the same time!) to disable certificate signature check, or add a custom CA bundle to perform this check, respectively:"]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"export MLFLOW_S3_IGNORE_TLS=true\n#or\nexport AWS_CA_BUNDLE=/some/ca/bundle.pem\n"})}),"\n",(0,r.jsx)(t.h4,{id:"setting-bucket-region",children:"Setting Bucket Region"}),"\n",(0,r.jsxs)(t.p,{children:["Additionally, if MinIO server is configured with non-default region, you should set ",(0,r.jsx)(t.code,{children:"AWS_DEFAULT_REGION"})," variable:"]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"export AWS_DEFAULT_REGION=my_region\n"})}),"\n",(0,r.jsx)(t.admonition,{type:"warning",children:(0,r.jsxs)(t.p,{children:["The MLflow tracking server utilizes specific reserved keywords to generate a qualified path. These environment configurations, if present in the client environment, can create path resolution issues.\nFor example, providing ",(0,r.jsx)(t.code,{children:"--default-artifact-root $MLFLOW_S3_ENDPOINT_URL"})," on the server side ",(0,r.jsx)(t.strong,{children:"and"})," ",(0,r.jsx)(t.code,{children:"MLFLOW_S3_ENDPOINT_URL"})," on the client side will create a client path resolution issue for the artifact storage location.\nUpon resolving the artifact storage location, the MLflow client will use the value provided by ",(0,r.jsx)(t.code,{children:"--default-artifact-root"})," and suffixes the location with the values provided in the environment variable ",(0,r.jsx)(t.code,{children:"MLFLOW_S3_ENDPOINT_URL"}),".\nDepending on the value set for the environment variable ",(0,r.jsx)(t.code,{children:"MLFLOW_S3_ENDPOINT_URL"}),", the resulting artifact storage path for this scenario would be one of the following invalid object store paths: ",(0,r.jsx)(t.code,{children:"https://<bucketname>.s3.<region>.amazonaws.com/<key>/<bucketname>/<key>"})," or ",(0,r.jsx)(t.code,{children:"s3://<bucketname>/<key>/<bucketname>/<key>"}),".\nTo prevent path parsing issues, ",(0,r.jsxs)(t.strong,{children:["ensure that reserved environment variables are removed (",(0,r.jsx)(t.code,{children:"unset"}),") from client environments"]}),"."]})}),"\n",(0,r.jsx)(t.h2,{id:"azure-blob-storage",children:"Azure Blob Storage"}),"\n",(0,r.jsxs)(t.p,{children:["To store artifacts in Azure Blob Storage, specify a URI of the form\n",(0,r.jsx)(t.code,{children:"wasbs://<container>@<storage-account>.blob.core.windows.net/<path>"}),".\nMLflow expects that your Azure Storage access credentials are located in the\n",(0,r.jsx)(t.code,{children:"AZURE_STORAGE_CONNECTION_STRING"})," and ",(0,r.jsx)(t.code,{children:"AZURE_STORAGE_ACCESS_KEY"})," environment variables\nor having your credentials configured such that the ",(0,r.jsx)(t.a,{href:"https://docs.microsoft.com/en-us/python/api/overview/azure/identity-readme?view=azure-python",children:"DefaultAzureCredential()"})," class can pick them up.\nThe order of precedence is:"]}),"\n",(0,r.jsxs)(t.ol,{children:["\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.code,{children:"AZURE_STORAGE_CONNECTION_STRING"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.code,{children:"AZURE_STORAGE_ACCESS_KEY"})}),"\n",(0,r.jsx)(t.li,{children:(0,r.jsx)(t.code,{children:"DefaultAzureCredential()"})}),"\n"]}),"\n",(0,r.jsxs)(t.p,{children:["You must set one of these options on ",(0,r.jsx)(t.strong,{children:"both your client application and your MLflow tracking server"}),".\nAlso, you must run ",(0,r.jsx)(t.code,{children:"pip install azure-storage-blob"})," separately (on both your client and the server) to access Azure Blob Storage.\nFinally, if you want to use DefaultAzureCredential, you must ",(0,r.jsx)(t.code,{children:"pip install azure-identity"}),";\nMLflow does not declare a dependency on these packages by default."]}),"\n",(0,r.jsx)(t.p,{children:"You may set an MLflow environment variable to configure the timeout for artifact uploads and downloads:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.code,{children:"MLFLOW_ARTIFACT_UPLOAD_DOWNLOAD_TIMEOUT"})," - (Experimental, may be changed or removed) Sets the timeout for artifact upload/download in seconds (Default: 600 for Azure blob)."]}),"\n"]}),"\n",(0,r.jsx)(t.h2,{id:"google-cloud-storage",children:"Google Cloud Storage"}),"\n",(0,r.jsxs)(t.p,{children:["To store artifacts in Google Cloud Storage, specify a URI of the form ",(0,r.jsx)(t.code,{children:"gs://<bucket>/<path>"}),".\nYou should configure credentials for accessing the GCS container on the client and server as described\nin the ",(0,r.jsx)(t.a,{href:"https://google-cloud.readthedocs.io/en/latest/core/auth.html",children:"GCS documentation"}),".\nFinally, you must run ",(0,r.jsx)(t.code,{children:"pip install google-cloud-storage"})," (on both your client and the server)\nto access Google Cloud Storage; MLflow does not declare a dependency on this package by default."]}),"\n",(0,r.jsx)(t.p,{children:"You may set some MLflow environment variables to troubleshoot GCS read-timeouts (eg. due to slow transfer speeds) using the following variables:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.code,{children:"MLFLOW_ARTIFACT_UPLOAD_DOWNLOAD_TIMEOUT"})," - (Experimental, may be changed or removed) Sets the standard timeout for transfer operations in seconds (Default: 60 for GCS). Use -1 for indefinite timeout."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.code,{children:"MLFLOW_GCS_UPLOAD_CHUNK_SIZE"})," - Sets the standard upload chunk size for bigger files in bytes (Default: 104857600 \u2259 100MiB), must be multiple of 256 KB."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.code,{children:"MLFLOW_GCS_DOWNLOAD_CHUNK_SIZE"})," - Sets the standard download chunk size for bigger files in bytes (Default: 104857600 \u2259 100MiB), must be multiple of 256 KB"]}),"\n"]}),"\n",(0,r.jsx)(t.h3,{id:"ftp-server",children:"FTP server"}),"\n",(0,r.jsxs)(t.p,{children:["To store artifacts in a FTP server, specify a URI of the form ftp://user@host/path/to/directory .\nThe URI may optionally include a password for logging into the server, e.g. ",(0,r.jsx)(t.code,{children:"ftp://user:pass@host/path/to/directory"})]}),"\n",(0,r.jsx)(t.h3,{id:"sftp-server",children:"SFTP Server"}),"\n",(0,r.jsxs)(t.p,{children:["To store artifacts in an SFTP server, specify a URI of the form ",(0,r.jsx)(t.code,{children:"sftp://user@host/path/to/directory"}),".\nYou should configure the client to be able to log in to the SFTP server without a password over SSH (e.g. public key, identity file in ssh_config, etc.)."]}),"\n",(0,r.jsxs)(t.p,{children:["The format ",(0,r.jsx)(t.code,{children:"sftp://user:pass@host/"})," is supported for logging in. However, for safety reasons this is not recommended."]}),"\n",(0,r.jsxs)(t.p,{children:["When using this store, ",(0,r.jsx)(t.code,{children:"pysftp"})," must be installed on both the server and the client. Run ",(0,r.jsx)(t.code,{children:"pip install pysftp"})," to install the required package."]}),"\n",(0,r.jsx)(t.h3,{id:"nfs",children:"NFS"}),"\n",(0,r.jsxs)(t.p,{children:["To store artifacts in an NFS mount, specify a URI as a normal file system path, e.g., ",(0,r.jsx)(t.code,{children:"/mnt/nfs"}),".\nThis path must be the same on both the server and the client -- you may need to use symlinks or remount\nthe client in order to enforce this property."]}),"\n",(0,r.jsx)(t.h3,{id:"hdfs",children:"HDFS"}),"\n",(0,r.jsxs)(t.p,{children:["To store artifacts in HDFS, specify a ",(0,r.jsx)(t.code,{children:"hdfs:"})," URI. It can contain host and port: ",(0,r.jsx)(t.code,{children:"hdfs://<host>:<port>/<path>"})," or just the path: ",(0,r.jsx)(t.code,{children:"hdfs://<path>"}),"."]}),"\n",(0,r.jsx)(t.p,{children:"There are also two ways to authenticate to HDFS:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"Use current UNIX account authorization"}),"\n",(0,r.jsx)(t.li,{children:"Kerberos credentials using the following environment variables:"}),"\n"]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"export MLFLOW_KERBEROS_TICKET_CACHE=/tmp/krb5cc_22222222\nexport MLFLOW_KERBEROS_USER=user_name_to_use\n"})}),"\n",(0,r.jsxs)(t.p,{children:["The HDFS artifact store is accessed using the ",(0,r.jsx)(t.code,{children:"pyarrow.fs"})," module, refer to the\n",(0,r.jsx)(t.a,{href:"https://arrow.apache.org/docs/python/filesystems.html#filesystem-hdfs",children:"PyArrow Documentation"})," for configuration and environment variables needed."]}),"\n",(0,r.jsx)(t.h2,{id:"deletion-behavior",children:"Deletion Behavior"}),"\n",(0,r.jsxs)(t.p,{children:["In order to allow MLflow Runs to be restored, Run metadata and artifacts are not automatically removed\nfrom the backend store or artifact store when a Run is deleted. The ",(0,r.jsx)(i.A,{to:"/api_reference/cli.html",target:"_blank",children:"mlflow gc"})," CLI is provided\nfor permanently removing Run metadata and artifacts for deleted runs."]}),"\n",(0,r.jsx)(t.h2,{id:"multipart-upload-for-proxied-artifact-access",children:"Multipart upload for proxied artifact access"}),"\n",(0,r.jsx)(t.admonition,{type:"note",children:(0,r.jsx)(t.p,{children:"This feature is experimental and may be changed or removed in a future release without notice."})}),"\n",(0,r.jsxs)(t.p,{children:["Tracking Server supports uploading large artifacts using multipart upload for proxied artifact access.\nTo enable this feature, set ",(0,r.jsx)(t.code,{children:"MLFLOW_ENABLE_PROXY_MULTIPART_UPLOAD"})," to ",(0,r.jsx)(t.code,{children:"true"}),"."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"export MLFLOW_ENABLE_PROXY_MULTIPART_UPLOAD=true\n"})}),"\n",(0,r.jsx)(t.p,{children:"Under the hood, the Tracking Server will create a multipart upload request with the underlying storage,\ngenerate presigned urls for each part, and let the client upload the parts directly to the storage.\nOnce all parts are uploaded, the Tracking Server will complete the multipart upload.\nNone of the data will pass through the Tracking Server."}),"\n",(0,r.jsx)(t.p,{children:"If the underlying storage does not support multipart upload, the Tracking Server will fallback to a single part upload.\nIf multipart upload is supported but fails for any reason, an exception will be thrown."}),"\n",(0,r.jsx)(t.p,{children:"MLflow supports multipart upload for the following storage for proxied artifact access:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"Amazon S3"}),"\n",(0,r.jsx)(t.li,{children:"Google Cloud Storage"}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:"You can configure the following environment variables:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.code,{children:"MLFLOW_MULTIPART_UPLOAD_MINIMUM_FILE_SIZE"})," - Specifies the minimum file size in bytes to use multipart upload\nwhen logging artifacts (Default: 500 MB)"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.code,{children:"MLFLOW_MULTIPART_UPLOAD_CHUNK_SIZE"})," - Specifies the chunk size in bytes to use when performing multipart upload\n(Default: 100 MB)"]}),"\n"]})]})}function f(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(p,{...e})}):p(e)}}}]);