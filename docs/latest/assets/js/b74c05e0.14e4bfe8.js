"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7199],{2371:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/compare-prompt-versions-2082121aeaca4be99a0cf968535141ed.png"},11470:(e,t,n)=>{n.d(t,{A:()=>_});var r=n(96540),o=n(34164),a=n(23104),i=n(56347),l=n(205),s=n(57485),p=n(31682),m=n(70679);function c(e){return r.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function h(e){const{values:t,children:n}=e;return(0,r.useMemo)((()=>{const e=t??function(e){return c(e).map((({props:{value:e,label:t,attributes:n,default:r}})=>({value:e,label:t,attributes:n,default:r})))}(n);return function(e){const t=(0,p.XI)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,n])}function d({value:e,tabValues:t}){return t.some((t=>t.value===e))}function g({queryString:e=!1,groupId:t}){const n=(0,i.W6)(),o=function({queryString:e=!1,groupId:t}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:e,groupId:t});return[(0,s.aZ)(o),(0,r.useCallback)((e=>{if(!o)return;const t=new URLSearchParams(n.location.search);t.set(o,e),n.replace({...n.location,search:t.toString()})}),[o,n])]}function f(e){const{defaultValue:t,queryString:n=!1,groupId:o}=e,a=h(e),[i,s]=(0,r.useState)((()=>function({defaultValue:e,tabValues:t}){if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!d({value:e,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const n=t.find((e=>e.default))??t[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:t,tabValues:a}))),[p,c]=g({queryString:n,groupId:o}),[f,u]=function({groupId:e}){const t=function(e){return e?`docusaurus.tab.${e}`:null}(e),[n,o]=(0,m.Dv)(t);return[n,(0,r.useCallback)((e=>{t&&o.set(e)}),[t,o])]}({groupId:o}),w=(()=>{const e=p??f;return d({value:e,tabValues:a})?e:null})();(0,l.A)((()=>{w&&s(w)}),[w]);return{selectedValue:i,selectValue:(0,r.useCallback)((e=>{if(!d({value:e,tabValues:a}))throw new Error(`Can't select invalid tab value=${e}`);s(e),c(e),u(e)}),[c,u,a]),tabValues:a}}var u=n(92303);const w={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var x=n(74848);function y({className:e,block:t,selectedValue:n,selectValue:r,tabValues:i}){const l=[],{blockElementScrollPositionUntilNextRender:s}=(0,a.a_)(),p=e=>{const t=e.currentTarget,o=l.indexOf(t),a=i[o].value;a!==n&&(s(t),r(a))},m=e=>{let t=null;switch(e.key){case"Enter":p(e);break;case"ArrowRight":{const n=l.indexOf(e.currentTarget)+1;t=l[n]??l[0];break}case"ArrowLeft":{const n=l.indexOf(e.currentTarget)-1;t=l[n]??l[l.length-1];break}}t?.focus()};return(0,x.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.A)("tabs",{"tabs--block":t},e),children:i.map((({value:e,label:t,attributes:r})=>(0,x.jsx)("li",{role:"tab",tabIndex:n===e?0:-1,"aria-selected":n===e,ref:e=>{l.push(e)},onKeyDown:m,onClick:p,...r,className:(0,o.A)("tabs__item",w.tabItem,r?.className,{"tabs__item--active":n===e}),children:t??e},e)))})}function j({lazy:e,children:t,selectedValue:n}){const a=(Array.isArray(t)?t:[t]).filter(Boolean);if(e){const e=a.find((e=>e.props.value===n));return e?(0,r.cloneElement)(e,{className:(0,o.A)("margin-top--md",e.props.className)}):null}return(0,x.jsx)("div",{className:"margin-top--md",children:a.map(((e,t)=>(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==n})))})}function v(e){const t=f(e);return(0,x.jsxs)("div",{className:(0,o.A)("tabs-container",w.tabList),children:[(0,x.jsx)(y,{...t,...e}),(0,x.jsx)(j,{...t,...e})]})}function _(e){const t=(0,u.A)();return(0,x.jsx)(v,{...e,children:c(e.children)},String(t))}},19365:(e,t,n)=>{n.d(t,{A:()=>i});n(96540);var r=n(34164);const o={tabItem:"tabItem_Ymn6"};var a=n(74848);function i({children:e,hidden:t,className:n}){return(0,a.jsx)("div",{role:"tabpanel",className:(0,r.A)(o.tabItem,n),hidden:t,children:e})}},25800:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/prompt-logged-trace-f531e466499e24d2b8541d655237ea91.png"},28453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>l});var r=n(96540);const o={},a=r.createContext(o);function i(e){const t=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),r.createElement(a.Provider,{value:t},e.children)}},45576:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/prompt-logged-model-links-b4c073f2c15e203ec34d7ef35c840112.png"},48853:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>m,default:()=>g,frontMatter:()=>p,metadata:()=>r,toc:()=>h});const r=JSON.parse('{"id":"prompt-version-mgmt/prompt-registry/index","title":"Prompt Registry","description":"MLflow Prompt Registry","source":"@site/docs/genai/prompt-version-mgmt/prompt-registry/index.mdx","sourceDirName":"prompt-version-mgmt/prompt-registry","slug":"/prompt-version-mgmt/prompt-registry/","permalink":"/docs/latest/genai/prompt-version-mgmt/prompt-registry/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Prompt Registry","description":"MLflow Prompt Registry"},"sidebar":"genAISidebar","previous":{"title":"Building with ResponsesAgent","permalink":"/docs/latest/genai/flavors/responses-agent-intro"},"next":{"title":"Create and Edit Prompts","permalink":"/docs/latest/genai/prompt-version-mgmt/prompt-registry/create-and-edit-prompts"}}');var o=n(74848),a=n(28453),i=n(49374),l=n(11470),s=n(19365);const p={title:"Prompt Registry",description:"MLflow Prompt Registry"},m="Prompt Registry in Databricks",c={},h=[{value:"What is MLflow Prompt Registry?",id:"what-is-mlflow-prompt-registry",level:2},{value:"Integration with Unity Catalog",id:"integration-with-unity-catalog",level:2},{value:"Future Capabilities",id:"future-capabilities",level:2},{value:"Stay Updated",id:"stay-updated",level:2},{value:"Prompt Registry in OSS MLflow",id:"prompt-registry-in-oss-mlflow",level:2},{value:"1. Create a Prompt",id:"1-create-a-prompt",level:3},{value:"2. Update the Prompt with a New Version",id:"2-update-the-prompt-with-a-new-version",level:3},{value:"3. Compare the Prompt Versions",id:"3-compare-the-prompt-versions",level:3},{value:"4. Load and Use the Prompt",id:"4-load-and-use-the-prompt",level:3},{value:"5. Search Prompts",id:"5-search-prompts",level:3},{value:"Prompt Object",id:"prompt-object",level:2},{value:"Log Prompts with Models",id:"log-prompts-with-models",level:2},{value:"Basic Usage",id:"basic-usage",level:3},{value:"Example 1: Logging Prompts with LangChain",id:"example-1-logging-prompts-with-langchain",level:3},{value:"1. Create a prompt",id:"1-create-a-prompt-1",level:4},{value:"2. Define a Chain using the registered prompts",id:"2-define-a-chain-using-the-registered-prompts",level:4},{value:"3. Log the Chain to MLflow",id:"3-log-the-chain-to-mlflow",level:4},{value:"Example 2: Automatic Prompt Logging with Models-from-Code",id:"example-2-automatic-prompt-logging-with-models-from-code",level:3},{value:"1. Create a prompt",id:"1-create-a-prompt-2",level:4},{value:"2. Define a Graph using the registered prompt",id:"2-define-a-graph-using-the-registered-prompt",level:4},{value:"3. Log the Graph to MLflow",id:"3-log-the-graph-to-mlflow",level:4},{value:"4. Load the graph back and invoke",id:"4-load-the-graph-back-and-invoke",level:4},{value:"FAQ",id:"faq",level:2},{value:"Q: How do I delete a prompt version?",id:"q-how-do-i-delete-a-prompt-version",level:4},{value:"Q: Can I update the prompt template of an existing prompt version?",id:"q-can-i-update-the-prompt-template-of-an-existing-prompt-version",level:4},{value:"Q: Can I use prompt templates with frameworks like LangChain or LlamaIndex?",id:"q-can-i-use-prompt-templates-with-frameworks-like-langchain-or-llamaindex",level:4},{value:"Q: Is Prompt Registry integrated with the Prompt Engineering UI?",id:"q-is-prompt-registry-integrated-with-the-prompt-engineering-ui",level:4},{value:"What&#39;s Next",id:"whats-next",level:2}];function d(e){const t={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.header,{children:(0,o.jsx)(t.h1,{id:"prompt-registry-in-databricks",children:"Prompt Registry in Databricks"})}),"\n",(0,o.jsx)(t.h2,{id:"what-is-mlflow-prompt-registry",children:"What is MLflow Prompt Registry?"}),"\n",(0,o.jsxs)(t.p,{children:[(0,o.jsx)(t.strong,{children:"MLflow Prompt Registry"})," is a powerful tool that streamlines prompt engineering and management in your Generative AI (GenAI) applications. It enables you to version, track, and reuse prompts across your organization, helping maintain consistency and improving collaboration in prompt development."]}),"\n",(0,o.jsx)(t.admonition,{title:"Key Features",type:"tip",children:(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Reusability"})," - Store and manage prompts in a centralized registry and reuse them across multiple applications."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Version Control"})," - Track the evolution of your prompts with Git-inspired commit-based versioning and side-by-side comparison of prompt versions with diff highlighting."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Aliasing"})," - Build robust yet flexible deployment pipelines for prompts using aliases, allowing you to isolate prompt versions from main application code and perform tasks such as A/B testing and roll-backs with ease."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Lineage"})," - Seamlessly integrate with MLflow's existing features such as model tracking and evaluation for end-to-end GenAI lifecycle management."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Collaboration"})," - Share prompts across your organization with a centralized registry, enabling teams to build upon each other's work."]}),"\n"]})}),"\n",(0,o.jsx)(t.admonition,{type:"note",children:(0,o.jsx)(t.p,{children:"The MLflow Prompt Registry integration with Databricks Unity Catalog is coming soon."})}),"\n",(0,o.jsx)(t.p,{children:"It will be a centralized system for managing, versioning, and governing prompt templates used in your GenAI applications. It will be deeply integrated with Databricks Unity Catalog, providing:"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Centralized Prompt Management"}),": Store and organize prompt templates in a governed, searchable registry"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Version Control"}),": Track changes to prompts over time with full lineage and rollback capabilities"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Access Control"}),": Leverage Unity Catalog's permissions system to control who can view, edit, and use specific prompts"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Collaboration"}),": Enable teams to share and collaborate on prompt development"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Governance"}),": Apply data governance policies to prompt templates, including classification and compliance requirements"]}),"\n"]}),"\n",(0,o.jsx)(t.h2,{id:"integration-with-unity-catalog",children:"Integration with Unity Catalog"}),"\n",(0,o.jsx)(t.p,{children:"The Prompt Registry will leverage Unity Catalog's governance framework to provide:"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Fine-grained Access Control"}),": Control access to prompts at the individual, team, or organization level"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Data Lineage"}),": Track how prompts are used across different applications and experiments"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Audit Trails"}),": Monitor who accessed or modified prompts and when"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Classification and Tagging"}),": Organize prompts with metadata and apply governance policies"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Cross-workspace Sharing"}),": Share prompts securely across different Databricks workspaces"]}),"\n"]}),"\n",(0,o.jsx)(t.h2,{id:"future-capabilities",children:"Future Capabilities"}),"\n",(0,o.jsx)(t.p,{children:"When available, the Prompt Registry will support:"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Template Management"}),": Create, edit, and version prompt templates with variable substitution"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Testing and Validation"}),": Test prompts against evaluation datasets before deployment"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"A/B Testing"}),": Compare different prompt versions to optimize performance"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Integration with MLflow Tracking"}),": Automatically link prompt versions to experiments and model runs"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"API Access"}),": Programmatic access to prompts for use in automated workflows"]}),"\n"]}),"\n",(0,o.jsx)(t.h2,{id:"stay-updated",children:"Stay Updated"}),"\n",(0,o.jsx)(t.p,{children:"For the latest updates on Prompt Registry availability and features, monitor the MLflow documentation and Databricks release notes."}),"\n",(0,o.jsx)(t.h2,{id:"prompt-registry-in-oss-mlflow",children:"Prompt Registry in OSS MLflow"}),"\n",(0,o.jsx)(t.h3,{id:"1-create-a-prompt",children:"1. Create a Prompt"}),"\n",(0,o.jsxs)(l.A,{children:[(0,o.jsx)(s.A,{value:"ui",label:"UI",default:!0,children:(0,o.jsxs)("div",{class:"flex-column",children:[(0,o.jsx)("div",{style:{width:"70%",margin:"20px"},children:(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"Create Prompt UI",src:n(76599).A+"",width:"1239",height:"660"})})}),(0,o.jsxs)(t.ol,{children:["\n",(0,o.jsxs)(t.li,{children:["Run ",(0,o.jsx)(t.code,{children:"mlflow ui"})," in your terminal to start the MLflow UI."]}),"\n",(0,o.jsxs)(t.li,{children:["Navigate to the ",(0,o.jsx)(t.strong,{children:"Prompts"})," tab in the MLflow UI."]}),"\n",(0,o.jsxs)(t.li,{children:["Click on the ",(0,o.jsx)(t.strong,{children:"Create Prompt"})," button."]}),"\n",(0,o.jsx)(t.li,{children:"Fill in the prompt details such as name, prompt template text, and commit message (optional)."}),"\n",(0,o.jsxs)(t.li,{children:["Click ",(0,o.jsx)(t.strong,{children:"Create"})," to register the prompt."]}),"\n"]}),(0,o.jsx)(t.admonition,{type:"note",children:(0,o.jsxs)(t.p,{children:["Prompt template text can contain variables in ",(0,o.jsx)(t.code,{children:"{{variable}}"})," format. These variables can be filled with dynamic content when using the prompt in your GenAI application. MLflow also provides the ",(0,o.jsx)(t.code,{children:"to_single_brace_format()"})," API to convert templates into single brace format for frameworks like LangChain or LlamaIndex that require single brace interpolation."]})})]})}),(0,o.jsx)(s.A,{value:"python",label:"Python",default:!0,children:(0,o.jsxs)("div",{class:"flex-column",children:[(0,o.jsxs)(t.p,{children:["To create a new prompt using the Python API, use ",(0,o.jsx)(i.B,{fn:"mlflow.genai.register_prompt"})," API:"]}),(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'import mlflow\n\n# Use double curly braces for variables in the template\ninitial_template = """\\\nSummarize content you are provided with in {{ num_sentences }} sentences.\n\nSentences: {{ sentences }}\n"""\n\n# Register a new prompt\nprompt = mlflow.genai.register_prompt(\n    name="summarization-prompt",\n    template=initial_template,\n    # Optional: Provide a commit message to describe the changes\n    commit_message="Initial commit",\n    # Optional: Specify any additional metadata about the prompt version\n    version_metadata={\n        "author": "author@example.com",\n    },\n    # Optional: Set tags applies to the prompt (across versions)\n    tags={\n        "task": "summarization",\n        "language": "en",\n    },\n)\n\n# The prompt object contains information about the registered prompt\nprint(f"Created prompt \'{prompt.name}\' (version {prompt.version})")\n'})})]})})]}),"\n",(0,o.jsx)(t.p,{children:"This creates a new prompt with the specified template text and metadata. The prompt is now available in the MLflow UI for further management."}),"\n",(0,o.jsx)("div",{style:{width:"90%",margin:"10px"},children:(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"Registered Prompt in UI",src:n(72406).A+"",width:"1287",height:"616"})})}),"\n",(0,o.jsx)(t.h3,{id:"2-update-the-prompt-with-a-new-version",children:"2. Update the Prompt with a New Version"}),"\n",(0,o.jsxs)(l.A,{children:[(0,o.jsx)(s.A,{value:"ui",label:"UI",default:!0,children:(0,o.jsxs)("div",{class:"flex-column",children:[(0,o.jsx)("div",{style:{width:"70%",margin:"20px"},children:(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"Update Prompt UI",src:n(53296).A+"",width:"1150",height:"594"})})}),(0,o.jsxs)(t.ol,{children:["\n",(0,o.jsxs)(t.li,{children:["The previous step leads to the created prompt page. (If you closed the page, navigate to the ",(0,o.jsx)(t.strong,{children:"Prompts"})," tab in the MLflow UI and click on the prompt name.)"]}),"\n",(0,o.jsxs)(t.li,{children:["Click on the ",(0,o.jsx)(t.strong,{children:"Create prompt Version"})," button."]}),"\n",(0,o.jsx)(t.li,{children:"The popup dialog is pre-filled with the existing prompt text. Modify the prompt as you wish."}),"\n",(0,o.jsxs)(t.li,{children:["Click ",(0,o.jsx)(t.strong,{children:"Create"})," to register the new version."]}),"\n"]})]})}),(0,o.jsx)(s.A,{value:"python",label:"Python",default:!0,children:(0,o.jsxs)("div",{class:"flex-column",children:[(0,o.jsxs)(t.p,{children:["To update an existing prompt with a new version, use the ",(0,o.jsx)(i.B,{fn:"mlflow.genai.register_prompt"})," API with the existing prompt name:"]}),(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'import mlflow\n\nnew_template = """\\\nYou are an expert summarizer. Condense the following content into exactly {{ num_sentences }} clear and informative sentences that capture the key points.\n\nSentences: {{ sentences }}\n\nYour summary should:\n- Contain exactly {{ num_sentences }} sentences\n- Include only the most important information\n- Be written in a neutral, objective tone\n- Maintain the same level of formality as the original text\n"""\n\n# Register a new version of an existing prompt\nupdated_prompt = mlflow.genai.register_prompt(\n    name="summarization-prompt",  # Specify the existing prompt name\n    template=new_template,\n    commit_message="Improvement",\n    version_metadata={\n        "author": "author@example.com",\n    },\n)\n'})})]})})]}),"\n",(0,o.jsx)(t.h3,{id:"3-compare-the-prompt-versions",children:"3. Compare the Prompt Versions"}),"\n",(0,o.jsxs)(t.p,{children:["Once you have multiple versions of a prompt, you can compare them to understand the changes between versions. To compare prompt versions in the MLflow UI, click on the ",(0,o.jsx)(t.strong,{children:"Compare"})," tab in the prompt details page:"]}),"\n",(0,o.jsx)("div",{style:{width:"90%",margin:"10px"},children:(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"Compare Prompt\nVersions",src:n(2371).A+"",width:"1267",height:"713"})})}),"\n",(0,o.jsx)(t.h3,{id:"4-load-and-use-the-prompt",children:"4. Load and Use the Prompt"}),"\n",(0,o.jsxs)(t.p,{children:["To use a prompt in your GenAI application, you can load it with the ",(0,o.jsx)(i.B,{fn:"mlflow.genai.load_prompt"})," API and fill in the variables using the ",(0,o.jsx)(i.B,{fn:"mlflow.entities.Prompt.format"})," method of the prompt object:"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'import mlflow\nimport openai\n\ntarget_text = """\nMLflow is an open source platform for managing the end-to-end machine learning lifecycle.\nIt tackles four primary functions in the ML lifecycle: Tracking experiments, packaging ML\ncode for reuse, managing and deploying models, and providing a central model registry.\nMLflow currently offers these functions as four components: MLflow Tracking,\nMLflow Projects, MLflow Models, and MLflow Registry.\n"""\n\n# Load the prompt\nprompt = mlflow.genai.load_prompt("prompts:/summarization-prompt/2")\n\n# Use the prompt with an LLM\nclient = openai.OpenAI()\nresponse = client.chat.completions.create(\n    messages=[\n        {\n            "role": "user",\n            "content": prompt.format(num_sentences=1, sentences=target_text),\n        }\n    ],\n    model="gpt-4o-mini",\n)\n\nprint(response.choices[0].message.content)\n'})}),"\n",(0,o.jsx)(t.h3,{id:"5-search-prompts",children:"5. Search Prompts"}),"\n",(0,o.jsx)(t.p,{children:"You can discover prompts by name, tag or other registry fields:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'import mlflow\n\n# Fluent API: returns a flat list of all matching prompts\nprompts = mlflow.genai.search_prompts(filter_string="task=\'summarization\'")\nprint(f"Found {len(prompts)} prompts")\n\n# For pagination control, use the client API:\nfrom mlflow.tracking import MlflowClient\n\nclient = MlflowClient()\nall_prompts = []\ntoken = None\nwhile True:\n    page = client.search_prompts(\n        filter_string="task=\'summarization\'",\n        max_results=50,\n        page_token=token,\n    )\n    all_prompts.extend(page)\n    token = page.token\n    if not token:\n        break\nprint(f"Total prompts across pages: {len(all_prompts)}")\n'})}),"\n",(0,o.jsx)(t.h2,{id:"prompt-object",children:"Prompt Object"}),"\n",(0,o.jsxs)(t.p,{children:["The ",(0,o.jsx)(t.code,{children:"Prompt"})," object is the core entity in MLflow Prompt Registry. It represents a versioned template text that can contain variables for dynamic content."]}),"\n",(0,o.jsx)(t.p,{children:"Key attributes of a Prompt object:"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"Name"}),": A unique identifier for the prompt."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"Template"}),": The text of the prompt, which can include variables in ",(0,o.jsx)(t.code,{children:"{{variable}}"})," format."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"Version"}),": A sequential number representing the revision of the prompt."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"Commit Message"}),": A description of the changes made in the prompt version, similar to Git commit messages."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"Version Metadata"}),": Optional key-value pairs for adding metadata to the prompt version. For example, you may use this for tracking the author of the prompt version."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"Tags"}),": Optional key-value pairs assigned at the prompt level (across versions)\nfor categorization and filtering. For example, you may add tags for project name, language, etc, which apply to all versions of the prompt."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.code,{children:"Alias"}),": An mutable named reference to the prompt. For example, you can create an alias named ",(0,o.jsx)(t.code,{children:"production"})," to refer to the version used in your production system. See ",(0,o.jsx)(t.a,{href:"/genai/data-model/prompts#alias-management",children:"Aliases"})," for more details."]}),"\n"]}),"\n",(0,o.jsx)(t.h2,{id:"log-prompts-with-models",children:"Log Prompts with Models"}),"\n",(0,o.jsx)(t.p,{children:"Prompts are often used as a part of GenAI applications. Managing the association between prompts and models is crucial for tracking the evolution of models and ensuring consistency across different environments. MLflow Prompt Registry is integrated with MLflow's model tracking capability, allowing you to track which prompts (and versions) are used by your models and applications."}),"\n",(0,o.jsx)(t.h3,{id:"basic-usage",children:"Basic Usage"}),"\n",(0,o.jsxs)(t.p,{children:["To log a model with associated prompts, use the ",(0,o.jsx)(t.code,{children:"prompts"})," parameter in the ",(0,o.jsx)(t.code,{children:"log_model"})," method. The ",(0,o.jsx)(t.code,{children:"prompts"})," parameter accepts a list of prompt URLs or prompt objects that are associated with the model. The associated prompts are displayed in the MLflow UI for the model run."]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{children:'import mlflow\n\nwith mlflow.start_run():\n    mlflow.<flavor>.log_model(\n        model,\n        ...\n        # Specify a list of prompt URLs or prompt objects.\n        prompts=["prompts:/summarization-prompt/2"]\n    )\n'})}),"\n",(0,o.jsx)(t.admonition,{type:"warning",children:(0,o.jsxs)(t.p,{children:["The ",(0,o.jsx)(t.code,{children:"prompts"})," parameter for associating prompts with models is only supported for GenAI flavors such as OpenAI, LangChain, LlamaIndex, DSPy, etc."]})}),"\n",(0,o.jsx)(t.h3,{id:"example-1-logging-prompts-with-langchain",children:"Example 1: Logging Prompts with LangChain"}),"\n",(0,o.jsx)(t.h4,{id:"1-create-a-prompt-1",children:"1. Create a prompt"}),"\n",(0,o.jsxs)(t.p,{children:["If you haven't already created a prompt, follow ",(0,o.jsx)(t.a,{href:"#1-create-a-prompt",children:"this step"})," to create a new prompt."]}),"\n",(0,o.jsx)(t.h4,{id:"2-define-a-chain-using-the-registered-prompts",children:"2. Define a Chain using the registered prompts"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'from langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\n\n# Load registered prompt\nprompt = mlflow.genai.load_prompt("prompts:/summarization-prompt/2")\n\n# Create LangChain prompt object\nlangchain_prompt = ChatPromptTemplate.from_messages(\n    [\n        (\n            # IMPORTANT: Convert prompt template from double to single curly braces format\n            "system",\n            prompt.to_single_brace_format(),\n        ),\n        ("placeholder", "{messages}"),\n    ]\n)\n\n# Define the LangChain chain\nllm = ChatOpenAI()\nchain = langchain_prompt | llm\n\n# Invoke the chain\nresponse = chain.invoke({"num_sentences": 1, "sentences": "This is a test sentence."})\nprint(response)\n'})}),"\n",(0,o.jsx)(t.h4,{id:"3-log-the-chain-to-mlflow",children:"3. Log the Chain to MLflow"}),"\n",(0,o.jsxs)(t.p,{children:["Then log the chain to MLflow and specify the prompt URL in the ",(0,o.jsx)(t.code,{children:"prompts"})," parameter:"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'with mlflow.start_run(run_name="summarizer-model"):\n    mlflow.langchain.log_model(\n        chain, name="model", prompts=["prompts:/summarization-prompt/2"]\n    )\n'})}),"\n",(0,o.jsx)(t.p,{children:"Now you can view the associated prompts to the model in MLflow UI:"}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"Associated Prompts",src:n(54548).A+"",width:"888",height:"382"})}),"\n",(0,o.jsx)(t.p,{children:"Moreover, you can view the list of models (runs) that use a specific prompt in the prompt details page:"}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"Associated Prompts",src:n(45576).A+"",width:"3364",height:"1244"})}),"\n",(0,o.jsx)(t.h3,{id:"example-2-automatic-prompt-logging-with-models-from-code",children:"Example 2: Automatic Prompt Logging with Models-from-Code"}),"\n",(0,o.jsxs)(t.p,{children:[(0,o.jsx)(t.a,{href:"/ml/model/models-from-code",children:"Models-from-Code"})," is a feature that allows you to define and log models in code.\nLogging a model with code brings several benefits, such as portability, readability, avoiding serialization, and more."]}),"\n",(0,o.jsxs)(t.p,{children:["Combining with MLflow Prompt Registry, the feature unlocks even more flexibility to manage prompt versions. Notably,\nif your model code uses a prompt from MLflow Prompt Registry, MLflow ",(0,o.jsx)(t.strong,{children:"automatically"})," logs it with the model for you."]}),"\n",(0,o.jsx)(t.p,{children:"In the following example, we use LangGraph to define a very simple chat bot using the registered prompt."}),"\n",(0,o.jsx)(t.h4,{id:"1-create-a-prompt-2",children:"1. Create a prompt"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{children:'import mlflow\n\n# Register a new prompt\nprompt = mlflow.genai.register_prompt(\n    name="chat-prompt",\n    template="You are an expert in programming. Please answer the user\'s question about programming.",\n)\n'})}),"\n",(0,o.jsx)(t.h4,{id:"2-define-a-graph-using-the-registered-prompt",children:"2. Define a Graph using the registered prompt"}),"\n",(0,o.jsxs)(t.p,{children:["Create a Python script ",(0,o.jsx)(t.code,{children:"chatbot.py"})," with the following content."]}),"\n",(0,o.jsx)(t.admonition,{type:"tip",children:(0,o.jsxs)(t.p,{children:["If you are using Jupyter notebook, you can uncomment the ",(0,o.jsx)(t.code,{children:"%writefile"})," magic\ncommand and run the following code in a cell to generate the script."]})}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'# %%writefile chatbot.py\n\nimport mlflow\nfrom typing import Annotated\nfrom typing_extensions import TypedDict\n\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.graph.message import add_messages\n\n\nclass State(TypedDict):\n    messages: list\n\n\nllm = ChatOpenAI(model="gpt-4o-mini", temperature=0.1)\nsystem_prompt = mlflow.genai.load_prompt("prompts:/chat-prompt/1")\n\n\ndef add_system_message(state: State):\n    return {\n        "messages": [\n            {\n                "role": "system",\n                "content": system_prompt.to_single_brace_format(),\n            },\n            *state["messages"],\n        ]\n    }\n\n\ndef chatbot(state: State):\n    return {"messages": [llm.invoke(state["messages"])]}\n\n\ngraph_builder = StateGraph(State)\ngraph_builder.add_node("add_system_message", add_system_message)\ngraph_builder.add_node("chatbot", chatbot)\ngraph_builder.add_edge(START, "add_system_message")\ngraph_builder.add_edge("add_system_message", "chatbot")\ngraph_builder.add_edge("chatbot", END)\n\ngraph = graph_builder.compile()\n\nmlflow.models.set_model(graph)\n'})}),"\n",(0,o.jsx)(t.h4,{id:"3-log-the-graph-to-mlflow",children:"3. Log the Graph to MLflow"}),"\n",(0,o.jsxs)(t.p,{children:["Specify the file path to the script in the ",(0,o.jsx)(t.code,{children:"model"})," parameter:"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'with mlflow.start_run():\n    model_info = mlflow.langchain.log_model(\n        lc_model="./chatbot.py",\n        name="graph",\n    )\n'})}),"\n",(0,o.jsxs)(t.p,{children:["We didn't specify the ",(0,o.jsx)(t.code,{children:"prompts"})," parameter this time, but MLflow automatically logs the prompt loaded within the script to the logged model. Now you can view the associated prompt in MLflow UI:"]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"Associated Prompts",src:n(54255).A+"",width:"878",height:"413"})}),"\n",(0,o.jsx)(t.h4,{id:"4-load-the-graph-back-and-invoke",children:"4. Load the graph back and invoke"}),"\n",(0,o.jsx)(t.p,{children:"Finally, let's load the graph back and invoke it to see the chatbot in action."}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'# Enable MLflow tracing for LangChain to view the prompt passed to LLM.\nmlflow.langchain.autolog()\n\n# Load the graph\ngraph = mlflow.langchain.load_model(model_info.model_uri)\n\ngraph.invoke(\n    {\n        "messages": [\n            {\n                "role": "user",\n                "content": "What is the difference between multi-threading and multi-processing?",\n            }\n        ]\n    }\n)\n'})}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"Chatbot",src:n(25800).A+"",width:"1751",height:"797"})}),"\n",(0,o.jsx)(t.h2,{id:"faq",children:"FAQ"}),"\n",(0,o.jsx)(t.h4,{id:"q-how-do-i-delete-a-prompt-version",children:"Q: How do I delete a prompt version?"}),"\n",(0,o.jsx)(t.p,{children:"A: You can delete a prompt version using the MLflow UI or Python API:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'import mlflow\n\n# Delete a prompt version\nmlflow.delete_prompt("summarization-prompt", version=2)\n'})}),"\n",(0,o.jsx)(t.p,{children:"To avoid accidental deletion, you can only delete one version at a time via API. If you delete the all versions of a prompt, the prompt itself will be deleted."}),"\n",(0,o.jsx)(t.h4,{id:"q-can-i-update-the-prompt-template-of-an-existing-prompt-version",children:"Q: Can I update the prompt template of an existing prompt version?"}),"\n",(0,o.jsx)(t.p,{children:"A: No, prompt versions are immutable once created. To update a prompt, create a new version with the desired changes."}),"\n",(0,o.jsx)(t.h4,{id:"q-can-i-use-prompt-templates-with-frameworks-like-langchain-or-llamaindex",children:"Q: Can I use prompt templates with frameworks like LangChain or LlamaIndex?"}),"\n",(0,o.jsxs)(t.p,{children:["A: Yes, you can load prompts from MLflow and use them with any framework. For example, the following example demonstrates how to use a prompt registered in MLflow with LangChain. Also refer to ",(0,o.jsx)(t.a,{href:"#example-1-logging-prompts-with-langchain",children:"Logging Prompts with LangChain"})," for more details."]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:"import mlflow\nfrom langchain.prompts import PromptTemplate\n\n# Load prompt from MLflow\nprompt = mlflow.genai.load_prompt(\"question_answering\")\n\n# Convert the prompt to single brace format for LangChain (MLflow uses double braces),\n# using the `to_single_brace_format` method.\nlangchain_prompt = PromptTemplate.from_template(prompt.to_single_brace_format())\nprint(langchain_prompt.input_variables)\n# Output: ['num_sentences', 'sentences']\n"})}),"\n",(0,o.jsx)(t.h4,{id:"q-is-prompt-registry-integrated-with-the-prompt-engineering-ui",children:"Q: Is Prompt Registry integrated with the Prompt Engineering UI?"}),"\n",(0,o.jsx)(t.p,{children:"A. Direct integration between the Prompt Registry and the Prompt Engineering UI is coming soon. In the meantime, you can iterate on prompt template in the Prompt Engineering UI and register the final version in the Prompt Registry by manually copying the prompt template."}),"\n",(0,o.jsx)(t.h2,{id:"whats-next",children:"What's Next"}),"\n",(0,o.jsx)(t.p,{children:"Manage prompts using other MLflow capabilities:"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:"Store prompt templates as parameters in MLflow experiments"}),"\n",(0,o.jsx)(t.li,{children:"Version prompts alongside your application code in Git"}),"\n",(0,o.jsx)(t.li,{children:"Use MLflow's version tracking features to link specific prompt versions to application versions"}),"\n",(0,o.jsx)(t.li,{children:"Leverage MLflow's tagging system to organize and categorize prompts"}),"\n"]}),"\n",(0,o.jsxs)(t.p,{children:["See the ",(0,o.jsx)(t.a,{href:"/genai/prompt-version-mgmt/version-tracking",children:"Version Tracking"})," section for current best practices on some of these other approaches."]})]})}function g(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},49374:(e,t,n)=>{n.d(t,{B:()=>s});n(96540);const r=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var o=n(86025),a=n(28774),i=n(74848);const l=e=>{const t=e.split(".");for(let n=t.length;n>0;n--){const e=t.slice(0,n).join(".");if(r[e])return e}return null};function s({fn:e,children:t}){const n=l(e);if(!n)return(0,i.jsx)(i.Fragment,{children:t});const s=(0,o.Ay)(`/${r[n]}#${e}`);return(0,i.jsx)(a.A,{to:s,target:"_blank",children:t??(0,i.jsxs)("code",{children:[e,"()"]})})}},53296:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/update-prompt-ui-74a489e65098893bbffe253f43fb210d.png"},54255:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/prompt-logged-graph-0b4cd4a6c6e28f2afeffea5a9bcee188.png"},54548:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/prompt-logged-model-5db16e3e39f3bbd4ca3138c96dff045e.png"},72406:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/registered-prompt-b8d47ff0d061d8703b61a9a6e94a77c3.png"},76599:(e,t,n)=>{n.d(t,{A:()=>r});const r=n.p+"assets/images/create-prompt-ui-03c88144e65d28eb7847b2ae5d8dd49a.png"}}]);