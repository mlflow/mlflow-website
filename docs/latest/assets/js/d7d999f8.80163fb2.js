"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4681],{16734:(e,t,n)=>{n.d(t,{d:()=>i});var o=n(58069);const s="codeBlock_oJcR";var l=n(74848);const i=e=>{let{children:t,executionCount:n}=e;return(0,l.jsx)("div",{style:{flexGrow:1,minWidth:0,marginTop:"var(--padding-md)",width:"100%"},children:(0,l.jsx)(o.A,{className:s,language:"python",children:t})})}},20723:(e,t,n)=>{n.d(t,{O:()=>l});var o=n(96540),s=n(74848);function l(e){let{children:t,href:n}=e;const l=(0,o.useCallback)((async e=>{if(e.preventDefault(),window.gtag)try{window.gtag("event","notebook-download",{href:n})}catch{}const t=await fetch(n),o=await t.blob(),s=window.URL.createObjectURL(o),l=document.createElement("a");l.style.display="none",l.href=s;const i=n.split("/").pop();l.download=i,document.body.appendChild(l),l.click(),window.URL.revokeObjectURL(s),document.body.removeChild(l)}),[n]);return(0,s.jsx)("a",{className:"button button--primary",style:{marginBottom:"1rem",display:"block",width:"min-content"},href:n,download:!0,onClick:l,children:t})}},61536:(e,t,n)=>{n.d(t,{p:()=>s});var o=n(74848);const s=e=>{let{children:t,isStderr:n}=e;return(0,o.jsx)("pre",{style:{margin:0,borderRadius:0,background:"none",fontSize:"0.85rem",flexGrow:1,padding:"var(--padding-sm)"},children:t})}},86563:(e,t,n)=>{n.d(t,{Q:()=>s});var o=n(74848);const s=e=>{let{children:t}=e;return(0,o.jsx)("div",{style:{flexGrow:1,minWidth:0,fontSize:"0.8rem",width:"100%"},children:t})}},88160:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>h,contentTitle:()=>d,default:()=>f,frontMatter:()=>c,metadata:()=>o,toc:()=>u});const o=JSON.parse('{"id":"deep-learning/tensorflow/quickstart/quickstart_tensorflow-ipynb","title":"Get Started with MLflow + Tensorflow","description":"Download this notebook","source":"@site/docs/deep-learning/tensorflow/quickstart/quickstart_tensorflow-ipynb.mdx","sourceDirName":"deep-learning/tensorflow/quickstart","slug":"/deep-learning/tensorflow/quickstart/quickstart_tensorflow","permalink":"/docs/latest/deep-learning/tensorflow/quickstart/quickstart_tensorflow","draft":false,"unlisted":false,"editUrl":"https://github.com/mlflow/mlflow/edit/master/docs/docs/deep-learning/tensorflow/quickstart/quickstart_tensorflow.ipynb","tags":[],"version":"current","frontMatter":{"custom_edit_url":"https://github.com/mlflow/mlflow/edit/master/docs/docs/deep-learning/tensorflow/quickstart/quickstart_tensorflow.ipynb","slug":"quickstart_tensorflow"},"sidebar":"docsSidebar","previous":{"title":"Tensorflow within MLflow","permalink":"/docs/latest/deep-learning/tensorflow/guide/"},"next":{"title":"Overview","permalink":"/docs/latest/traditional-ml/"}}');var s=n(74848),l=n(28453),i=n(16734),r=n(61536),a=(n(86563),n(20723));const c={custom_edit_url:"https://github.com/mlflow/mlflow/edit/master/docs/docs/deep-learning/tensorflow/quickstart/quickstart_tensorflow.ipynb",slug:"quickstart_tensorflow"},d="Get Started with MLflow + Tensorflow",h={},u=[{value:"Install dependencies",id:"install-dependencies",level:2},{value:"Load the dataset",id:"load-the-dataset",level:2},{value:"Define the Model",id:"define-the-model",level:2},{value:"Set up tracking/visualization tool",id:"set-up-trackingvisualization-tool",level:2},{value:"Logging with MLflow",id:"logging-with-mlflow",level:2},{value:"MLflow Auto Logging",id:"mlflow-auto-logging",level:3},{value:"Log with MLflow Callback",id:"log-with-mlflow-callback",level:3},{value:"Customize the MLflow Callback",id:"customize-the-mlflow-callback",level:3},{value:"Wrap up",id:"wrap-up",level:2}];function p(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"get-started-with-mlflow--tensorflow",children:"Get Started with MLflow + Tensorflow"})}),"\n",(0,s.jsx)(a.O,{href:"https://raw.githubusercontent.com/mlflow/mlflow/master/docs/docs/deep-learning/tensorflow/quickstart/quickstart_tensorflow.ipynb",children:"Download this notebook"}),"\n",(0,s.jsx)(t.p,{children:"In this guide, we will show how to train your model with Tensorflow and log your training using MLflow."}),"\n",(0,s.jsxs)(t.p,{children:["We will use the ",(0,s.jsx)(t.a,{href:"https://mlflow.org/docs/latest/getting-started/databricks-trial.html",children:"Databricks Free Trial"}),", which has built-in support for MLflow. The Databricks Free Trial provides an opportunity to use Databricks platform for free, if you haven't, please register an account via ",(0,s.jsx)(t.a,{href:"http://signup.databricks.com",children:"link"}),"."]}),"\n",(0,s.jsx)(t.p,{children:"You can run code in this guide from cloud-based notebooks like Databricks notebook or Google Colab, or run it on your local machine."}),"\n",(0,s.jsx)(t.h2,{id:"install-dependencies",children:"Install dependencies"}),"\n",(0,s.jsxs)(t.p,{children:["Let's install the ",(0,s.jsx)(t.code,{children:"mlflow"})," package."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{children:"%pip install -q mlflow\n"})}),"\n",(0,s.jsx)(t.p,{children:"Then let's import the packages."}),"\n",(0,s.jsx)(i.d,{executionCount:2,children:"import tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom tensorflow import keras"}),"\n",(0,s.jsx)(t.h2,{id:"load-the-dataset",children:"Load the dataset"}),"\n",(0,s.jsxs)(t.p,{children:["We will do a simple image classification on handwritten digits with ",(0,s.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/MNIST_database",children:"mnist dataset"}),"."]}),"\n",(0,s.jsxs)(t.p,{children:["Let's load the dataset using ",(0,s.jsx)(t.code,{children:"tensorflow_datasets"})," (",(0,s.jsx)(t.code,{children:"tfds"}),"), which returns datasets in the format of ",(0,s.jsx)(t.code,{children:"tf.data.Dataset"}),"."]}),"\n",(0,s.jsx)(i.d,{executionCount:3,children:'# Load the mnist dataset.\ntrain_ds, test_ds = tfds.load(\n  "mnist",\n  split=["train", "test"],\n  shuffle_files=True,\n)'}),"\n",(0,s.jsx)(r.p,{children:"Downloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1..."}),"\n",(0,s.jsx)(r.p,{children:"Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"}),"\n",(0,s.jsx)(r.p,{children:"Dataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data."}),"\n",(0,s.jsx)(t.p,{children:"Let's preprocess our data with the following steps:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["Scale each pixel's value to ",(0,s.jsx)(t.code,{children:"[0, 1)"}),"."]}),"\n",(0,s.jsx)(t.li,{children:"Batch the dataset."}),"\n",(0,s.jsxs)(t.li,{children:["Use ",(0,s.jsx)(t.code,{children:"prefetch"})," to speed up the training."]}),"\n"]}),"\n",(0,s.jsx)(i.d,{executionCount:4,children:'def preprocess_fn(data):\n  image = tf.cast(data["image"], tf.float32) / 255\n  label = data["label"]\n  return (image, label)\n\n\ntrain_ds = train_ds.map(preprocess_fn).batch(128).prefetch(tf.data.AUTOTUNE)\ntest_ds = test_ds.map(preprocess_fn).batch(128).prefetch(tf.data.AUTOTUNE)'}),"\n",(0,s.jsx)(t.h2,{id:"define-the-model",children:"Define the Model"}),"\n",(0,s.jsxs)(t.p,{children:["Let's define a convolutional neural network as our classifier. We can use ",(0,s.jsx)(t.code,{children:"keras.Sequential"})," to stack up the layers."]}),"\n",(0,s.jsx)(i.d,{executionCount:13,children:'input_shape = (28, 28, 1)\nnum_classes = 10\n\nmodel = keras.Sequential(\n  [\n      keras.Input(shape=input_shape),\n      keras.layers.Conv2D(32, kernel_size=(3, 3), activation="relu"),\n      keras.layers.MaxPooling2D(pool_size=(2, 2)),\n      keras.layers.Conv2D(64, kernel_size=(3, 3), activation="relu"),\n      keras.layers.MaxPooling2D(pool_size=(2, 2)),\n      keras.layers.Flatten(),\n      keras.layers.Dropout(0.5),\n      keras.layers.Dense(num_classes, activation="softmax"),\n  ]\n)'}),"\n",(0,s.jsx)(t.p,{children:"Set training-related configs, optimizers, loss function, metrics."}),"\n",(0,s.jsx)(i.d,{executionCount:14,children:"model.compile(\n  loss=keras.losses.SparseCategoricalCrossentropy(),\n  optimizer=keras.optimizers.Adam(0.001),\n  metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)"}),"\n",(0,s.jsx)(t.h2,{id:"set-up-trackingvisualization-tool",children:"Set up tracking/visualization tool"}),"\n",(0,s.jsxs)(t.p,{children:["In this tutorial, we will use Databricks Free Trial for MLflow tracking server. For other options such as using your local MLflow server, please read the ",(0,s.jsx)(t.a,{href:"https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",children:"Tracking Server Overview"}),"."]}),"\n",(0,s.jsxs)(t.p,{children:["If you have not, please set up your account and access token of the Databricks Free Trial by following ",(0,s.jsx)(t.a,{href:"https://mlflow.org/docs/latest/getting-started/tracking-server-overview/index.html",children:"this guide"}),". It should take no longer than 5 mins to register. The Databricks Free Trial is a way for users to try out Databricks features for free. For this guide, we need the ML experiment dashboard for us to track our training progress."]}),"\n",(0,s.jsx)(t.p,{children:"After successfully registering an account on the Databricks Free Trial, let's connnect MLflow to the Databricks Workspace. You will need to enter following information:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Databricks Host"}),": https://<your workspace host>.cloud.databricks.com/"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Token"}),": You Personal Access Token"]}),"\n"]}),"\n",(0,s.jsx)(i.d,{executionCount:" ",children:"import mlflow\n\nmlflow.login()"}),"\n",(0,s.jsx)(t.p,{children:"Now this colab is connected to the hosted tracking server. Let's configure MLflow metadata. Two things to set up:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"mlflow.set_tracking_uri"}),': always use "databricks".']}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"mlflow.set_experiment"}),": pick up a name you like, start with ",(0,s.jsx)(t.code,{children:"/"}),"."]}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"logging-with-mlflow",children:"Logging with MLflow"}),"\n",(0,s.jsx)(t.p,{children:"There are two ways you can log to MLflow from your Tensorflow pipeline:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"MLflow auto logging."}),"\n",(0,s.jsx)(t.li,{children:"Use a callback."}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"Auto logging is simple to configure, but gives you less control. Using a callback is more flexible. Let's see how each way is done."}),"\n",(0,s.jsx)(t.h3,{id:"mlflow-auto-logging",children:"MLflow Auto Logging"}),"\n",(0,s.jsxs)(t.p,{children:["All you need to do is to call ",(0,s.jsx)(t.code,{children:"mlflow.tensorflow.autolog()"})," before kicking off the training, then the backend will automatically log the metrics into the server you configured earlier. In our case, Databricks Workspace."]}),"\n",(0,s.jsx)(i.d,{executionCount:15,children:'# Choose any name that you like.\nmlflow.set_experiment("/Users/<your email>/mlflow-tf-keras-mnist")\n\nmlflow.tensorflow.autolog()\n\nmodel.fit(x=train_ds, epochs=3)'}),"\n",(0,s.jsx)(r.p,{isStderr:!0,children:"2023/11/15 01:53:35 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '7c1db53e417b43f0a1d9e095c9943acb', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow"}),"\n",(0,s.jsx)(r.p,{children:"Epoch 1/3\n469/469 [==============================] - 13s 7ms/step - loss: 0.3610 - sparse_categorical_accuracy: 0.8890\nEpoch 2/3\n469/469 [==============================] - 3s 6ms/step - loss: 0.1035 - sparse_categorical_accuracy: 0.9681\nEpoch 3/3\n469/469 [==============================] - 4s 8ms/step - loss: 0.0798 - sparse_categorical_accuracy: 0.9760"}),"\n",(0,s.jsx)(r.p,{isStderr:!0,children:'2023/11/15 01:54:05 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: tuple index out of range\n2023/11/15 01:54:05 WARNING mlflow.models.model: Model logged without a signature. Signatures will be required for upcoming model registry features as they validate model inputs and denote the expected schema of model outputs. Please visit https://www.mlflow.org/docs/2.8.1/models.html#set-signature-on-logged-model for instructions on setting a model signature on your logged model.\n2023/11/15 01:54:05 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model\'s pyfunc representation accepts pandas DataFrames as inference inputs.\n2023/11/15 01:54:13 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils."'}),"\n",(0,s.jsx)(r.p,{children:"Uploading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"}),"\n",(0,s.jsx)(r.p,{isStderr:!0,children:"2023/11/15 01:54:13 INFO mlflow.store.artifact.cloud_artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false"}),"\n",(0,s.jsx)(r.p,{children:"Uploading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"}),"\n",(0,s.jsx)(r.p,{children:"<keras.src.callbacks.History at 0x7d48e6556b60>"}),"\n",(0,s.jsxs)(t.p,{children:["While your training is ongoing, you can find this training in your dashboard. Log in to your Databricks Workspace, and click on the ",(0,s.jsx)(t.code,{children:"Experiments tab"}),". See the screenshot below:\n",(0,s.jsx)(t.img,{src:"https://i.imgur.com/bBiIPqp.png",alt:"landing page"})]}),"\n",(0,s.jsxs)(t.p,{children:["After clicking the ",(0,s.jsx)(t.code,{children:"Experiments"})," button, it will bring you to the experiments page, where you can find your runs. Clicking on the most recent experiment and run, you can find your metrics there, similar to:\n",(0,s.jsx)(t.img,{src:"https://i.imgur.com/Idddpqe.png",alt:"experiment page"})]}),"\n",(0,s.jsx)(t.p,{children:"You can click on metrics to see the chart."}),"\n",(0,s.jsx)(t.p,{children:"Let's evaluate the training result."}),"\n",(0,s.jsx)(i.d,{executionCount:17,children:'score = model.evaluate(test_ds)\n\nprint(f"Test loss: {score[0]:.4f}")\nprint(f"Test accuracy: {score[1]: .2f}")'}),"\n",(0,s.jsx)(r.p,{children:"79/79 [==============================] - 1s 12ms/step - loss: 0.0484 - sparse_categorical_accuracy: 0.9838\nTest loss: 0.05\nTest accuracy:  0.98"}),"\n",(0,s.jsx)(t.h3,{id:"log-with-mlflow-callback",children:"Log with MLflow Callback"}),"\n",(0,s.jsxs)(t.p,{children:["Auto logging is powerful and convenient, but if you are looking for a more native way as Tensorflow pipelines, you can use ",(0,s.jsx)(t.code,{children:"mlflow.tensorflow.MllflowCallback"})," inside ",(0,s.jsx)(t.code,{children:"model.fit()"}),", it will log:"]}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Your model configuration, layers, hyperparameters and so on."}),"\n",(0,s.jsxs)(t.li,{children:["The training stats, including losses and metrics configured with ",(0,s.jsx)(t.code,{children:"model.compile()"}),"."]}),"\n"]}),"\n",(0,s.jsx)(i.d,{executionCount:22,children:"from mlflow.tensorflow import MlflowCallback\n\n# Turn off autologging.\nmlflow.tensorflow.autolog(disable=True)\n\nwith mlflow.start_run() as run:\n  model.fit(\n      x=train_ds,\n      epochs=2,\n      callbacks=[MlflowCallback(run)],\n  )"}),"\n",(0,s.jsx)(r.p,{children:"Epoch 1/2\n469/469 [==============================] - 5s 10ms/step - loss: 0.0473 - sparse_categorical_accuracy: 0.9851\nEpoch 2/2\n469/469 [==============================] - 4s 8ms/step - loss: 0.0432 - sparse_categorical_accuracy: 0.9866"}),"\n",(0,s.jsx)(t.p,{children:"Going to the Databricks Workspace experiment view, you will see a similar dashboard as before."}),"\n",(0,s.jsx)(t.h3,{id:"customize-the-mlflow-callback",children:"Customize the MLflow Callback"}),"\n",(0,s.jsxs)(t.p,{children:["If you want to add extra logging logic, you can customize the MLflow callback. You can either subclass from ",(0,s.jsx)(t.code,{children:"keras.callbacks.Callback"})," and write everything from scratch or subclass from ",(0,s.jsx)(t.code,{children:"mlflow.tensorflow.MllflowCallback"})," to add you custom logging logic."]}),"\n",(0,s.jsx)(t.p,{children:"Let's look at an example that we want to replace the loss with its log value to log to MLflow."}),"\n",(0,s.jsx)(i.d,{executionCount:19,children:'import math\n\n\n# Create our own callback by subclassing `MlflowCallback`.\nclass MlflowCustomCallback(MlflowCallback):\n  def on_epoch_end(self, epoch, logs=None):\n      if not self.log_every_epoch:\n          return\n      loss = logs["loss"]\n      logs["log_loss"] = math.log(loss)\n      del logs["loss"]\n      mlflow.log_metrics(logs, epoch)'}),"\n",(0,s.jsx)(t.p,{children:"Train the model with the new callback."}),"\n",(0,s.jsx)(i.d,{executionCount:21,children:"with mlflow.start_run() as run:\n  run_id = run.info.run_id\n  model.fit(\n      x=train_ds,\n      epochs=2,\n      callbacks=[MlflowCustomCallback(run)],\n  )"}),"\n",(0,s.jsx)(r.p,{children:"Epoch 1/2\n469/469 [==============================] - 5s 10ms/step - loss: 0.0537 - sparse_categorical_accuracy: 0.9834 - log_loss: -2.9237\nEpoch 2/2\n469/469 [==============================] - 4s 9ms/step - loss: 0.0497 - sparse_categorical_accuracy: 0.9846 - log_loss: -3.0022"}),"\n",(0,s.jsxs)(t.p,{children:["Going to your Databricks Workspace page, you should find the ",(0,s.jsx)(t.code,{children:"log_loss"})," is replacing the ",(0,s.jsx)(t.code,{children:"loss"})," metric, similar to what is shown in the screenshot below."]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://i.imgur.com/tgP4Cji.png",alt:"log loss screenshot"})}),"\n",(0,s.jsx)(t.h2,{id:"wrap-up",children:"Wrap up"}),"\n",(0,s.jsx)(t.p,{children:"Now you have learned the basic integration between MLflow and Tensorflow. There are a few things not covered by this quickstart, e.g., saving TF model to MLflow and loading it back. For a detailed guide, please refer to our main guide for integration between MLflow and Tensorflow."})]})}function f(e={}){const{wrapper:t}={...(0,l.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(p,{...e})}):p(e)}}}]);