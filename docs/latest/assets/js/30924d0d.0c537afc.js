"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["8072"],{55322(e,n,t){t.r(n),t.d(n,{metadata:()=>r,default:()=>v,frontMatter:()=>h,contentTitle:()=>g,toc:()=>u,assets:()=>m});var r=JSON.parse('{"id":"tracing/integrations/listing/livekit","title":"Tracing LiveKit Agents","description":"MLflow Tracing provides automatic tracing capability for LiveKit Agents, an open-source framework for building real-time multimodal AI applications. MLflow supports tracing for LiveKit Agents through the OpenTelemetry integration.","source":"@site/docs/genai/tracing/integrations/listing/livekit.mdx","sourceDirName":"tracing/integrations/listing","slug":"/tracing/integrations/listing/livekit","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/livekit","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6,"sidebar_label":"LiveKit Agents"},"sidebar":"genAISidebar","previous":{"title":"LangGraph","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/langgraph"},"next":{"title":"LangChain Deep Agent","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/deepagent"}}'),i=t(74848),s=t(28453),o=t(43975),a=t(60665),l=t(93893),c=t(46077),d=t(10440),p=t(77541);let h={sidebar_position:6,sidebar_label:"LiveKit Agents"},g="Tracing LiveKit Agents",m={},u=[{value:"Step 1: Install Libraries",id:"step-1-install-libraries",level:2},{value:"Step 2: Start the MLflow Tracking Server",id:"step-2-start-the-mlflow-tracking-server",level:2},{value:"Step 3: Set Environment Variables",id:"step-3-set-environment-variables",level:2},{value:"Step 4: Create Your Voice Agent",id:"step-4-create-your-voice-agent",level:2},{value:"Step 5: Run the Agent",id:"step-5-run-the-agent",level:2},{value:"Step 6: View Traces in MLflow",id:"step-6-view-traces-in-mlflow",level:2},{value:"LLM-Only Example (No LiveKit Server Required)",id:"llm-only-example-no-livekit-server-required",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Traces Not Appearing in MLflow",id:"traces-not-appearing-in-mlflow",level:3},{value:"Agent Not Responding",id:"agent-not-responding",level:3},{value:"Missing Conversation Content",id:"missing-conversation-content",level:3},{value:"Next Steps",id:"next-steps",level:2}];function x(e){let n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"tracing-livekit-agents",children:"Tracing LiveKit Agents"})}),"\n",(0,i.jsx)(c.A,{src:"/images/llms/tracing/livekit-tracing.png",alt:"LiveKit Agents Tracing"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"/genai/tracing",children:"MLflow Tracing"})," provides automatic tracing capability for ",(0,i.jsx)(n.a,{href:"https://github.com/livekit/agents",children:"LiveKit Agents"}),", an open-source framework for building real-time multimodal AI applications. MLflow supports tracing for LiveKit Agents through the ",(0,i.jsx)(n.a,{href:"/genai/tracing/opentelemetry",children:"OpenTelemetry"})," integration."]}),"\n",(0,i.jsxs)(n.admonition,{title:"What is LiveKit Agents?",type:"tip",children:[(0,i.jsx)(n.p,{children:"LiveKit Agents is a framework for building real-time, multimodal AI applications. It enables developers to create voice-enabled AI assistants that can:"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Process speech-to-text (STT) in real-time"}),"\n",(0,i.jsx)(n.li,{children:"Generate responses using LLMs (OpenAI, Anthropic, etc.)"}),"\n",(0,i.jsx)(n.li,{children:"Convert text to speech (TTS) with natural voices"}),"\n",(0,i.jsx)(n.li,{children:"Handle voice activity detection (VAD)"}),"\n",(0,i.jsx)(n.li,{children:"Execute tools and function calls"}),"\n"]})]}),"\n",(0,i.jsx)(n.h2,{id:"step-1-install-libraries",children:"Step 1: Install Libraries"}),"\n",(0,i.jsx)(n.p,{children:"Install the required packages for LiveKit Agents with OpenTelemetry support:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pip install livekit-agents livekit-plugins-openai livekit-plugins-silero\n"})}),"\n",(0,i.jsx)(n.h2,{id:"step-2-start-the-mlflow-tracking-server",children:"Step 2: Start the MLflow Tracking Server"}),"\n",(0,i.jsx)(n.p,{children:"Start the MLflow Tracking Server with a SQL-based backend store:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"mlflow server --port 5000\n"})}),"\n",(0,i.jsxs)(n.p,{children:["This example uses SQLite as the backend store. To use other types of SQL databases such as PostgreSQL, MySQL, and MSSQL, change the store URI as described in the ",(0,i.jsx)(n.a,{href:"/self-hosting/architecture/backend-store",children:"backend store documentation"}),". OpenTelemetry ingestion is not supported with file-based backend stores."]}),"\n",(0,i.jsx)(n.h2,{id:"step-3-set-environment-variables",children:"Step 3: Set Environment Variables"}),"\n",(0,i.jsx)(n.p,{children:"Configure OpenTelemetry and LiveKit credentials:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"export OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:5000\nexport OTEL_EXPORTER_OTLP_HEADERS=x-mlflow-experiment-id=0\nexport OTEL_SERVICE_NAME=livekit-voice-agent\n\n# LiveKit Cloud credentials (get free at https://cloud.livekit.io)\nexport LIVEKIT_URL=wss://your-project.livekit.cloud\nexport LIVEKIT_API_KEY=your-api-key\nexport LIVEKIT_API_SECRET=your-api-secret\n\n# LLM provider\nexport OPENAI_API_KEY=your-openai-api-key\n"})}),"\n",(0,i.jsxs)(n.admonition,{type:"note",children:[(0,i.jsxs)(n.mdxAdmonitionTitle,{children:["About ",(0,i.jsx)(n.code,{children:"x-mlflow-experiment-id"})]}),(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"x-mlflow-experiment-id"})," header tells MLflow which experiment to associate the traces with. You can use ",(0,i.jsx)(n.code,{children:"0"})," for the default experiment, or specify a custom experiment ID. To create a new experiment and get its ID, run:"]}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'mlflow experiments create --experiment-name "my-livekit-experiment"\n'})}),(0,i.jsx)(n.p,{children:"This will output the experiment ID which you can use in the header."})]}),"\n",(0,i.jsx)(n.admonition,{title:"Free LiveKit Cloud Account",type:"tip",children:(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"https://cloud.livekit.io",children:"LiveKit Cloud"})," offers a free tier with no credit card required. Sign up to get your ",(0,i.jsx)(n.code,{children:"LIVEKIT_URL"}),", ",(0,i.jsx)(n.code,{children:"LIVEKIT_API_KEY"}),", and ",(0,i.jsx)(n.code,{children:"LIVEKIT_API_SECRET"}),"."]})}),"\n",(0,i.jsx)(n.h2,{id:"step-4-create-your-voice-agent",children:"Step 4: Create Your Voice Agent"}),"\n",(0,i.jsx)(n.p,{children:"Create a voice agent with automatic MLflow tracing. All tracing is handled automatically by LiveKit's built-in OpenTelemetry instrumentation - no manual span creation required."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# voice_agent.py\nimport os\nimport logging\n\nfrom livekit.agents import JobContext, JobProcess, WorkerOptions, cli\nfrom livekit.agents.voice import Agent, AgentSession\nfrom livekit.agents.telemetry import set_tracer_provider\nfrom livekit.plugins import openai, silero\n\nfrom opentelemetry import trace\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\nfrom opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\nfrom opentelemetry.sdk.resources import Resource, SERVICE_NAME\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger("voice-agent")\n\n\ndef configure_mlflow_tracing():\n    """Configure OpenTelemetry to send traces to MLflow."""\n    if not os.getenv("OTEL_EXPORTER_OTLP_ENDPOINT"):\n        logger.warning("OTEL_EXPORTER_OTLP_ENDPOINT not set, tracing disabled")\n        return None\n\n    service_name = os.getenv("OTEL_SERVICE_NAME", "livekit-voice-agent")\n    resource = Resource.create({SERVICE_NAME: service_name})\n\n    provider = TracerProvider(resource=resource)\n    provider.add_span_processor(BatchSpanProcessor(OTLPSpanExporter()))\n\n    # Set both global and LiveKit tracer provider\n    trace.set_tracer_provider(provider)\n    set_tracer_provider(provider)\n\n    logger.info("MLflow tracing configured successfully!")\n    return provider\n\n\nasync def entrypoint(ctx: JobContext) -> None:\n    """Main entrypoint for the agent."""\n    logger.info(f"Agent starting for room: {ctx.room.name}")\n\n    # Connect to the room\n    await ctx.connect()\n\n    # Create the voice agent with all components\n    agent = Agent(\n        instructions="""You are a helpful voice assistant. Keep your responses\n        concise and conversational since you\'re speaking out loud.\n        Be friendly and helpful.""",\n        vad=silero.VAD.load(),  # Voice Activity Detection\n        stt=openai.STT(),  # Speech-to-Text (Whisper)\n        llm=openai.LLM(model="gpt-4o-mini"),  # Language Model\n        tts=openai.TTS(voice="alloy"),  # Text-to-Speech\n    )\n\n    # Create and start the agent session\n    session = AgentSession()\n    await session.start(agent, room=ctx.room)\n\n    logger.info("Agent session started! Ready for conversation.")\n\n\ndef prewarm(proc: JobProcess) -> None:\n    """Prewarm function to load models before handling requests."""\n    # Configure tracing before anything else\n    configure_mlflow_tracing()\n\n    # Preload Silero VAD model for faster startup\n    proc.userdata["vad"] = silero.VAD.load()\n    logger.info("Prewarmed VAD model")\n\n\nif __name__ == "__main__":\n    cli.run_app(\n        WorkerOptions(\n            entrypoint_fnc=entrypoint,\n            prewarm_fnc=prewarm,\n        )\n    )\n'})}),"\n",(0,i.jsx)(n.h2,{id:"step-5-run-the-agent",children:"Step 5: Run the Agent"}),"\n",(0,i.jsx)(n.p,{children:"Start your LiveKit agent:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Run in dev mode\npython voice_agent.py dev\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Once the agent is running and registered, connect to it using the ",(0,i.jsx)(n.a,{href:"https://agents-playground.livekit.io/",children:"LiveKit Agents Playground"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"step-6-view-traces-in-mlflow",children:"Step 6: View Traces in MLflow"}),"\n",(0,i.jsxs)(n.p,{children:["After having a conversation with your agent, open the MLflow UI at ",(0,i.jsx)(n.code,{children:"http://localhost:5000"})," and navigate to the Traces tab."]}),"\n",(0,i.jsx)(n.p,{children:"You will see detailed traces showing:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Agent Session"}),": The overall session containing all interactions"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"User Turns"}),": Each user speech input with transcriptions"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Agent Turns"}),": Each agent response including LLM and TTS processing"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"LLM Requests"}),": Full message history with inputs/outputs and token usage"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"STT Processing"}),": Speech-to-text transcriptions"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"TTS Synthesis"}),": Text-to-speech generation"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"The Chat tab provides a clean conversation view showing the full dialogue between user and assistant."}),"\n",(0,i.jsx)(n.h2,{id:"llm-only-example-no-livekit-server-required",children:"LLM-Only Example (No LiveKit Server Required)"}),"\n",(0,i.jsx)(n.p,{children:"For quick testing without a LiveKit server, you can use LiveKit's LLM plugin directly:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# livekit_llm_example.py\nimport os\nimport asyncio\n\nfrom opentelemetry import trace\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\nfrom opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\nfrom opentelemetry.sdk.resources import Resource, SERVICE_NAME\n\nfrom livekit.agents.telemetry import set_tracer_provider\nfrom livekit.agents.llm import ChatContext\nfrom livekit.plugins.openai import LLM\n\n\ndef configure_tracing():\n    endpoint = os.getenv("OTEL_EXPORTER_OTLP_ENDPOINT")\n    if not endpoint:\n        print("ERROR: OTEL_EXPORTER_OTLP_ENDPOINT not set!")\n        return None\n\n    headers_str = os.getenv("OTEL_EXPORTER_OTLP_HEADERS", "")\n    headers = {}\n    if headers_str:\n        for item in headers_str.split(","):\n            if "=" in item:\n                key, value = item.split("=", 1)\n                headers[key.strip()] = value.strip()\n\n    service_name = os.getenv("OTEL_SERVICE_NAME", "livekit-agent")\n    resource = Resource.create({SERVICE_NAME: service_name})\n    exporter = OTLPSpanExporter(endpoint=endpoint, headers=headers if headers else None)\n\n    provider = TracerProvider(resource=resource)\n    provider.add_span_processor(BatchSpanProcessor(exporter))\n\n    trace.set_tracer_provider(provider)\n    set_tracer_provider(provider)\n    return provider\n\n\nasync def main():\n    provider = configure_tracing()\n    if not provider:\n        return\n\n    # Create LLM instance - traces are created AUTOMATICALLY\n    llm = LLM(model="gpt-4o-mini")\n\n    chat_ctx = ChatContext()\n    chat_ctx.add_message(role="system", content="You are a helpful assistant.")\n    chat_ctx.add_message(role="user", content="What is the capital of France?")\n\n    print("User: What is the capital of France?")\n\n    # This call automatically generates traces\n    stream = llm.chat(chat_ctx=chat_ctx)\n\n    response = ""\n    async for chunk in stream:\n        if chunk.delta and chunk.delta.content:\n            response += chunk.delta.content\n\n    await stream.aclose()\n    print(f"Assistant: {response}")\n\n    await llm.aclose()\n    provider.force_flush()\n    provider.shutdown()\n\n    print("\\nCheck MLflow UI for traces!")\n\n\nif __name__ == "__main__":\n    asyncio.run(main())\n'})}),"\n",(0,i.jsx)(n.p,{children:"Run with:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"export OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:5000\nexport OTEL_EXPORTER_OTLP_HEADERS=x-mlflow-experiment-id=0\nexport OPENAI_API_KEY=your-key\n\npython livekit_llm_example.py\n"})}),"\n",(0,i.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,i.jsx)(n.h3,{id:"traces-not-appearing-in-mlflow",children:"Traces Not Appearing in MLflow"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Check backend store"}),": Ensure MLflow is using a SQL backend, not file-based storage"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Verify endpoint"}),": Confirm the MLflow server is running and accessible at the configured endpoint"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Check headers"}),": Ensure the experiment ID header is correctly set"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Flush traces"}),": Call ",(0,i.jsx)(n.code,{children:"provider.force_flush()"})," before shutdown to ensure all traces are exported"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"agent-not-responding",children:"Agent Not Responding"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Check LiveKit credentials"}),": Verify ",(0,i.jsx)(n.code,{children:"LIVEKIT_URL"}),", ",(0,i.jsx)(n.code,{children:"LIVEKIT_API_KEY"}),", and ",(0,i.jsx)(n.code,{children:"LIVEKIT_API_SECRET"})," are set correctly"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Check agent registration"}),': Look for "registered worker" in the agent logs']}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Kill orphan processes"}),": LiveKit agents spawn child processes. If you stop the parent, kill child processes too:"]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'pkill -f "multiprocessing.spawn"\n'})}),"\n",(0,i.jsx)(n.h3,{id:"missing-conversation-content",children:"Missing Conversation Content"}),"\n",(0,i.jsxs)(n.p,{children:["Ensure you're using the latest version of ",(0,i.jsx)(n.code,{children:"livekit-agents"}),". The GenAI events (",(0,i.jsx)(n.code,{children:"gen_ai.system.message"}),", ",(0,i.jsx)(n.code,{children:"gen_ai.user.message"}),", ",(0,i.jsx)(n.code,{children:"gen_ai.assistant.message"}),", ",(0,i.jsx)(n.code,{children:"gen_ai.choice"}),") are automatically captured and displayed in MLflow's Chat UI."]}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsxs)(d.A,{children:[(0,i.jsx)(p.A,{icon:o.A,iconSize:48,title:"Evaluate the Agent",description:"Learn how to evaluate the agent's performance with LLM judges.",href:"/genai/eval-monitor/running-evaluation/agents",linkText:"Evaluate agents \u2192"}),(0,i.jsx)(p.A,{icon:a.A,iconSize:48,title:"Manage Prompts",description:"Learn how to manage prompts with MLflow's prompt registry.",href:"/genai/prompt-registry",linkText:"Manage prompts \u2192"}),(0,i.jsx)(p.A,{icon:l.A,iconSize:48,title:"Automatic Agent Optimization",description:"Automatically optimize the agent end-to-end with state-of-the-art algorithms.",href:"/genai/prompt-registry/optimize-prompts",linkText:"Optimize prompts \u2192"})]})]})}function v(e={}){let{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(x,{...e})}):x(e)}},75689(e,n,t){t.d(n,{A:()=>l});var r=t(96540);let i=e=>{let n=e.replace(/^([A-Z])|[\s-_]+(\w)/g,(e,n,t)=>t?t.toUpperCase():n.toLowerCase());return n.charAt(0).toUpperCase()+n.slice(1)},s=(...e)=>e.filter((e,n,t)=>!!e&&""!==e.trim()&&t.indexOf(e)===n).join(" ").trim();var o={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};let a=(0,r.forwardRef)(({color:e="currentColor",size:n=24,strokeWidth:t=2,absoluteStrokeWidth:i,className:a="",children:l,iconNode:c,...d},p)=>(0,r.createElement)("svg",{ref:p,...o,width:n,height:n,stroke:e,strokeWidth:i?24*Number(t)/Number(n):t,className:s("lucide",a),...!l&&!(e=>{for(let n in e)if(n.startsWith("aria-")||"role"===n||"title"===n)return!0})(d)&&{"aria-hidden":"true"},...d},[...c.map(([e,n])=>(0,r.createElement)(e,n)),...Array.isArray(l)?l:[l]])),l=(e,n)=>{let t=(0,r.forwardRef)(({className:t,...o},l)=>(0,r.createElement)(a,{ref:l,iconNode:n,className:s(`lucide-${i(e).replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()}`,`lucide-${e}`,t),...o}));return t.displayName=i(e),t}},60665(e,n,t){t.d(n,{A:()=>r});let r=(0,t(75689).A)("book-open",[["path",{d:"M12 7v14",key:"1akyts"}],["path",{d:"M3 18a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h5a4 4 0 0 1 4 4 4 4 0 0 1 4-4h5a1 1 0 0 1 1 1v13a1 1 0 0 1-1 1h-6a3 3 0 0 0-3 3 3 3 0 0 0-3-3z",key:"ruj8y"}]])},43975(e,n,t){t.d(n,{A:()=>r});let r=(0,t(75689).A)("scale",[["path",{d:"m16 16 3-8 3 8c-.87.65-1.92 1-3 1s-2.13-.35-3-1Z",key:"7g6ntu"}],["path",{d:"m2 16 3-8 3 8c-.87.65-1.92 1-3 1s-2.13-.35-3-1Z",key:"ijws7r"}],["path",{d:"M7 21h10",key:"1b0cd5"}],["path",{d:"M12 3v18",key:"108xh3"}],["path",{d:"M3 7h2c2 0 5-1 7-2 2 1 5 2 7 2h2",key:"3gwbw2"}]])},93893(e,n,t){t.d(n,{A:()=>r});let r=(0,t(75689).A)("users",[["path",{d:"M16 21v-2a4 4 0 0 0-4-4H6a4 4 0 0 0-4 4v2",key:"1yyitq"}],["path",{d:"M16 3.128a4 4 0 0 1 0 7.744",key:"16gr8j"}],["path",{d:"M22 21v-2a4 4 0 0 0-3-3.87",key:"kshegd"}],["circle",{cx:"9",cy:"7",r:"4",key:"nufk8"}]])},46077(e,n,t){t.d(n,{A:()=>s});var r=t(74848);t(96540);var i=t(66497);function s({src:e,alt:n,width:t,caption:s,className:o}){return(0,r.jsxs)("div",{className:`container_JwLF ${o||""}`,children:[(0,r.jsx)("div",{className:"imageWrapper_RfGN",style:t?{width:t}:{},children:(0,r.jsx)("img",{src:(0,i.default)(e),alt:n,className:"image_bwOA"})}),s&&(0,r.jsx)("p",{className:"caption_jo2G",children:s})]})}},77541(e,n,t){t.d(n,{A:()=>c});var r=t(74848);t(96540);var i=t(95310),s=t(34164);let o="tileImage_O4So";var a=t(66497),l=t(92802);function c({icon:e,image:n,imageDark:t,imageWidth:c,imageHeight:d,iconSize:p=32,containerHeight:h,title:g,description:m,href:u,linkText:x="Learn more \u2192",className:v}){if(!e&&!n)throw Error("TileCard requires either an icon or image prop");let f=h?{height:`${h}px`}:{},j={};return c&&(j.width=`${c}px`),d&&(j.height=`${d}px`),(0,r.jsxs)(i.A,{href:u,className:(0,s.A)("tileCard_NHsj",v),children:[(0,r.jsx)("div",{className:"tileIcon_pyoR",style:f,children:e?(0,r.jsx)(e,{size:p}):t?(0,r.jsx)(l.A,{sources:{light:(0,a.default)(n),dark:(0,a.default)(t)},alt:g,className:o,style:j}):(0,r.jsx)("img",{src:(0,a.default)(n),alt:g,className:o,style:j})}),(0,r.jsx)("h3",{children:g}),(0,r.jsx)("p",{children:m}),(0,r.jsx)("div",{className:"tileLink_iUbu",children:x})]})}},10440(e,n,t){t.d(n,{A:()=>s});var r=t(74848);t(96540);var i=t(34164);function s({children:e,className:n}){return(0,r.jsx)("div",{className:(0,i.A)("tilesGrid_hB9N",n),children:e})}},28453(e,n,t){t.d(n,{R:()=>o,x:()=>a});var r=t(96540);let i={},s=r.createContext(i);function o(e){let n=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);