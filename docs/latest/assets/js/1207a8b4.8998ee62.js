"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[5380],{11470:(e,t,n)=>{n.d(t,{A:()=>j});var a=n(96540),l=n(34164),r=n(17559),o=n(23104),i=n(56347),s=n(205),c=n(57485),p=n(31682),m=n(70679);function h(e){return a.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function d(e){const{values:t,children:n}=e;return(0,a.useMemo)(()=>{const e=t??function(e){return h(e).map(({props:{value:e,label:t,attributes:n,default:a}})=>({value:e,label:t,attributes:n,default:a}))}(n);return function(e){const t=(0,p.XI)(e,(e,t)=>e.value===t.value);if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[t,n])}function f({value:e,tabValues:t}){return t.some(t=>t.value===e)}function u({queryString:e=!1,groupId:t}){const n=(0,i.W6)(),l=function({queryString:e=!1,groupId:t}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:e,groupId:t});return[(0,c.aZ)(l),(0,a.useCallback)(e=>{if(!l)return;const t=new URLSearchParams(n.location.search);t.set(l,e),n.replace({...n.location,search:t.toString()})},[l,n])]}function w(e){const{defaultValue:t,queryString:n=!1,groupId:l}=e,r=d(e),[o,i]=(0,a.useState)(()=>function({defaultValue:e,tabValues:t}){if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!f({value:e,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${t.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const n=t.find(e=>e.default)??t[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:t,tabValues:r})),[c,p]=u({queryString:n,groupId:l}),[h,w]=function({groupId:e}){const t=function(e){return e?`docusaurus.tab.${e}`:null}(e),[n,l]=(0,m.Dv)(t);return[n,(0,a.useCallback)(e=>{t&&l.set(e)},[t,l])]}({groupId:l}),_=(()=>{const e=c??h;return f({value:e,tabValues:r})?e:null})();(0,s.A)(()=>{_&&i(_)},[_]);return{selectedValue:o,selectValue:(0,a.useCallback)(e=>{if(!f({value:e,tabValues:r}))throw new Error(`Can't select invalid tab value=${e}`);i(e),p(e),w(e)},[p,w,r]),tabValues:r}}var _=n(92303);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var y=n(74848);function x({className:e,block:t,selectedValue:n,selectValue:a,tabValues:r}){const i=[],{blockElementScrollPositionUntilNextRender:s}=(0,o.a_)(),c=e=>{const t=e.currentTarget,l=i.indexOf(t),o=r[l].value;o!==n&&(s(t),a(o))},p=e=>{let t=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const n=i.indexOf(e.currentTarget)+1;t=i[n]??i[0];break}case"ArrowLeft":{const n=i.indexOf(e.currentTarget)-1;t=i[n]??i[i.length-1];break}}t?.focus()};return(0,y.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,l.A)("tabs",{"tabs--block":t},e),children:r.map(({value:e,label:t,attributes:a})=>(0,y.jsx)("li",{role:"tab",tabIndex:n===e?0:-1,"aria-selected":n===e,ref:e=>{i.push(e)},onKeyDown:p,onClick:c,...a,className:(0,l.A)("tabs__item",g.tabItem,a?.className,{"tabs__item--active":n===e}),children:t??e},e))})}function v({lazy:e,children:t,selectedValue:n}){const r=(Array.isArray(t)?t:[t]).filter(Boolean);if(e){const e=r.find(e=>e.props.value===n);return e?(0,a.cloneElement)(e,{className:(0,l.A)("margin-top--md",e.props.className)}):null}return(0,y.jsx)("div",{className:"margin-top--md",children:r.map((e,t)=>(0,a.cloneElement)(e,{key:t,hidden:e.props.value!==n}))})}function b(e){const t=w(e);return(0,y.jsxs)("div",{className:(0,l.A)(r.G.tabs.container,"tabs-container",g.tabList),children:[(0,y.jsx)(x,{...t,...e}),(0,y.jsx)(v,{...t,...e})]})}function j(e){const t=(0,_.A)();return(0,y.jsx)(b,{...e,children:h(e.children)},String(t))}},19365:(e,t,n)=>{n.d(t,{A:()=>o});n(96540);var a=n(34164);const l={tabItem:"tabItem_Ymn6"};var r=n(74848);function o({children:e,hidden:t,className:n}){return(0,r.jsx)("div",{role:"tabpanel",className:(0,a.A)(l.tabItem,n),hidden:t,children:e})}},28453:(e,t,n)=>{n.d(t,{R:()=>o,x:()=>i});var a=n(96540);const l={},r=a.createContext(l);function o(e){const t=a.useContext(r);return a.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:o(e.components),a.createElement(r.Provider,{value:t},e.children)}},49374:(e,t,n)=>{n.d(t,{B:()=>i});n(96540);const a=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}');var l=n(86025),r=n(74848);const o=e=>{const t=e.split(".");for(let n=t.length;n>0;n--){const e=t.slice(0,n).join(".");if(a[e])return e}return null};function i({fn:e,children:t,hash:n}){const i=o(e);if(!i)return(0,r.jsx)(r.Fragment,{children:t});const s=(0,l.Ay)(`/${a[i]}#${n??e}`);return(0,r.jsx)("a",{href:s,target:"_blank",children:t??(0,r.jsxs)("code",{children:[e,"()"]})})}},54329:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>m,contentTitle:()=>p,default:()=>f,frontMatter:()=>c,metadata:()=>a,toc:()=>h});const a=JSON.parse('{"id":"getting-started/deep-learning","title":"Deep Learning Quickstart","description":"In this tutorial, we demonstrate how to use MLflow to track deep learning experiments with Pytorch. By combining MLflow","source":"@site/docs/classic-ml/getting-started/deep-learning.mdx","sourceDirName":"getting-started","slug":"/getting-started/deep-learning","permalink":"/mlflow-website/docs/latest/ml/getting-started/deep-learning","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"toc_max_heading_level":4,"sidebar_label":"Deep Learning"},"sidebar":"classicMLSidebar","previous":{"title":"Hyperparameter Tuning","permalink":"/mlflow-website/docs/latest/ml/getting-started/hyperparameter-tuning/"},"next":{"title":"Overview","permalink":"/mlflow-website/docs/latest/ml/traditional-ml/"}}');var l=n(74848),r=n(28453),o=n(11470),i=n(19365),s=(n(49374),n(66927));const c={sidebar_position:2,toc_max_heading_level:4,sidebar_label:"Deep Learning"},p="Deep Learning Quickstart",m={},h=[{value:"Prerequisites: Set up MLflow and Pytorch",id:"prerequisites-set-up-mlflow-and-pytorch",level:2},{value:"Step 1: Create a new experiment",id:"step-1-create-a-new-experiment",level:2},{value:"Step 2: Prepare the dataset",id:"step-2-prepare-the-dataset",level:2},{value:"Step 3: Define the model and optimizer",id:"step-3-define-the-model-and-optimizer",level:2},{value:"Step 4: Train the model",id:"step-4-train-the-model",level:2},{value:"Step 5: View the training results in the MLflow UI",id:"step-5-view-the-training-results-in-the-mlflow-ui",level:2},{value:"Step 6: Load back the model and run inference",id:"step-6-load-back-the-model-and-run-inference",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(t.header,{children:(0,l.jsx)(t.h1,{id:"deep-learning-quickstart",children:"Deep Learning Quickstart"})}),"\n",(0,l.jsx)(s.A,{src:"/images/tutorials/introductory/deep-learning/ui-system-metrics.png",alt:"MLflow UI System metrics page",width:"80%"}),"\n",(0,l.jsx)(t.p,{children:"In this tutorial, we demonstrate how to use MLflow to track deep learning experiments with Pytorch. By combining MLflow"}),"\n",(0,l.jsxs)(t.ul,{children:["\n",(0,l.jsxs)(t.li,{children:["Save ",(0,l.jsx)(t.strong,{children:"checkpoints"})," with metrics."]}),"\n",(0,l.jsxs)(t.li,{children:["Visualize the ",(0,l.jsx)(t.strong,{children:"loss curve"})," during training."]}),"\n",(0,l.jsxs)(t.li,{children:["Monitor ",(0,l.jsx)(t.strong,{children:"system metrics"})," such as GPU utilization, memory footprint, disk usage, network, etc."]}),"\n",(0,l.jsxs)(t.li,{children:["Record ",(0,l.jsx)(t.strong,{children:"hyperparameters"})," and optimizer settings."]}),"\n",(0,l.jsxs)(t.li,{children:["Snapshot ",(0,l.jsx)(t.strong,{children:"library versions"})," for reproducibility."]}),"\n"]}),"\n",(0,l.jsx)(t.h2,{id:"prerequisites-set-up-mlflow-and-pytorch",children:"Prerequisites: Set up MLflow and Pytorch"}),"\n",(0,l.jsx)(t.p,{children:"MLflow is available on PyPI. Install MLflow and Pytorch with:"}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-bash",children:"pip install mlflow torch torchvision\n"})}),"\n",(0,l.jsxs)(t.p,{children:["Then, follow the instructions in the ",(0,l.jsx)(t.a,{href:"/ml/getting-started/running-notebooks",children:"Set Up MLflow"})," guide to set up MLflow."]}),"\n",(0,l.jsx)(t.h2,{id:"step-1-create-a-new-experiment",children:"Step 1: Create a new experiment"}),"\n",(0,l.jsx)(t.p,{children:"Create a new MLflow experiment for the tutorial and enable system metrics monitoring. Here we set the monitoring interval to 1 second because the training will be quick, but for longer training runs, you can set it to a larger value."}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-python",children:'import mlflow\n\n# The set_experiment API creates a new experiment if it doesn\'t exist.\nmlflow.set_experiment("Deep Learning Experiment")\n\n# IMPORTANT: Enable system metrics monitoring\nmlflow.config.enable_system_metrics_logging()\nmlflow.config.set_system_metrics_sampling_interval(1)\n'})}),"\n",(0,l.jsx)(t.h2,{id:"step-2-prepare-the-dataset",children:"Step 2: Prepare the dataset"}),"\n",(0,l.jsx)(t.p,{children:"In this example, we will use the FashionMNIST dataset, which is a collection of 28x28 grayscale images of 10 different types of clothing."}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-python",children:'import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\n# Define device\ndevice = torch.device("cuda" if torch.cuda.is_available() else "cpu")\n\n# Load and prepare data\ntransform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n)\ntrain_dataset = datasets.FashionMNIST(\n    "data", train=True, download=True, transform=transform\n)\ntest_dataset = datasets.FashionMNIST("data", train=False, transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=1000)\n'})}),"\n",(0,l.jsx)(t.h2,{id:"step-3-define-the-model-and-optimizer",children:"Step 3: Define the model and optimizer"}),"\n",(0,l.jsx)(t.p,{children:"Define a simple MLP model with 2 hidden layers."}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-python",children:"import torch.nn as nn\n\n\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28 * 28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10),\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n\n\nmodel = NeuralNetwork().to(device)\n"})}),"\n",(0,l.jsx)(t.p,{children:"Then, define the training parameters and optimizer."}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-python",children:'# Training parameters\nparams = {\n    "epochs": 5,\n    "learning_rate": 1e-3,\n    "batch_size": 64,\n    "optimizer": "SGD",\n    "model_type": "MLP",\n    "hidden_units": [512, 512],\n}\n\n# Define optimizer and loss function\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=params["learning_rate"])\n'})}),"\n",(0,l.jsx)(t.h2,{id:"step-4-train-the-model",children:"Step 4: Train the model"}),"\n",(0,l.jsx)(t.p,{children:"Now we are ready to train the model. Inside the training loop, we log the metrics and checkpoints to MLflow. The key points in this code are:"}),"\n",(0,l.jsxs)(t.ul,{children:["\n",(0,l.jsxs)(t.li,{children:["Initiate an MLflow ",(0,l.jsx)(t.strong,{children:"run"})," context to start a new run that we will log the model and metadata to."]}),"\n",(0,l.jsxs)(t.li,{children:["Log training parameters using ",(0,l.jsx)(t.code,{children:"mlflow.log_params"}),"."]}),"\n",(0,l.jsxs)(t.li,{children:["Log various metrics using ",(0,l.jsx)(t.code,{children:"mlflow.log_metrics"}),"."]}),"\n",(0,l.jsxs)(t.li,{children:["Save checkpoints for each epoch using ",(0,l.jsx)(t.code,{children:"mlflow.pytorch.log_model"}),"."]}),"\n"]}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-python",children:'with mlflow.start_run() as run:\n    # Log training parameters\n    mlflow.log_params(params)\n\n    for epoch in range(params["epochs"]):\n        model.train()\n        train_loss = correct, total = 0, 0, 0\n\n        for batch_idx, (data, target) in enumerate(train_loader):\n            data, target = data.to(device), target.to(device)\n\n            # Forward pass\n            optimizer.zero_grad()\n            output = model(data)\n            loss = loss_fn(output, target)\n\n            # Backward pass\n            loss.backward()\n            optimizer.step()\n\n            # Calculate metrics\n            train_loss += loss.item()\n            _, predicted = output.max(1)\n            total += target.size(0)\n            correct += predicted.eq(target).sum().item()\n\n            # Log batch metrics (every 100 batches)\n            if batch_idx % 100 == 0:\n                batch_loss = train_loss / (batch_idx + 1)\n                batch_acc = 100.0 * correct / total\n                mlflow.log_metrics(\n                    {"batch_loss": batch_loss, "batch_accuracy": batch_acc},\n                    step=epoch * len(train_loader) + batch_idx,\n                )\n\n        # Calculate epoch metrics\n        epoch_loss = train_loss / len(train_loader)\n        epoch_acc = 100.0 * correct / total\n\n        # Validation\n        model.eval()\n        val_loss, val_correct, val_total = 0, 0, 0\n        with torch.no_grad():\n            for data, target in test_loader:\n                data, target = data.to(device), target.to(device)\n                output = model(data)\n                loss = loss_fn(output, target)\n\n                val_loss += loss.item()\n                _, predicted = output.max(1)\n                val_total += target.size(0)\n                val_correct += predicted.eq(target).sum().item()\n\n        # Calculate and log epoch validation metrics\n        val_loss = val_loss / len(test_loader)\n        val_acc = 100.0 * val_correct / val_total\n\n        # Log epoch metrics\n        mlflow.log_metrics(\n            {\n                "train_loss": epoch_loss,\n                "train_accuracy": epoch_acc,\n                "val_loss": val_loss,\n                "val_accuracy": val_acc,\n            },\n            step=epoch,\n        )\n        # Log checkpoint at the end of each epoch\n        mlflow.pytorch.log_model(model, name=f"checkpoint_{epoch}")\n\n        print(\n            f"Epoch {epoch+1}/{params[\'epochs\']}, "\n            f"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}%, "\n            f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%"\n        )\n\n    # Log the final trained model\n    model_info = mlflow.pytorch.log_model(model, name="final_model")\n'})}),"\n",(0,l.jsx)(t.h2,{id:"step-5-view-the-training-results-in-the-mlflow-ui",children:"Step 5: View the training results in the MLflow UI"}),"\n",(0,l.jsxs)(t.p,{children:["To see the results of training, you can access the MLflow UI by navigating to the URL of the Tracking Server. If you have not started one, open a new terminal and run the following command at the root of the MLflow project and access the UI at ",(0,l.jsx)(t.a,{href:"http://localhost:5000",children:"http://localhost:5000"})," (or the port number you specified)."]}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-bash",children:"mlflow ui --port 5000\n"})}),"\n",(0,l.jsx)(t.p,{children:"When opening the site, you will see a screen similar to the following:"}),"\n",(0,l.jsx)(s.A,{src:"/images/tutorials/introductory/deep-learning/ui-home.png",alt:"MLflow UI Home page"}),"\n",(0,l.jsx)(t.p,{children:'The "Experiments" section shows a list of (recently created) experiments. Click on the "Deep Learning Experiment" experiment we\'ve created for this tutorial.'}),"\n",(0,l.jsx)(s.A,{src:"/images/tutorials/introductory/hyperparameter-tuning/ui-run-list.png",alt:"MLflow UI Run list page"}),"\n",(0,l.jsxs)(t.p,{children:["Click the Run in the table to view the details of the run. The overview page shows metadata such as the run duration, start time, training parameters, tags, etc. Navigate to the ",(0,l.jsx)(t.strong,{children:"Model metrics"})," and ",(0,l.jsx)(t.strong,{children:"System metrics"})," tabs to view the performance and system metrics logged during training."]}),"\n",(0,l.jsxs)(o.A,{children:[(0,l.jsx)(i.A,{value:"overview",label:"Overview",children:(0,l.jsx)(s.A,{src:"/images/tutorials/introductory/deep-learning/ui-run-overview.png",alt:"MLflow UI Overview page"})}),(0,l.jsx)(i.A,{value:"model-metrics",label:"Model Metrics",default:!0,children:(0,l.jsx)(s.A,{src:"/images/tutorials/introductory/deep-learning/ui-model-metrics.png",alt:"MLflow UI Model metrics page"})}),(0,l.jsx)(i.A,{value:"system-metrics",label:"System Metrics",children:(0,l.jsx)(s.A,{src:"/images/tutorials/introductory/deep-learning/ui-system-metrics.png",alt:"MLflow UI System metrics page"})})]}),"\n",(0,l.jsx)(t.h2,{id:"step-6-load-back-the-model-and-run-inference",children:"Step 6: Load back the model and run inference"}),"\n",(0,l.jsxs)(t.p,{children:["You can load the final model or checkpoint from MLflow using the ",(0,l.jsx)(t.code,{children:"mlflow.pytorch.load_model"})," function. Let's run the loaded model on the test set and evaluate the performance."]}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-python",children:'# Load the final model\nmodel = mlflow.pytorch.load_model("runs:/<run_id>/final_model")\n# or load a checkpoint\n# model = mlflow.pytorch.load_model("runs:/<run_id>/checkpoint_<epoch>")\nloaded_model.to(device)\nloaded_model.eval()\n\n# Resume the previous run to log test metrics\nwith mlflow.start_run(run_id=run.info.run_id) as run:\n    # Evaluate the model on the test set\n    test_loss, test_correct, test_total = 0, 0, 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n        output = model(data)\n        loss = loss_fn(output, target)\n\n        test_loss += loss.item()\n        _, predicted = output.max(1)\n        test_total += target.size(0)\n        test_correct += predicted.eq(target).sum().item()\n\n    # Calculate and log final test metrics\n    test_loss = test_loss / len(test_loader)\n    test_acc = 100.0 * test_correct / test_total\n\n    mlflow.log_metrics({"test_loss": test_loss, "test_accuracy": test_acc})\n    print(f"Final Test Accuracy: {test_acc:.2f}%")\n'})}),"\n",(0,l.jsx)(t.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,l.jsx)(t.p,{children:"Congratulations on working through the MLflow Deep Learning Quickstart! You should now have a basic understanding of how to combine MLflow with deep learning frameworks such as PyTorch to track your experiments and models."}),"\n",(0,l.jsxs)(t.ul,{children:["\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.a,{href:"/ml/deep-learning",children:"MLflow for Deep Learning"}),": Learn more about MLflow integration with deep learning frameworks."]}),"\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.a,{href:"/genai",children:"MLflow for GenAI"}),": Learn how to use MLflow for GenAI/LLM development."]}),"\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.a,{href:"/ml/tracking/",children:"MLflow Tracking"}),": Learn more about the MLflow Tracking APIs."]}),"\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.a,{href:"/self-hosting",children:"Self-hosting Guide"}),": Learn how to self-host the MLflow Tracking Server and set it up for team collaboration."]}),"\n"]})]})}function f(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,l.jsx)(t,{...e,children:(0,l.jsx)(d,{...e})}):d(e)}},66927:(e,t,n)=>{n.d(t,{A:()=>o});n(96540);const a={container:"container_JwLF",imageWrapper:"imageWrapper_RfGN",image:"image_bwOA",caption:"caption_jo2G"};var l=n(86025),r=n(74848);function o({src:e,alt:t,width:n,caption:o,className:i}){return(0,r.jsxs)("div",{className:`${a.container} ${i||""}`,children:[(0,r.jsx)("div",{className:a.imageWrapper,style:n?{width:n}:{},children:(0,r.jsx)("img",{src:(0,l.Ay)(e),alt:t,className:a.image})}),o&&(0,r.jsx)("p",{className:a.caption,children:o})]})}}}]);