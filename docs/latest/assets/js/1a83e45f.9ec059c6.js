"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[1932],{10493:(e,n,l)=>{l.d(n,{Zp:()=>s,AC:()=>o,WO:()=>p,_C:()=>c,$3:()=>m,jK:()=>d});var a=l(34164);const t={CardGroup:"CardGroup_P84T",NoGap:"NoGap_O9Dj",MaxThreeColumns:"MaxThreeColumns_FO1r",AutofillColumns:"AutofillColumns_fKhQ",Card:"Card_aSCR",CardBordered:"CardBordered_glGF",CardBody:"CardBody_BhRs",TextColor:"TextColor_a8Tp",BoxRoot:"BoxRoot_Etgr",FlexWrapNowrap:"FlexWrapNowrap_f60k",FlexJustifyContentFlexStart:"FlexJustifyContentFlexStart_ZYv5",FlexDirectionRow:"FlexDirectionRow_T2qL",FlexAlignItemsCenter:"FlexAlignItemsCenter_EHVM",FlexFlex:"FlexFlex__JTE",Link:"Link_fVkl",MarginLeft4:"MarginLeft4_YQSJ",MarginTop4:"MarginTop4_jXKN",PaddingBottom4:"PaddingBottom4_O9gt",LogoCardContent:"LogoCardContent_kCQm",LogoCardImage:"LogoCardImage_JdcX",SmallLogoCardContent:"SmallLogoCardContent_LxhV",SmallLogoCardRounded:"SmallLogoCardRounded_X50_",SmallLogoCardImage:"SmallLogoCardImage_tPZl",NewFeatureCardContent:"NewFeatureCardContent_Rq3d",NewFeatureCardHeading:"NewFeatureCardHeading_f6q3",NewFeatureCardHeadingSeparator:"NewFeatureCardHeadingSeparator_pSx8",NewFeatureCardTags:"NewFeatureCardTags_IFHO",NewFeatureCardWrapper:"NewFeatureCardWrapper_NQ0k",TitleCardContent:"TitleCardContent_l9MQ",TitleCardTitle:"TitleCardTitle__K8J",TitleCardSeparator:"TitleCardSeparator_IN2E",Cols1:"Cols1_Gr2U",Cols2:"Cols2_sRvc",Cols3:"Cols3_KjUS",Cols4:"Cols4_dKOj",Cols5:"Cols5_jDmj",Cols6:"Cols6_Q0OR"};var i=l(28774),r=l(74848);const o=({children:e,isSmall:n,cols:l,noGap:i})=>(0,r.jsx)("div",{className:(0,a.A)(t.CardGroup,n?t.AutofillColumns:l?t[`Cols${l}`]:t.MaxThreeColumns,i&&t.NoGap),children:e}),s=({children:e,link:n=""})=>n?(0,r.jsx)(i.A,{className:(0,a.A)(t.Link,t.Card,t.CardBordered),to:n,children:e}):(0,r.jsx)("div",{className:(0,a.A)(t.Card,t.CardBordered),children:e}),c=({headerText:e,link:n,text:l})=>(0,r.jsx)(s,{link:n,children:(0,r.jsxs)("span",{children:[(0,r.jsx)("div",{className:(0,a.A)(t.CardTitle,t.BoxRoot,t.PaddingBottom4),style:{pointerEvents:"none"},children:(0,r.jsx)("div",{className:(0,a.A)(t.BoxRoot,t.FlexFlex,t.FlexAlignItemsCenter,t.FlexDirectionRow,t.FlexJustifyContentFlexStart,t.FlexWrapNowrap),style:{marginLeft:"-4px",marginTop:"-4px"},children:(0,r.jsx)("div",{className:(0,a.A)(t.BoxRoot,t.BoxHideIfEmpty,t.MarginTop4,t.MarginLeft4),style:{pointerEvents:"auto"},children:(0,r.jsx)("span",{className:"",children:e})})})}),(0,r.jsx)("span",{className:(0,a.A)(t.TextColor,t.CardBody),children:(0,r.jsx)("p",{children:l})})]})}),p=({description:e,children:n,link:l})=>(0,r.jsx)(s,{link:l,children:(0,r.jsxs)("div",{className:t.LogoCardContent,children:[(0,r.jsx)("div",{className:t.LogoCardImage,children:n}),(0,r.jsx)("p",{className:t.TextColor,children:e})]})}),m=({children:e,link:n})=>(0,r.jsx)("div",{className:(0,a.A)(t.Card,t.CardBordered,t.SmallLogoCardRounded),children:n?(0,r.jsx)(i.A,{className:(0,a.A)(t.Link),to:n,children:(0,r.jsx)("div",{className:t.SmallLogoCardContent,children:(0,r.jsx)("div",{className:(0,a.A)("max-height-img-container",t.SmallLogoCardImage),children:e})})}):(0,r.jsx)("div",{className:t.SmallLogoCardContent,children:(0,r.jsx)("div",{className:(0,a.A)("max-height-img-container",t.SmallLogoCardImage),children:e})})}),d=({title:e,description:n,link:l=""})=>(0,r.jsx)(s,{link:l,children:(0,r.jsxs)("div",{className:t.TitleCardContent,children:[(0,r.jsx)("div",{className:(0,a.A)(t.TitleCardTitle),style:{textAlign:"left",fontWeight:"bold"},children:e}),(0,r.jsx)("hr",{className:(0,a.A)(t.TitleCardSeparator),style:{margin:"12px 0"}}),(0,r.jsx)("p",{className:(0,a.A)(t.TextColor),children:n})]})})},31609:(e,n,l)=>{l.r(n),l.d(n,{assets:()=>p,contentTitle:()=>c,default:()=>h,frontMatter:()=>s,metadata:()=>a,toc:()=>m});const a=JSON.parse('{"id":"tracing/integrations/listing/semantic_kernel","title":"Tracing Semantic Kernel","description":"Semantic Kernel is a lightweight, open-source SDK that functions as AI middleware, enabling you to integrate AI models into your C#, Python, or Java codebase via a uniform API layer. By abstracting model interactions, it lets you swap in new models without rewriting your application logic.","source":"@site/docs/genai/tracing/integrations/listing/semantic_kernel.mdx","sourceDirName":"tracing/integrations/listing","slug":"/tracing/integrations/listing/semantic_kernel","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/semantic_kernel","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6,"sidebar_label":"Semantic Kernel"},"sidebar":"genAISidebar","previous":{"title":"AutoGen","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/autogen"},"next":{"title":"CrewAI","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/crewai"}}');var t=l(74848),i=l(28453),r=l(49374),o=(l(10493),l(66927));l(14252),l(11470),l(19365);const s={sidebar_position:6,sidebar_label:"Semantic Kernel"},c="Tracing Semantic Kernel",p={},m=[{value:"Getting Started",id:"getting-started",level:2},{value:"Example Usage",id:"example-usage",level:2},{value:"Token Usage Tracking",id:"token-usage-tracking",level:2},{value:"Disable Auto-tracing",id:"disable-auto-tracing",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"tracing-semantic-kernel",children:"Tracing Semantic Kernel"})}),"\n",(0,t.jsx)(o.A,{src:"/images/llms/tracing/semantic-kernel-tracing.png",alt:"Semantic Kernel Tracing via autolog"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://learn.microsoft.com/en-us/semantic-kernel/overview/",children:"Semantic Kernel"})," is a lightweight, open-source SDK that functions as AI middleware, enabling you to integrate AI models into your C#, Python, or Java codebase via a uniform API layer. By abstracting model interactions, it lets you swap in new models without rewriting your application logic."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"/genai/tracing",children:"MLflow Tracing"})," provides automatic tracing capability for Semantic Kernel. By enabling auto tracing for Semantic Kernel via the ",(0,t.jsx)(r.B,{fn:"mlflow.semantic_kernel.autolog"})," function, MLflow will capture traces for LLM invocations and log them to the active MLflow Experiment."]}),"\n",(0,t.jsx)(n.p,{children:"MLflow trace automatically captures the following information about Semantic Kernel calls:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Prompts and completion responses"}),"\n",(0,t.jsx)(n.li,{children:"Chat history and messages"}),"\n",(0,t.jsx)(n.li,{children:"Latencies"}),"\n",(0,t.jsx)(n.li,{children:"Model name and provider"}),"\n",(0,t.jsx)(n.li,{children:"Kernel functions and plugins"}),"\n",(0,t.jsx)(n.li,{children:"Template variables and arguments"}),"\n",(0,t.jsx)(n.li,{children:"Token usage information"}),"\n",(0,t.jsx)(n.li,{children:"Any exceptions if raised"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Currently, tracing for streaming is not supported. If you want this feature, please file a ",(0,t.jsx)(n.a,{href:"https://github.com/mlflow/mlflow/issues",children:"feature request"}),"."]}),"\n",(0,t.jsx)(n.h2,{id:"getting-started",children:"Getting Started"}),"\n",(0,t.jsx)(n.p,{children:"To get started, let's install the requisite libraries. Note that we will use OpenAI for demonstration purposes, but this tutorial extends to all providers supported by Semantic Kernel."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"pip install 'mlflow>=3.2.0' semantic_kernel openai\n"})}),"\n",(0,t.jsx)(n.p,{children:"Then, enable autologging in your Python code:"}),"\n",(0,t.jsx)(n.admonition,{type:"important",children:(0,t.jsxs)(n.p,{children:["You must run ",(0,t.jsx)(n.code,{children:"mlflow.semantic_kernel.autolog()"})," prior to running Semantic Kernel code. If this is not performed, traces may not be logged properly."]})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import mlflow\n\nmlflow.semantic_kernel.autolog()\n"})}),"\n",(0,t.jsx)(n.p,{children:"Finally, for setup, let's establish our OpenAI token:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import os\nfrom getpass import getpass\n\n# Set the OpenAI API key as an environment variable\nos.environ["OPENAI_API_KEY"] = getpass("openai_api_key: ")\n'})}),"\n",(0,t.jsx)(n.h2,{id:"example-usage",children:"Example Usage"}),"\n",(0,t.jsx)(n.admonition,{type:"note",children:(0,t.jsxs)(n.p,{children:["Semantic Kernel primarily uses asynchronous programming patterns. The examples below use ",(0,t.jsx)(n.code,{children:"async"}),"/",(0,t.jsx)(n.code,{children:"await"})," syntax. If you're running these in a Jupyter notebook, the code will work as-is. For scripts, you'll need to wrap the async calls appropriately (e.g., using ",(0,t.jsx)(n.code,{children:"asyncio.run()"}),")."]})}),"\n",(0,t.jsxs)(n.p,{children:["The simplest example to show the tracing integration is to instrument a ",(0,t.jsx)(n.a,{href:"https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/?tabs=csharp-AzureOpenAI%2Cpython-AzureOpenAI%2Cjava-AzureOpenAI&pivots=programming-language-python",children:"ChatCompletion Kernel"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import openai\nfrom semantic_kernel import Kernel\nfrom semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\nfrom semantic_kernel.functions.function_result import FunctionResult\n\n# Create a basic OpenAI client\nopenai_client = openai.AsyncOpenAI()\n\n# Create a Semantic Kernel instance and register the OpenAI chat completion service\nkernel = Kernel()\nkernel.add_service(\n    OpenAIChatCompletion(\n        service_id="chat-gpt",\n        ai_model_id="gpt-4o-mini",\n        async_client=openai_client,\n    )\n)\n\nanswer = await kernel.invoke_prompt("Is sushi the best food ever?")\nprint("AI says:", answer)\n'})}),"\n",(0,t.jsx)(n.h2,{id:"token-usage-tracking",children:"Token Usage Tracking"}),"\n",(0,t.jsxs)(n.p,{children:["MLflow >= 3.2.0 supports token usage tracking for Semantic Kernel. The token usage for each LLM call during a kernel invocation will be logged in the ",(0,t.jsx)(n.code,{children:"mlflow.chat.tokenUsage"})," span attribute, and the total usage in the entire trace will be logged in the ",(0,t.jsx)(n.code,{children:"mlflow.trace.tokenUsage"})," metadata field."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Generate a trace using the above example\n# ...\n\n\n# Get the trace object just created\nlast_trace_id = mlflow.get_last_active_trace_id()\ntrace = mlflow.get_trace(trace_id=last_trace_id)\n\n# Print the token usage\ntotal_usage = trace.info.token_usage\nprint("== Total token usage: ==")\nprint(f"  Input tokens: {total_usage[\'input_tokens\']}")\nprint(f"  Output tokens: {total_usage[\'output_tokens\']}")\nprint(f"  Total tokens: {total_usage[\'total_tokens\']}")\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"== Total token usage: ==\n  Input tokens: 14\n  Output tokens: 113\n  Total tokens: 127\n"})}),"\n",(0,t.jsx)(n.h2,{id:"disable-auto-tracing",children:"Disable Auto-tracing"}),"\n",(0,t.jsxs)(n.p,{children:["Auto tracing for Semantic Kernel can be disabled globally by calling ",(0,t.jsx)(n.code,{children:"mlflow.semantic_kernel.autolog(disable=True)"})," or ",(0,t.jsx)(n.code,{children:"mlflow.autolog(disable=True)"}),"."]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},49374:(e,n,l)=>{l.d(n,{B:()=>o});l(96540);const a=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}');var t=l(86025),i=l(74848);const r=e=>{const n=e.split(".");for(let l=n.length;l>0;l--){const e=n.slice(0,l).join(".");if(a[e])return e}return null};function o({fn:e,children:n,hash:l}){const o=r(e);if(!o)return(0,i.jsx)(i.Fragment,{children:n});const s=(0,t.Ay)(`/${a[o]}#${l??e}`);return(0,i.jsx)("a",{href:s,target:"_blank",children:n??(0,i.jsxs)("code",{children:[e,"()"]})})}},66927:(e,n,l)=>{l.d(n,{A:()=>r});l(96540);const a={container:"container_JwLF",imageWrapper:"imageWrapper_RfGN",image:"image_bwOA",caption:"caption_jo2G"};var t=l(86025),i=l(74848);function r({src:e,alt:n,width:l,caption:r,className:o}){return(0,i.jsxs)("div",{className:`${a.container} ${o||""}`,children:[(0,i.jsx)("div",{className:a.imageWrapper,style:l?{width:l}:{},children:(0,i.jsx)("img",{src:(0,t.Ay)(e),alt:n,className:a.image})}),r&&(0,i.jsx)("p",{className:a.caption,children:r})]})}}}]);