"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[231],{2406:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>p,contentTitle:()=>a,default:()=>d,frontMatter:()=>l,metadata:()=>i,toc:()=>m});const i=JSON.parse('{"id":"prompt-registry/optimize-prompts","title":"Optimize Prompts (Experimental)","description":"MLflow offers the  API, enabling you to automatically improve your prompts using evaluation metrics and training data. This powerful feature allows you to enhance prompt effectiveness across any agent framework by applying prompt optimization algorithms, reducing manual effort and ensuring consistent quality.","source":"@site/docs/genai/prompt-registry/optimize-prompts.mdx","sourceDirName":"prompt-registry","slug":"/prompt-registry/optimize-prompts","permalink":"/mlflow-website/docs/latest/genai/prompt-registry/optimize-prompts","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"sidebar_label":"Optimize Prompts"},"sidebar":"genAISidebar","previous":{"title":"Structured Output","permalink":"/mlflow-website/docs/latest/genai/prompt-registry/structured-output"},"next":{"title":"Auto-rewrite Prompts for New Models \ud83c\udd95","permalink":"/mlflow-website/docs/latest/genai/prompt-registry/rewrite-prompts"}}');var r=t(74848),o=t(28453),s=t(49374);const l={sidebar_position:5,sidebar_label:"Optimize Prompts"},a="Optimize Prompts (Experimental)",p={},m=[{value:"Quick Start",id:"quick-start",level:2},{value:"Example: Simple Prompt \u2192 Optimized Prompt",id:"example-simple-prompt--optimized-prompt",level:3},{value:"Components",id:"components",level:2},{value:"1. Target Prompt URIs",id:"1-target-prompt-uris",level:3},{value:"2. Predict Function",id:"2-predict-function",level:3},{value:"3. Training Data",id:"3-training-data",level:3},{value:"4. Optimizer",id:"4-optimizer",level:3},{value:"Advanced Usage",id:"advanced-usage",level:2},{value:"Using Custom Scorers",id:"using-custom-scorers",level:3},{value:"Custom Optimization Algorithm",id:"custom-optimization-algorithm",level:3},{value:"Multi-Prompt Optimization",id:"multi-prompt-optimization",level:3},{value:"Use Agent Framework",id:"use-agent-framework",level:3},{value:"Result Object",id:"result-object",level:2},{value:"Common Use Cases",id:"common-use-cases",level:2},{value:"Improving Accuracy",id:"improving-accuracy",level:3},{value:"Optimizing for Safeness",id:"optimizing-for-safeness",level:3},{value:"Model Switching and Migration",id:"model-switching-and-migration",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Issue: Optimization Takes Too Long",id:"issue-optimization-takes-too-long",level:3},{value:"Issue: No Improvement Observed",id:"issue-no-improvement-observed",level:3},{value:"Issue: Prompts Not Being Used",id:"issue-prompts-not-being-used",level:3},{value:"See Also",id:"see-also",level:2}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"optimize-prompts-experimental",children:"Optimize Prompts (Experimental)"})}),"\n",(0,r.jsxs)(n.p,{children:["MLflow offers the ",(0,r.jsx)(s.B,{fn:"mlflow.genai.optimize_prompts"})," API, enabling you to automatically improve your prompts using evaluation metrics and training data. This powerful feature allows you to enhance prompt effectiveness across any agent framework by applying prompt optimization algorithms, reducing manual effort and ensuring consistent quality."]}),"\n",(0,r.jsxs)(n.p,{children:["Currently, MLflow supports the ",(0,r.jsx)(n.a,{href:"https://arxiv.org/abs/2507.19457",children:"GEPA"})," optimization algorithm through the ",(0,r.jsx)(s.B,{fn:"mlflow.genai.optimize.GepaPromptOptimizer",children:(0,r.jsx)(n.code,{children:"GepaPromptOptimizer"})}),". GEPA iteratively refines prompts using LLM-driven reflection and automated feedback, leading to systematic and data-driven improvements."]}),"\n",(0,r.jsx)(n.admonition,{title:"Key Benefits",type:"tip",children:(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Automatic Improvement"}),": Optimize prompts based on evaluation metrics without manual tuning"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Data-Driven Optimization"}),": Uses your training data and custom scorers to guide optimization"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Framework Agnostic"}),": Works with any agent framework, providing broad compatibility"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Joint Optimization"}),": Enable the simultaneous refinement of multiple prompts for best overall performance"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Flexible Evaluation"}),": Support for custom scorers and aggregation function"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Version Control"}),": Automatically registers optimized prompts in MLflow Prompt Registry"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Extensible"}),": Plug in custom optimization algorithms by extending the base class"]}),"\n"]})}),"\n",(0,r.jsx)(n.admonition,{title:"Version Requirements",type:"note",children:(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.code,{children:"optimize_prompts"})," API requires ",(0,r.jsx)(n.strong,{children:"MLflow >= 3.5.0"}),"."]})}),"\n",(0,r.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,r.jsx)(n.p,{children:"Here's a simple example of optimizing a prompt for better accuracy:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport openai\nfrom mlflow.genai.optimize import GepaPromptOptimizer\nfrom mlflow.genai.scorers import Correctness\n\n# Register initial prompt\nprompt = mlflow.genai.register_prompt(\n    name="qa",\n    template="Answer this question: {{question}}",\n)\n\n\n# Define your prediction function\ndef predict_fn(question: str) -> str:\n    prompt = mlflow.genai.load_prompt("prompts:/qa/1")\n    completion = openai.OpenAI().chat.completions.create(\n        model="gpt-5-mini",\n        messages=[{"role": "user", "content": prompt.format(question=question)}],\n    )\n    return completion.choices[0].message.content\n\n\n# Training data with inputs and expected outputs\ndataset = [\n    {\n        # The inputs schema should match with the input arguments of the prediction function.\n        "inputs": {"question": "What is the capital of France?"},\n        "expectations": {"expected_response": "Paris"},\n    },\n    {\n        "inputs": {"question": "What is the capital of Germany?"},\n        "expectations": {"expected_response": "Berlin"},\n    },\n    {\n        "inputs": {"question": "What is the capital of Japan?"},\n        "expectations": {"expected_response": "Tokyo"},\n    },\n    {\n        "inputs": {"question": "What is the capital of Italy?"},\n        "expectations": {"expected_response": "Rome"},\n    },\n]\n\n# Optimize the prompt\nresult = mlflow.genai.optimize_prompts(\n    predict_fn=predict_fn,\n    train_data=dataset,\n    prompt_uris=[prompt.uri],\n    optimizer=GepaPromptOptimizer(reflection_model="openai:/gpt-5"),\n    scorers=[Correctness(model="openai:/gpt-5")],\n)\n\n# Use the optimized prompt\noptimized_prompt = result.optimized_prompts[0]\nprint(f"Optimized template: {optimized_prompt.template}")\n'})}),"\n",(0,r.jsx)(n.p,{children:"The API will produce an improved prompt that performs better on your evaluation criteria."}),"\n",(0,r.jsx)(n.h3,{id:"example-simple-prompt--optimized-prompt",children:"Example: Simple Prompt \u2192 Optimized Prompt"}),"\n",(0,r.jsx)("table",{children:(0,r.jsxs)("tr",{children:[(0,r.jsxs)("td",{width:"50%",valign:"top",children:[(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Before Optimization:"})}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:"Answer this question: {{question}}\n"})})]}),(0,r.jsxs)("td",{width:"50%",valign:"top",children:[(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"After Optimization:"})}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-text",children:'Answer this question: {{question}}.\nFocus on providing precise,\nfactual information without additional commentary or explanations.\n\n1. **Identify the Subject**: Clearly determine the specific subject\nof the question (e.g., geography, history)\nand provide a concise answer.\n\n2. **Clarity and Precision**: Your response should be a single,\nclear statement that directly addresses the question.\nDo not add extra details, context, or alternatives.\n\n3. **Expected Format**: The expected output should be the exact answer\nwith minimal words where appropriate.\nFor instance, when asked about capitals, the answer should\nsimply state the name of the capital city,\ne.g., "Tokyo" for Japan, "Rome" for Italy, and "Paris" for France.\n\n4. **Handling Variations**: If the question contains multiple\nparts or variations, focus on the primary query\n and answer it directly. Avoid over-complication.\n\n5. **Niche Knowledge**: Ensure that the responses are based on\ncommonly accepted geographic and historical facts,\nas this type of information is crucial for accuracy in your answers.\n\nAdhere strictly to these guidelines to maintain consistency\nand quality in your responses.\n'})})]})]})}),"\n",(0,r.jsx)(n.h2,{id:"components",children:"Components"}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(s.B,{fn:"mlflow.genai.optimize_prompts"})," API requires the following components:"]}),"\n",(0,r.jsxs)("table",{style:{width:"100%"},children:[(0,r.jsx)("thead",{children:(0,r.jsxs)("tr",{children:[(0,r.jsx)("th",{style:{width:"30%"},children:"Component"}),(0,r.jsx)("th",{style:{width:"70%"},children:"Description"})]})}),(0,r.jsxs)("tbody",{children:[(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{children:(0,r.jsx)("strong",{children:"Target Prompt URIs"})}),(0,r.jsxs)("td",{children:["List of prompt URIs to optimize (e.g., ",(0,r.jsx)("code",{children:'["prompts:/qa/1"]'}),")"]})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{children:(0,r.jsx)("strong",{children:"Predict Function"})}),(0,r.jsx)("td",{children:"A callable that takes inputs as keyword arguments and returns outputs. Must use prompts from MLflow Prompt Registry."})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{children:(0,r.jsx)("strong",{children:"Training Data"})}),(0,r.jsxs)("td",{children:["Dataset with ",(0,r.jsx)("code",{children:"inputs"})," (dict) and ",(0,r.jsx)("code",{children:"outputs"})," (expected results). Supports pandas DataFrame, list of dicts, or MLflow EvaluationDataset."]})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{children:(0,r.jsx)("strong",{children:"Optimizer"})}),(0,r.jsxs)("td",{children:["Prompt optimizer instance (e.g., ",(0,r.jsx)(s.B,{fn:"mlflow.genai.optimize.GepaPromptOptimizer",children:(0,r.jsx)(n.code,{children:"GepaPromptOptimizer"})}),")"]})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"1-target-prompt-uris",children:"1. Target Prompt URIs"}),"\n",(0,r.jsx)(n.p,{children:"Specify which prompts to optimize using their URIs from MLflow Prompt Registry:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'prompt_uris = [\n    "prompts:/qa/1",  # Specific version\n    "prompts:/instruction@latest",  # Latest version\n]\n'})}),"\n",(0,r.jsx)(n.p,{children:"You can reference prompts by:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Specific version"}),": ",(0,r.jsx)(n.code,{children:'"prompts:/qa/1"'})," - Optimize a particular version"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Latest version"}),": ",(0,r.jsx)(n.code,{children:'"prompts:/qa@latest"'})," - Optimize the most recent version"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Alias"}),": ",(0,r.jsx)(n.code,{children:'"prompts:/qa@champion"'})," - Optimize a version with a specific alias"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"2-predict-function",children:"2. Predict Function"}),"\n",(0,r.jsxs)(n.p,{children:["Your ",(0,r.jsx)(n.code,{children:"predict_fn"})," must:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Accept inputs as keyword arguments matching the inputs field of the dataset"}),"\n",(0,r.jsxs)(n.li,{children:["Use MLflow Prompt Registry and format and call ",(0,r.jsx)(s.B,{fn:"mlflow.entities.model_registry.PromptVersion.format",children:(0,r.jsx)(n.code,{children:"PromptVersion.format"})})," during execution"]}),"\n",(0,r.jsxs)(n.li,{children:["Return outputs in the same format as your training data (e.g., ",(0,r.jsx)(n.code,{children:'{"answer": "xxx"}'})," is the expectations are ",(0,r.jsx)(n.code,{children:'{"expected_response": {"answer": "xxx"}}'}),")"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def predict_fn(question: str) -> str:\n    # Load prompt from registry\n    prompt = mlflow.genai.load_prompt("prompts:/qa/1")\n\n    # Format the prompt with input variables\n    formatted_prompt = prompt.format(question=question)\n\n    # Call your LLM\n    response = your_llm_call(formatted_prompt)\n\n    return response\n'})}),"\n",(0,r.jsx)(n.h3,{id:"3-training-data",children:"3. Training Data"}),"\n",(0,r.jsxs)(n.p,{children:["Provide a dataset with ",(0,r.jsx)(n.code,{children:"inputs"})," and ",(0,r.jsx)(n.code,{children:"expectations"}),". Both columns should have dictionary values. ",(0,r.jsx)(n.code,{children:"inputs"})," values will be passed to the predict function as keyword arguments. Please refer to ",(0,r.jsx)(n.a,{href:"/genai/eval-monitor/scorers/llm-judge/predefined/",children:"Predefined LLM Scorers"})," for the expected format of each built in scorers."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# List of dictionaries\ndataset = [\n    {\n        "inputs": {"question": "What is AI?"},\n        "expectations": {"expected_response": "Artificial Intelligence"},\n    },\n    {\n        "inputs": {"question": "What is ML?"},\n        "expectations": {"expected_response": "Machine Learning"},\n    },\n]\n\n# Or pandas DataFrame\nimport pandas as pd\n\ndataset = pd.DataFrame(\n    {\n        "inputs": [\n            {"question": "What is AI?"},\n            {"question": "What is ML?"},\n        ],\n        "expectations": [\n            {"expected_response": "Artificial Intelligence"},\n            {"expected_response": "Machine Learning"},\n        ],\n    }\n)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"4-optimizer",children:"4. Optimizer"}),"\n",(0,r.jsxs)(n.p,{children:["Create an optimizer instance for the optimization algorithm. Currently only ",(0,r.jsx)(s.B,{fn:"mlflow.genai.optimize.GepaPromptOptimizer",children:(0,r.jsx)(n.code,{children:"GepaPromptOptimizer"})})," is supported natively."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from mlflow.genai.optimize import GepaPromptOptimizer\n\noptimizer = GepaPromptOptimizer(\n    reflection_model="openai:/gpt-5",  # Powerful model for optimization\n    max_metric_calls=100,\n    display_progress_bar=False,\n)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"advanced-usage",children:"Advanced Usage"}),"\n",(0,r.jsx)(n.h3,{id:"using-custom-scorers",children:"Using Custom Scorers"}),"\n",(0,r.jsx)(n.p,{children:"Define custom evaluation metrics to guide optimization:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from typing import Any\nfrom mlflow.genai.scorers import scorer\n\n\n@scorer\ndef accuracy_scorer(outputs: Any, expectations: dict[str, Any]):\n    """Check if output matches expected value."""\n    return 1.0 if outputs.lower() == expectations.lower() else 0.0\n\n\n@scorer\ndef brevity_scorer(outputs: Any):\n    """Prefer shorter outputs (max 50 chars)."""\n    return min(1.0, 50 / max(len(outputs), 1))\n\n\n# Combine scorers with a weighted objective\ndef weighted_objective(scores: dict[str, Any]):\n    return 0.7 * scores["accuracy_scorer"] + 0.3 * scores["brevity_scorer"]\n\n\n# Use custom scorers\nresult = mlflow.genai.optimize_prompts(\n    predict_fn=predict_fn,\n    train_data=dataset,\n    prompt_uris=[prompt.uri],\n    optimizer=GepaPromptOptimizer(reflection_model="openai:/gpt-5"),\n    scorers=[accuracy_scorer, brevity_scorer],\n    aggregation=weighted_objective,\n)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"custom-optimization-algorithm",children:"Custom Optimization Algorithm"}),"\n",(0,r.jsxs)(n.p,{children:["Implement your own optimizer by extending ",(0,r.jsx)(s.B,{fn:"mlflow.genai.optimize.BasePromptOptimizer",children:(0,r.jsx)(n.code,{children:"BasePromptOptimizer"})}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from mlflow.genai.optimize import BasePromptOptimizer, PromptOptimizerOutput\nfrom mlflow.genai.scorers import Correctness\n\n\nclass MyCustomOptimizer(BasePromptOptimizer):\n    def __init__(self, model_name: str):\n        self.model_name = model_name\n\n    def optimize(self, eval_fn, train_data, target_prompts, enable_tracking):\n        # Your custom optimization logic\n        optimized_prompts = {}\n        for prompt_name, prompt_template in target_prompts.items():\n            # Implement your algorithm\n            optimized_prompts[prompt_name] = your_optimization_algorithm(\n                prompt_template, train_data, self.model_name\n            )\n\n        return PromptOptimizerOutput(optimized_prompts=optimized_prompts)\n\n\n# Use custom optimizer\nresult = mlflow.genai.optimize_prompts(\n    predict_fn=predict_fn,\n    train_data=dataset,\n    prompt_uris=[prompt.uri],\n    optimizer=MyCustomOptimizer(model_name="openai:/gpt-5"),\n    scorers=[Correctness(model="openai:/gpt-5")],\n)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"multi-prompt-optimization",children:"Multi-Prompt Optimization"}),"\n",(0,r.jsx)(n.p,{children:"Optimize multiple prompts together:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom mlflow.genai.scorers import Correctness\n\n# Register multiple prompts\nplan_prompt = mlflow.genai.register_prompt(\n    name="plan",\n    template="Make a plan to answer {{question}}.",\n)\nanswer_prompt = mlflow.genai.register_prompt(\n    name="answer",\n    template="Answer {{question}} following the plan: {{plan}}",\n)\n\n\ndef predict_fn(question: str) -> str:\n    plan_prompt = mlflow.genai.load_prompt("prompts:/plan/1")\n    completion = openai.OpenAI().chat.completions.create(\n        model="gpt-5",  # strong model\n        messages=[{"role": "user", "content": plan_prompt.format(question=question)}],\n    )\n    plan = completion.choices[0].message.content\n\n    answer_prompt = mlflow.genai.load_prompt("prompts:/answer/1")\n    completion = openai.OpenAI().chat.completions.create(\n        model="gpt-5-mini",  # cost efficient model\n        messages=[\n            {\n                "role": "user",\n                "content": answer_prompt.format(question=question, plan=plan),\n            }\n        ],\n    )\n    return completion.choices[0].message.content\n\n\n# Optimize both\nresult = mlflow.genai.optimize_prompts(\n    predict_fn=predict_fn,\n    train_data=dataset,\n    prompt_uris=[plan_prompt.uri, answer_prompt.uri],\n    optimizer=GepaPromptOptimizer(reflection_model="openai:/gpt-5"),\n    scorers=[Correctness(model="openai:/gpt-5")],\n)\n\n# Access optimized prompts\noptimized_plan = result.optimized_prompts[0]\noptimized_answer = result.optimized_prompts[1]\n'})}),"\n",(0,r.jsx)(n.h3,{id:"use-agent-framework",children:"Use Agent Framework"}),"\n",(0,r.jsxs)(n.p,{children:["You can optimize your prompt used with agent frameworks. The example below optimizes a prompt for a LangChain workflow. Note that we call ",(0,r.jsx)(s.B,{fn:"mlflow.entities.model_registry.PromptVersion.to_single_brace_format",children:(0,r.jsx)(n.code,{children:"PromptVersion.to_single_brace_format()"})})," instead of ",(0,r.jsx)(n.code,{children:"format"})," inside ",(0,r.jsx)(n.code,{children:"predict_fn"}),". This is one of the exceptions that is allowed, however ",(0,r.jsx)(s.B,{fn:"mlflow.genai.optimize_prompts"})," generally requires ",(0,r.jsx)(n.code,{children:"predict_fn"})," to call ",(0,r.jsx)(s.B,{fn:"mlflow.entities.model_registry.PromptVersion.format",children:(0,r.jsx)(n.code,{children:"PromptVersion.format()"})}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom mlflow.genai.scorers import Correctness\nfrom mlflow.genai.optimize.optimizers import GepaPromptOptimizer\nfrom langchain.prompts import PromptTemplate\nfrom langchain.llms import OpenAI\nfrom langchain.chains import LLMChain\n\n\ndef predict_fn(input_language, output_language, text):\n    template = PromptTemplate(\n        input_variables=["input_language", "output_language", "text"],\n        template=prompt.to_single_brace_format(),  # call to_single_brace_format\n    )\n\n    llm = OpenAI(temperature=0.7)\n\n    chain = LLMChain(llm=llm, prompt=template)\n\n    result = chain.run(\n        input_language=input_language, output_language=output_language, text=text\n    )\n\n    return result\n\n\ndataset = [\n    {\n        "inputs": {\n            "input_language": "English",\n            "output_language": "French",\n            "text": "Hello, how are you?",\n        },\n        "expectations": {"expected_response": "Bonjour, comment allez-vous?"},\n    },\n    {\n        "inputs": {\n            "input_language": "English",\n            "output_language": "Spanish",\n            "text": "Good morning",\n        },\n        "expectations": {"expected_response": "Buenos d\xedas"},\n    },\n    {\n        "inputs": {\n            "input_language": "English",\n            "output_language": "German",\n            "text": "Thank you very much",\n        },\n        "expectations": {"expected_response": "Vielen Dank"},\n    },\n]\n\nresult = mlflow.genai.optimize_prompts(\n    predict_fn=predict_fn,\n    train_data=dataset,\n    prompt_uris=[prompt.uri],\n    optimizer=GepaPromptOptimizer(reflection_model="openai:/gpt-5"),\n    scorers=[Correctness(model="openai:/gpt-5")],\n)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"result-object",children:"Result Object"}),"\n",(0,r.jsxs)(n.p,{children:["The API returns a ",(0,r.jsx)(s.B,{fn:"mlflow.genai.optimize.PromptOptimizationResult",children:(0,r.jsx)(n.code,{children:"PromptOptimizationResult"})})," object:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'result = mlflow.genai.optimize_prompts(...)\n\n# Access optimized prompts\nfor prompt in result.optimized_prompts:\n    print(f"Name: {prompt.name}")\n    print(f"Version: {prompt.version}")\n    print(f"Template: {prompt.template}")\n    print(f"URI: {prompt.uri}")\n\n# Check optimizer used\nprint(f"Optimizer: {result.optimizer_name}")\n\n# View evaluation scores (if available)\nprint(f"Initial score: {result.initial_eval_score}")\nprint(f"Final score: {result.final_eval_score}")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"common-use-cases",children:"Common Use Cases"}),"\n",(0,r.jsx)(n.h3,{id:"improving-accuracy",children:"Improving Accuracy"}),"\n",(0,r.jsx)(n.p,{children:"Optimize prompts to produce more accurate outputs:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from mlflow.genai.scorers import Correctness\n\n\nresult = mlflow.genai.optimize_prompts(\n    predict_fn=predict_fn,\n    train_data=dataset,\n    prompt_uris=[prompt.uri],\n    optimizer=GepaPromptOptimizer(reflection_model="openai:/gpt-5"),\n    scorers=[Correctness(model="openai:/gpt-5")],\n)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"optimizing-for-safeness",children:"Optimizing for Safeness"}),"\n",(0,r.jsx)(n.p,{children:"Ensure outputs are safe:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from mlflow.genai.scorers import Safety\n\n\nresult = mlflow.genai.optimize_prompts(\n    predict_fn=predict_fn,\n    train_data=dataset,\n    prompt_uris=[prompt.uri],\n    optimizer=GepaPromptOptimizer(reflection_model="openai:/gpt-5"),\n    scorers=[Safety(model="openai:/gpt-5")],\n)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"model-switching-and-migration",children:"Model Switching and Migration"}),"\n",(0,r.jsxs)(n.p,{children:["When switching between different language models (e.g., migrating from ",(0,r.jsx)(n.code,{children:"gpt-5"})," to ",(0,r.jsx)(n.code,{children:"gpt-5-mini"})," for cost reduction), you may need to rewrite your prompts to maintain output quality with the new model. The ",(0,r.jsx)(s.B,{fn:"mlflow.genai.optimize_prompts"})," API can help adapt prompts automatically using your existing application outputs as training data."]}),"\n",(0,r.jsxs)(n.p,{children:["See the ",(0,r.jsx)(n.a,{href:"/genai/prompt-registry/rewrite-prompts",children:"Auto-rewrite Prompts for New Models"})," guide for a complete model migration workflow."]}),"\n",(0,r.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,r.jsx)(n.h3,{id:"issue-optimization-takes-too-long",children:"Issue: Optimization Takes Too Long"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Solution"}),": Reduce dataset size or reduce the optimizer budget:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Use fewer examples\nsmall_dataset = dataset[:20]\n\n# Use faster model for optimization\noptimizer = GepaPromptOptimizer(\n    reflection_model="openai:/gpt-5-mini", max_metric_calls=100\n)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"issue-no-improvement-observed",children:"Issue: No Improvement Observed"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Solution"}),": Check your evaluation metrics and increase dataset diversity:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Ensure scorers accurately measure what you care about"}),"\n",(0,r.jsx)(n.li,{children:"Increase training data size and diversity"}),"\n",(0,r.jsx)(n.li,{children:"Try to modify optimizer configurations"}),"\n",(0,r.jsx)(n.li,{children:"Verify outputs format matches expectations"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"issue-prompts-not-being-used",children:"Issue: Prompts Not Being Used"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Solution"}),": Ensure ",(0,r.jsx)(n.code,{children:"predict_fn"})," calls ",(0,r.jsx)(s.B,{fn:"mlflow.entities.model_registry.PromptVersion.format",children:(0,r.jsx)(n.code,{children:"PromptVersion.format()"})})," during execution:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# \u2705 Correct - loads from registry\ndef predict_fn(question: str):\n    prompt = mlflow.genai.load_prompt("prompts:/qa@latest")\n    return llm_call(prompt.format(question=question))\n\n\n# \u274c Incorrect - hardcoded prompt\ndef predict_fn(question: str):\n    return llm_call(f"Answer: {question}")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"see-also",children:"See Also"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/genai/prompt-registry/rewrite-prompts",children:"Auto-rewrite Prompts for New Models"}),": Adapt prompts when switching between language models"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/genai/prompt-registry/create-and-edit-prompts",children:"Create and Edit Prompts"}),": Basic Prompt Registry usage"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"/genai/eval-monitor/running-evaluation/prompts",children:"Evaluate Prompts"}),": Evaluate prompt performance"]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>l});var i=t(96540);const r={},o=i.createContext(r);function s(e){const n=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),i.createElement(o.Provider,{value:n},e.children)}},49374:(e,n,t)=>{t.d(n,{B:()=>l});t(96540);const i=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}');var r=t(86025),o=t(74848);const s=e=>{const n=e.split(".");for(let t=n.length;t>0;t--){const e=n.slice(0,t).join(".");if(i[e])return e}return null};function l({fn:e,children:n,hash:t}){const l=s(e);if(!l)return(0,o.jsx)(o.Fragment,{children:n});const a=(0,r.Ay)(`/${i[l]}#${t??e}`);return(0,o.jsx)("a",{href:a,target:"_blank",children:n??(0,o.jsxs)("code",{children:[e,"()"]})})}}}]);