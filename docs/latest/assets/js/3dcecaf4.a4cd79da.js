"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[9044],{29225:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/trace-set-tag-c0cbad6b75c04328db03a8f1eb4c3a09.gif"},53579:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>p,frontMatter:()=>o,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"tracing/api/how-to","title":"Tracing SDK How-to Guides","description":"Render Trace inside Jupyter Notebook","source":"@site/docs/tracing/api/how-to.mdx","sourceDirName":"tracing/api","slug":"/tracing/api/how-to","permalink":"/docs/latest/tracing/api/how-to","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"sidebar_label":"How-to Guide"},"sidebar":"docsSidebar","previous":{"title":"Query Traces","permalink":"/docs/latest/tracing/api/search"},"next":{"title":"Low-level Client APIs","permalink":"/docs/latest/tracing/api/client"}}');var r=n(74848),l=n(28453),i=n(67756);n(86294),n(61096),n(65537),n(79329);const o={sidebar_position:3,sidebar_label:"How-to Guide"},s="Tracing SDK How-to Guides",c={},d=[{value:"Render Trace inside Jupyter Notebook",id:"render-trace-inside-jupyter-notebook",level:2},{value:"Manually Creating a Trace and a Span",id:"manually-creating-a-trace-and-a-span",level:2},{value:"Setting Trace Tags",id:"setting-trace-tags",level:2},{value:"Setting Tags on an Active Trace",id:"setting-tags-on-an-active-trace",level:3},{value:"Setting Tags on a Finished Trace",id:"setting-tags-on-a-finished-trace",level:3},{value:"Setting Tags via the MLflow UI",id:"setting-tags-via-the-mlflow-ui",level:3},{value:"Delete Traces",id:"delete-traces",level:2},{value:"Disabling Traces",id:"disabling-traces",level:2},{value:"Associating Traces to MLflow Run",id:"associating-traces-to-mlflow-run",level:2},{value:"Logging Traces Asynchronously",id:"logging-traces-asynchronously",level:2},{value:"Customize Request and Response Preview in Trace UI",id:"customize-request-and-response-preview-in-trace-ui",level:2}];function h(e){const t={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,l.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"tracing-sdk-how-to-guides",children:"Tracing SDK How-to Guides"})}),"\n",(0,r.jsx)(t.h2,{id:"render-trace-inside-jupyter-notebook",children:"Render Trace inside Jupyter Notebook"}),"\n",(0,r.jsx)(t.admonition,{type:"note",children:(0,r.jsxs)(t.p,{children:["Jupyter integration is available in ",(0,r.jsx)(t.strong,{children:"MLflow 2.20 and above"})]})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.img,{alt:"MLflow Trace UI in Jupyter Notebook",src:n(72371).A+"",width:"2440",height:"1586"})}),"\n",(0,r.jsxs)(t.p,{children:["The trace UI is also available within Jupyter notebooks!\nThis feature requires using an ",(0,r.jsx)(t.a,{href:"/tracking/server",children:"MLflow Tracking Server"}),", as\nthis is where the UI assets are fetched from. To get started, simply ensure that the MLflow\nTracking URI is set to your tracking server (e.g. ",(0,r.jsx)(t.code,{children:'mlflow.set_tracking_uri("http://localhost:5000")'}),")."]}),"\n",(0,r.jsx)(t.p,{children:"By default, the trace UI will automatically be displayed for the following events:"}),"\n",(0,r.jsxs)(t.ol,{children:["\n",(0,r.jsxs)(t.li,{children:["When the cell code generates a trace (e.g. via  ",(0,r.jsx)(t.a,{href:"/tracing/#automatic-tracing",children:"automatic tracing"}),", or by running a manually traced function)"]}),"\n",(0,r.jsxs)(t.li,{children:["When ",(0,r.jsx)(i.B,{fn:"mlflow.search_traces"})," is called"]}),"\n",(0,r.jsxs)(t.li,{children:["When a ",(0,r.jsx)(i.B,{fn:"mlflow.entities.Trace"})," object is displayed (e.g. via IPython's ",(0,r.jsx)(t.code,{children:"display"})," function, or when it is the last value returned in a cell)"]}),"\n"]}),"\n",(0,r.jsxs)(t.p,{children:["To disable the display, simply call ",(0,r.jsx)(i.B,{fn:"mlflow.tracing.disable_notebook_display"}),", and rerun the cell\ncontaining the UI. To enable it again, call ",(0,r.jsx)(i.B,{fn:"mlflow.tracing.enable_notebook_display"}),"."]}),"\n",(0,r.jsxs)(t.p,{children:["For a more complete example, try running this ",(0,r.jsx)(t.a,{href:"/tracing/tutorials/jupyter-trace-demo",children:"demo notebook"}),"!"]}),"\n",(0,r.jsx)(t.h2,{id:"manually-creating-a-trace-and-a-span",children:"Manually Creating a Trace and a Span"}),"\n",(0,r.jsxs)(t.p,{children:["Please refer to the ",(0,r.jsx)(t.a,{href:"/tracing/api/manual-instrumentation",children:"Manual Tracing"})," guide for how to create a trace and span manually."]}),"\n",(0,r.jsx)(t.h2,{id:"setting-trace-tags",children:"Setting Trace Tags"}),"\n",(0,r.jsx)(t.p,{children:"Tags can be added to traces to provide additional metadata at the trace level. For example, you can attach a session ID to a trace to group traces by a conversation session. MLflow provides APIs to set and delete tags on traces. Select the right API based on whether you want to set tags on an active trace or on an already finished trace."}),"\n",(0,r.jsxs)("table",{children:[(0,r.jsx)("thead",{children:(0,r.jsxs)("tr",{children:[(0,r.jsx)("th",{children:"API / Method"}),(0,r.jsx)("th",{children:"Use Case"})]})}),(0,r.jsxs)("tbody",{children:[(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{children:(0,r.jsxs)(t.p,{children:[(0,r.jsx)(i.B,{fn:"mlflow.update_current_trace"})," API."]})}),(0,r.jsxs)("td",{children:["Setting tags on an ",(0,r.jsx)(t.strong,{children:"active"})," trace during the code execution."]})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{children:(0,r.jsxs)(t.p,{children:[(0,r.jsx)(i.B,{fn:"mlflow.set_trace_tag",children:(0,r.jsx)(t.code,{children:"mlflow.set_trace_tag"})})," API."]})}),(0,r.jsx)("td",{children:"Programmatically setting tags on a finished trace."})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{children:"MLflow UI"}),(0,r.jsx)("td",{children:"Setting tags on a finished trace conveniently."})]})]})]}),"\n",(0,r.jsx)(t.h3,{id:"setting-tags-on-an-active-trace",children:"Setting Tags on an Active Trace"}),"\n",(0,r.jsxs)(t.p,{children:["If you are using automatic tracing or fluent APIs to create traces and want to add tags to the trace during its execution, you can use the ",(0,r.jsx)(i.B,{fn:"mlflow.update_current_trace"})," function."]}),"\n",(0,r.jsxs)(t.p,{children:["For example, the following code example adds the ",(0,r.jsx)(t.code,{children:'"fruit": "apple"'})," tag to the trace created for the ",(0,r.jsx)(t.code,{children:"my_func"})," function:"]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'@mlflow.trace\ndef my_func(x):\n    mlflow.update_current_trace(tags={"fruit": "apple"})\n    return x + 1\n'})}),"\n",(0,r.jsx)(t.admonition,{type:"note",children:(0,r.jsxs)(t.p,{children:["The ",(0,r.jsx)(i.B,{fn:"mlflow.update_current_trace"})," function adds the specified tag(s) to the current trace when the key is not already present. If the key is already present, it updates the key with the new value."]})}),"\n",(0,r.jsx)(t.h3,{id:"setting-tags-on-a-finished-trace",children:"Setting Tags on a Finished Trace"}),"\n",(0,r.jsxs)(t.p,{children:["To set tags on a trace that has already been completed and logged in the backend store, use the ",(0,r.jsx)(i.B,{fn:"mlflow.set_trace_tag",children:(0,r.jsx)(t.code,{children:"mlflow.set_trace_tag"})})," method to set a tag on a trace,\nand the ",(0,r.jsx)(i.B,{fn:"mlflow.delete_trace_tag",children:(0,r.jsx)(t.code,{children:"mlflow.delete_trace_tag"})})," method to remove a tag from a trace."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'# Set a tag on a trace\nclient.set_trace_tag(trace_id=trace_id, key="tag_key", value="tag_value")\n\n# Delete a tag from a trace\nclient.delete_trace_tag(trace_id=trace_id, key="tag_key")\n'})}),"\n",(0,r.jsx)(t.h3,{id:"setting-tags-via-the-mlflow-ui",children:"Setting Tags via the MLflow UI"}),"\n",(0,r.jsx)(t.p,{children:"Alternatively, you can update or delete tags on a trace from the MLflow UI. To do this, navigate to the trace tab, then click on the pencil icon next to the tag you want to update."}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.img,{alt:"Traces tag update",src:n(29225).A+"",width:"1188",height:"720"})}),"\n",(0,r.jsx)(t.h2,{id:"delete-traces",children:"Delete Traces"}),"\n",(0,r.jsxs)(t.p,{children:["You can delete traces based on specific criteria using the ",(0,r.jsx)(i.B,{fn:"mlflow.client.MlflowClient.delete_traces",children:(0,r.jsx)(t.code,{children:"MlflowClient.delete_traces"})})," method. This method allows you to delete traces by ",(0,r.jsx)(t.strong,{children:"experiment ID"}),",\n",(0,r.jsx)(t.strong,{children:"maximum timestamp"}),", or ",(0,r.jsx)(t.strong,{children:"trace IDs"}),"."]}),"\n",(0,r.jsx)(t.admonition,{type:"tip",children:(0,r.jsxs)(t.p,{children:["Deleting a trace is an irreversible process. Ensure that the setting provided within the ",(0,r.jsx)(t.code,{children:"delete_traces"})," API meet the intended range for deletion."]})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'import time\n\n# Get the current timestamp in milliseconds\ncurrent_time = int(time.time() * 1000)\n\n# Delete traces older than a specific timestamp\ndeleted_count = client.delete_traces(\n    experiment_id="1", max_timestamp_millis=current_time, max_traces=10\n)\n'})}),"\n",(0,r.jsx)(t.h2,{id:"disabling-traces",children:"Disabling Traces"}),"\n",(0,r.jsxs)(t.p,{children:["To ",(0,r.jsx)(t.strong,{children:"disable"})," tracing, the ",(0,r.jsx)(i.B,{fn:"mlflow.tracing.disable"})," API will cease the collection of trace data from within MLflow and will not log\nany data to the MLflow Tracking service regarding traces."]}),"\n",(0,r.jsxs)(t.p,{children:["To ",(0,r.jsx)(t.strong,{children:"enable"})," tracing (if it had been temporarily disabled), the ",(0,r.jsx)(i.B,{fn:"mlflow.tracing.enable"})," API will re-enable tracing functionality for instrumented models\nthat are invoked."]}),"\n",(0,r.jsx)(t.h2,{id:"associating-traces-to-mlflow-run",children:"Associating Traces to MLflow Run"}),"\n",(0,r.jsx)(t.p,{children:"If a trace is generated within a run context, the recorded traces to an active Experiment will be associated with the active Run."}),"\n",(0,r.jsxs)(t.p,{children:["For example, in the following code, the traces are generated within the ",(0,r.jsx)(t.code,{children:"start_run"})," context."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'import mlflow\n\n# Create and activate an Experiment\nmlflow.set_experiment("Run Associated Tracing")\n\n# Start a new MLflow Run\nwith mlflow.start_run() as run:\n    # Initiate a trace by starting a Span context from within the Run context\n    with mlflow.start_span(name="Run Span") as parent_span:\n        parent_span.set_inputs({"input": "a"})\n        parent_span.set_outputs({"response": "b"})\n        parent_span.set_attribute("a", "b")\n        # Initiate a child span from within the parent Span\'s context\n        with mlflow.start_span(name="Child Span") as child_span:\n            child_span.set_inputs({"input": "b"})\n            child_span.set_outputs({"response": "c"})\n            child_span.set_attributes({"b": "c", "c": "d"})\n'})}),"\n",(0,r.jsx)(t.p,{children:"When navigating to the MLflow UI and selecting the active Experiment, the trace display view will show the run that is associated with the trace, as\nwell as providing a link to navigate to the run within the MLflow UI. See the below video for an example of this in action."}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.img,{alt:"Tracing within a Run Context",src:n(96017).A+"",width:"2048",height:"1079"})}),"\n",(0,r.jsxs)(t.p,{children:["You can also programmatically retrieve the traces associated to a particular Run by using the ",(0,r.jsx)(i.B,{fn:"mlflow.search_traces"})," method."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'import mlflow\n\n# Retrieve traces associated with a specific Run\ntraces = mlflow.search_traces(run_id=run.info.run_id, return_type="list")\n\nprint(traces)\n'})}),"\n",(0,r.jsx)(t.h2,{id:"logging-traces-asynchronously",children:"Logging Traces Asynchronously"}),"\n",(0,r.jsxs)(t.p,{children:["When logging traces to a self-hosted MLflow tracking server, MLflow Traces are logged synchronously. This may introduce a performance overhead when logging Traces, especially when your MLflow Tracking Server is running on a remote server. If the performance overhead is a concern for you, you can enable ",(0,r.jsx)(t.strong,{children:"asynchronous logging"})," for tracing in MLflow 2.16.0 and later."]}),"\n",(0,r.jsxs)(t.p,{children:["To enable async logging for tracing, call ",(0,r.jsx)(i.B,{fn:"mlflow.config.enable_async_logging"})," in your code. This will make the trace logging operation non-blocking and reduce the performance overhead."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'import mlflow\n\nmlflow.config.enable_async_logging()\n\n# Traces will be logged asynchronously\nwith mlflow.start_span(name="foo") as span:\n    span.set_inputs({"a": 1})\n    span.set_outputs({"b": 2})\n\n# If you don\'t see the traces in the UI after waiting for a while, you can manually flush the traces\n# mlflow.flush_trace_async_logging()\n'})}),"\n",(0,r.jsx)(t.p,{children:"Note that the async logging does not fully eliminate the performance overhead. Some backend calls still need to be made synchronously and there are other factors such as data serialization. However, async logging can significantly reduce the overall overhead of logging traces, empirically about ~80% for typical workloads."}),"\n",(0,r.jsx)(t.p,{children:"The following configurations are available for async logging:"}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Environment Variable"}),(0,r.jsx)(t.th,{children:"Description"}),(0,r.jsx)(t.th,{children:"Default Value"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"MLFLOW_ASYNC_TRACE_LOGGING_MAX_WORKERS"})}),(0,r.jsx)(t.td,{children:"The maximum number of worker threads to use for async trace logging."}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"10"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"MLFLOW_ASYNC_TRACE_LOGGING_MAX_QUEUE_SIZE"})}),(0,r.jsx)(t.td,{children:"The maximum number of traces that can be queued for logging. Traces will be discarded if the queue is full."}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"1000"})})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"MLFLOW_ASYNC_TRACE_LOGGING_RETRY_TIMEOUT"})}),(0,r.jsx)(t.td,{children:"Timeout in seconds for retrying failed trace logging. Namely, failed traces will be retried up to this timeout with backoff, after which they will be discarded."}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"500"})})]})]})]}),"\n",(0,r.jsx)(t.h2,{id:"customize-request-and-response-preview-in-trace-ui",children:"Customize Request and Response Preview in Trace UI"}),"\n",(0,r.jsxs)(t.p,{children:["The Traces tab in MLflow UI displays a list of traces logged in the MLflow tracking server. The ",(0,r.jsx)(t.code,{children:"Request"})," and ",(0,r.jsx)(t.code,{children:"Response"})," columns\nshow the preview of the end input and output of the trace, so that you can quickly understand the trace."]}),"\n",(0,r.jsxs)(t.p,{children:["By default, the preview is truncated to a fix number of characters for each request and response. However, you can also customize the preview by setting the ",(0,r.jsx)(t.code,{children:"request_preview"})," and ",(0,r.jsx)(t.code,{children:"response_preview"})," parameters in the ",(0,r.jsx)(i.B,{fn:"mlflow.update_current_trace"})," function."]}),"\n",(0,r.jsx)(t.p,{children:"Below is an example of setting a custom request preview for a trace to render large message history nicely in the UI."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'import mlflow\nimport openai\n\n\n@mlflow.trace\ndef predict(messages: list[dict]) -> str:\n    # Customize the request preview to show the first and last messages\n    custom_preview = f\'{messages[0]["content"][:10]} ... {messages[-1]["content"][:10]}\'\n    mlflow.update_current_trace(request_preview=custom_preview)\n\n    # Call the model\n    response = openai.chat.completions.create(\n        model="o4-mini",\n        messages=messages,\n    )\n\n    return response.choices[0].message.content\n\n\nmessages = [\n    {"role": "user", "content": "Hi, how are you?"},\n    {"role": "assistant", "content": "I\'m good, thank you!"},\n    {"role": "user", "content": "What\'s your name?"},\n    # ... (long message history)\n    {"role": "assistant", "content": "Bye!"},\n]\npredict(messages)\n\n# The request preview rendered in the UI will be:\n#     "Hi, how are you? ... Bye!"\n'})})]})}function p(e={}){const{wrapper:t}={...(0,l.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}},67756:(e,t,n)=>{n.d(t,{B:()=>s});n(96540);const a=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var r=n(29030),l=n(56289),i=n(74848);const o=e=>{const t=e.split(".");for(let n=t.length;n>0;n--){const e=t.slice(0,n).join(".");if(a[e])return e}return null};function s(e){let{fn:t,children:n}=e;const s=o(t);if(!s)return(0,i.jsx)(i.Fragment,{children:n});const c=(0,r.Ay)(`/${a[s]}#${t}`);return(0,i.jsx)(l.A,{to:c,target:"_blank",children:n??(0,i.jsxs)("code",{children:[t,"()"]})})}},72371:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/jupyter-trace-ui-a11c56c439864da666540e9d501329cb.png"},86294:(e,t,n)=>{n.d(t,{Zp:()=>s,AC:()=>o,WO:()=>d,tf:()=>p,_C:()=>c,$3:()=>h,jK:()=>m});var a=n(34164);const r={CardGroup:"CardGroup_P84T",MaxThreeColumns:"MaxThreeColumns_FO1r",AutofillColumns:"AutofillColumns_fKhQ",Card:"Card_aSCR",CardBordered:"CardBordered_glGF",CardBody:"CardBody_BhRs",TextColor:"TextColor_a8Tp",BoxRoot:"BoxRoot_Etgr",FlexWrapNowrap:"FlexWrapNowrap_f60k",FlexJustifyContentFlexStart:"FlexJustifyContentFlexStart_ZYv5",FlexDirectionRow:"FlexDirectionRow_T2qL",FlexAlignItemsCenter:"FlexAlignItemsCenter_EHVM",FlexFlex:"FlexFlex__JTE",Link:"Link_fVkl",MarginLeft4:"MarginLeft4_YQSJ",MarginTop4:"MarginTop4_jXKN",PaddingBottom4:"PaddingBottom4_O9gt",LogoCardContent:"LogoCardContent_kCQm",LogoCardImage:"LogoCardImage_JdcX",SmallLogoCardContent:"SmallLogoCardContent_LxhV",SmallLogoCardImage:"SmallLogoCardImage_tPZl",NewFeatureCardContent:"NewFeatureCardContent_Rq3d",NewFeatureCardHeading:"NewFeatureCardHeading_f6q3",NewFeatureCardHeadingSeparator:"NewFeatureCardHeadingSeparator_pSx8",NewFeatureCardTags:"NewFeatureCardTags_IFHO",NewFeatureCardWrapper:"NewFeatureCardWrapper_NQ0k",TitleCardContent:"TitleCardContent_l9MQ",TitleCardTitle:"TitleCardTitle__K8J",TitleCardSeparator:"TitleCardSeparator_IN2E",Cols1:"Cols1_Gr2U",Cols2:"Cols2_sRvc",Cols3:"Cols3_KjUS",Cols4:"Cols4_dKOj",Cols5:"Cols5_jDmj",Cols6:"Cols6_Q0OR"};var l=n(56289),i=n(74848);const o=e=>{let{children:t,isSmall:n,cols:l}=e;return(0,i.jsx)("div",{className:(0,a.A)(r.CardGroup,n?r.AutofillColumns:l?r[`Cols${l}`]:r.MaxThreeColumns),children:t})},s=e=>{let{children:t,link:n=""}=e;return n?(0,i.jsx)(l.A,{className:(0,a.A)(r.Link,r.Card,r.CardBordered),to:n,children:t}):(0,i.jsx)("div",{className:(0,a.A)(r.Card,r.CardBordered),children:t})},c=e=>{let{headerText:t,link:n,text:l}=e;return(0,i.jsx)(s,{link:n,children:(0,i.jsxs)("span",{children:[(0,i.jsx)("div",{className:(0,a.A)(r.CardTitle,r.BoxRoot,r.PaddingBottom4),style:{pointerEvents:"none"},children:(0,i.jsx)("div",{className:(0,a.A)(r.BoxRoot,r.FlexFlex,r.FlexAlignItemsCenter,r.FlexDirectionRow,r.FlexJustifyContentFlexStart,r.FlexWrapNowrap),style:{marginLeft:"-4px",marginTop:"-4px"},children:(0,i.jsx)("div",{className:(0,a.A)(r.BoxRoot,r.BoxHideIfEmpty,r.MarginTop4,r.MarginLeft4),style:{pointerEvents:"auto"},children:(0,i.jsx)("span",{className:"",children:t})})})}),(0,i.jsx)("span",{className:(0,a.A)(r.TextColor,r.CardBody),children:(0,i.jsx)("p",{children:l})})]})})},d=e=>{let{description:t,children:n,link:a}=e;return(0,i.jsx)(s,{link:a,children:(0,i.jsxs)("div",{className:r.LogoCardContent,children:[(0,i.jsx)("div",{className:r.LogoCardImage,children:n}),(0,i.jsx)("p",{className:r.TextColor,children:t})]})})},h=e=>{let{children:t,link:n}=e;return(0,i.jsx)(s,{link:n,children:(0,i.jsx)("div",{className:r.SmallLogoCardContent,children:(0,i.jsx)("div",{className:(0,a.A)("max-height-img-container",r.SmallLogoCardImage),children:t})})})},p=e=>{let{children:t,description:n,name:a,releaseVersion:o,learnMoreLink:c=""}=e;return(0,i.jsx)(s,{children:(0,i.jsxs)("div",{className:r.NewFeatureCardWrapper,children:[(0,i.jsxs)("div",{className:r.NewFeatureCardContent,children:[(0,i.jsxs)("div",{className:r.NewFeatureCardHeading,children:[a,(0,i.jsx)("br",{}),(0,i.jsx)("hr",{className:r.NewFeatureCardHeadingSeparator})]}),(0,i.jsx)("div",{className:r.LogoCardImage,children:t}),(0,i.jsx)("br",{}),(0,i.jsx)("p",{children:n}),(0,i.jsx)("br",{})]}),(0,i.jsxs)("div",{className:r.NewFeatureCardTags,children:[(0,i.jsx)("div",{children:c&&(0,i.jsx)(l.A,{className:"button button--outline button--sm button--primary",to:c,children:"Learn more"})}),(0,i.jsxs)(l.A,{className:"button button--outline button--sm button--primary",to:`https://github.com/mlflow/mlflow/releases/tag/v${o}`,children:["released in ",o]})]})]})})},m=e=>{let{title:t,description:n,link:l=""}=e;return(0,i.jsx)(s,{link:l,children:(0,i.jsxs)("div",{className:r.TitleCardContent,children:[(0,i.jsx)("div",{className:(0,a.A)(r.TitleCardTitle),style:{textAlign:"left",fontWeight:"bold"},children:t}),(0,i.jsx)("hr",{className:(0,a.A)(r.TitleCardSeparator),style:{margin:"12px 0"}}),(0,i.jsx)("p",{className:(0,a.A)(r.TextColor),children:n})]})})}},96017:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/run-trace-cbe44f5add2e57d90cea039724a7dea0.gif"}}]);