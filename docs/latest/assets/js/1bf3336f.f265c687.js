"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[865],{11470:(e,n,t)=>{t.d(n,{A:()=>_});var r=t(96540),i=t(34164),a=t(23104),s=t(56347),l=t(205),o=t(57485),c=t(31682),d=t(70679);function p(e){return r.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function h(e){const{values:n,children:t}=e;return(0,r.useMemo)((()=>{const e=n??function(e){return p(e).map((({props:{value:e,label:n,attributes:t,default:r}})=>({value:e,label:n,attributes:t,default:r})))}(t);return function(e){const n=(0,c.XI)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function u({value:e,tabValues:n}){return n.some((n=>n.value===e))}function m({queryString:e=!1,groupId:n}){const t=(0,s.W6)(),i=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,o.aZ)(i),(0,r.useCallback)((e=>{if(!i)return;const n=new URLSearchParams(t.location.search);n.set(i,e),t.replace({...t.location,search:n.toString()})}),[i,t])]}function f(e){const{defaultValue:n,queryString:t=!1,groupId:i}=e,a=h(e),[s,o]=(0,r.useState)((()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!u({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const t=n.find((e=>e.default))??n[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:a}))),[c,p]=m({queryString:t,groupId:i}),[f,g]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[t,i]=(0,d.Dv)(n);return[t,(0,r.useCallback)((e=>{n&&i.set(e)}),[n,i])]}({groupId:i}),x=(()=>{const e=c??f;return u({value:e,tabValues:a})?e:null})();(0,l.A)((()=>{x&&o(x)}),[x]);return{selectedValue:s,selectValue:(0,r.useCallback)((e=>{if(!u({value:e,tabValues:a}))throw new Error(`Can't select invalid tab value=${e}`);o(e),p(e),g(e)}),[p,g,a]),tabValues:a}}var g=t(92303);const x={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var j=t(74848);function y({className:e,block:n,selectedValue:t,selectValue:r,tabValues:s}){const l=[],{blockElementScrollPositionUntilNextRender:o}=(0,a.a_)(),c=e=>{const n=e.currentTarget,i=l.indexOf(n),a=s[i].value;a!==t&&(o(n),r(a))},d=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=l.indexOf(e.currentTarget)+1;n=l[t]??l[0];break}case"ArrowLeft":{const t=l.indexOf(e.currentTarget)-1;n=l[t]??l[l.length-1];break}}n?.focus()};return(0,j.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":n},e),children:s.map((({value:e,label:n,attributes:r})=>(0,j.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{l.push(e)},onKeyDown:d,onClick:c,...r,className:(0,i.A)("tabs__item",x.tabItem,r?.className,{"tabs__item--active":t===e}),children:n??e},e)))})}function w({lazy:e,children:n,selectedValue:t}){const a=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=a.find((e=>e.props.value===t));return e?(0,r.cloneElement)(e,{className:(0,i.A)("margin-top--md",e.props.className)}):null}return(0,j.jsx)("div",{className:"margin-top--md",children:a.map(((e,n)=>(0,r.cloneElement)(e,{key:n,hidden:e.props.value!==t})))})}function v(e){const n=f(e);return(0,j.jsxs)("div",{className:(0,i.A)("tabs-container",x.tabList),children:[(0,j.jsx)(y,{...n,...e}),(0,j.jsx)(w,{...n,...e})]})}function _(e){const n=(0,g.A)();return(0,j.jsx)(v,{...e,children:p(e.children)},String(n))}},19365:(e,n,t)=>{t.d(n,{A:()=>s});t(96540);var r=t(34164);const i={tabItem:"tabItem_Ymn6"};var a=t(74848);function s({children:e,hidden:n,className:t}){return(0,a.jsx)("div",{role:"tabpanel",className:(0,r.A)(i.tabItem,t),hidden:n,children:e})}},21657:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/images/trace_info_architecture-0a66e4960efd9299f04427c0aef04a45.png"},27073:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/images/tracing-traditional-ml-b68a864624358e76deb8ab918f339d30.png"},28453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>l});var r=t(96540);const i={},a=r.createContext(i);function s(e){const n=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),r.createElement(a.Provider,{value:n},e.children)}},40135:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/images/span_architecture-01e1f5a3edf522f567e7eaad16f2b1d1.png"},49374:(e,n,t)=>{t.d(n,{B:()=>o});t(96540);const r=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var i=t(86025),a=t(28774),s=t(74848);const l=e=>{const n=e.split(".");for(let t=n.length;t>0;t--){const e=n.slice(0,t).join(".");if(r[e])return e}return null};function o({fn:e,children:n}){const t=l(e);if(!t)return(0,s.jsx)(s.Fragment,{children:n});const o=(0,i.Ay)(`/${r[t]}#${e}`);return(0,s.jsx)(a.A,{to:o,target:"_blank",children:n??(0,s.jsxs)("code",{children:[e,"()"]})})}},58090:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/images/trace_architecture-4d7b474a12b802862207e96a40040e12.png"},60629:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/images/trace_data_architecture-96cd4fb71c42d2616dd28acdba33b5e6.png"},68321:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/images/chat-completions-architecture-e42be08f963a4162dd72fb8cb5d70c43.png"},68699:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>p,contentTitle:()=>d,default:()=>m,frontMatter:()=>c,metadata:()=>r,toc:()=>h});const r=JSON.parse('{"id":"tracing/concepts/trace-instrumentation","title":"Tracing Concepts","description":"This guide introduces the core concepts of tracing and observability for GenAI applications. If you\'re new to tracing, this conceptual overview will help you understand the fundamental building blocks before diving into implementation.","source":"@site/docs/genai/tracing/concepts/trace-instrumentation.mdx","sourceDirName":"tracing/concepts","slug":"/tracing/concepts/trace-instrumentation","permalink":"/docs/latest/genai/tracing/concepts/trace-instrumentation","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"genAISidebar","previous":{"title":"Add New Integration","permalink":"/docs/latest/genai/tracing/integrations/contribute"},"next":{"title":"Tracing Concepts","permalink":"/docs/latest/genai/tracing/concepts/trace-instrumentation"}}');var i=t(74848),a=t(28453),s=t(11470),l=t(19365),o=t(49374);const c={},d="Tracing Concepts",p={},h=[{value:"What is Tracing?",id:"what-is-tracing",level:2},{value:"Core Architecture: Trace = TraceInfo + TraceData",id:"core-architecture-trace--traceinfo--tracedata",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"Trace",id:"trace",level:3},{value:"Span",id:"span",level:3},{value:"Parent-Child Relationships",id:"parent-child-relationships",level:3},{value:"Span Types",id:"span-types",level:2},{value:"Trace Structure Example",id:"trace-structure-example",level:2},{value:"Observability Benefits",id:"observability-benefits",level:2},{value:"Debugging",id:"debugging",level:3},{value:"Optimization",id:"optimization",level:3},{value:"Monitoring",id:"monitoring",level:3},{value:"Specialized Schemas",id:"specialized-schemas",level:2},{value:"Retriever Spans",id:"retriever-spans",level:3},{value:"Chat Model Spans",id:"chat-model-spans",level:3},{value:"Use Cases",id:"use-cases",level:2},{value:"GenAI ChatCompletions Use Case",id:"genai-chatcompletions-use-case",level:2},{value:"What Tracing Captures",id:"what-tracing-captures",level:3},{value:"Key Metadata for ChatCompletions",id:"key-metadata-for-chatcompletions",level:3},{value:"Example: Enhanced Chat Application",id:"example-enhanced-chat-application",level:3},{value:"Advanced Retrieval-Augmented Generation (RAG) Applications",id:"advanced-retrieval-augmented-generation-rag-applications",level:2},{value:"The Challenge Without Tracing",id:"the-challenge-without-tracing",level:3},{value:"Critical Steps in RAG (Often Hidden)",id:"critical-steps-in-rag-often-hidden",level:3},{value:"Example: Traced RAG Application",id:"example-traced-rag-application",level:3},{value:"Benefits of RAG Tracing",id:"benefits-of-rag-tracing",level:3},{value:"Beyond GenAI: Tracing for Traditional Machine Learning",id:"beyond-genai-tracing-for-traditional-machine-learning",level:2},{value:"Traditional ML Characteristics",id:"traditional-ml-characteristics",level:3},{value:"Example: Spam Detection Model",id:"example-spam-detection-model",level:3},{value:"When Tracing Helps in Traditional ML",id:"when-tracing-helps-in-traditional-ml",level:3},{value:"1. Performance Monitoring",id:"1-performance-monitoring",level:4},{value:"2. API Access Logging",id:"2-api-access-logging",level:4},{value:"3. Multi-Model Pipelines",id:"3-multi-model-pipelines",level:4},{value:"Differences from GenAI Tracing",id:"differences-from-genai-tracing",level:3},{value:"Getting Started with Concepts",id:"getting-started-with-concepts",level:2}];function u(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"tracing-concepts",children:"Tracing Concepts"})}),"\n",(0,i.jsx)(n.p,{children:"This guide introduces the core concepts of tracing and observability for GenAI applications. If you're new to tracing, this conceptual overview will help you understand the fundamental building blocks before diving into implementation."}),"\n",(0,i.jsx)(n.h2,{id:"what-is-tracing",children:"What is Tracing?"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Tracing"})," is an observability technique that captures the complete execution flow of a request through your application. Unlike traditional logging that captures discrete events, tracing creates a detailed map of how data flows through your system, recording every operation, transformation, and decision point."]}),"\n",(0,i.jsx)(n.p,{children:"In the context of GenAI applications, tracing becomes essential because these systems involve complex, multi-step workflows that are difficult to debug and optimize without complete visibility into their execution."}),"\n",(0,i.jsx)(n.h2,{id:"core-architecture-trace--traceinfo--tracedata",children:"Core Architecture: Trace = TraceInfo + TraceData"}),"\n",(0,i.jsxs)(n.p,{children:["MLflow traces follow a simple but powerful structure: ",(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.code,{children:"Trace = TraceInfo + TraceData"})})," where ",(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.code,{children:"TraceData = List[Span]"})})]}),"\n",(0,i.jsxs)(s.A,{children:[(0,i.jsxs)(l.A,{value:"trace-overview",label:"Complete Trace Structure",default:!0,children:[(0,i.jsxs)(n.p,{children:["A ",(0,i.jsx)(o.B,{fn:"mlflow.entities.Trace",children:"Trace"})," in MLflow consists of two main components:"]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(o.B,{fn:"mlflow.entities.TraceInfo",children:"TraceInfo"})}),": Metadata about the overall trace (timing, status, preview data)"]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(o.B,{fn:"mlflow.entities.TraceData",children:"TraceData"})}),": The core execution data containing all the individual spans"]}),(0,i.jsx)(n.p,{children:"This separation allows for efficient querying and filtering of traces while maintaining detailed execution information."}),(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Trace Architecture",src:t(58090).A+"",width:"1204",height:"903"})})]}),(0,i.jsxs)(l.A,{value:"trace-info",label:"TraceInfo: The Metadata",children:[(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"TraceInfo"})," provides a lightweight snapshot of critical data about the overall trace, including:"]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Identification"}),": Unique trace ID and storage location"]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Timing"}),": Start time and total execution duration"]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Status"}),": Success, failure, or in-progress state"]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Previews"}),": Summary of request and response data"]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Organization"}),": Tags and metadata for searching and filtering"]}),(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Trace Info Architecture",src:t(21657).A+"",width:"1242",height:"994"})})]}),(0,i.jsxs)(l.A,{value:"trace-data",label:"TraceData: The Execution Details",children:[(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"TraceData"})," contains the core execution information as a list of ",(0,i.jsx)(o.B,{fn:"mlflow.entities.Span",children:"Span"})," objects. These spans are organized in a hierarchical relationship that shows the complete flow of operations in your application."]}),(0,i.jsx)(n.p,{children:"Each span represents a single operation and includes detailed information about inputs, outputs, timing, and any errors that occurred."}),(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Trace Data Architecture",src:t(60629).A+"",width:"1243",height:"935"})})]}),(0,i.jsxs)(l.A,{value:"span-structure",label:"Span: Individual Operations",children:[(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Spans"})," are the fundamental building blocks that represent individual operations. Each span complies with the ",(0,i.jsx)(n.a,{href:"https://opentelemetry.io/docs/concepts/signals/traces#spans",children:"OpenTelemetry Span specification"})," and includes:"]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Identity"}),": Unique span ID and parent relationships"]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Timing"}),": Precise start and end timestamps"]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Data"}),": Inputs, outputs, and operational metadata"]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Context"}),": Attributes and events for debugging"]}),(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Span Architecture",src:t(40135).A+"",width:"1880",height:"1149"})})]})]}),"\n",(0,i.jsx)(n.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,i.jsx)(n.h3,{id:"trace",children:"Trace"}),"\n",(0,i.jsxs)(n.p,{children:["A ",(0,i.jsx)(n.strong,{children:"trace"})," represents the complete journey of a single request through your application. It's a collection of related operations (spans) that together tell the story of how your system processed a user's input to generate an output."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Example"}),': A user asks "What\'s the weather in Paris?" - the trace captures everything from parsing the question to returning the final weather report.']}),"\n",(0,i.jsx)(n.h3,{id:"span",children:"Span"}),"\n",(0,i.jsxs)(n.p,{children:["A ",(0,i.jsx)(n.strong,{children:"span"})," represents a single, discrete operation within a trace. Each span has a clear beginning and end, and captures the inputs, outputs, timing, and metadata for that specific operation."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Key span properties"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Name"}),': Human-readable identifier (e.g., "Document Retrieval", "LLM Call")']}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Duration"}),": How long the operation took (measured in nanoseconds for precision)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Status"}),": Success, failure, or error with detailed information"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Inputs"}),": Data that went into the operation (JSON-serialized)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Outputs"}),": Results produced by the operation (JSON-serialized)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Attributes"}),": Additional metadata (model parameters, user ID, configuration values)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Events"}),": Significant moments during execution (errors, warnings, checkpoints)"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"parent-child-relationships",children:"Parent-Child Relationships"}),"\n",(0,i.jsx)(n.p,{children:"Spans form hierarchical relationships that mirror your application's call structure:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Root span"}),": The top-level operation representing the entire request"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Child spans"}),": Operations called by parent operations"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Sibling spans"}),": Operations at the same level of the hierarchy"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.strong,{children:"parent_id"})," property establishes these hierarchical associations, creating a clear order-of-operations linkage."]}),"\n",(0,i.jsx)(n.h2,{id:"span-types",children:"Span Types"}),"\n",(0,i.jsx)(n.p,{children:"MLflow categorizes spans by their purpose to make traces easier to understand and analyze. Each span type has semantic meaning and may have specialized schemas for enhanced functionality:"}),"\n",(0,i.jsxs)(s.A,{children:[(0,i.jsxs)(l.A,{value:"llm-types",label:"LLM & Chat",default:!0,children:[(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"SpanType.LLM"}),": Calls to language models"]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"SpanType.CHAT_MODEL"}),": Interactions with chat completion APIs"]}),(0,i.jsx)(n.p,{children:"Examples: OpenAI chat completion, Anthropic Claude call, local model inference"}),(0,i.jsx)(n.p,{children:"Typically captures: model name, parameters, prompt, response, token usage"}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.em,{children:"Special attributes"}),": ",(0,i.jsx)(n.code,{children:"mlflow.chat.messages"})," and ",(0,i.jsx)(n.code,{children:"mlflow.chat.tools"})," for rich UI display"]})]}),(0,i.jsxs)(l.A,{value:"retrieval-types",label:"Retrieval & Data",children:[(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"SpanType.RETRIEVER"}),": Operations that fetch relevant information"]}),(0,i.jsx)(n.p,{children:"Examples: Vector database search, web search, document lookup"}),(0,i.jsx)(n.p,{children:"Typically captures: query, retrieved documents, similarity scores, result count"}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.em,{children:"Special schema"}),": Output must be ",(0,i.jsx)(n.code,{children:"List[Document]"})," for enhanced UI features"]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"SpanType.EMBEDDING"}),": Vector embedding generation"]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"SpanType.PARSER"}),": Data parsing and transformation operations"]})]}),(0,i.jsxs)(l.A,{value:"workflow-types",label:"Workflow & Logic",children:[(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"SpanType.CHAIN"}),": Multi-step workflows or pipelines"]}),(0,i.jsx)(n.p,{children:"Examples: RAG pipeline, multi-agent workflow, complex reasoning chain"}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"SpanType.AGENT"}),": Autonomous agent operations"]}),(0,i.jsx)(n.p,{children:"Examples: Planning steps, decision making, goal-oriented behaviors"}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"SpanType.TOOL"}),": External tool or function calls"]}),(0,i.jsx)(n.p,{children:"Examples: API calls, database queries, file operations, calculations"})]}),(0,i.jsxs)(l.A,{value:"other-types",label:"Other Types",children:[(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"SpanType.RERANKER"}),": Re-ranking operations for retrieved contexts"]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"SpanType.UNKNOWN"}),": General operations that don't fit other categories"]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.em,{children:"Custom types"}),": You can also define your own span types as strings for specialized operations"]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"trace-structure-example",children:"Trace Structure Example"}),"\n",(0,i.jsx)(n.p,{children:"Let's examine how these concepts work together in a typical RAG (Retrieval-Augmented Generation) application:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:'\ud83d\udccb Trace: "Answer User Question" (Root)\n\u251c\u2500\u2500 \ud83d\udd0d Span: "Query Processing" (UNKNOWN)\n\u2502   \u251c\u2500\u2500 Input: "What are MLflow\'s key features?"\n\u2502   \u2514\u2500\u2500 Output: "Processed query: \'mlflow features\'"\n\u251c\u2500\u2500 \ud83d\udcda Span: "Document Retrieval" (RETRIEVER)\n\u2502   \u251c\u2500\u2500 \ud83d\udd17 Span: "Embedding Generation" (EMBEDDING)\n\u2502   \u2502   \u251c\u2500\u2500 Input: "mlflow features"\n\u2502   \u2502   \u2514\u2500\u2500 Output: [0.1, 0.3, -0.2, ...] (vector)\n\u2502   \u2514\u2500\u2500 \ud83d\uddc4\ufe0f Span: "Vector Search" (TOOL)\n\u2502       \u251c\u2500\u2500 Input: {query_vector, top_k: 5}\n\u2502       \u2514\u2500\u2500 Output: [Document(...), Document(...)] (5 docs)\n\u251c\u2500\u2500 \ud83e\udde0 Span: "Response Generation" (CHAIN)\n\u2502   \u251c\u2500\u2500 \ud83d\udcdd Span: "Prompt Building" (UNKNOWN)\n\u2502   \u2502   \u251c\u2500\u2500 Input: {documents, user_query}\n\u2502   \u2502   \u2514\u2500\u2500 Output: "Based on these docs: ... Answer: ..."\n\u2502   \u2514\u2500\u2500 \ud83e\udd16 Span: "LLM Call" (CHAT_MODEL)\n\u2502       \u251c\u2500\u2500 Input: {messages, model: "gpt-4", temperature: 0.7}\n\u2502       \u2514\u2500\u2500 Output: "MLflow\'s key features include..."\n\u2514\u2500\u2500 \u2705 Span: "Response Formatting" (UNKNOWN)\n    \u251c\u2500\u2500 Input: "MLflow\'s key features include..."\n    \u2514\u2500\u2500 Output: {formatted_response, metadata}\n'})}),"\n",(0,i.jsx)(n.p,{children:"Each span captures specific information relevant to its operation type, and the hierarchical structure shows the logical flow of the application."}),"\n",(0,i.jsx)(n.h2,{id:"observability-benefits",children:"Observability Benefits"}),"\n",(0,i.jsx)(n.p,{children:"Understanding these concepts enables several powerful observability capabilities:"}),"\n",(0,i.jsx)(n.h3,{id:"debugging",children:"Debugging"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Root cause analysis"}),": Trace the exact path that led to an error or unexpected result"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Performance bottlenecks"}),": Identify which operations consume the most time using precise nanosecond timing"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Data flow validation"}),": Verify that data is transformed correctly at each step by examining inputs and outputs"]}),"\n",(0,i.jsx)(n.h3,{id:"optimization",children:"Optimization"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Cost tracking"}),": Monitor token usage, API calls, and resource consumption across operations using span attributes"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Latency analysis"}),": Understand where delays occur in your application with detailed timing data"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Quality correlation"}),": Connect input quality (e.g., retrieval relevance scores) to output quality"]}),"\n",(0,i.jsx)(n.h3,{id:"monitoring",children:"Monitoring"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"System health"}),": Track success rates and error patterns across different components using span status"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Usage patterns"}),": Understand how users interact with your application through trace metadata"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Trend analysis"}),": Monitor performance and quality changes over time using trace history"]}),"\n",(0,i.jsx)(n.h2,{id:"specialized-schemas",children:"Specialized Schemas"}),"\n",(0,i.jsx)(n.p,{children:"Some span types have specialized schemas that enable enhanced functionality:"}),"\n",(0,i.jsx)(n.h3,{id:"retriever-spans",children:"Retriever Spans"}),"\n",(0,i.jsxs)(n.p,{children:["For ",(0,i.jsx)(n.code,{children:"RETRIEVER"})," spans, the output should conform to a ",(0,i.jsx)(n.code,{children:"List[Document]"})," structure:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"page_content"}),": The text content of the document"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"metadata"}),": Additional context including ",(0,i.jsx)(n.code,{children:"doc_uri"})," for links and ",(0,i.jsx)(n.code,{children:"chunk_id"})," for evaluation"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"This enables rich document display in the UI and proper evaluation metric calculation."}),"\n",(0,i.jsx)(n.h3,{id:"chat-model-spans",children:"Chat Model Spans"}),"\n",(0,i.jsxs)(n.p,{children:["For ",(0,i.jsx)(n.code,{children:"CHAT_MODEL"})," and ",(0,i.jsx)(n.code,{children:"LLM"})," spans, special attributes provide enhanced conversation display:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"mlflow.chat.messages"}),": Structured conversation data for rich UI rendering"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"mlflow.chat.tools"}),": Available tools for function calling scenarios"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["These attributes can be set using helper functions like ",(0,i.jsx)(o.B,{fn:"mlflow.tracing.set_span_chat_messages"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"use-cases",children:"Use Cases"}),"\n",(0,i.jsxs)(s.A,{children:[(0,i.jsxs)(l.A,{value:"genai-applications",label:"GenAI Applications",children:[(0,i.jsx)(n.h2,{id:"genai-chatcompletions-use-case",children:"GenAI ChatCompletions Use Case"}),(0,i.jsx)(n.p,{children:"In Generative AI (GenAI) applications, such as chat completions, tracing becomes essential for developers building GenAI-powered applications. These applications involve generating human-like text based on input prompts, and tracing provides visibility into the entire interaction context."}),(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"GenAI ChatCompletions Architecture",src:t(68321).A+"",width:"935",height:"459"})}),(0,i.jsx)(n.h3,{id:"what-tracing-captures",children:"What Tracing Captures"}),(0,i.jsx)(n.p,{children:"Enabling tracing on chat interfaces allows you to evaluate:"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Full Contextual History"}),": Complete conversation context"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Prompt Engineering"}),": How prompts are constructed and modified"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Input Processing"}),": User input validation and preprocessing"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Configuration Parameters"}),": Model settings and their effects"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Output Generation"}),": Response quality and characteristics"]}),"\n"]}),(0,i.jsx)(n.h3,{id:"key-metadata-for-chatcompletions",children:"Key Metadata for ChatCompletions"}),(0,i.jsx)(n.p,{children:"Additional metadata surrounding the inference process is useful for various reasons:"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Token Counts"}),": Number of tokens processed (affects billing and performance)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Model Name"}),": Specific model used for inference"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Provider Type"}),": Service or platform providing the model (OpenAI, Anthropic, etc.)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Query Parameters"}),": Settings like temperature, top-k, max_tokens"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Query Input"}),": The request input (user question)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Query Response"}),": System-generated response"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Latency"}),": Time taken for each operation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cost"}),": API costs associated with the request"]}),"\n"]}),(0,i.jsx)(n.h3,{id:"example-enhanced-chat-application",children:"Example: Enhanced Chat Application"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom openai import OpenAI\nimport time\n\n\n@mlflow.trace\ndef enhanced_chat_completion(user_message, conversation_history=None):\n    start_time = time.time()\n\n    # Add context to the trace\n    mlflow.update_current_trace(\n        tags={\n            "application": "customer_support_chat",\n            "user_type": "premium",\n            "conversation_length": len(conversation_history or []),\n        }\n    )\n\n    # Prepare messages with history\n    messages = conversation_history or []\n    messages.append({"role": "user", "content": user_message})\n\n    client = OpenAI()\n    response = client.chat.completions.create(\n        model="gpt-4o-mini", messages=messages, temperature=0.7, max_tokens=500\n    )\n\n    # Add performance metrics\n    mlflow.update_current_trace(\n        attributes={\n            "response_time_seconds": time.time() - start_time,\n            "token_count": response.usage.total_tokens,\n            "model_used": response.model,\n        }\n    )\n\n    return response.choices[0].message.content\n'})})]}),(0,i.jsxs)(l.A,{value:"rag-applications",label:"RAG Applications",children:[(0,i.jsx)(n.h2,{id:"advanced-retrieval-augmented-generation-rag-applications",children:"Advanced Retrieval-Augmented Generation (RAG) Applications"}),(0,i.jsx)(n.p,{children:"In more complex applications like Retrieval-Augmented Generation (RAG), tracing becomes essential for effective debugging and optimization. RAG involves multiple stages, including document retrieval, embedding, and interaction with GenAI models."}),(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"RAG Architecture",src:t(86375).A+"",width:"986",height:"495"})}),(0,i.jsx)(n.h3,{id:"the-challenge-without-tracing",children:"The Challenge Without Tracing"}),(0,i.jsx)(n.p,{children:"When only the input and output are visible, it becomes challenging to identify the source of issues. If a GenAI system generates an unsatisfactory response, the problem might lie in:"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Vector Store Optimization"}),": Efficiency and accuracy of document retrieval"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Embedding Model"}),": Quality of the model used to encode and search documents"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Reference Material"}),": Content and quality of the documents being queried"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Query Processing"}),": How user queries are transformed for retrieval"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Context Assembly"}),": How retrieved documents are combined with the prompt"]}),"\n"]}),(0,i.jsx)(n.h3,{id:"critical-steps-in-rag-often-hidden",children:"Critical Steps in RAG (Often Hidden)"}),(0,i.jsx)(n.p,{children:'Without tracing, these steps are effectively a "black box":'}),(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"Embedding of the input query"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"The return of the encoded query vector"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"The vector search input"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"The retrieved document chunks from the Vector Database"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"The final input to the GenAI model"})}),"\n"]}),(0,i.jsx)(n.h3,{id:"example-traced-rag-application",children:"Example: Traced RAG Application"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom openai import OpenAI\nimport numpy as np\n\n\n@mlflow.trace\ndef rag_chat_completion(user_question, vector_store):\n    # Tag the trace for RAG-specific monitoring\n    mlflow.update_current_trace(\n        tags={\n            "application_type": "rag",\n            "vector_store_type": "chromadb",\n            "retrieval_strategy": "semantic_search",\n        }\n    )\n\n    # Step 1: Embed the user question\n    embedded_question = embed_query(user_question)\n\n    # Step 2: Retrieve relevant documents\n    relevant_docs = retrieve_documents(embedded_question, vector_store)\n\n    # Step 3: Generate response with context\n    response = generate_with_context(user_question, relevant_docs)\n\n    return response\n\n\n@mlflow.trace\ndef embed_query(query):\n    """Convert user query to vector embedding."""\n    # Embedding logic here\n    mlflow.update_current_trace(\n        attributes={\n            "query_length": len(query),\n            "embedding_model": "text-embedding-ada-002",\n        }\n    )\n    # Return embedding vector\n    return np.random.rand(1536)  # Placeholder\n\n\n@mlflow.trace\ndef retrieve_documents(query_embedding, vector_store, top_k=5):\n    """Retrieve relevant documents from vector store."""\n    # Vector search logic here\n    mlflow.update_current_trace(\n        attributes={"top_k": top_k, "search_type": "cosine_similarity"}\n    )\n\n    # Simulate document retrieval\n    documents = [\n        {"content": "Document 1 content...", "score": 0.85},\n        {"content": "Document 2 content...", "score": 0.82},\n    ]\n\n    mlflow.update_current_trace(\n        attributes={\n            "documents_found": len(documents),\n            "avg_relevance_score": sum(d["score"] for d in documents) / len(documents),\n        }\n    )\n\n    return documents\n\n\n@mlflow.trace\ndef generate_with_context(question, documents):\n    """Generate answer using retrieved context."""\n    # Prepare context from documents\n    context = "\\n".join([doc["content"] for doc in documents])\n\n    mlflow.update_current_trace(\n        attributes={"context_length": len(context), "num_context_docs": len(documents)}\n    )\n\n    # Generate response with context\n    client = OpenAI()\n    response = client.chat.completions.create(\n        model="gpt-4o-mini",\n        messages=[\n            {"role": "system", "content": f"Answer based on this context: {context}"},\n            {"role": "user", "content": question},\n        ],\n    )\n\n    return response.choices[0].message.content\n'})}),(0,i.jsx)(n.h3,{id:"benefits-of-rag-tracing",children:"Benefits of RAG Tracing"}),(0,i.jsx)(n.p,{children:"With this tracing setup, you can:"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Debug Retrieval Issues"}),": See exactly which documents were retrieved and their relevance scores"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Optimize Embedding"}),": Monitor embedding quality and performance"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Tune Context Assembly"}),": Understand how context affects generation quality"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Monitor Performance"}),": Track latency at each stage of the pipeline"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Analyze Failures"}),": Identify which component caused issues"]}),"\n"]})]}),(0,i.jsxs)(l.A,{value:"traditional-ml",label:"Traditional ML",children:[(0,i.jsx)(n.h2,{id:"beyond-genai-tracing-for-traditional-machine-learning",children:"Beyond GenAI: Tracing for Traditional Machine Learning"}),(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsx)(n.p,{children:"While this documentation focuses on GenAI applications where tracing provides the most value, MLflow Tracing can also be applied to traditional ML workflows for monitoring and performance analysis."})}),(0,i.jsx)(n.p,{children:"In traditional ML, the inference process is relatively straightforward compared to GenAI applications. When a request is made, input data is fed into the model, which processes the data and generates a prediction."}),(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Traditional ML Inference Architecture",src:t(27073).A+"",width:"715",height:"370"})}),(0,i.jsx)(n.h3,{id:"traditional-ml-characteristics",children:"Traditional ML Characteristics"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Transparent Process"}),": Both input and output are clearly defined and understandable"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Deterministic"}),": Same input typically produces the same output"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Single Model"}),": Usually involves one primary model for prediction"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Structured Data"}),": Often works with tabular or well-defined data formats"]}),"\n"]}),(0,i.jsx)(n.h3,{id:"example-spam-detection-model",children:"Example: Spam Detection Model"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Input: Email text\nemail_text = "Congratulations! You\'ve won $1000. Click here to claim..."\n\n# Output: Binary classification\nis_spam = True  # or False\n'})}),(0,i.jsx)(n.p,{children:"This process is wholly visible - the email content and spam/not-spam label are both interpretable."}),(0,i.jsx)(n.h3,{id:"when-tracing-helps-in-traditional-ml",children:"When Tracing Helps in Traditional ML"}),(0,i.jsx)(n.p,{children:"While qualitative model performance assessment may not require tracing, it can still provide value for:"}),(0,i.jsx)(n.h4,{id:"1-performance-monitoring",children:"1. Performance Monitoring"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport time\n\n\n@mlflow.trace\ndef predict_fraud(transaction_data):\n    start_time = time.time()\n\n    # Preprocess the data\n    processed_data = preprocess_transaction(transaction_data)\n\n    # Make prediction\n    prediction = fraud_model.predict(processed_data)\n\n    # Log performance metrics\n    mlflow.update_current_trace(\n        attributes={\n            "prediction_time_ms": (time.time() - start_time) * 1000,\n            "model_version": "v2.1.0",\n            "confidence_score": prediction.probability,\n        }\n    )\n\n    return prediction\n'})}),(0,i.jsx)(n.h4,{id:"2-api-access-logging",children:"2. API Access Logging"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'@mlflow.trace\ndef ml_api_endpoint(request_data, user_id):\n    mlflow.update_current_trace(\n        tags={"user_id": user_id, "api_version": "v1", "endpoint": "/predict"}\n    )\n\n    # Process request and return prediction\n    result = make_prediction(request_data)\n\n    mlflow.update_current_trace(\n        attributes={\n            "request_size_bytes": len(str(request_data)),\n            "response_size_bytes": len(str(result)),\n        }\n    )\n\n    return result\n'})}),(0,i.jsx)(n.h4,{id:"3-multi-model-pipelines",children:"3. Multi-Model Pipelines"}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"@mlflow.trace\ndef ensemble_prediction(input_data):\n    # Use multiple models in sequence\n    preprocessed = preprocessing_model(input_data)\n    features = feature_extraction_model(preprocessed)\n    prediction = final_model(features)\n\n    return prediction\n"})}),(0,i.jsx)(n.h3,{id:"differences-from-genai-tracing",children:"Differences from GenAI Tracing"}),(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Aspect"}),(0,i.jsx)(n.th,{children:"Traditional ML"}),(0,i.jsx)(n.th,{children:"GenAI Applications"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Complexity"})}),(0,i.jsx)(n.td,{children:"Simple input \u2192 output"}),(0,i.jsx)(n.td,{children:"Multi-step, contextual processes"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Transparency"})}),(0,i.jsx)(n.td,{children:"High (interpretable I/O)"}),(0,i.jsx)(n.td,{children:"Low (complex internal processing)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Debugging Need"})}),(0,i.jsx)(n.td,{children:"Performance & infrastructure"}),(0,i.jsx)(n.td,{children:"Quality, relevance, hallucinations"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Trace Value"})}),(0,i.jsx)(n.td,{children:"Operational monitoring"}),(0,i.jsx)(n.td,{children:"Essential for development & debugging"})]})]})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"getting-started-with-concepts",children:"Getting Started with Concepts"}),"\n",(0,i.jsx)(n.p,{children:"Now that you understand these fundamental concepts:"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/genai/tracing/app-instrumentation",children:"Instrument Your App"})}),": Learn how to add tracing to your applications"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/genai/tracing/data-model",children:"Trace Data Model"})}),": Explore the detailed schema and API reference"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/genai/tracing/app-instrumentation/automatic",children:"Automatic Tracing"})}),": Enable one-line tracing for supported libraries"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/genai/tracing/app-instrumentation/manual-tracing",children:"Manual Tracing"})}),": Create custom spans for your application logic"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.em,{children:"These concepts form the foundation for understanding how MLflow Tracing provides observability into your GenAI applications. The hierarchical structure of traces and spans, combined with rich metadata capture and specialized schemas, enables deep insights into your application's behavior and performance."})})]})}function m(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(u,{...e})}):u(e)}},86375:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/images/rag-architecture-6f938acab86926f8a2bb36f06bdb9b67.png"}}]);