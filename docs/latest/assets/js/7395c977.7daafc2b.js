"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["6110"],{40521(e,n,r){r.r(n),r.d(n,{metadata:()=>a,default:()=>x,frontMatter:()=>m,contentTitle:()=>g,toc:()=>h,assets:()=>u});var a=JSON.parse('{"id":"deep-learning/transformers/index","title":"MLflow Transformers Flavor","description":"The MLflow Transformers flavor provides native integration with the Hugging Face Transformers library, supporting model logging, loading, and inference for NLP, audio, vision, and multimodal tasks.","source":"@site/docs/classic-ml/deep-learning/transformers/index.mdx","sourceDirName":"deep-learning/transformers","slug":"/deep-learning/transformers/","permalink":"/mlflow-website/docs/latest/ml/deep-learning/transformers/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"classicMLSidebar","previous":{"title":"Keras","permalink":"/mlflow-website/docs/latest/ml/deep-learning/keras/"},"next":{"title":"\u{1F917} Transformers within MLflow","permalink":"/mlflow-website/docs/latest/ml/deep-learning/transformers/guide/"}}'),i=r(74848),t=r(28453),l=r(3340),o=r(10440),s=r(77541),d=r(60665),c=r(80827);let m={},g="MLflow Transformers Flavor",u={},h=[{value:"Key Features",id:"key-features",level:2},{value:"Installation",id:"installation",level:2},{value:"Basic Usage",id:"basic-usage",level:2},{value:"Logging a Pipeline",id:"logging-a-pipeline",level:3},{value:"Loading and Inference",id:"loading-and-inference",level:3},{value:"Autologging with HuggingFace Trainer",id:"autologging-with-huggingface-trainer",level:2},{value:"Tutorials",id:"tutorials",level:2},{value:"Quickstart",id:"quickstart",level:3},{value:"Fine-Tuning",id:"fine-tuning",level:3},{value:"Advanced Use Cases",id:"advanced-use-cases",level:3},{value:"Important Considerations",id:"important-considerations",level:2},{value:"PyFunc Limitations",id:"pyfunc-limitations",level:3},{value:"Input/Output Types",id:"inputoutput-types",level:3},{value:"Model Configuration",id:"model-configuration",level:3},{value:"Working with Large Models",id:"working-with-large-models",level:2},{value:"Tasks",id:"tasks",level:2},{value:"Learn More",id:"learn-more",level:2}];function p(e){let n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"mlflow-transformers-flavor",children:"MLflow Transformers Flavor"})}),"\n",(0,i.jsxs)(n.p,{children:["The MLflow Transformers flavor provides native integration with the ",(0,i.jsx)(n.a,{href:"https://huggingface.co/docs/transformers/index",children:"Hugging Face Transformers"})," library, supporting model logging, loading, and inference for NLP, audio, vision, and multimodal tasks."]}),"\n",(0,i.jsx)(n.h2,{id:"key-features",children:"Key Features"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Pipeline and Component Logging"}),": Save complete pipelines or individual model components"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"PyFunc Integration"}),": Deploy models with standardized inference interfaces"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"PEFT Support"}),": Native support for parameter-efficient fine-tuning (LoRA, QLoRA, etc.)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Prompt Templates"}),": Save and manage prompt templates with pipelines"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Automatic Metadata Logging"}),": Model cards and metadata logged automatically"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Flexible Inference Configuration"}),": Customize model behavior via ",(0,i.jsx)(n.code,{children:"model_config"})," and signature parameters"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pip install mlflow transformers\n"})}),"\n",(0,i.jsx)(n.h2,{id:"basic-usage",children:"Basic Usage"}),"\n",(0,i.jsx)(n.h3,{id:"logging-a-pipeline",children:"Logging a Pipeline"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom transformers import pipeline\n\n# Create a text generation pipeline\ntext_gen = pipeline("text-generation", model="gpt2")\n\n# Log the pipeline\nwith mlflow.start_run():\n    mlflow.transformers.log_model(\n        transformers_model=text_gen,\n        name="model",\n    )\n'})}),"\n",(0,i.jsx)(n.h3,{id:"loading-and-inference",children:"Loading and Inference"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Load as native transformers\nmodel = mlflow.transformers.load_model("runs:/<run_id>/model")\nresult = model("Hello, how are you?")\n\n# Load as PyFunc\npyfunc_model = mlflow.pyfunc.load_model("runs:/<run_id>/model")\nresult = pyfunc_model.predict("Hello, how are you?")\n'})}),"\n",(0,i.jsx)(n.h2,{id:"autologging-with-huggingface-trainer",children:"Autologging with HuggingFace Trainer"}),"\n",(0,i.jsxs)(n.p,{children:["When using the HuggingFace ",(0,i.jsx)(n.code,{children:"Trainer"})," class for fine-tuning, you can enable automatic logging to MLflow by setting ",(0,i.jsx)(n.code,{children:'report_to="mlflow"'})," in the ",(0,i.jsx)(n.code,{children:"TrainingArguments"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir="./results",\n    report_to="mlflow",  # Enable MLflow logging\n    # ... other training arguments\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    # ... other trainer arguments\n)\n\ntrainer.train()\n'})}),"\n",(0,i.jsx)(n.p,{children:"This automatically logs training metrics, hyperparameters, and model checkpoints to your active MLflow run."}),"\n",(0,i.jsx)(n.h2,{id:"tutorials",children:"Tutorials"}),"\n",(0,i.jsx)(n.h3,{id:"quickstart",children:"Quickstart"}),"\n",(0,i.jsx)(l.AC,{children:(0,i.jsx)(l._C,{headerText:"Text Generation with Transformers",link:"/ml/deep-learning/transformers/tutorials/text-generation/text-generation/",text:"Introductory quickstart for using Transformers with MLflow"})}),"\n",(0,i.jsx)(n.h3,{id:"fine-tuning",children:"Fine-Tuning"}),"\n",(0,i.jsxs)(l.AC,{children:[(0,i.jsx)(l._C,{headerText:"Fine-tuning a Foundation Model",link:"/ml/deep-learning/transformers/tutorials/fine-tuning/transformers-fine-tuning/",text:"Track fine-tuning experiments and log optimized models"}),(0,i.jsx)(l._C,{headerText:"Fine-tuning with PEFT",link:"/ml/deep-learning/transformers/tutorials/fine-tuning/transformers-peft/",text:"Memory-efficient fine-tuning using PEFT (QLoRA) techniques"})]}),"\n",(0,i.jsx)(n.h3,{id:"advanced-use-cases",children:"Advanced Use Cases"}),"\n",(0,i.jsxs)(l.AC,{children:[(0,i.jsx)(l._C,{headerText:"Audio Transcription",link:"/ml/deep-learning/transformers/tutorials/audio-transcription/whisper/",text:"Use Whisper models for audio transcription"}),(0,i.jsx)(l._C,{headerText:"Translation",link:"/ml/deep-learning/transformers/tutorials/translation/component-translation/",text:"Component-based model logging for translation tasks"}),(0,i.jsx)(l._C,{headerText:"Conversational Pipelines",link:"/ml/deep-learning/transformers/tutorials/conversational/conversational-model/",text:"Stateful chat with conversational pipelines"}),(0,i.jsx)(l._C,{headerText:"OpenAI-Compatible Chatbot",link:"/ml/deep-learning/transformers/tutorials/conversational/pyfunc-chat-model/",text:"Build and serve an OpenAI-compatible chatbot"}),(0,i.jsx)(l._C,{headerText:"Prompt Templating",link:"/ml/deep-learning/transformers/tutorials/prompt-templating/prompt-templating/",text:"Optimize LLM outputs with prompt templates"})]}),"\n",(0,i.jsx)(n.h2,{id:"important-considerations",children:"Important Considerations"}),"\n",(0,i.jsx)(n.h3,{id:"pyfunc-limitations",children:"PyFunc Limitations"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Not all pipeline types are supported for PyFunc inference"}),"\n",(0,i.jsx)(n.li,{children:"Some outputs (e.g., additional scores, references) may not be captured"}),"\n",(0,i.jsx)(n.li,{children:"Audio and text LLMs are supported; vision and multimodal models require native loading"}),"\n",(0,i.jsxs)(n.li,{children:["See the ",(0,i.jsx)(n.a,{href:"/ml/deep-learning/transformers/guide#loading-a-transformers-model-as-a-python-function",children:"guide"})," for supported pipeline types"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"inputoutput-types",children:"Input/Output Types"}),"\n",(0,i.jsx)(n.p,{children:"Input and output formats for PyFunc may differ from native pipelines. Ensure compatibility with your data processing workflows."}),"\n",(0,i.jsx)(n.h3,{id:"model-configuration",children:"Model Configuration"}),"\n",(0,i.jsxs)(n.p,{children:["Parameters in ",(0,i.jsx)(n.code,{children:"ModelSignature"})," override those in ",(0,i.jsx)(n.code,{children:"model_config"})," when both are provided."]}),"\n",(0,i.jsx)(n.h2,{id:"working-with-large-models",children:"Working with Large Models"}),"\n",(0,i.jsxs)(n.p,{children:["For models with billions of parameters, MLflow provides optimization techniques to reduce memory usage and speed up logging. See the ",(0,i.jsx)(n.a,{href:"/ml/deep-learning/transformers/large-models",children:"large models guide"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"tasks",children:"Tasks"}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"task"})," parameter determines input/output format. MLflow supports native Transformers tasks plus advanced tasks like ",(0,i.jsx)(n.code,{children:"llm/v1/chat"})," and ",(0,i.jsx)(n.code,{children:"llm/v1/completions"})," for OpenAI-compatible inference. See the ",(0,i.jsx)(n.a,{href:"/ml/deep-learning/transformers/task",children:"tasks guide"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"learn-more",children:"Learn More"}),"\n",(0,i.jsxs)(o.A,{children:[(0,i.jsx)(s.A,{icon:d.A,title:"Detailed Guide",description:"Comprehensive documentation covering pipelines, PyFunc, signatures, PEFT, and more",href:"/ml/deep-learning/transformers/guide"}),(0,i.jsx)(s.A,{icon:c.A,title:"Transformers Documentation",description:"Official Hugging Face Transformers documentation",href:"https://huggingface.co/docs/transformers/index"})]})]})}function x(e={}){let{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(p,{...e})}):p(e)}},75689(e,n,r){r.d(n,{A:()=>s});var a=r(96540);let i=e=>{let n=e.replace(/^([A-Z])|[\s-_]+(\w)/g,(e,n,r)=>r?r.toUpperCase():n.toLowerCase());return n.charAt(0).toUpperCase()+n.slice(1)},t=(...e)=>e.filter((e,n,r)=>!!e&&""!==e.trim()&&r.indexOf(e)===n).join(" ").trim();var l={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};let o=(0,a.forwardRef)(({color:e="currentColor",size:n=24,strokeWidth:r=2,absoluteStrokeWidth:i,className:o="",children:s,iconNode:d,...c},m)=>(0,a.createElement)("svg",{ref:m,...l,width:n,height:n,stroke:e,strokeWidth:i?24*Number(r)/Number(n):r,className:t("lucide",o),...!s&&!(e=>{for(let n in e)if(n.startsWith("aria-")||"role"===n||"title"===n)return!0})(c)&&{"aria-hidden":"true"},...c},[...d.map(([e,n])=>(0,a.createElement)(e,n)),...Array.isArray(s)?s:[s]])),s=(e,n)=>{let r=(0,a.forwardRef)(({className:r,...l},s)=>(0,a.createElement)(o,{ref:s,iconNode:n,className:t(`lucide-${i(e).replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()}`,`lucide-${e}`,r),...l}));return r.displayName=i(e),r}},60665(e,n,r){r.d(n,{A:()=>a});let a=(0,r(75689).A)("book-open",[["path",{d:"M12 7v14",key:"1akyts"}],["path",{d:"M3 18a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h5a4 4 0 0 1 4 4 4 4 0 0 1 4-4h5a1 1 0 0 1 1 1v13a1 1 0 0 1-1 1h-6a3 3 0 0 0-3 3 3 3 0 0 0-3-3z",key:"ruj8y"}]])},80827(e,n,r){r.d(n,{A:()=>a});let a=(0,r(75689).A)("file-text",[["path",{d:"M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z",key:"1rqfz7"}],["path",{d:"M14 2v4a2 2 0 0 0 2 2h4",key:"tnqrlb"}],["path",{d:"M10 9H8",key:"b1mrlr"}],["path",{d:"M16 13H8",key:"t4e002"}],["path",{d:"M16 17H8",key:"z1uh3a"}]])},3340(e,n,r){r.d(n,{WO:()=>c,$3:()=>m,jK:()=>g,_C:()=>d,Zp:()=>s,AC:()=>o});var a=r(74848),i=r(34164);let t={CardGroup:"CardGroup_P84T",NoGap:"NoGap_O9Dj",MaxThreeColumns:"MaxThreeColumns_FO1r",AutofillColumns:"AutofillColumns_fKhQ",Card:"Card_aSCR",CardBordered:"CardBordered_glGF",CardBody:"CardBody_BhRs",TextColor:"TextColor_a8Tp",BoxRoot:"BoxRoot_Etgr",FlexWrapNowrap:"FlexWrapNowrap_f60k",FlexJustifyContentFlexStart:"FlexJustifyContentFlexStart_ZYv5",FlexDirectionRow:"FlexDirectionRow_T2qL",FlexAlignItemsCenter:"FlexAlignItemsCenter_EHVM",FlexFlex:"FlexFlex__JTE",Link:"Link_fVkl",MarginLeft4:"MarginLeft4_YQSJ",MarginTop4:"MarginTop4_jXKN",PaddingBottom4:"PaddingBottom4_O9gt",LogoCardContent:"LogoCardContent_kCQm",LogoCardImage:"LogoCardImage_JdcX",SmallLogoCardContent:"SmallLogoCardContent_LxhV",SmallLogoCardRounded:"SmallLogoCardRounded_X50_",SmallLogoCardImage:"SmallLogoCardImage_tPZl",SmallLogoCardImageWithTitle:"SmallLogoCardImageWithTitle_K6Vu",SmallLogoCardImageDefault:"SmallLogoCardImageDefault_nyru",SmallLogoCardRow:"SmallLogoCardRow_kcMP",SmallLogoCardLabel:"SmallLogoCardLabel_f5RQ",SmallLogoCardArrow:"SmallLogoCardArrow_J536",SmallLogoCardLink:"SmallLogoCardLink_Cm5j",NewFeatureCardContent:"NewFeatureCardContent_Rq3d",NewFeatureCardHeading:"NewFeatureCardHeading_f6q3",NewFeatureCardHeadingSeparator:"NewFeatureCardHeadingSeparator_pSx8",NewFeatureCardTags:"NewFeatureCardTags_IFHO",NewFeatureCardWrapper:"NewFeatureCardWrapper_NQ0k",TitleCardContent:"TitleCardContent_l9MQ",TitleCardHeader:"TitleCardHeader_fUQy",TitleCardHeaderRight:"TitleCardHeaderRight_iBLX",TitleCardTitle:"TitleCardTitle__K8J",TitleCardSeparator:"TitleCardSeparator_IN2E",Cols1:"Cols1_Gr2U",Cols2:"Cols2_sRvc",Cols3:"Cols3_KjUS",Cols4:"Cols4_dKOj",Cols5:"Cols5_jDmj",Cols6:"Cols6_Q0OR"};var l=r(95310);let o=({children:e,isSmall:n,cols:r,noGap:l})=>(0,a.jsx)("div",{className:(0,i.A)(t.CardGroup,n?t.AutofillColumns:r?t[`Cols${r}`]:t.MaxThreeColumns,l&&t.NoGap),children:e}),s=({children:e,link:n="",style:r})=>n?(0,a.jsx)(l.A,{className:(0,i.A)(t.Link,t.Card,t.CardBordered),style:r,to:n,children:e}):(0,a.jsx)("div",{className:(0,i.A)(t.Card,t.CardBordered),style:r,children:e}),d=({headerText:e,link:n,text:r})=>(0,a.jsx)(s,{link:n,children:(0,a.jsxs)("span",{children:[(0,a.jsx)("div",{className:(0,i.A)(t.CardTitle,t.BoxRoot,t.PaddingBottom4),style:{pointerEvents:"none"},children:(0,a.jsx)("div",{className:(0,i.A)(t.BoxRoot,t.FlexFlex,t.FlexAlignItemsCenter,t.FlexDirectionRow,t.FlexJustifyContentFlexStart,t.FlexWrapNowrap),style:{marginLeft:"-4px",marginTop:"-4px"},children:(0,a.jsx)("div",{className:(0,i.A)(t.BoxRoot,t.BoxHideIfEmpty,t.MarginTop4,t.MarginLeft4),style:{pointerEvents:"auto"},children:(0,a.jsx)("span",{className:"",children:e})})})}),(0,a.jsx)("span",{className:(0,i.A)(t.TextColor,t.CardBody),children:(0,a.jsx)("p",{children:r})})]})}),c=({description:e,children:n,link:r})=>(0,a.jsx)(s,{link:r,children:(0,a.jsxs)("div",{className:t.LogoCardContent,children:[(0,a.jsx)("div",{className:t.LogoCardImage,children:n}),(0,a.jsx)("p",{className:t.TextColor,children:e})]})}),m=({children:e,link:n,title:r=""})=>(0,a.jsx)(l.A,{className:(0,i.A)(t.Card,t.CardBordered,t.SmallLogoCardRounded,t.SmallLogoCardLink),to:n,children:(0,a.jsx)("div",{className:t.SmallLogoCardContent,children:r?(0,a.jsxs)("div",{className:t.SmallLogoCardRow,children:[(0,a.jsx)("div",{className:(0,i.A)("max-height-img-container",t.SmallLogoCardImage,t.SmallLogoCardImageWithTitle),children:e}),(0,a.jsx)("div",{className:t.SmallLogoCardLabel,children:(0,a.jsx)("span",{children:r})})]}):(0,a.jsx)("div",{className:(0,i.A)("max-height-img-container",t.SmallLogoCardImage,t.SmallLogoCardImageDefault),children:e})})}),g=({title:e,description:n,link:r="",headerRight:l,children:o})=>(0,a.jsx)(s,{link:r,children:(0,a.jsxs)("div",{className:t.TitleCardContent,children:[(0,a.jsxs)("div",{className:(0,i.A)(t.TitleCardHeader),children:[(0,a.jsx)("div",{className:(0,i.A)(t.TitleCardTitle),style:{textAlign:"left",fontWeight:"bold"},children:e}),(0,a.jsx)("div",{className:t.TitleCardHeaderRight,children:l})]}),(0,a.jsx)("hr",{className:(0,i.A)(t.TitleCardSeparator),style:{margin:"12px 0"}}),o?(0,a.jsx)("div",{className:(0,i.A)(t.TextColor),children:o}):(0,a.jsx)("p",{className:(0,i.A)(t.TextColor),dangerouslySetInnerHTML:{__html:n}})]})})},77541(e,n,r){r.d(n,{A:()=>d});var a=r(74848);r(96540);var i=r(95310),t=r(34164);let l="tileImage_O4So";var o=r(66497),s=r(92802);function d({icon:e,image:n,imageDark:r,imageWidth:d,imageHeight:c,iconSize:m=32,containerHeight:g,title:u,description:h,href:p,linkText:x="Learn more \u2192",className:f}){if(!e&&!n)throw Error("TileCard requires either an icon or image prop");let C=g?{height:`${g}px`}:{},j={};return d&&(j.width=`${d}px`),c&&(j.height=`${c}px`),(0,a.jsxs)(i.A,{href:p,className:(0,t.A)("tileCard_NHsj",f),children:[(0,a.jsx)("div",{className:"tileIcon_pyoR",style:C,children:e?(0,a.jsx)(e,{size:m}):r?(0,a.jsx)(s.A,{sources:{light:(0,o.default)(n),dark:(0,o.default)(r)},alt:u,className:l,style:j}):(0,a.jsx)("img",{src:(0,o.default)(n),alt:u,className:l,style:j})}),(0,a.jsx)("h3",{children:u}),(0,a.jsx)("p",{children:h}),(0,a.jsx)("div",{className:"tileLink_iUbu",children:x})]})}},10440(e,n,r){r.d(n,{A:()=>t});var a=r(74848);r(96540);var i=r(34164);function t({children:e,className:n}){return(0,a.jsx)("div",{className:(0,i.A)("tilesGrid_hB9N",n),children:e})}},28453(e,n,r){r.d(n,{R:()=>l,x:()=>o});var a=r(96540);let i={},t=a.createContext(i);function l(e){let n=a.useContext(t);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),a.createElement(t.Provider,{value:n},e.children)}}}]);