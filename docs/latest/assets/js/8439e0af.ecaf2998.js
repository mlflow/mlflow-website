"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[5853],{6789:(e,n,t)=>{t.d(n,{A:()=>c});t(96540);var i=t(28774),a=t(34164);const r={tileCard:"tileCard_NHsj",tileIcon:"tileIcon_pyoR",tileLink:"tileLink_iUbu",tileImage:"tileImage_O4So"};var l=t(86025),s=t(15626),o=t(74848);function c({icon:e,image:n,imageDark:t,imageWidth:c,imageHeight:m,iconSize:d=32,containerHeight:p,title:h,description:u,href:g,linkText:f="Learn more \u2192",className:_}){if(!e&&!n)throw new Error("TileCard requires either an icon or image prop");const j=p?{height:`${p}px`}:{},x={};return c&&(x.width=`${c}px`),m&&(x.height=`${m}px`),(0,o.jsxs)(i.A,{href:g,className:(0,a.A)(r.tileCard,_),children:[(0,o.jsx)("div",{className:r.tileIcon,style:j,children:e?(0,o.jsx)(e,{size:d}):t?(0,o.jsx)(s.A,{sources:{light:(0,l.default)(n),dark:(0,l.default)(t)},alt:h,className:r.tileImage,style:x}):(0,o.jsx)("img",{src:(0,l.default)(n),alt:h,className:r.tileImage,style:x})}),(0,o.jsx)("h3",{children:h}),(0,o.jsx)("p",{children:u}),(0,o.jsx)("div",{className:r.tileLink,children:f})]})}},28680:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>N,contentTitle:()=>z,default:()=>M,frontMatter:()=>k,metadata:()=>i,toc:()=>S});const i=JSON.parse('{"id":"eval-monitor/scorers/llm-judge/alignment","title":"Judge Alignment: Teaching AI to Match Human Preferences","description":"Transform Generic Judges into Domain Experts","source":"@site/docs/genai/eval-monitor/scorers/llm-judge/alignment.mdx","sourceDirName":"eval-monitor/scorers/llm-judge","slug":"/eval-monitor/scorers/llm-judge/alignment","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/alignment","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"genAISidebar","previous":{"title":"Code-based Scorers","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/custom"},"next":{"title":"Versioning Scorers","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/versioning"}}');var a=t(74848),r=t(28453),l=t(11470),s=t(19365),o=t(49374),c=t(47020),m=t(82238),d=t(79206),p=t(65592),h=t(6789),u=t(56955),g=t(87073),f=t(47792),_=t(15977),j=t(22492),x=t(80964),w=t(93893),y=t(96393),v=t(51004),b=t(61878),A=t(66927);const k={},z="Judge Alignment: Teaching AI to Match Human Preferences",N={},S=[{value:"Transform Generic Judges into Domain Experts",id:"transform-generic-judges-into-domain-experts",level:2},{value:"Why Alignment Matters",id:"why-alignment-matters",level:2},{value:"How Judge Alignment Works",id:"how-judge-alignment-works",level:2},{value:"Quick Start: Align Your First Judge",id:"quick-start-align-your-first-judge",level:2},{value:"Step 1: Setup and Generate Traces",id:"step-1-setup-and-generate-traces",level:3},{value:"Step 2: Collect Human Feedback",id:"step-2-collect-human-feedback",level:3},{value:"Step 3: Align and Register",id:"step-3-align-and-register",level:3},{value:"The SIMBA Alignment Optimizer",id:"the-simba-alignment-optimizer",level:2},{value:"Controlling Optimization Output",id:"controlling-optimization-output",level:3},{value:"Collecting Feedback for Alignment",id:"collecting-feedback-for-alignment",level:2},{value:"Feedback Collection Approaches",id:"feedback-collection-approaches",level:3},{value:"Custom Alignment Optimizers",id:"custom-alignment-optimizers",level:2},{value:"Creating a Custom Optimizer",id:"creating-a-custom-optimizer",level:3},{value:"Using Custom Optimizers",id:"using-custom-optimizers",level:3},{value:"Available Optimizers",id:"available-optimizers",level:3},{value:"Testing Alignment Effectiveness",id:"testing-alignment-effectiveness",level:2},{value:"Next Steps",id:"next-steps",level:2}];function I(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"judge-alignment-teaching-ai-to-match-human-preferences",children:"Judge Alignment: Teaching AI to Match Human Preferences"})}),"\n",(0,a.jsx)(n.h2,{id:"transform-generic-judges-into-domain-experts",children:"Transform Generic Judges into Domain Experts"}),"\n",(0,a.jsx)(n.p,{children:"Judge alignment is the process of refining LLM judges to match human evaluation standards. Through systematic learning from human feedback, judges evolve from generic evaluators to domain-specific experts that understand your unique quality criteria."}),"\n",(0,a.jsx)(n.h2,{id:"why-alignment-matters",children:"Why Alignment Matters"}),"\n",(0,a.jsx)(n.p,{children:'Even the most sophisticated LLMs need calibration to match your specific evaluation standards. What constitutes "good" customer service varies by industry. Medical accuracy requirements differ from general health advice. Alignment bridges this gap, teaching judges your specific quality standards through example.'}),"\n",(0,a.jsx)(m.A,{features:[{icon:g.A,title:"Learn from Expert Feedback",description:"Judges improve by learning from your domain experts' assessments, capturing nuanced quality criteria that generic prompts miss."},{icon:f.A,title:"Consistent Standards at Scale",description:"Once aligned, judges apply your exact quality standards consistently across millions of evaluations."},{icon:_.A,title:"Continuous Improvement",description:"As your standards evolve, judges can be re-aligned with new feedback, maintaining relevance over time."},{icon:j.A,title:"Reduced Evaluation Errors",description:"Aligned judges show 30-50% reduction in false positives/negatives compared to generic evaluation prompts."}]}),"\n",(0,a.jsx)(n.h2,{id:"how-judge-alignment-works",children:"How Judge Alignment Works"}),"\n",(0,a.jsx)(u.A,{title:"Alignment Lifecycle",steps:[{icon:x.A,title:"Create Initial Judge",description:"Define basic criteria",detailedDescription:"Start with a judge that has basic evaluation instructions. This will be refined through the alignment process."},{icon:w.A,title:"Collect Human Feedback",description:"Experts assess outputs",detailedDescription:"Domain experts review judge outputs and provide ground truth assessments that capture your specific quality standards."},{icon:g.A,title:"Run Alignment",description:"Learn from patterns",detailedDescription:"The SIMBA optimizer analyzes feedback patterns and automatically refines judge instructions to match human preferences.",isFocus:!0},{icon:f.A,title:"Validate Accuracy",description:"Test improvements",detailedDescription:"Compare aligned judge against baseline on held-out test data to verify genuine accuracy improvements."},{icon:y.A,title:"Monitor & Iterate",description:"Track performance",detailedDescription:"Monitor judge accuracy in production and collect new feedback for continuous improvement."}],loopBackIcon:_.A,loopBackText:"Continuous Refinement",loopBackDescription:"As standards evolve, continue collecting feedback and re-aligning",circleSize:500}),"\n",(0,a.jsx)(n.h2,{id:"quick-start-align-your-first-judge",children:"Quick Start: Align Your First Judge"}),"\n",(0,a.jsxs)(n.admonition,{title:"Critical Requirement for Alignment",type:"warning",children:[(0,a.jsxs)(n.p,{children:["For alignment to work, each trace must have BOTH judge assessments AND human feedback ",(0,a.jsx)(n.strong,{children:"with the same assessment name"}),". The alignment process learns by comparing judge assessments with human feedback on the same traces."]}),(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"The assessment name must exactly match the judge name"}),' - if your judge is named "product_quality", both the judge\'s assessments and human feedback must use the name "product_quality".']}),(0,a.jsx)(n.p,{children:"The order doesn't matter - humans can provide feedback before or after the judge evaluates."})]}),"\n",(0,a.jsx)(n.h3,{id:"step-1-setup-and-generate-traces",children:"Step 1: Setup and Generate Traces"}),"\n",(0,a.jsx)(n.p,{children:"First, create your judge and generate traces with initial assessments:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from mlflow.genai.judges import make_judge\nfrom mlflow.genai.judges.optimizers import SIMBAAlignmentOptimizer\nfrom mlflow.entities import AssessmentSource, AssessmentSourceType\nfrom typing import Literal\nimport mlflow\n\n# Create experiment and initial judge\nexperiment_id = mlflow.create_experiment("product-quality-alignment")\nmlflow.set_experiment(experiment_id=experiment_id)\n\ninitial_judge = make_judge(\n    name="product_quality",\n    instructions=(\n        "Evaluate if the product description in {{ outputs }} "\n        "is accurate and helpful for the query in {{ inputs }}. "\n        "Rate as: excellent, good, fair, or poor"\n    ),\n    feedback_value_type=Literal["excellent", "good", "fair", "poor"],\n    model="anthropic:/claude-opus-4-1-20250805",\n)\n\n# Generate traces from your application (minimum 10 required)\ntraces = []\nfor i in range(15):  # Generate 15 traces (more than minimum of 10)\n    with mlflow.start_span(f"product_description_{i}") as span:\n        # Your application logic\n        query = f"Product query {i}"\n        description = f"Product description for query {i}"\n        span.set_inputs({"query": query})\n        span.set_outputs({"description": description})\n        traces.append(span.trace_id)\n\n# Run the judge on these traces to get initial assessments\nfor trace_id in traces:\n    trace = mlflow.get_trace(trace_id)\n\n    # Extract inputs and outputs from the trace for field-based evaluation\n    inputs = trace.data.spans[0].inputs  # Get inputs from trace\n    outputs = trace.data.spans[0].outputs  # Get outputs from trace\n\n    # Judge evaluates using field-based approach (inputs/outputs)\n    judge_result = initial_judge(inputs=inputs, outputs=outputs)\n    # Judge\'s assessment is automatically logged when called\n'})}),"\n",(0,a.jsx)(n.h3,{id:"step-2-collect-human-feedback",children:"Step 2: Collect Human Feedback"}),"\n",(0,a.jsx)(n.p,{children:"After running your judge on traces, you need to collect human feedback. You can either:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Use the MLflow UI"})," (recommended): Review traces and add feedback through the intuitive interface"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Log programmatically"}),": If you already have ground truth labels"]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["For detailed instructions on collecting feedback, see ",(0,a.jsx)(n.a,{href:"#collecting-feedback-for-alignment",children:"Collecting Feedback for Alignment"})," below."]}),"\n",(0,a.jsx)(n.h3,{id:"step-3-align-and-register",children:"Step 3: Align and Register"}),"\n",(0,a.jsx)(n.p,{children:"After collecting feedback, align your judge and register it:"}),"\n",(0,a.jsx)(c.A,{children:(0,a.jsxs)(l.A,{children:[(0,a.jsx)(s.A,{value:"default",label:"Default Optimizer (Recommended)",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Retrieve traces with both judge and human assessments\ntraces_for_alignment = mlflow.search_traces(\n    experiment_ids=[experiment_id], max_results=15, return_type="list"\n)\n\n# Align the judge using human corrections (minimum 10 traces recommended)\nif len(traces_for_alignment) >= 10:\n    optimizer = SIMBAAlignmentOptimizer(model="anthropic:/claude-opus-4-1-20250805")\n\n    # Run alignment - shows minimal progress by default:\n    # INFO: Starting SIMBA optimization with 15 examples (set logging to DEBUG for detailed output)\n    # INFO: SIMBA optimization completed\n    aligned_judge = initial_judge.align(optimizer, traces_for_alignment)\n\n    # Register the aligned judge\n    aligned_judge.register(experiment_id=experiment_id)\n    print("Judge aligned successfully with human feedback")\nelse:\n    print(f"Need at least 10 traces for alignment, have {len(traces_for_alignment)}")\n'})})}),(0,a.jsx)(s.A,{value:"explicit",label:"Explicit Optimizer",children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from mlflow.genai.judges.optimizers import SIMBAAlignmentOptimizer\n\n# Retrieve traces with both judge and human assessments\ntraces_for_alignment = mlflow.search_traces(\n    experiment_ids=[experiment_id], max_results=15, return_type="list"\n)\n\n# Align the judge using human corrections (minimum 10 traces recommended)\nif len(traces_for_alignment) >= 10:\n    # Explicitly specify SIMBA with custom model configuration\n    optimizer = SIMBAAlignmentOptimizer(model="anthropic:/claude-opus-4-1-20250805")\n    aligned_judge = initial_judge.align(traces_for_alignment, optimizer)\n\n    # Register the aligned judge\n    aligned_judge.register(experiment_id=experiment_id)\n    print("Judge aligned successfully with human feedback")\nelse:\n    print(f"Need at least 10 traces for alignment, have {len(traces_for_alignment)}")\n'})})})]})}),"\n",(0,a.jsx)(n.h2,{id:"the-simba-alignment-optimizer",children:"The SIMBA Alignment Optimizer"}),"\n",(0,a.jsxs)(n.p,{children:["MLflow provides the ",(0,a.jsx)(n.strong,{children:"default alignment optimizer"})," using ",(0,a.jsx)(n.a,{href:"https://dspy.ai/api/optimizers/SIMBA/",children:"DSPy's implementation of SIMBA"})," (Simplified Multi-Bootstrap Aggregation). When you call ",(0,a.jsx)(n.code,{children:"align()"})," without specifying an optimizer, the SIMBA optimizer is used automatically:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Default: Uses SIMBA optimizer automatically\naligned_judge = initial_judge.align(traces_with_feedback)\n\n# Explicit: Same as above but with custom model specification\nfrom mlflow.genai.judges.optimizers import SIMBAAlignmentOptimizer\n\noptimizer = SIMBAAlignmentOptimizer(\n    model="anthropic:/claude-opus-4-1-20250805"  # Model used for optimization\n)\naligned_judge = initial_judge.align(traces_with_feedback, optimizer)\n\n# Requirements for alignment:\n# - Minimum 10 traces with BOTH judge assessments and human feedback\n# - Both assessments must use the same name (matching the judge name)\n# - Order doesn\'t matter - humans can assess before or after judge\n# - Mix of agreements and disagreements between judge and human recommended\n'})}),"\n",(0,a.jsx)(n.admonition,{title:"Default Optimizer Behavior",type:"tip",children:(0,a.jsxs)(n.p,{children:["When using ",(0,a.jsx)(n.code,{children:"align()"})," without an optimizer parameter, MLflow automatically uses the SIMBA optimizer. This simplifies the alignment process while still allowing customization when needed."]})}),"\n",(0,a.jsx)(n.h3,{id:"controlling-optimization-output",children:"Controlling Optimization Output"}),"\n",(0,a.jsx)(n.p,{children:"By default, alignment shows minimal progress information to keep logs clean. If you need to debug the optimization process or see detailed iteration progress, enable DEBUG logging:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import logging\n\n# Enable detailed optimization output\nlogging.getLogger("mlflow.genai.judges.optimizers.simba").setLevel(logging.DEBUG)\n\n# Now alignment will show:\n# - Detailed iteration-by-iteration progress\n# - Score improvements at each step\n# - Strategy selection details\n# - Full DSPy optimization output\n\naligned_judge = initial_judge.align(optimizer, traces_with_feedback)\n\n# Reset to default (minimal output) after debugging\nlogging.getLogger("mlflow.genai.judges.optimizers.simba").setLevel(logging.INFO)\n'})}),"\n",(0,a.jsxs)(n.admonition,{title:"When to Use Detailed Logging",type:"tip",children:[(0,a.jsx)(n.p,{children:"Enable DEBUG logging when:"}),(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Optimization seems stuck or is taking too long"}),"\n",(0,a.jsx)(n.li,{children:"You want to understand how the optimizer is improving instructions"}),"\n",(0,a.jsx)(n.li,{children:"Debugging alignment failures or unexpected results"}),"\n",(0,a.jsx)(n.li,{children:"Learning how SIMBA optimization works internally"}),"\n"]}),(0,a.jsx)(n.p,{children:"Keep it at INFO (default) for production use to avoid verbose output."})]}),"\n",(0,a.jsx)(n.h2,{id:"collecting-feedback-for-alignment",children:"Collecting Feedback for Alignment"}),"\n",(0,a.jsx)(n.p,{children:"The quality of alignment depends on the quality and quantity of feedback. Choose the approach that best fits your situation:"}),"\n",(0,a.jsx)(n.h3,{id:"feedback-collection-approaches",children:"Feedback Collection Approaches"}),"\n",(0,a.jsx)(c.A,{children:(0,a.jsxs)(l.A,{children:[(0,a.jsxs)(s.A,{value:"ui",label:"MLflow UI (Recommended)",default:!0,children:[(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"When to use:"})," You don't have existing ground truth labels and need to collect human feedback."]}),(0,a.jsx)(n.p,{children:"The MLflow UI provides an intuitive interface for reviewing traces and adding feedback:"}),(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Navigate to the Traces tab"})," in your experiment"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Click on individual traces"})," to review inputs, outputs, and any existing judge assessments"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Add feedback"}),' by clicking the "Add Feedback" button']}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Select the assessment name"}),' that matches your judge name (e.g., "product_quality")']}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Provide your rating"})," according to your evaluation criteria"]}),"\n"]}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Tips for effective feedback collection:"})}),(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["If you're ",(0,a.jsx)(n.strong,{children:"not a domain expert"}),": Distribute traces among team members or domain experts for review"]}),"\n",(0,a.jsxs)(n.li,{children:["If you ",(0,a.jsx)(n.strong,{children:"are the domain expert"}),": Create a rubric or guidelines document to ensure consistency"]}),"\n",(0,a.jsxs)(n.li,{children:["For ",(0,a.jsx)(n.strong,{children:"multiple reviewers"}),": Organize feedback sessions where reviewers can work through batches together"]}),"\n",(0,a.jsxs)(n.li,{children:["For ",(0,a.jsx)(n.strong,{children:"consistency"}),": Document your evaluation criteria clearly before starting"]}),"\n"]}),(0,a.jsx)(n.p,{children:"The UI automatically logs feedback in the correct format for alignment."}),(0,a.jsx)(A.A,{src:"/images/assessments/add_feedback_ui.png",alt:"MLflow UI Feedback Interface",width:"800px"})]}),(0,a.jsxs)(s.A,{value:"programmatic",label:"Programmatic (Ground Truth)",children:[(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"When to use:"})," You have existing ground truth labels from your data."]}),(0,a.jsx)(n.p,{children:"If you already have labeled data, you can programmatically log it as feedback:"}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom mlflow.entities import AssessmentSource, AssessmentSourceType\n\n# Your existing ground truth dataset\nground_truth_data = [\n    {"trace_id": "trace1", "label": "excellent", "query": "What is MLflow?"},\n    {"trace_id": "trace2", "label": "poor", "query": "How to use tracking?"},\n    {"trace_id": "trace3", "label": "good", "query": "How to log models?"},\n]\n\n# Log ground truth as feedback for alignment\nfor item in ground_truth_data:\n    mlflow.log_feedback(\n        trace_id=item["trace_id"],\n        name="product_quality",  # Must match your judge name\n        value=item["label"],\n        source=AssessmentSource(\n            source_type=AssessmentSourceType.HUMAN, source_id="ground_truth_dataset"\n        ),\n    )\n\nprint(f"Logged {len(ground_truth_data)} ground truth labels for alignment")\n'})}),(0,a.jsx)(n.p,{children:"This approach is efficient when you have pre-labeled data from:"}),(0,a.jsx)(n.p,{children:"\u2022 Previous manual labeling efforts\n\u2022 Expert annotations\n\u2022 Production feedback systems\n\u2022 Test datasets with known correct answers"})]})]})}),"\n",(0,a.jsx)(d.A,{concepts:[{icon:w.A,title:"Diverse Reviewers",description:"Include feedback from multiple experts to capture different perspectives and reduce individual bias."},{icon:y.A,title:"Balanced Examples",description:"Include both positive and negative examples. Aim for at least 30% of each to help the judge learn boundaries."},{icon:v.A,title:"Sufficient Volume",description:"Collect at least 10 feedback examples (minimum for SIMBA), but 50-100 examples typically yield better results."},{icon:f.A,title:"Consistent Standards",description:"Ensure reviewers use consistent criteria. Provide guidelines or rubrics to standardize assessments."}]}),"\n",(0,a.jsx)(n.h2,{id:"custom-alignment-optimizers",children:"Custom Alignment Optimizers"}),"\n",(0,a.jsxs)(n.p,{children:["MLflow's alignment system is designed as a ",(0,a.jsx)(n.strong,{children:"plugin architecture"}),", allowing you to create custom optimizers for different alignment strategies. This extensibility enables you to implement domain-specific optimization approaches while leveraging MLflow's judge infrastructure."]}),"\n",(0,a.jsx)(n.h3,{id:"creating-a-custom-optimizer",children:"Creating a Custom Optimizer"}),"\n",(0,a.jsxs)(n.p,{children:["To create a custom alignment optimizer, extend the ",(0,a.jsx)(o.B,{fn:"mlflow.genai.judges.base.AlignmentOptimizer",children:"AlignmentOptimizer"})," abstract base class:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from mlflow.genai.judges.base import AlignmentOptimizer, Judge\nfrom mlflow.entities.trace import Trace\n\n\nclass MyCustomOptimizer(AlignmentOptimizer):\n    """Custom optimizer implementation for judge alignment."""\n\n    def __init__(self, model: str = None, **kwargs):\n        """Initialize your optimizer with custom parameters."""\n        self.model = model\n        # Add any custom initialization logic\n\n    def align(self, judge: Judge, traces: list[Trace]) -> Judge:\n        """\n        Implement your alignment algorithm.\n\n        Args:\n            judge: The judge to be optimized\n            traces: List of traces containing human feedback\n\n        Returns:\n            A new Judge instance with improved alignment\n        """\n        # Your custom alignment logic here\n        # 1. Extract feedback from traces\n        # 2. Analyze disagreements between judge and human\n        # 3. Generate improved instructions\n        # 4. Return new judge with better alignment\n\n        # Example: Return judge with modified instructions\n        from mlflow.genai.judges import make_judge\n\n        improved_instructions = self._optimize_instructions(judge.instructions, traces)\n\n        return make_judge(\n            name=judge.name,\n            instructions=improved_instructions,\n            feedback_value_type=str,\n            model=judge.model,\n        )\n\n    def _optimize_instructions(self, instructions: str, traces: list[Trace]) -> str:\n        """Your custom optimization logic."""\n        # Implement your optimization strategy\n        pass\n'})}),"\n",(0,a.jsx)(n.h3,{id:"using-custom-optimizers",children:"Using Custom Optimizers"}),"\n",(0,a.jsx)(n.p,{children:"Once implemented, use your custom optimizer just like the built-in ones:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Create your custom optimizer\ncustom_optimizer = MyCustomOptimizer(model="your-model")\n\n# Use it for alignment\naligned_judge = initial_judge.align(traces_with_feedback, custom_optimizer)\n'})}),"\n",(0,a.jsx)(n.h3,{id:"available-optimizers",children:"Available Optimizers"}),"\n",(0,a.jsx)(n.p,{children:"MLflow currently provides:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"SIMBAAlignmentOptimizer"})," (default): Uses ",(0,a.jsx)(n.a,{href:"https://dspy.ai/api/optimizers/SIMBA/",children:"DSPy's Simplified Multi-Bootstrap Aggregation"})," for robust alignment"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Custom optimizers"}),": Extend ",(0,a.jsx)(n.code,{children:"AlignmentOptimizer"})," to implement your own strategies"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"The plugin architecture ensures that new optimization strategies can be added without modifying the core judge system, promoting extensibility and experimentation with different alignment approaches."}),"\n",(0,a.jsx)(n.h2,{id:"testing-alignment-effectiveness",children:"Testing Alignment Effectiveness"}),"\n",(0,a.jsx)(n.p,{children:"Validate that alignment improved your judge:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'def test_alignment_improvement(\n    original_judge, aligned_judge, test_traces: list\n) -> dict:\n    """Compare judge performance before and after alignment."""\n\n    original_correct = 0\n    aligned_correct = 0\n\n    for trace in test_traces:\n        # Get human ground truth from trace assessments\n        feedbacks = trace.search_assessments(type="feedback")\n        human_feedback = next(\n            (f for f in feedbacks if f.source.source_type == "HUMAN"), None\n        )\n\n        if not human_feedback:\n            continue\n\n        # Get judge evaluations\n        original_eval = original_judge(trace=trace)\n        aligned_eval = aligned_judge(trace=trace)\n\n        # Check agreement with human\n        if original_eval.value == human_feedback.value:\n            original_correct += 1\n        if aligned_eval.value == human_feedback.value:\n            aligned_correct += 1\n\n    total = len(test_traces)\n    return {\n        "original_accuracy": original_correct / total,\n        "aligned_accuracy": aligned_correct / total,\n        "improvement": (aligned_correct - original_correct) / total,\n    }\n'})}),"\n",(0,a.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,a.jsxs)(p.A,{children:[(0,a.jsx)(h.A,{icon:g.A,iconSize:48,title:"Create Custom Judges",description:"Learn to create domain-specific judges with make_judge.",href:"/genai/eval-monitor/scorers/llm-judge/make-judge",linkText:"Create judges \u2192",containerHeight:64}),(0,a.jsx)(h.A,{icon:b.A,iconSize:48,title:"Development Workflow",description:"See complete workflow from creation to aligned production judge.",href:"/genai/eval-monitor/scorers/llm-judge/workflow",linkText:"View workflow \u2192",containerHeight:64}),(0,a.jsx)(h.A,{icon:v.A,iconSize:48,title:"Dataset Integration",description:"Use judges with evaluation datasets for systematic testing.",href:"/genai/datasets",linkText:"Learn integration \u2192",containerHeight:64})]})]})}function M(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(I,{...e})}):I(e)}},47020:(e,n,t)=>{t.d(n,{A:()=>r});t(96540);const i={wrapper:"wrapper_sf5q"};var a=t(74848);function r({children:e}){return(0,a.jsx)("div",{className:i.wrapper,children:e})}},49374:(e,n,t)=>{t.d(n,{B:()=>s});t(96540);const i=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}');var a=t(86025),r=t(74848);const l=e=>{const n=e.split(".");for(let t=n.length;t>0;t--){const e=n.slice(0,t).join(".");if(i[e])return e}return null};function s({fn:e,children:n,hash:t}){const s=l(e);if(!s)return(0,r.jsx)(r.Fragment,{children:n});const o=(0,a.default)(`/${i[s]}#${t??e}`);return(0,r.jsx)("a",{href:o,target:"_blank",children:n??(0,r.jsxs)("code",{children:[e,"()"]})})}},56955:(e,n,t)=>{t.d(n,{A:()=>H});var i=t(96540);const a="loopContainer_P7aD",r="loopTitle_JPUj",l="loopContent_d_OB",s="circleContainer_r3vu",o="svgCanvas_uDoP",c="arrowPath_C9al",m="arrowHead_pHvN",d="stepNode_dfTI",p="stepNodeContent_qttg",h="highlighted_oNtg",u="focusNode_z3RB",g="stepNumber_LNrP",f="stepLabel_vl8R",_="centerIcon_KAOa",j="loopIconWrapper_xBPW",x="loopText_T4eg",w="tooltip_UzKu",y="tooltipTitle_HAKW",v="tooltipDescription_EDYJ",b="tooltipArrow_WNhr",A="centerTooltip_R18b",k="centerTooltipDescription_ttXB",z="mobileLinearContent_PCYK",N="mobileStepItem_x9mX",S="mobileStepIndicator_zWzO",I="mobileStepNumber_HnjD",M="mobileFocusNode_FTRa",T="mobileStepConnector_kK9y",C="mobileStepContent_jmKx",O="mobileStepTitle_P2DM",L="mobileStepDescription_qbMN",B="mobileLoopBack_nXtn",D="mobileLoopIcon_FAGz",q="mobileLoopContent_BRFV",E="mobileLoopTitle_JcCt",R="mobileLoopDescription_5B8T";var F=t(74848);const H=({steps:e,title:n,loopBackIcon:t,loopBackText:H,loopBackDescription:J,circleSize:$=400})=>{const[G,P]=(0,i.useState)(null),[W,U]=(0,i.useState)(!1),[Y,K]=(0,i.useState)({x:0,y:0}),[V,X]=(0,i.useState)(!1),Q=(0,i.useRef)(null);i.useEffect(()=>{const e=()=>{X(window.innerWidth<=768)};return e(),window.addEventListener("resize",e),()=>window.removeEventListener("resize",e)},[]);const Z=V?280:$,ee=(()=>{const n=$/2,t=V?100:140,i=V?130:220,a=Math.min(1.2,.8+.05*e.length),r=(n-(V?50:80))*a;return Math.max(t,Math.min(i,r))})(),ne=Z/2,te=Z/2,ie=n=>{const t=2*n*Math.PI/e.length-Math.PI/2;return{x:ne+ee*Math.cos(t),y:te+ee*Math.sin(t)}},ae=(e,n)=>{const t=ie(e),i=ie(n),a=i.x-t.x,r=i.y-t.y,l=(t.x+i.x)/2,s=(t.y+i.y)/2,o=Math.sqrt(a*a+r*r),c=a/o,m=r/o;return`M ${l-10*c} ${s-10*m} L ${l+10*c} ${s+10*m}`},re=()=>{P(null)};return V?(0,F.jsxs)("div",{className:a,children:[n&&(0,F.jsx)("h3",{className:r,children:n}),(0,F.jsxs)("div",{className:z,children:[e.map((n,t)=>(0,F.jsxs)("div",{className:N,children:[(0,F.jsxs)("div",{className:S,children:[(0,F.jsx)("div",{className:`${I} ${n.isFocus?M:""}`,children:n.icon?(0,F.jsx)(n.icon,{size:20}):(0,F.jsx)("span",{children:t+1})}),t<e.length-1&&(0,F.jsx)("div",{className:T})]}),(0,F.jsxs)("div",{className:C,children:[(0,F.jsx)("h4",{className:O,children:n.title}),(0,F.jsx)("p",{className:L,children:n.detailedDescription||n.description})]})]},t)),t&&J&&(0,F.jsxs)("div",{className:B,children:[(0,F.jsx)("div",{className:D,children:(0,F.jsx)(t,{size:24})}),(0,F.jsxs)("div",{className:q,children:[(0,F.jsx)("h4",{className:E,children:H||"Iterate"}),(0,F.jsx)("p",{className:R,children:J})]})]})]})]}):(0,F.jsxs)("div",{className:a,children:[n&&(0,F.jsx)("h3",{className:r,children:n}),(0,F.jsx)("div",{className:l,children:(0,F.jsxs)("div",{className:s,ref:Q,style:{width:`${Z}px`,height:`${Z}px`},children:[(0,F.jsxs)("svg",{width:Z,height:Z,className:o,children:[e.map((n,t)=>{const i=(t+1)%e.length;return(0,F.jsxs)("g",{children:[(0,F.jsx)("defs",{children:(0,F.jsx)("marker",{id:`arrowhead-${t}`,markerWidth:"6",markerHeight:"6",refX:"5",refY:"3",orient:"auto",children:(0,F.jsx)("path",{d:"M 0 0 L 6 3 L 0 6 L 1.5 3 Z",fill:"currentColor",opacity:"1",className:m})})}),(0,F.jsx)("path",{d:ae(t,i),fill:"none",stroke:"currentColor",strokeWidth:"2",strokeDasharray:"0",opacity:"0.9",markerEnd:`url(#arrowhead-${t})`,className:c})]},`arrow-${t}`)}),t&&(0,F.jsxs)("g",{className:_,onMouseEnter:()=>U(!0),onMouseLeave:()=>U(!1),style:{cursor:"pointer"},children:[(0,F.jsx)("foreignObject",{x:ne-35,y:te-35,width:"70",height:"70",children:(0,F.jsx)("div",{className:j,children:(0,F.jsx)(t,{size:32})})}),H&&(0,F.jsx)("text",{x:ne,y:te+50,textAnchor:"middle",className:x,children:H})]})]}),e.map((e,n)=>{const t=ie(n);return(0,F.jsxs)("div",{className:`${d} ${e.highlight?h:""} ${e.isFocus?u:""}`,style:{left:`${t.x}px`,top:`${t.y}px`,transform:"translate(-50%, -50%)"},onMouseEnter:e=>(e=>{if(P(e),Q.current){Q.current.getBoundingClientRect();const n=ie(e);K({x:n.x,y:n.y})}})(n),onMouseLeave:re,children:[(0,F.jsx)("div",{className:p,children:e.icon?(0,F.jsx)(e.icon,{size:24}):(0,F.jsx)("span",{className:g,children:n+1})}),(0,F.jsx)("div",{className:f,children:e.title})]},n)}),null!==G&&(0,F.jsxs)("div",{className:w,style:{left:`${Y.x}px`,top:`${Y.y}px`,transform:"translate(-50%, -120%)"},children:[(0,F.jsx)("h4",{className:y,children:e[G].title}),(0,F.jsx)("p",{className:v,children:e[G].detailedDescription||e[G].description}),(0,F.jsx)("div",{className:b})]}),W&&J&&(0,F.jsx)("div",{className:A,style:{left:`${ne}px`,top:`${te}px`,transform:"translate(-50%, -50%)"},children:(0,F.jsx)("p",{className:k,children:J})})]})})]})}},65592:(e,n,t)=>{t.d(n,{A:()=>l});t(96540);var i=t(34164);const a={tilesGrid:"tilesGrid_hB9N"};var r=t(74848);function l({children:e,className:n}){return(0,r.jsx)("div",{className:(0,i.A)(a.tilesGrid,n),children:e})}},66927:(e,n,t)=>{t.d(n,{A:()=>l});t(96540);const i={container:"container_JwLF",imageWrapper:"imageWrapper_RfGN",image:"image_bwOA",caption:"caption_jo2G"};var a=t(86025),r=t(74848);function l({src:e,alt:n,width:t,caption:l,className:s}){return(0,r.jsxs)("div",{className:`${i.container} ${s||""}`,children:[(0,r.jsx)("div",{className:i.imageWrapper,style:t?{width:t}:{},children:(0,r.jsx)("img",{src:(0,a.default)(e),alt:n,className:i.image})}),l&&(0,r.jsx)("p",{className:i.caption,children:l})]})}},79206:(e,n,t)=>{t.d(n,{A:()=>r});t(96540);const i={conceptOverview:"conceptOverview_x8T_",overviewTitle:"overviewTitle_HyAI",conceptGrid:"conceptGrid_uJNV",conceptCard:"conceptCard_oday",conceptHeader:"conceptHeader_HCk5",conceptIcon:"conceptIcon_gejw",conceptTitle:"conceptTitle_TGMM",conceptDescription:"conceptDescription_ZyDn"};var a=t(74848);function r({concepts:e,title:n}){return(0,a.jsxs)("div",{className:i.conceptOverview,children:[n&&(0,a.jsx)("h3",{className:i.overviewTitle,children:n}),(0,a.jsx)("div",{className:i.conceptGrid,children:e.map((e,n)=>(0,a.jsxs)("div",{className:i.conceptCard,children:[(0,a.jsxs)("div",{className:i.conceptHeader,children:[e.icon&&(0,a.jsx)("div",{className:i.conceptIcon,children:(0,a.jsx)(e.icon,{size:20})}),(0,a.jsx)("h4",{className:i.conceptTitle,children:e.title})]}),(0,a.jsx)("p",{className:i.conceptDescription,children:e.description})]},n))})]})}},82238:(e,n,t)=>{t.d(n,{A:()=>r});t(96540);const i={featureHighlights:"featureHighlights_Ardf",highlightItem:"highlightItem_XPnN",highlightIcon:"highlightIcon_SUR8",highlightContent:"highlightContent_d0XP"};var a=t(74848);function r({features:e,col:n=2}){return(0,a.jsx)("div",{className:i.featureHighlights,style:{gridTemplateColumns:`repeat(${n}, 1fr)`},children:e.map((e,n)=>(0,a.jsxs)("div",{className:i.highlightItem,children:[e.icon&&(0,a.jsx)("div",{className:i.highlightIcon,children:(0,a.jsx)(e.icon,{size:24})}),(0,a.jsxs)("div",{className:i.highlightContent,children:[(0,a.jsx)("h4",{children:e.title}),(0,a.jsx)("p",{children:e.description})]})]},n))})}}}]);