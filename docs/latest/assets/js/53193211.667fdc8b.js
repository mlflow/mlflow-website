"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[4324],{10493:(e,n,t)=>{t.d(n,{Zp:()=>s,AC:()=>r,WO:()=>p,_C:()=>c,$3:()=>d,jK:()=>h});var l=t(34164);const i={CardGroup:"CardGroup_P84T",NoGap:"NoGap_O9Dj",MaxThreeColumns:"MaxThreeColumns_FO1r",AutofillColumns:"AutofillColumns_fKhQ",Card:"Card_aSCR",CardBordered:"CardBordered_glGF",CardBody:"CardBody_BhRs",TextColor:"TextColor_a8Tp",BoxRoot:"BoxRoot_Etgr",FlexWrapNowrap:"FlexWrapNowrap_f60k",FlexJustifyContentFlexStart:"FlexJustifyContentFlexStart_ZYv5",FlexDirectionRow:"FlexDirectionRow_T2qL",FlexAlignItemsCenter:"FlexAlignItemsCenter_EHVM",FlexFlex:"FlexFlex__JTE",Link:"Link_fVkl",MarginLeft4:"MarginLeft4_YQSJ",MarginTop4:"MarginTop4_jXKN",PaddingBottom4:"PaddingBottom4_O9gt",LogoCardContent:"LogoCardContent_kCQm",LogoCardImage:"LogoCardImage_JdcX",SmallLogoCardContent:"SmallLogoCardContent_LxhV",SmallLogoCardRounded:"SmallLogoCardRounded_X50_",SmallLogoCardImage:"SmallLogoCardImage_tPZl",NewFeatureCardContent:"NewFeatureCardContent_Rq3d",NewFeatureCardHeading:"NewFeatureCardHeading_f6q3",NewFeatureCardHeadingSeparator:"NewFeatureCardHeadingSeparator_pSx8",NewFeatureCardTags:"NewFeatureCardTags_IFHO",NewFeatureCardWrapper:"NewFeatureCardWrapper_NQ0k",TitleCardContent:"TitleCardContent_l9MQ",TitleCardHeader:"TitleCardHeader_fUQy",TitleCardHeaderRight:"TitleCardHeaderRight_iBLX",TitleCardTitle:"TitleCardTitle__K8J",TitleCardSeparator:"TitleCardSeparator_IN2E",Cols1:"Cols1_Gr2U",Cols2:"Cols2_sRvc",Cols3:"Cols3_KjUS",Cols4:"Cols4_dKOj",Cols5:"Cols5_jDmj",Cols6:"Cols6_Q0OR"};var a=t(28774),o=t(74848);const r=({children:e,isSmall:n,cols:t,noGap:a})=>(0,o.jsx)("div",{className:(0,l.A)(i.CardGroup,n?i.AutofillColumns:t?i[`Cols${t}`]:i.MaxThreeColumns,a&&i.NoGap),children:e}),s=({children:e,link:n="",style:t})=>n?(0,o.jsx)(a.A,{className:(0,l.A)(i.Link,i.Card,i.CardBordered),style:t,to:n,children:e}):(0,o.jsx)("div",{className:(0,l.A)(i.Card,i.CardBordered),style:t,children:e}),c=({headerText:e,link:n,text:t})=>(0,o.jsx)(s,{link:n,children:(0,o.jsxs)("span",{children:[(0,o.jsx)("div",{className:(0,l.A)(i.CardTitle,i.BoxRoot,i.PaddingBottom4),style:{pointerEvents:"none"},children:(0,o.jsx)("div",{className:(0,l.A)(i.BoxRoot,i.FlexFlex,i.FlexAlignItemsCenter,i.FlexDirectionRow,i.FlexJustifyContentFlexStart,i.FlexWrapNowrap),style:{marginLeft:"-4px",marginTop:"-4px"},children:(0,o.jsx)("div",{className:(0,l.A)(i.BoxRoot,i.BoxHideIfEmpty,i.MarginTop4,i.MarginLeft4),style:{pointerEvents:"auto"},children:(0,o.jsx)("span",{className:"",children:e})})})}),(0,o.jsx)("span",{className:(0,l.A)(i.TextColor,i.CardBody),children:(0,o.jsx)("p",{children:t})})]})}),p=({description:e,children:n,link:t})=>(0,o.jsx)(s,{link:t,children:(0,o.jsxs)("div",{className:i.LogoCardContent,children:[(0,o.jsx)("div",{className:i.LogoCardImage,children:n}),(0,o.jsx)("p",{className:i.TextColor,children:e})]})}),d=({children:e,link:n})=>(0,o.jsx)(a.A,{className:(0,l.A)(i.Card,i.CardBordered,i.SmallLogoCardRounded),to:n,children:(0,o.jsx)("div",{className:i.SmallLogoCardContent,children:(0,o.jsx)("div",{className:(0,l.A)("max-height-img-container",i.SmallLogoCardImage),children:e})})}),h=({title:e,description:n,link:t="",headerRight:a,children:r})=>(0,o.jsx)(s,{link:t,children:(0,o.jsxs)("div",{className:i.TitleCardContent,children:[(0,o.jsxs)("div",{className:(0,l.A)(i.TitleCardHeader),children:[(0,o.jsx)("div",{className:(0,l.A)(i.TitleCardTitle),style:{textAlign:"left",fontWeight:"bold"},children:e}),(0,o.jsx)("div",{className:i.TitleCardHeaderRight,children:a})]}),(0,o.jsx)("hr",{className:(0,l.A)(i.TitleCardSeparator),style:{margin:"12px 0"}}),r?(0,o.jsx)("div",{className:(0,l.A)(i.TextColor),children:r}):(0,o.jsx)("p",{className:(0,l.A)(i.TextColor),dangerouslySetInnerHTML:{__html:n}})]})})},46158:(e,n,t)=>{t.d(n,{A:()=>l});const l=t.p+"assets/images/gemini-tracing-fd066260b1e75fa44bfdd89dd000f76d.png"},47020:(e,n,t)=>{t.d(n,{A:()=>a});t(96540);const l={wrapper:"wrapper_sf5q"};var i=t(74848);function a({children:e}){return(0,i.jsx)("div",{className:l.wrapper,children:e})}},49374:(e,n,t)=>{t.d(n,{B:()=>r});t(96540);const l=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}');var i=t(86025),a=t(74848);const o=e=>{const n=e.split(".");for(let t=n.length;t>0;t--){const e=n.slice(0,t).join(".");if(l[e])return e}return null};function r({fn:e,children:n,hash:t}){const r=o(e);if(!r)return(0,a.jsx)(a.Fragment,{children:n});const s=(0,i.default)(`/${l[r]}#${t??e}`);return(0,a.jsx)("a",{href:s,target:"_blank",children:n??(0,a.jsxs)("code",{children:[e,"()"]})})}},79639:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>h,contentTitle:()=>d,default:()=>g,frontMatter:()=>p,metadata:()=>l,toc:()=>m});const l=JSON.parse('{"id":"tracing/integrations/listing/gemini","title":"Tracing Gemini","description":"OpenAI Tracing via autolog","source":"@site/docs/genai/tracing/integrations/listing/gemini.mdx","sourceDirName":"tracing/integrations/listing","slug":"/tracing/integrations/listing/gemini","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/gemini","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":9,"frontMatter":{"sidebar_position":9,"sidebar_label":"Gemini"},"sidebar":"genAISidebar","previous":{"title":"DeepSeek","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/deepseek"},"next":{"title":"Groq","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/groq"}}');var i=t(74848),a=t(28453),o=t(49374),r=(t(10493),t(14252),t(11470)),s=t(19365),c=t(47020);const p={sidebar_position:9,sidebar_label:"Gemini"},d="Tracing Gemini",h={},m=[{value:"Supported APIs",id:"supported-apis",level:2},{value:"Python",id:"python",level:3},{value:"TypeScript / JavaScript",id:"typescript--javascript",level:3},{value:"Basic Example",id:"basic-example",level:2},{value:"Multi-turn chat interactions",id:"multi-turn-chat-interactions",level:2},{value:"Async",id:"async",level:2},{value:"Embeddings",id:"embeddings",level:2},{value:"Token usage",id:"token-usage",level:2},{value:"Disable auto-tracing",id:"disable-auto-tracing",level:3}];function f(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"tracing-gemini",children:"Tracing Gemini"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"OpenAI Tracing via autolog",src:t(46158).A+"",width:"2696",height:"694"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"../../",children:"MLflow Tracing"})," provides automatic tracing capability for Google Gemini. By enabling auto tracing\nfor Gemini by calling the ",(0,i.jsx)(o.B,{fn:"mlflow.gemini.autolog"})," function, MLflow will capture nested traces and log them to the active MLflow Experiment upon invocation of Gemini Python SDK. In Typescript, you can instead use the ",(0,i.jsx)(n.code,{children:"tracedGemini"})," function to wrap the Gemini client."]}),"\n",(0,i.jsx)(c.A,{children:(0,i.jsxs)(r.A,{children:[(0,i.jsx)(s.A,{value:"python",label:"Python",default:!0,children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import mlflow\n\nmlflow.gemini.autolog()\n"})})}),(0,i.jsx)(s.A,{value:"typescript",label:"JS / TS",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:'import { GoogleGenAI } from "@google/genai";\nimport { tracedGemini } from "mlflow-gemini";\n\nconst client = tracedGemini(new GoogleGenAI());\n'})})})]})}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsxs)(n.p,{children:["Current MLflow tracing integration supports both new ",(0,i.jsx)(n.a,{href:"https://github.com/googleapis/python-genai",children:"Google GenAI SDK"})," and legacy ",(0,i.jsx)(n.a,{href:"https://github.com/google-gemini/generative-ai-python",children:"Google AI Python SDK"}),".\nHowever, it may drop support for the legacy package without notice, and it is highly recommended to migrate your use cases to the new Google GenAI SDK."]})}),"\n",(0,i.jsx)(n.p,{children:"MLflow trace automatically captures the following information about Gemini calls:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Prompts and completion responses"}),"\n",(0,i.jsx)(n.li,{children:"Latencies"}),"\n",(0,i.jsx)(n.li,{children:"Model name"}),"\n",(0,i.jsxs)(n.li,{children:["Additional metadata such as ",(0,i.jsx)(n.code,{children:"temperature"}),", ",(0,i.jsx)(n.code,{children:"max_tokens"}),", if specified."]}),"\n",(0,i.jsx)(n.li,{children:"Token usage (input, output, and total tokens)"}),"\n",(0,i.jsx)(n.li,{children:"Function calling if returned in the response"}),"\n",(0,i.jsx)(n.li,{children:"Any exception if raised"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"supported-apis",children:"Supported APIs"}),"\n",(0,i.jsx)(n.p,{children:"MLflow supports automatic tracing for the following Gemini APIs:"}),"\n",(0,i.jsx)(n.h3,{id:"python",children:"Python"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{style:{textAlign:"center"},children:"Text Generation"}),(0,i.jsx)(n.th,{style:{textAlign:"center"},children:"Chat"}),(0,i.jsx)(n.th,{style:{textAlign:"center"},children:"Function Calling"}),(0,i.jsx)(n.th,{style:{textAlign:"center"},children:"Streaming"}),(0,i.jsx)(n.th,{style:{textAlign:"center"},children:"Async"}),(0,i.jsx)(n.th,{style:{textAlign:"center"},children:"Image"}),(0,i.jsx)(n.th,{style:{textAlign:"center"},children:"Video"})]})}),(0,i.jsx)(n.tbody,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"\u2705"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"\u2705"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"\u2705"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"-"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"\u2705 (*1)"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"-"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"-"})]})})]}),"\n",(0,i.jsx)("div",{style:{fontSize:"0.9em",marginTop:"10px"},children:(0,i.jsx)(n.p,{children:"(*1) Async support was added in MLflow 3.2.0."})}),"\n",(0,i.jsx)(n.h3,{id:"typescript--javascript",children:"TypeScript / JavaScript"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{style:{textAlign:"center"},children:"Content Generation"}),(0,i.jsx)(n.th,{style:{textAlign:"center"},children:"Chat"}),(0,i.jsx)(n.th,{style:{textAlign:"center"},children:"Function Calling"}),(0,i.jsx)(n.th,{style:{textAlign:"center"},children:"Streaming"}),(0,i.jsx)(n.th,{style:{textAlign:"center"},children:"Async"})]})}),(0,i.jsx)(n.tbody,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"\u2705"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"-"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"\u2705 (*2)"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"-"}),(0,i.jsx)(n.td,{style:{textAlign:"center"},children:"\u2705"})]})})]}),"\n",(0,i.jsx)("div",{style:{fontSize:"0.9em",marginTop:"10px"},children:(0,i.jsxs)(n.p,{children:["(*2) Only ",(0,i.jsx)(n.code,{children:"models.generateContent()"})," is supported. Function calls in responses are captured and can be rendered in the MLflow UI. The TypeScript SDK is natively async."]})}),"\n",(0,i.jsxs)(n.p,{children:["To request support for additional APIs, please open a ",(0,i.jsx)(n.a,{href:"https://github.com/mlflow/mlflow/issues",children:"feature request"})," on GitHub."]}),"\n",(0,i.jsx)(n.h2,{id:"basic-example",children:"Basic Example"}),"\n",(0,i.jsxs)(r.A,{children:[(0,i.jsx)(s.A,{value:"python",label:"Python",default:!0,children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport google.genai as genai\nimport os\n\n# Turn on auto tracing for Gemini\nmlflow.gemini.autolog()\n\n# Optional: Set a tracking URI and an experiment\nmlflow.set_tracking_uri("http://localhost:5000")\nmlflow.set_experiment("Gemini")\n\n\n# Configure the SDK with your API key.\nclient = genai.Client(api_key=os.environ["GEMINI_API_KEY"])\n\n# Use the generate_content method to generate responses to your prompts.\nresponse = client.models.generate_content(\n    model="gemini-1.5-flash", contents="The opposite of hot is"\n)\n'})})}),(0,i.jsx)(s.A,{value:"typescript",label:"JS / TS",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:'import { GoogleGenAI } from "@google/genai";\nimport { tracedGemini } from "mlflow-gemini";\n\nconst client = tracedGemini(new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY }));\n\nconst response = await client.models.generateContent({\n    model: "gemini-2.5-flash",\n    contents: "What is the capital of France?"\n});\n'})})})]}),"\n",(0,i.jsx)(n.h2,{id:"multi-turn-chat-interactions",children:"Multi-turn chat interactions"}),"\n",(0,i.jsx)(n.p,{children:"MLflow support tracing multi-turn conversations with Gemini:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import mlflow\n\nmlflow.gemini.autolog()\n\nchat = client.chats.create(model="gemini-1.5-flash")\nresponse = chat.send_message(\n    "In one sentence, explain how a computer works to a young child."\n)\nprint(response.text)\nresponse = chat.send_message(\n    "Okay, how about a more detailed explanation to a high schooler?"\n)\nprint(response.text)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"async",children:"Async"}),"\n",(0,i.jsx)(n.p,{children:"MLflow Tracing supports asynchronous API of the Gemini SDK since MLflow 3.2.0. The usage is same as the synchronous API."}),"\n",(0,i.jsxs)(r.A,{children:[(0,i.jsx)(s.A,{value:"python",label:"Python",default:!0,children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Configure the SDK with your API key.\nclient = genai.Client(api_key=os.environ["GEMINI_API_KEY"])\n\n# Async API is invoked through the `aio` namespace.\nresponse = await client.aio.models.generate_content(\n    model="gemini-1.5-flash", contents="The opposite of hot is"\n)\n'})})}),(0,i.jsx)(s.A,{value:"typescript",label:"JS / TS",children:(0,i.jsx)(n.p,{children:"Gemini Typescript / Javascript SDK is natively async. See the basic example above."})})]}),"\n",(0,i.jsx)(n.h2,{id:"embeddings",children:"Embeddings"}),"\n",(0,i.jsx)(n.p,{children:"MLflow Tracing for Gemini SDK supports embeddings API (Python only):"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'result = client.models.embed_content(model="text-embedding-004", contents="Hello world")\n'})}),"\n",(0,i.jsx)(n.h2,{id:"token-usage",children:"Token usage"}),"\n",(0,i.jsxs)(n.p,{children:["MLflow >= 3.4.0 supports token usage tracking for Gemini. The token usage for each LLM call will be logged in the ",(0,i.jsx)(n.code,{children:"mlflow.chat.tokenUsage"})," attribute. The total token usage throughout the trace will be\navailable in the ",(0,i.jsx)(n.code,{children:"token_usage"})," field of the trace info object."]}),"\n",(0,i.jsxs)(r.A,{children:[(0,i.jsx)(s.A,{value:"python",label:"Python",default:!0,children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import json\nimport mlflow\n\nmlflow.gemini.autolog()\n\nclient = genai.Client(api_key=os.environ["GEMINI_API_KEY"])\n\n# Use the generate_content method to generate responses to your prompts.\nresponse = client.models.generate_content(\n    model="gemini-1.5-flash", contents="The opposite of hot is"\n)\n\n# Get the trace object just created\ntrace = mlflow.get_trace(mlflow.get_last_active_trace_id())\n\n# Print the token usage\ntotal_usage = trace.info.token_usage\nprint("== Total token usage: ==")\nprint(f"  Input tokens: {total_usage[\'input_tokens\']}")\nprint(f"  Output tokens: {total_usage[\'output_tokens\']}")\nprint(f"  Total tokens: {total_usage[\'total_tokens\']}")\n\n# Print the token usage for each LLM call\nprint("\\n== Detailed usage for each LLM call: ==")\nfor span in trace.data.spans:\n    if usage := span.get_attribute("mlflow.chat.tokenUsage"):\n        print(f"{span.name}:")\n        print(f"  Input tokens: {usage[\'input_tokens\']}")\n        print(f"  Output tokens: {usage[\'output_tokens\']}")\n        print(f"  Total tokens: {usage[\'total_tokens\']}")\n'})})}),(0,i.jsx)(s.A,{value:"typescript",label:"JS / TS",children:(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:'import * as mlflow from "mlflow-tracing";\n\n// After your Gemini call completes, flush and fetch the trace\nawait mlflow.flushTraces();\nconst lastTraceId = mlflow.getLastActiveTraceId();\n\nif (lastTraceId) {\n  const client = new mlflow.MlflowClient({ trackingUri: "http://localhost:5000" });\n  const trace = await client.getTrace(lastTraceId);\n\n  // Total token usage on the trace\n  console.log("== Total token usage: ==");\n  console.log(trace.info.tokenUsage); // { input_tokens, output_tokens, total_tokens }\n\n  // Per-span usage (if provided by the provider)\n  console.log("\\n== Detailed usage for each LLM call: ==");\n  for (const span of trace.data.spans) {\n    const usage = span.attributes?.["mlflow.chat.tokenUsage"];\n    if (usage) {\n      console.log(`${span.name}:`, usage);\n    }\n  }\n}\n'})})})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"== Total token usage: ==\n  Input tokens: 5\n  Output tokens: 2\n  Total tokens: 7\n\n== Detailed usage for each LLM call: ==\nModels.generate_content:\n  Input tokens: 5\n  Output tokens: 2\n  Total tokens: 7\nModels._generate_content:\n  Input tokens: 5\n  Output tokens: 2\n  Total tokens: 7\n"})}),"\n",(0,i.jsx)(n.p,{children:"Token usage tracking is supported for both Python and TypeScript/JavaScript implementations."}),"\n",(0,i.jsx)(n.h3,{id:"disable-auto-tracing",children:"Disable auto-tracing"}),"\n",(0,i.jsxs)(n.p,{children:["Auto tracing for Gemini can be disabled globally by calling ",(0,i.jsx)(n.code,{children:"mlflow.gemini.autolog(disable=True)"})," or ",(0,i.jsx)(n.code,{children:"mlflow.autolog(disable=True)"}),"."]})]})}function g(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(f,{...e})}):f(e)}}}]);