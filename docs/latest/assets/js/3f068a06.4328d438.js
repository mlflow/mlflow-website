"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5245],{21611:(e,n,t)=>{t.d(n,{A:()=>l});const l=t.p+"assets/images/simple_example_traces-a2541a183f751017e6196464856d764f.png"},28453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>i});var l=t(96540);const a={},r=l.createContext(a);function o(e){const n=l.useContext(r);return l.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),l.createElement(r.Provider,{value:n},e.children)}},35322:(e,n,t)=>{t.d(n,{A:()=>l});const l=t.p+"assets/images/simple_example_model-2e4308dadc59c0c42361949f5a628051.png"},45065:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>p,contentTitle:()=>m,default:()=>u,frontMatter:()=>d,metadata:()=>l,toc:()=>h});const l=JSON.parse('{"id":"mlflow-3/index","title":"MLflow 3.0 (Preview)","description":"Discover the next generation of MLflow, designed to streamline your AI experimentation and accelerate your journey from idea to production. MLflow 3.0 brings cutting-edge support for GenAI workflows, enabling seamless integration of generative AI models into your projects.","source":"@site/docs/mlflow-3/index.mdx","sourceDirName":"mlflow-3","slug":"/mlflow-3/","permalink":"/docs/latest/mlflow-3/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_label":"MLflow 3.0","sidebar_position":1},"sidebar":"docsSidebar","previous":{"title":"MLflow","permalink":"/docs/latest/"},"next":{"title":"Gen AI Development","permalink":"/docs/latest/mlflow-3/genai-agent"}}');var a=t(74848),r=t(28453),o=t(65537),i=t(79329),s=t(67756),c=t(86294);const d={sidebar_label:"MLflow 3.0",sidebar_position:1},m="MLflow 3.0 (Preview)",p={},h=[{value:"What is MLflow 3.0?",id:"what-is-mlflow-30",level:2},{value:"Enhanced Model Tracking",id:"enhanced-model-tracking",level:2},{value:"Quickstart",id:"quickstart",level:3},{value:"MLflow 3.0 Showcases",id:"mlflow-30-showcases",level:2},{value:"Migration Guide",id:"migration-guide",level:2},{value:"Key changes",id:"key-changes",level:3},{value:"Removed Features",id:"removed-features",level:3}];function f(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"mlflow-30-preview",children:"MLflow 3.0 (Preview)"})}),"\n",(0,a.jsx)(n.p,{children:"Discover the next generation of MLflow, designed to streamline your AI experimentation and accelerate your journey from idea to production. MLflow 3.0 brings cutting-edge support for GenAI workflows, enabling seamless integration of generative AI models into your projects."}),"\n",(0,a.jsx)(n.h2,{id:"what-is-mlflow-30",children:"What is MLflow 3.0?"}),"\n",(0,a.jsx)(n.p,{children:"MLflow 3.0 delivers best-in-class experiment tracking, observability, and performance evaluation for machine learning models, AI applications, and generative AI agents!\nWith MLflow 3.0, it's now easier than ever to:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Centrally track and analyze the performance of your models, agents, and generative AI applications ",(0,a.jsx)(n.strong,{children:"across all environments"}),", from interactive queries in a development notebook through production batch or real-time serving deployments."]}),"\n",(0,a.jsxs)(n.li,{children:["Select the best models, agents, and generative AI applications for production with an ",(0,a.jsx)(n.strong,{children:"enhanced performance comparison experience"})," powered by MLflow's tracing and evaluation capabilities."]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["MLflow 3.0's enhanced model tracking helps you manage and evaluate different model, agent, and generative AI application configurations in your experiments.\nImproved comparison workflows with the new ",(0,a.jsx)(s.B,{fn:"mlflow.entities.LoggedModel",children:"LoggedModel"})," enable you to quickly identify the best candidates for production,\nand MLflow tracing provides rich observability everywhere that your models, agents, and generative AI applications are deployed."]}),"\n",(0,a.jsx)(n.h2,{id:"enhanced-model-tracking",children:"Enhanced Model Tracking"}),"\n",(0,a.jsx)(n.p,{children:"In MLflow 3.0, we introduce a refined architecture along with revamped APIs and UI, tailored to enhance generative AI and deep learning workflows.\nWith GenAI agents, there are multiple rounds of offline evaluation via batch jobs and interactive queries from human beta testers.\nIn deep learning, training often generates multiple model checkpoints, where the best candidates are further evaluated before production deployment."}),"\n",(0,a.jsxs)(n.p,{children:["We are introducing a new first-class object, the ",(0,a.jsx)(s.B,{fn:"mlflow.entities.LoggedModel",children:"LoggedModel"})," entity, into MLflow Tracking to streamline these processes. As you define and evaluate your GenAI agents in code,\nor your deep learning jobs create and evaluate models, they will be automatically stored as MLflow Logged Models in your MLflow Experiment."]}),"\n",(0,a.jsxs)(n.p,{children:["When developing a new version of a GenAI agent or application, you can group all of the traces and metrics from interactive queries and automated evaluation jobs using MLflow's ",(0,a.jsx)(s.B,{fn:"mlflow.entities.LoggedModel",children:"LoggedModel"})," API.\nThis enables rich, comprehensive comparisons across versions.\nSimilarly, every deep learning checkpoint is stored as a ",(0,a.jsx)(s.B,{fn:"mlflow.entities.LoggedModel",children:"LoggedModel"})," with its own metrics and parameters, simplifying the process of identifying the best checkpoint for deployment or continued training."]}),"\n",(0,a.jsx)(n.h3,{id:"quickstart",children:"Quickstart"}),"\n",(0,a.jsx)(n.p,{children:"Prerequisites:\nRun the following command to install MLflow 3.0 and OpenAI packages."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"pip install --upgrade 'mlflow>=3.0.0rc0' --pre\npip install openai\n"})}),"\n",(0,a.jsx)(n.p,{children:"This quickstart demonstrates how to create a generative AI application with prompt engineering and evaluate it using MLflow 3.0.\nIt highlights the integration of the LoggedModel lineage feature with runs and traces, showcasing seamless tracking and observability for GenAI workflows."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from openai import OpenAI\n\nimport mlflow\nfrom mlflow.metrics.genai import answer_correctness, answer_similarity, faithfulness\n\n# set an active model for linking traces, a model named `openai_model` will be created\nmlflow.set_active_model(name="openai_model")\n\n# turn on autologging for automatic tracing\nmlflow.openai.autolog()\n\n# Initialize OpenAI client\nclient = OpenAI()\n\n# define a prompt template\nprompt_template = """\\\nYou are an expert AI assistant. Answer the user\'s question with clarity, accuracy, and conciseness.\n\n## Question:\n{question}\n\n## Guidelines:\n- Keep responses factual and to the point.\n- If relevant, provide examples or step-by-step instructions.\n- If the question is ambiguous, clarify before answering.\n\nRespond below:\n"""\n\n# groundtruth result for evaluation\nmlflow_ground_truth = (\n    "MLflow is an open-source platform for managing "\n    "the end-to-end machine learning (ML) lifecycle. It was developed by Databricks, "\n    "a company that specializes in big data and machine learning solutions. MLflow is "\n    "designed to address the challenges that data scientists and machine learning "\n    "engineers face when developing, training, and deploying machine learning models."\n)\n\n# Define evaluation metrics\nmetrics = {\n    "answer_similarity": answer_similarity(model="openai:/gpt-4o"),\n    "answer_correctness": answer_correctness(model="openai:/gpt-4o"),\n    "faithfulness": faithfulness(model="openai:/gpt-4o"),\n}\nquestion = "What is MLflow?"\n\n# # Start a run to represent the evaluation process\nwith mlflow.start_run():\n    response = (\n        client.chat.completions.create(\n            messages=[\n                {"role": "user", "content": prompt_template.format(question=question)}\n            ],\n            model="gpt-4o-mini",\n            temperature=0.1,\n            max_tokens=2000,\n        )\n        .choices[0]\n        .message.content\n    )\n\n    # Calculate metrics based on the input, response and ground truth\n    # The evaluation metrics are callables that can be invoked directly\n    answer_similarity_score = metrics["answer_similarity"](\n        predictions=response, inputs=question, targets=mlflow_ground_truth\n    ).scores[0]\n    answer_correctness_score = metrics["answer_correctness"](\n        predictions=response, inputs=question, targets=mlflow_ground_truth\n    ).scores[0]\n    faithfulness_score = metrics["faithfulness"](\n        predictions=response, inputs=question, context=mlflow_ground_truth\n    ).scores[0]\n\n    # get the active model id\n    active_model_id = mlflow.get_active_model_id()\n\n    # Log metrics and pass model_id to link the metrics\n    mlflow.log_metrics(\n        {\n            "answer_similarity": answer_similarity_score,\n            "answer_correctness": answer_correctness_score,\n            "faithfulness": faithfulness_score,\n        },\n        model_id=active_model_id,\n    )\n\n\ntraces = mlflow.search_traces(model_id=active_model_id)\ntraces\n#                            trace_id                                             trace  ...  assessments                        request_id\n# 0  7bb4569d3d884e3e87b1d8752276a13c  Trace(trace_id=7bb4569d3d884e3e87b1d8752276a13c)  ...           []  7bb4569d3d884e3e87b1d8752276a13c\n# [1 rows x 12 columns]\n'})}),"\n",(0,a.jsxs)(n.p,{children:["Navigate to the ",(0,a.jsx)(n.strong,{children:"Models"})," tab of the experiment to view the newly created LoggedModel. Evaluation metrics, model ID, source run, parameters, and other details are displayed on the models detail page, providing a comprehensive overview of the model's performance and lineage."]}),"\n",(0,a.jsx)("div",{className:"center-div",style:{width:"100%"},children:(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"The MLflow UI showing the models tab",src:t(56623).A+"",width:"3444",height:"732"})})}),"\n",(0,a.jsx)("div",{className:"center-div",style:{width:"100%"},children:(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"The MLflow UI showing the logged model",src:t(35322).A+"",width:"3444",height:"1702"})})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Traces"})," tab of the model displays the auto-generated traces:"]}),"\n",(0,a.jsx)("div",{className:"center-div",style:{width:"100%"},children:(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"The MLflow UI showing the logged model traces",src:t(21611).A+"",width:"4660",height:"2282"})})}),"\n",(0,a.jsx)(n.p,{children:"Clicking on the source_run takes you to the evaluation run's page with all the metrics:"}),"\n",(0,a.jsx)("div",{className:"center-div",style:{width:"100%"},children:(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"The MLflow UI showing the run and logged model",src:t(60714).A+"",width:"3444",height:"1444"})})}),"\n",(0,a.jsx)(n.h2,{id:"mlflow-30-showcases",children:"MLflow 3.0 Showcases"}),"\n",(0,a.jsx)(n.p,{children:"Explore the examples below to see how MLflow 3.0's powerful features can be applied across various domains."}),"\n",(0,a.jsxs)(c.AC,{children:[(0,a.jsx)(c._C,{headerText:"GenAI with MLflow 3.0",link:"/mlflow-3/genai-agent",text:"Discover how to log, evaluate, and trace GenAI agents using MLflow 3.0."}),(0,a.jsx)(c._C,{headerText:"Deep Learning with MLflow 3.0",link:"/mlflow-3/deep-learning",text:"Learn how to leverage MLflow 3.0 to identify the best models in deep learning workflows."})]}),"\n",(0,a.jsx)(n.h2,{id:"migration-guide",children:"Migration Guide"}),"\n",(0,a.jsx)(n.p,{children:"MLflow 3.0 introduces some key API changes while also removes some outdated features. This guide will help you transition smoothly to the latest version."}),"\n",(0,a.jsx)(n.h3,{id:"key-changes",children:"Key changes"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"mlflow.<flavor>.log_model"})," API usage: ",(0,a.jsx)(n.code,{children:"artifact_path"})," parameter is deprecated, use ",(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.code,{children:"name"})})," instead"]}),"\n"]}),"\n",(0,a.jsxs)(o.A,{children:[(0,a.jsx)(i.A,{label:"MLflow 2.x",value:"mlflow_2",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'with mlflow.start_run():\n    mlflow.pyfunc.log_model(artifact_path="model", python_model=python_model, ...)\n'})})}),(0,a.jsxs)(i.A,{label:"MLflow 3.0",value:"mlflow_3",children:[(0,a.jsxs)(n.p,{children:["Pass ",(0,a.jsx)(n.code,{children:"name"})," when logging a model. This allows you to later search for LoggedModels using this name."]}),(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["MLflow no longer requires starting a Run before logging models, because Models become\nfirst citizen entity in MLflow 3. You can directly call the ",(0,a.jsx)(n.code,{children:"log_model"})," API without\n",(0,a.jsx)(n.code,{children:"mlflow.start_run()"})," context manager to log a model."]})}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'mlflow.pyfunc.log_model(name="python_model", python_model=python_model, ...)\n'})})]})]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Model artifacts storage location change: In MLflow 2.x, ",(0,a.jsx)(n.a,{href:"../model/#storage-format",children:"model artifacts"})," are stored as run artifacts.\nSince MLflow 3.0, those artifacts will be stored into models artifacts location. Note: this impacts the behavior of ",(0,a.jsx)(s.B,{fn:"mlflow.client.MlflowClient.list_artifacts",children:(0,a.jsx)(n.code,{children:"list_artifacts"})})," API."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"removed-features",children:"Removed Features"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"MLflow Recipes"}),"\n",(0,a.jsxs)(n.li,{children:["Flavors: the following model flavors are no longer supported","\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"fastai"}),"\n",(0,a.jsx)(n.li,{children:"h2o"}),"\n",(0,a.jsx)(n.li,{children:"mleap"}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.li,{children:"AI gateway client APIs: use deployments APIs instead"}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(f,{...e})}):f(e)}},56623:(e,n,t)=>{t.d(n,{A:()=>l});const l=t.p+"assets/images/simple_example_models_tab-3f095d0d315e1162ca3d676d59127493.png"},60714:(e,n,t)=>{t.d(n,{A:()=>l});const l=t.p+"assets/images/simple_example_run_page-9db892145698174ce764fdfe7bb025e2.png"},65537:(e,n,t)=>{t.d(n,{A:()=>b});var l=t(96540),a=t(34164),r=t(65627),o=t(56347),i=t(50372),s=t(30604),c=t(11861),d=t(78749);function m(e){return l.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,l.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function p(e){const{values:n,children:t}=e;return(0,l.useMemo)((()=>{const e=n??function(e){return m(e).map((e=>{let{props:{value:n,label:t,attributes:l,default:a}}=e;return{value:n,label:t,attributes:l,default:a}}))}(t);return function(e){const n=(0,c.XI)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function h(e){let{value:n,tabValues:t}=e;return t.some((e=>e.value===n))}function f(e){let{queryString:n=!1,groupId:t}=e;const a=(0,o.W6)(),r=function(e){let{queryString:n=!1,groupId:t}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:n,groupId:t});return[(0,s.aZ)(r),(0,l.useCallback)((e=>{if(!r)return;const n=new URLSearchParams(a.location.search);n.set(r,e),a.replace({...a.location,search:n.toString()})}),[r,a])]}function u(e){const{defaultValue:n,queryString:t=!1,groupId:a}=e,r=p(e),[o,s]=(0,l.useState)((()=>function(e){let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!h({value:n,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const l=t.find((e=>e.default))??t[0];if(!l)throw new Error("Unexpected error: 0 tabValues");return l.value}({defaultValue:n,tabValues:r}))),[c,m]=f({queryString:t,groupId:a}),[u,w]=function(e){let{groupId:n}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(n),[a,r]=(0,d.Dv)(t);return[a,(0,l.useCallback)((e=>{t&&r.set(e)}),[t,r])]}({groupId:a}),g=(()=>{const e=c??u;return h({value:e,tabValues:r})?e:null})();(0,i.A)((()=>{g&&s(g)}),[g]);return{selectedValue:o,selectValue:(0,l.useCallback)((e=>{if(!h({value:e,tabValues:r}))throw new Error(`Can't select invalid tab value=${e}`);s(e),m(e),w(e)}),[m,w,r]),tabValues:r}}var w=t(9136);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var _=t(74848);function x(e){let{className:n,block:t,selectedValue:l,selectValue:o,tabValues:i}=e;const s=[],{blockElementScrollPositionUntilNextRender:c}=(0,r.a_)(),d=e=>{const n=e.currentTarget,t=s.indexOf(n),a=i[t].value;a!==l&&(c(n),o(a))},m=e=>{let n=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const t=s.indexOf(e.currentTarget)+1;n=s[t]??s[0];break}case"ArrowLeft":{const t=s.indexOf(e.currentTarget)-1;n=s[t]??s[s.length-1];break}}n?.focus()};return(0,_.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,a.A)("tabs",{"tabs--block":t},n),children:i.map((e=>{let{value:n,label:t,attributes:r}=e;return(0,_.jsx)("li",{role:"tab",tabIndex:l===n?0:-1,"aria-selected":l===n,ref:e=>{s.push(e)},onKeyDown:m,onClick:d,...r,className:(0,a.A)("tabs__item",g.tabItem,r?.className,{"tabs__item--active":l===n}),children:t??n},n)}))})}function y(e){let{lazy:n,children:t,selectedValue:r}=e;const o=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=o.find((e=>e.props.value===r));return e?(0,l.cloneElement)(e,{className:(0,a.A)("margin-top--md",e.props.className)}):null}return(0,_.jsx)("div",{className:"margin-top--md",children:o.map(((e,n)=>(0,l.cloneElement)(e,{key:n,hidden:e.props.value!==r})))})}function v(e){const n=u(e);return(0,_.jsxs)("div",{className:(0,a.A)("tabs-container",g.tabList),children:[(0,_.jsx)(x,{...n,...e}),(0,_.jsx)(y,{...n,...e})]})}function b(e){const n=(0,w.A)();return(0,_.jsx)(v,{...e,children:m(e.children)},String(n))}},67756:(e,n,t)=>{t.d(n,{B:()=>s});t(96540);const l=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var a=t(29030),r=t(56289),o=t(74848);const i=e=>{const n=e.split(".");for(let t=n.length;t>0;t--){const e=n.slice(0,t).join(".");if(l[e])return e}return null};function s(e){let{fn:n,children:t}=e;const s=i(n);if(!s)return(0,o.jsx)(o.Fragment,{children:t});const c=(0,a.Ay)(`/${l[s]}#${n}`);return(0,o.jsx)(r.A,{to:c,target:"_blank",children:t??(0,o.jsxs)("code",{children:[n,"()"]})})}},79329:(e,n,t)=>{t.d(n,{A:()=>o});t(96540);var l=t(34164);const a={tabItem:"tabItem_Ymn6"};var r=t(74848);function o(e){let{children:n,hidden:t,className:o}=e;return(0,r.jsx)("div",{role:"tabpanel",className:(0,l.A)(a.tabItem,o),hidden:t,children:n})}},86294:(e,n,t)=>{t.d(n,{Zp:()=>s,AC:()=>i,WO:()=>d,tf:()=>p,_C:()=>c,$3:()=>m,jK:()=>h});var l=t(34164);const a={CardGroup:"CardGroup_P84T",MaxThreeColumns:"MaxThreeColumns_FO1r",AutofillColumns:"AutofillColumns_fKhQ",Card:"Card_aSCR",CardBordered:"CardBordered_glGF",CardBody:"CardBody_BhRs",TextColor:"TextColor_a8Tp",BoxRoot:"BoxRoot_Etgr",FlexWrapNowrap:"FlexWrapNowrap_f60k",FlexJustifyContentFlexStart:"FlexJustifyContentFlexStart_ZYv5",FlexDirectionRow:"FlexDirectionRow_T2qL",FlexAlignItemsCenter:"FlexAlignItemsCenter_EHVM",FlexFlex:"FlexFlex__JTE",Link:"Link_fVkl",MarginLeft4:"MarginLeft4_YQSJ",MarginTop4:"MarginTop4_jXKN",PaddingBottom4:"PaddingBottom4_O9gt",LogoCardContent:"LogoCardContent_kCQm",LogoCardImage:"LogoCardImage_JdcX",SmallLogoCardContent:"SmallLogoCardContent_LxhV",SmallLogoCardImage:"SmallLogoCardImage_tPZl",NewFeatureCardContent:"NewFeatureCardContent_Rq3d",NewFeatureCardHeading:"NewFeatureCardHeading_f6q3",NewFeatureCardHeadingSeparator:"NewFeatureCardHeadingSeparator_pSx8",NewFeatureCardTags:"NewFeatureCardTags_IFHO",NewFeatureCardWrapper:"NewFeatureCardWrapper_NQ0k",TitleCardContent:"TitleCardContent_l9MQ",TitleCardTitle:"TitleCardTitle__K8J",TitleCardSeparator:"TitleCardSeparator_IN2E",Cols1:"Cols1_Gr2U",Cols2:"Cols2_sRvc",Cols3:"Cols3_KjUS",Cols4:"Cols4_dKOj",Cols5:"Cols5_jDmj",Cols6:"Cols6_Q0OR"};var r=t(56289),o=t(74848);const i=e=>{let{children:n,isSmall:t,cols:r}=e;return(0,o.jsx)("div",{className:(0,l.A)(a.CardGroup,t?a.AutofillColumns:r?a[`Cols${r}`]:a.MaxThreeColumns),children:n})},s=e=>{let{children:n,link:t=""}=e;return t?(0,o.jsx)(r.A,{className:(0,l.A)(a.Link,a.Card,a.CardBordered),to:t,children:n}):(0,o.jsx)("div",{className:(0,l.A)(a.Card,a.CardBordered),children:n})},c=e=>{let{headerText:n,link:t,text:r}=e;return(0,o.jsx)(s,{link:t,children:(0,o.jsxs)("span",{children:[(0,o.jsx)("div",{className:(0,l.A)(a.CardTitle,a.BoxRoot,a.PaddingBottom4),style:{pointerEvents:"none"},children:(0,o.jsx)("div",{className:(0,l.A)(a.BoxRoot,a.FlexFlex,a.FlexAlignItemsCenter,a.FlexDirectionRow,a.FlexJustifyContentFlexStart,a.FlexWrapNowrap),style:{marginLeft:"-4px",marginTop:"-4px"},children:(0,o.jsx)("div",{className:(0,l.A)(a.BoxRoot,a.BoxHideIfEmpty,a.MarginTop4,a.MarginLeft4),style:{pointerEvents:"auto"},children:(0,o.jsx)("span",{className:"",children:n})})})}),(0,o.jsx)("span",{className:(0,l.A)(a.TextColor,a.CardBody),children:(0,o.jsx)("p",{children:r})})]})})},d=e=>{let{description:n,children:t,link:l}=e;return(0,o.jsx)(s,{link:l,children:(0,o.jsxs)("div",{className:a.LogoCardContent,children:[(0,o.jsx)("div",{className:a.LogoCardImage,children:t}),(0,o.jsx)("p",{className:a.TextColor,children:n})]})})},m=e=>{let{children:n,link:t}=e;return(0,o.jsx)(s,{link:t,children:(0,o.jsx)("div",{className:a.SmallLogoCardContent,children:(0,o.jsx)("div",{className:(0,l.A)("max-height-img-container",a.SmallLogoCardImage),children:n})})})},p=e=>{let{children:n,description:t,name:l,releaseVersion:i,learnMoreLink:c=""}=e;return(0,o.jsx)(s,{children:(0,o.jsxs)("div",{className:a.NewFeatureCardWrapper,children:[(0,o.jsxs)("div",{className:a.NewFeatureCardContent,children:[(0,o.jsxs)("div",{className:a.NewFeatureCardHeading,children:[l,(0,o.jsx)("br",{}),(0,o.jsx)("hr",{className:a.NewFeatureCardHeadingSeparator})]}),(0,o.jsx)("div",{className:a.LogoCardImage,children:n}),(0,o.jsx)("br",{}),(0,o.jsx)("p",{children:t}),(0,o.jsx)("br",{})]}),(0,o.jsxs)("div",{className:a.NewFeatureCardTags,children:[(0,o.jsx)("div",{children:c&&(0,o.jsx)(r.A,{className:"button button--outline button--sm button--primary",to:c,children:"Learn more"})}),(0,o.jsxs)(r.A,{className:"button button--outline button--sm button--primary",to:`https://github.com/mlflow/mlflow/releases/tag/v${i}`,children:["released in ",i]})]})]})})},h=e=>{let{title:n,description:t,link:r=""}=e;return(0,o.jsx)(s,{link:r,children:(0,o.jsxs)("div",{className:a.TitleCardContent,children:[(0,o.jsx)("div",{className:(0,l.A)(a.TitleCardTitle),style:{textAlign:"left",fontWeight:"bold"},children:n}),(0,o.jsx)("hr",{className:(0,l.A)(a.TitleCardSeparator),style:{margin:"12px 0"}}),(0,o.jsx)("p",{className:(0,l.A)(a.TextColor),children:t})]})})}}}]);