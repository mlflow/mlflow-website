"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["9793"],{48797(e,n,t){t.r(n),t.d(n,{metadata:()=>l,default:()=>b,frontMatter:()=>_,contentTitle:()=>y,toc:()=>k,assets:()=>x});var l=JSON.parse('{"id":"tracing/integrations/listing/fireworksai","title":"Tracing FireworksAI","description":"FireworksAI is an inference and customization engine for open source AI. It provides day zero access to the latest SOTA OSS models and allows developers to build lightning AI applications.","source":"@site/docs/genai/tracing/integrations/listing/fireworksai.mdx","sourceDirName":"tracing/integrations/listing","slug":"/tracing/integrations/listing/fireworksai","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/fireworksai","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":12,"frontMatter":{"sidebar_position":12,"sidebar_label":"FireworksAI"},"sidebar":"genAISidebar","previous":{"title":"DeepSeek","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/deepseek"},"next":{"title":"Gemini","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/gemini"}}'),a=t(74848),r=t(28453),o=t(54725),i=t(78010),s=t(57250),c=t(46077),p=t(95986),h=t(89001),m=t(8060),d=t(10440),f=t(77541),u=t(93893),w=t(60665),g=t(43975);let _={sidebar_position:12,sidebar_label:"FireworksAI"},y="Tracing FireworksAI",x={},k=[{value:"Getting Started",id:"getting-started",level:2},...m.RM,{value:"Supported APIs",id:"supported-apis",level:2},{value:"Chat Completion API Examples",id:"chat-completion-api-examples",level:2},{value:"Token Usage",id:"token-usage",level:2},{value:"Disable auto-tracing",id:"disable-auto-tracing",level:2},{value:"Next steps",id:"next-steps",level:2}];function j(e){let n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"tracing-fireworksai",children:"Tracing FireworksAI"})}),"\n",(0,a.jsx)(c.A,{src:"/images/llms/tracing/fireworks-ai-tracing.png",alt:"FireworksAI Tracing via autolog"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"https://fireworks.ai",children:"FireworksAI"})," is an inference and customization engine for open source AI. It provides day zero access to the latest SOTA OSS models and allows developers to build lightning AI applications."]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"/genai/tracing",children:"MLflow Tracing"})," provides automatic tracing capability for FireworksAI through the OpenAI SDK compatibility. FireworksAI is ",(0,a.jsx)(n.a,{href:"https://fireworks.ai/docs/tools-sdks/openai-compatibility#openai-compatibility",children:"OpenAI SDK compatible"}),", you can use the ",(0,a.jsx)(o.B,{fn:"mlflow.openai.autolog"})," function to enable automatic tracing. MLflow will capture traces for LLM invocations and log them to the active MLflow Experiment."]}),"\n",(0,a.jsx)(n.p,{children:"MLflow automatically captures the following information about FireworksAI calls:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Prompts and completion responses"}),"\n",(0,a.jsx)(n.li,{children:"Latencies"}),"\n",(0,a.jsx)(n.li,{children:"Model name"}),"\n",(0,a.jsxs)(n.li,{children:["Additional metadata such as ",(0,a.jsx)(n.code,{children:"temperature"}),", ",(0,a.jsx)(n.code,{children:"max_completion_tokens"}),", if specified"]}),"\n",(0,a.jsx)(n.li,{children:"Tool Use if returned in the response"}),"\n",(0,a.jsx)(n.li,{children:"Any exception if raised"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"getting-started",children:"Getting Started"}),"\n",(0,a.jsx)(h.A,{number:1,title:"Install Dependencies"}),"\n",(0,a.jsx)(p.A,{children:(0,a.jsxs)(i.A,{children:[(0,a.jsx)(s.A,{value:"python",label:"Python",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"pip install 'mlflow[genai]' openai\n"})})}),(0,a.jsx)(s.A,{value:"typescript",label:"JS / TS",children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"npm install mlflow-openai openai\n"})})})]})}),"\n",(0,a.jsx)(h.A,{number:2,title:"Start MLflow Server"}),"\n",(0,a.jsx)(m.Ay,{}),"\n",(0,a.jsx)(h.A,{number:3,title:"Enable Tracing and Make API Calls"}),"\n",(0,a.jsx)(p.A,{children:(0,a.jsxs)(i.A,{children:[(0,a.jsxs)(s.A,{value:"python",label:"Python",default:!0,children:[(0,a.jsxs)(n.p,{children:["Enable tracing with ",(0,a.jsx)(n.code,{children:"mlflow.openai.autolog()"})," and make API calls as usual."]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport openai\nimport os\n\n# Enable auto-tracing for FireworksAI (uses OpenAI SDK compatibility)\nmlflow.openai.autolog()\n\n# Set a tracking URI and an experiment\nmlflow.set_tracking_uri("http://localhost:5000")\nmlflow.set_experiment("FireworksAI")\n\n# Create an OpenAI client configured for FireworksAI\nclient = openai.OpenAI(\n    base_url="https://api.fireworks.ai/inference/v1",\n    api_key=os.getenv("FIREWORKS_API_KEY"),\n)\n\n# Use the client as usual - traces will be automatically captured\nresponse = client.chat.completions.create(\n    model="accounts/fireworks/models/deepseek-v3-0324",  # For other models see: https://fireworks.ai/models\n    messages=[\n        {"role": "user", "content": "Why is open source better than closed source?"}\n    ],\n)\n'})})]}),(0,a.jsxs)(s.A,{value:"typescript",label:"JS / TS",children:[(0,a.jsxs)(n.p,{children:["Wrap the OpenAI client with the ",(0,a.jsx)(n.code,{children:"tracedOpenAI"})," function and make API calls as usual."]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import { OpenAI } from "openai";\nimport { tracedOpenAI } from "mlflow-openai";\n\n// Wrap the OpenAI client and point to FireworksAI endpoint\nconst client = tracedOpenAI(\n  new OpenAI({\n    baseURL: "https://api.fireworks.ai/inference/v1",\n    apiKey: process.env.FIREWORKS_API_KEY,\n  })\n);\n\n// Use the client as usual - traces will be automatically captured\nconst response = await client.chat.completions.create({\n  model: "accounts/fireworks/models/deepseek-v3-0324",  // For other models see: https://fireworks.ai/models\n  messages: [\n    { role: "user", content: "Why is open source better than closed source?" }\n  ],\n});\n'})})]})]})}),"\n",(0,a.jsx)(h.A,{number:4,title:"View Traces in MLflow UI"}),"\n",(0,a.jsxs)(n.p,{children:["Browse to the MLflow UI at ",(0,a.jsx)(n.a,{href:"http://localhost:5000",children:"http://localhost:5000"})," (or your MLflow server URL) and you should see the traces for the FireworksAI API calls."]}),"\n",(0,a.jsx)(c.A,{src:"/images/llms/tracing/fireworks-ai-tracing.png",alt:"FireworksAI Tracing in MLflow UI"}),"\n",(0,a.jsxs)(n.p,{children:["\u2192 View ",(0,a.jsx)(n.a,{href:"#next-steps",children:"Next Steps"})," for learning about more MLflow features like user feedback tracking, prompt management, and evaluation."]}),"\n",(0,a.jsx)(n.h2,{id:"supported-apis",children:"Supported APIs"}),"\n",(0,a.jsxs)(n.p,{children:["Since FireworksAI is OpenAI SDK compatible, all APIs supported by MLflow's OpenAI integration work seamlessly with FireworksAI. See ",(0,a.jsx)(n.a,{href:"https://fireworks.ai/models",children:"the model library"})," for a list of available models on FireworksAI."]}),"\n",(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{style:{textAlign:"center"},children:"Normal"}),(0,a.jsx)(n.th,{style:{textAlign:"center"},children:"Tool Use"}),(0,a.jsx)(n.th,{style:{textAlign:"center"},children:"Structured Outputs"}),(0,a.jsx)(n.th,{style:{textAlign:"center"},children:"Streaming"}),(0,a.jsx)(n.th,{style:{textAlign:"center"},children:"Async"})]})}),(0,a.jsx)(n.tbody,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{style:{textAlign:"center"},children:"\u2705"}),(0,a.jsx)(n.td,{style:{textAlign:"center"},children:"\u2705"}),(0,a.jsx)(n.td,{style:{textAlign:"center"},children:"\u2705"}),(0,a.jsx)(n.td,{style:{textAlign:"center"},children:"\u2705"}),(0,a.jsx)(n.td,{style:{textAlign:"center"},children:"\u2705"})]})})]}),"\n",(0,a.jsx)(n.h2,{id:"chat-completion-api-examples",children:"Chat Completion API Examples"}),"\n",(0,a.jsx)(p.A,{children:(0,a.jsxs)(i.A,{children:[(0,a.jsx)(s.A,{value:"basic",label:"Basic Example",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import openai\nimport mlflow\nimport os\n\n# Enable auto-tracing\nmlflow.openai.autolog()\n\n# Optional: Set a tracking URI and an experiment\n# If running locally you can start a server with:  `mlflow server --host 127.0.0.1 --port 5000`\nmlflow.set_tracking_uri("http://127.0.0.1:5000")\nmlflow.set_experiment("FireworksAI")\n\n# Configure OpenAI client for FireworksAI\nopenai_client = openai.OpenAI(\n    base_url="https://api.fireworks.ai/inference/v1",\n    api_key=os.getenv("FIREWORKS_API_KEY"),\n)\n\nmessages = [\n    {\n        "role": "user",\n        "content": "What is the capital of France?",\n    }\n]\n\n# To use different models check out the model library at: https://fireworks.ai/models\nresponse = openai_client.chat.completions.create(\n    model="accounts/fireworks/models/deepseek-v3-0324",\n    messages=messages,\n    max_completion_tokens=100,\n)\n'})})}),(0,a.jsx)(s.A,{value:"typescript",label:"JS / TS",children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import { OpenAI } from "openai";\nimport { tracedOpenAI } from "mlflow-openai";\n\n// Configure OpenAI client for FireworksAI\nconst client = tracedOpenAI(\n  new OpenAI({\n    baseURL: "https://api.fireworks.ai/inference/v1",\n    apiKey: process.env.FIREWORKS_API_KEY,\n  })\n);\n\nconst messages = [\n  {\n    role: "user",\n    content: "What is the capital of France?",\n  }\n];\n\n// To use different models check out the model library at: https://fireworks.ai/models\nconst response = await client.chat.completions.create({\n  model: "accounts/fireworks/models/deepseek-v3-0324",\n  messages: messages,\n  max_tokens: 100,\n});\n\nconsole.log(response.choices[0].message.content);\n'})})}),(0,a.jsxs)(s.A,{value:"streaming",label:"Streaming",children:[(0,a.jsxs)(n.p,{children:["MLflow Tracing supports streaming API outputs of FireworksAI endpoints through the OpenAI SDK. With the same setup of auto tracing, MLflow automatically traces the streaming response and renders the concatenated output in the span UI. The actual chunks in the response stream can be found in the ",(0,a.jsx)(n.code,{children:"Event"})," tab as well."]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import openai\nimport mlflow\nimport os\n\n# Enable trace logging\nmlflow.openai.autolog()\n\nclient = openai.OpenAI(\n    base_url="https://api.fireworks.ai/inference/v1",\n    api_key=os.getenv("FIREWORKS_API_KEY"),\n)\n\nstream = client.chat.completions.create(\n    model="accounts/fireworks/models/deepseek-v3-0324",\n    messages=[\n        {"role": "user", "content": "How fast would a glass of water freeze on Titan?"}\n    ],\n    stream=True,  # Enable streaming response\n)\nfor chunk in stream:\n    print(chunk.choices[0].delta.content or "", end="")\n'})})]}),(0,a.jsxs)(s.A,{value:"async",label:"Async",children:[(0,a.jsx)(n.p,{children:"MLflow Tracing supports asynchronous API returns of FireworksAI through the OpenAI SDK. The usage is the same as the synchronous API."}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import openai\nimport mlflow\nimport os\n\n# Enable trace logging\nmlflow.openai.autolog()\n\nclient = openai.AsyncOpenAI(\n    base_url="https://api.fireworks.ai/inference/v1",\n    api_key=os.getenv("FIREWORKS_API_KEY"),\n)\n\nresponse = await client.chat.completions.create(\n    model="accounts/fireworks/models/deepseek-v3-0324",\n    messages=[{"role": "user", "content": "What is the best open source LLM?"}],\n    # Async streaming is also supported\n    # stream=True\n)\n'})})]}),(0,a.jsxs)(s.A,{value:"tool-use",label:"Tool Use",children:[(0,a.jsxs)(n.p,{children:["MLflow Tracing automatically captures tool use responses from FireworksAI models. The function instruction in the response will be highlighted in the trace UI. Moreover, you can annotate the tool function with the ",(0,a.jsx)(n.code,{children:"@mlflow.trace"})," decorator to create a span for the tool execution."]}),(0,a.jsx)(n.p,{children:"The following example implements a simple tool use agent using FireworksAI and MLflow Tracing:"}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import json\nfrom openai import OpenAI\nimport mlflow\nfrom mlflow.entities import SpanType\nimport os\n\nclient = OpenAI(\n    base_url="https://api.fireworks.ai/inference/v1",\n    api_key=os.getenv("FIREWORKS_API_KEY"),\n)\n\n\n# Define the tool function. Decorate it with `@mlflow.trace` to create a span for its execution.\n@mlflow.trace(span_type=SpanType.TOOL)\ndef get_weather(city: str) -> str:\n    if city == "Tokyo":\n        return "sunny"\n    elif city == "Paris":\n        return "rainy"\n    return "unknown"\n\n\ntools = [\n    {\n        "type": "function",\n        "function": {\n            "name": "get_weather",\n            "parameters": {\n                "type": "object",\n                "properties": {"city": {"type": "string"}},\n            },\n        },\n    }\n]\n\n_tool_functions = {"get_weather": get_weather}\n\n\n# Define a simple tool calling agent\n@mlflow.trace(span_type=SpanType.AGENT)\ndef run_tool_agent(question: str):\n    messages = [{"role": "user", "content": question}]\n\n    # Invoke the model with the given question and available tools\n    response = client.chat.completions.create(\n        model="accounts/fireworks/models/gpt-oss-20b",\n        messages=messages,\n        tools=tools,\n    )\n    ai_msg = response.choices[0].message\n    messages.append(ai_msg)\n\n    # If the model requests tool call(s), invoke the function with the specified arguments\n    if tool_calls := ai_msg.tool_calls:\n        for tool_call in tool_calls:\n            function_name = tool_call.function.name\n            if tool_func := _tool_functions.get(function_name):\n                args = json.loads(tool_call.function.arguments)\n                tool_result = tool_func(**args)\n            else:\n                raise RuntimeError("An invalid tool is returned from the assistant!")\n\n            messages.append(\n                {\n                    "role": "tool",\n                    "tool_call_id": tool_call.id,\n                    "content": tool_result,\n                }\n            )\n\n        # Send the tool results to the model and get a new response\n        response = client.chat.completions.create(\n            model="accounts/fireworks/models/llama-v3p1-8b-instruct", messages=messages\n        )\n\n    return response.choices[0].message.content\n\n\n# Run the tool calling agent\nquestion = "What\'s the weather like in Paris today?"\nanswer = run_tool_agent(question)\n'})})]})]})}),"\n",(0,a.jsx)(n.h2,{id:"token-usage",children:"Token Usage"}),"\n",(0,a.jsxs)(n.p,{children:["MLflow supports token usage tracking for FireworksAI. The token usage for each LLM call will be logged in the ",(0,a.jsx)(n.code,{children:"mlflow.chat.tokenUsage"})," attribute. The total token usage throughout the trace will be available in the ",(0,a.jsx)(n.code,{children:"token_usage"})," field of the trace info object."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import json\nimport mlflow\n\nmlflow.openai.autolog()\n\n# Run the tool calling agent defined in the previous section\nquestion = "What\'s the weather like in Paris today?"\nanswer = run_tool_agent(question)\n\n# Get the trace object just created\nlast_trace_id = mlflow.get_last_active_trace_id()\ntrace = mlflow.get_trace(trace_id=last_trace_id)\n\n# Print the token usage\ntotal_usage = trace.info.token_usage\nprint("== Total token usage: ==")\nprint(f"  Input tokens: {total_usage[\'input_tokens\']}")\nprint(f"  Output tokens: {total_usage[\'output_tokens\']}")\nprint(f"  Total tokens: {total_usage[\'total_tokens\']}")\n\n# Print the token usage for each LLM call\nprint("\\n== Detailed usage for each LLM call: ==")\nfor span in trace.data.spans:\n    if usage := span.get_attribute("mlflow.chat.tokenUsage"):\n        print(f"{span.name}:")\n        print(f"  Input tokens: {usage[\'input_tokens\']}")\n        print(f"  Output tokens: {usage[\'output_tokens\']}")\n        print(f"  Total tokens: {usage[\'total_tokens\']}")\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"== Total token usage: ==\n  Input tokens: 20\n  Output tokens: 283\n  Total tokens: 303\n\n== Detailed usage for each LLM call: ==\nCompletions:\n  Input tokens: 20\n  Output tokens: 283\n  Total tokens: 303\n"})}),"\n",(0,a.jsx)(n.h2,{id:"disable-auto-tracing",children:"Disable auto-tracing"}),"\n",(0,a.jsxs)(n.p,{children:["Auto tracing for FireworksAI can be disabled globally by calling ",(0,a.jsx)(n.code,{children:"mlflow.openai.autolog(disable=True)"})," or ",(0,a.jsx)(n.code,{children:"mlflow.autolog(disable=True)"}),"."]}),"\n",(0,a.jsx)(n.h2,{id:"next-steps",children:"Next steps"}),"\n",(0,a.jsxs)(d.A,{children:[(0,a.jsx)(f.A,{icon:u.A,iconSize:48,title:"Track User Feedback",description:"Record user feedback on traces for tracking user satisfaction.",href:"/genai/tracing/collect-user-feedback",linkText:"Learn about feedback \u2192",containerHeight:64}),(0,a.jsx)(f.A,{icon:w.A,iconSize:48,title:"Manage Prompts",description:"Learn how to manage prompts with MLflow's prompt registry.",href:"/genai/prompt-registry",linkText:"Manage prompts \u2192",containerHeight:64}),(0,a.jsx)(f.A,{icon:g.A,iconSize:48,title:"Evaluate Traces",description:"Evaluate traces with LLM judges to understand and improve your AI application's behavior.",href:"/genai/eval-monitor/running-evaluation/traces",linkText:"Evaluate traces \u2192",containerHeight:64})]})]})}function b(e={}){let{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(j,{...e})}):j(e)}},8060(e,n,t){t.d(n,{Ay:()=>p,RM:()=>s});var l=t(74848),a=t(28453),r=t(78010),o=t(57250),i=t(95986);let s=[];function c(e){let n={a:"a",code:"code",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,l.jsx)(i.A,{children:(0,l.jsxs)(r.A,{children:[(0,l.jsxs)(o.A,{value:"local",label:"Local (pip)",default:!0,children:[(0,l.jsxs)(n.p,{children:["If you have a local Python environment >= 3.10, you can start the MLflow server locally using the ",(0,l.jsx)(n.code,{children:"mlflow"})," CLI command."]}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"mlflow server\n"})})]}),(0,l.jsxs)(o.A,{value:"docker",label:"Local (docker)",children:[(0,l.jsx)(n.p,{children:"MLflow also provides a Docker Compose file to start a local MLflow server with a postgres database and a minio server."}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"git clone --depth 1 --filter=blob:none --sparse https://github.com/mlflow/mlflow.git\ncd mlflow\ngit sparse-checkout set docker-compose\ncd docker-compose\ncp .env.dev.example .env\ndocker compose up -d\n"})}),(0,l.jsxs)(n.p,{children:["Refer to the ",(0,l.jsx)(n.a,{href:"https://github.com/mlflow/mlflow/tree/master/docker-compose/README.md",children:"instruction"})," for more details, e.g., overriding the default environment variables."]})]})]})})}function p(e={}){let{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(c,{...e})}):c(e)}},75689(e,n,t){t.d(n,{A:()=>s});var l=t(96540);let a=e=>{let n=e.replace(/^([A-Z])|[\s-_]+(\w)/g,(e,n,t)=>t?t.toUpperCase():n.toLowerCase());return n.charAt(0).toUpperCase()+n.slice(1)},r=(...e)=>e.filter((e,n,t)=>!!e&&""!==e.trim()&&t.indexOf(e)===n).join(" ").trim();var o={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};let i=(0,l.forwardRef)(({color:e="currentColor",size:n=24,strokeWidth:t=2,absoluteStrokeWidth:a,className:i="",children:s,iconNode:c,...p},h)=>(0,l.createElement)("svg",{ref:h,...o,width:n,height:n,stroke:e,strokeWidth:a?24*Number(t)/Number(n):t,className:r("lucide",i),...!s&&!(e=>{for(let n in e)if(n.startsWith("aria-")||"role"===n||"title"===n)return!0})(p)&&{"aria-hidden":"true"},...p},[...c.map(([e,n])=>(0,l.createElement)(e,n)),...Array.isArray(s)?s:[s]])),s=(e,n)=>{let t=(0,l.forwardRef)(({className:t,...o},s)=>(0,l.createElement)(i,{ref:s,iconNode:n,className:r(`lucide-${a(e).replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()}`,`lucide-${e}`,t),...o}));return t.displayName=a(e),t}},60665(e,n,t){t.d(n,{A:()=>l});let l=(0,t(75689).A)("book-open",[["path",{d:"M12 7v14",key:"1akyts"}],["path",{d:"M3 18a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h5a4 4 0 0 1 4 4 4 4 0 0 1 4-4h5a1 1 0 0 1 1 1v13a1 1 0 0 1-1 1h-6a3 3 0 0 0-3 3 3 3 0 0 0-3-3z",key:"ruj8y"}]])},43975(e,n,t){t.d(n,{A:()=>l});let l=(0,t(75689).A)("scale",[["path",{d:"m16 16 3-8 3 8c-.87.65-1.92 1-3 1s-2.13-.35-3-1Z",key:"7g6ntu"}],["path",{d:"m2 16 3-8 3 8c-.87.65-1.92 1-3 1s-2.13-.35-3-1Z",key:"ijws7r"}],["path",{d:"M7 21h10",key:"1b0cd5"}],["path",{d:"M12 3v18",key:"108xh3"}],["path",{d:"M3 7h2c2 0 5-1 7-2 2 1 5 2 7 2h2",key:"3gwbw2"}]])},93893(e,n,t){t.d(n,{A:()=>l});let l=(0,t(75689).A)("users",[["path",{d:"M16 21v-2a4 4 0 0 0-4-4H6a4 4 0 0 0-4 4v2",key:"1yyitq"}],["path",{d:"M16 3.128a4 4 0 0 1 0 7.744",key:"16gr8j"}],["path",{d:"M22 21v-2a4 4 0 0 0-3-3.87",key:"kshegd"}],["circle",{cx:"9",cy:"7",r:"4",key:"nufk8"}]])},57250(e,n,t){t.d(n,{A:()=>r});var l=t(74848);t(96540);var a=t(34164);function r({children:e,hidden:n,className:t}){return(0,l.jsx)("div",{role:"tabpanel",className:(0,a.A)("tabItem_Ymn6",t),hidden:n,children:e})}},78010(e,n,t){t.d(n,{A:()=>y});var l=t(74848),a=t(96540),r=t(34164),o=t(88287),i=t(28584),s=t(56347),c=t(99989),p=t(96629),h=t(80618),m=t(41367);function d(e){return a.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,a.isValidElement)(e)&&function(e){let{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function f({value:e,tabValues:n}){return n.some(n=>n.value===e)}var u=t(19863);function w({className:e,block:n,selectedValue:t,selectValue:a,tabValues:o}){let s=[],{blockElementScrollPositionUntilNextRender:c}=(0,i.a_)(),p=e=>{let n=e.currentTarget,l=o[s.indexOf(n)].value;l!==t&&(c(n),a(l))},h=e=>{let n=null;switch(e.key){case"Enter":p(e);break;case"ArrowRight":{let t=s.indexOf(e.currentTarget)+1;n=s[t]??s[0];break}case"ArrowLeft":{let t=s.indexOf(e.currentTarget)-1;n=s[t]??s[s.length-1]}}n?.focus()};return(0,l.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":n},e),children:o.map(({value:e,label:n,attributes:a})=>(0,l.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{s.push(e)},onKeyDown:h,onClick:p,...a,className:(0,r.A)("tabs__item","tabItem_LNqP",a?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function g({lazy:e,children:n,selectedValue:t}){let o=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){let e=o.find(e=>e.props.value===t);return e?(0,a.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,l.jsx)("div",{className:"margin-top--md",children:o.map((e,n)=>(0,a.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function _(e){let n=function(e){let n,{defaultValue:t,queryString:l=!1,groupId:r}=e,o=function(e){let{values:n,children:t}=e;return(0,a.useMemo)(()=>{let e=n??d(t).map(({props:{value:e,label:n,attributes:t,default:l}})=>({value:e,label:n,attributes:t,default:l})),l=(0,h.XI)(e,(e,n)=>e.value===n.value);if(l.length>0)throw Error(`Docusaurus error: Duplicate values "${l.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`);return e},[n,t])}(e),[i,u]=(0,a.useState)(()=>(function({defaultValue:e,tabValues:n}){if(0===n.length)throw Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!f({value:e,tabValues:n}))throw Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}let t=n.find(e=>e.default)??n[0];if(!t)throw Error("Unexpected error: 0 tabValues");return t.value})({defaultValue:t,tabValues:o})),[w,g]=function({queryString:e=!1,groupId:n}){let t=(0,s.W6)(),l=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,p.aZ)(l),(0,a.useCallback)(e=>{if(!l)return;let n=new URLSearchParams(t.location.search);n.set(l,e),t.replace({...t.location,search:n.toString()})},[l,t])]}({queryString:l,groupId:r}),[_,y]=function({groupId:e}){let n=e?`docusaurus.tab.${e}`:null,[t,l]=(0,m.Dv)(n);return[t,(0,a.useCallback)(e=>{n&&l.set(e)},[n,l])]}({groupId:r}),x=f({value:n=w??_,tabValues:o})?n:null;return(0,c.A)(()=>{x&&u(x)},[x]),{selectedValue:i,selectValue:(0,a.useCallback)(e=>{if(!f({value:e,tabValues:o}))throw Error(`Can't select invalid tab value=${e}`);u(e),g(e),y(e)},[g,y,o]),tabValues:o}}(e);return(0,l.jsxs)("div",{className:(0,r.A)(o.G.tabs.container,"tabs-container","tabList__CuJ"),children:[(0,l.jsx)(w,{...n,...e}),(0,l.jsx)(g,{...n,...e})]})}function y(e){let n=(0,u.A)();return(0,l.jsx)(_,{...e,children:d(e.children)},String(n))}},54725(e,n,t){t.d(n,{B:()=>o});var l=t(74848);t(96540);var a=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}'),r=t(66497);function o({fn:e,children:n,hash:t}){let o=(e=>{let n=e.split(".");for(let e=n.length;e>0;e--){let t=n.slice(0,e).join(".");if(a[t])return t}return null})(e);if(!o)return(0,l.jsx)(l.Fragment,{children:n});let i=(0,r.default)(`/${a[o]}#${t??e}`);return(0,l.jsx)("a",{href:i,target:"_blank",children:n??(0,l.jsxs)("code",{children:[e,"()"]})})}},46077(e,n,t){t.d(n,{A:()=>r});var l=t(74848);t(96540);var a=t(66497);function r({src:e,alt:n,width:t,caption:r,className:o}){return(0,l.jsxs)("div",{className:`container_JwLF ${o||""}`,children:[(0,l.jsx)("div",{className:"imageWrapper_RfGN",style:t?{width:t}:{},children:(0,l.jsx)("img",{src:(0,a.default)(e),alt:n,className:"image_bwOA"})}),r&&(0,l.jsx)("p",{className:"caption_jo2G",children:r})]})}},89001(e,n,t){t.d(n,{A:()=>a});var l=t(74848);t(96540);let a=({number:e,title:n})=>(0,l.jsxs)("div",{className:"stepHeader_RqmM",children:[(0,l.jsx)("div",{className:"stepNumber_exmH",children:e}),(0,l.jsx)("h3",{className:"stepTitle_SzBx",children:n})]})},95986(e,n,t){t.d(n,{A:()=>a});var l=t(74848);t(96540);function a({children:e}){return(0,l.jsx)("div",{className:"wrapper_sf5q",children:e})}},77541(e,n,t){t.d(n,{A:()=>c});var l=t(74848);t(96540);var a=t(95310),r=t(34164);let o="tileImage_O4So";var i=t(66497),s=t(92802);function c({icon:e,image:n,imageDark:t,imageWidth:c,imageHeight:p,iconSize:h=32,containerHeight:m,title:d,description:f,href:u,linkText:w="Learn more \u2192",className:g}){if(!e&&!n)throw Error("TileCard requires either an icon or image prop");let _=m?{height:`${m}px`}:{},y={};return c&&(y.width=`${c}px`),p&&(y.height=`${p}px`),(0,l.jsxs)(a.A,{href:u,className:(0,r.A)("tileCard_NHsj",g),children:[(0,l.jsx)("div",{className:"tileIcon_pyoR",style:_,children:e?(0,l.jsx)(e,{size:h}):t?(0,l.jsx)(s.A,{sources:{light:(0,i.default)(n),dark:(0,i.default)(t)},alt:d,className:o,style:y}):(0,l.jsx)("img",{src:(0,i.default)(n),alt:d,className:o,style:y})}),(0,l.jsx)("h3",{children:d}),(0,l.jsx)("p",{children:f}),(0,l.jsx)("div",{className:"tileLink_iUbu",children:w})]})}},10440(e,n,t){t.d(n,{A:()=>r});var l=t(74848);t(96540);var a=t(34164);function r({children:e,className:n}){return(0,l.jsx)("div",{className:(0,a.A)("tilesGrid_hB9N",n),children:e})}},28453(e,n,t){t.d(n,{R:()=>o,x:()=>i});var l=t(96540);let a={},r=l.createContext(a);function o(e){let n=l.useContext(r);return l.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),l.createElement(r.Provider,{value:n},e.children)}}}]);