"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["6287"],{25358(e,n,t){t.r(n),t.d(n,{metadata:()=>r,default:()=>h,frontMatter:()=>s,contentTitle:()=>o,toc:()=>d,assets:()=>c});var r=JSON.parse('{"id":"tracing/integrations/listing/vercelai","title":"Tracing Vercel AI SDK","description":"MLflow Tracing provides automatic tracing for applications built with the Vercel AI SDK (the ai package) via OpenTelemetry, unlocking powerful observability capabilities for TypeScript and Javascript application developers.","source":"@site/docs/genai/tracing/integrations/listing/vercelai.mdx","sourceDirName":"tracing/integrations/listing","slug":"/tracing/integrations/listing/vercelai","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/vercelai","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"sidebar_label":"Vercel AI SDK"},"sidebar":"genAISidebar","previous":{"title":"Txtai","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/txtai"},"next":{"title":"VoltAgent","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/voltagent"}}'),i=t(74848),a=t(28453),l=t(66497);let s={sidebar_position:3,sidebar_label:"Vercel AI SDK"},o="Tracing Vercel AI SDK",c={},d=[{value:"Quickstart (NextJS)",id:"quickstart-nextjs",level:2},{value:"1. Start MLflow Tracking Server",id:"1-start-mlflow-tracking-server",level:3},{value:"2. Configure Environment Variables",id:"2-configure-environment-variables",level:3},{value:"3. Enable OpenTelemetry",id:"3-enable-opentelemetry",level:3},{value:"5. Run the Application and View Traces",id:"5-run-the-application-and-view-traces",level:3},{value:"Other Node.js Applications",id:"other-nodejs-applications",level:2},{value:"Streaming",id:"streaming",level:2},{value:"Token usage",id:"token-usage",level:2},{value:"Disable auto-tracing",id:"disable-auto-tracing",level:2}];function p(e){let n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"tracing-vercel-ai-sdk",children:"Tracing Vercel AI SDK"})}),"\n",(0,i.jsx)("video",{src:(0,l.default)("/images/llms/tracing/vercel-ai-tracing.mp4"),controls:!0,loop:!0,autoPlay:!0,muted:!0,"aria-label":"Vercel AI SDK tracing via MLflow"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"/genai/tracing",children:"MLflow Tracing"})," provides automatic tracing for applications built with the ",(0,i.jsx)(n.a,{href:"https://ai-sdk.dev/",children:"Vercel AI SDK"})," (the ",(0,i.jsx)(n.code,{children:"ai"})," package) via OpenTelemetry, unlocking powerful observability capabilities for TypeScript and Javascript application developers."]}),"\n",(0,i.jsx)(n.p,{children:"When the integration is enabled, MLflow allows you to record the following information for Vercel AI SDK calls:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Prompts or messages and generated responses"}),"\n",(0,i.jsx)(n.li,{children:"Latencies"}),"\n",(0,i.jsx)(n.li,{children:"Call hierarchy"}),"\n",(0,i.jsx)(n.li,{children:"Token usage when the provider returns it"}),"\n",(0,i.jsx)(n.li,{children:"Any exception if raised"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"quickstart-nextjs",children:"Quickstart (NextJS)"}),"\n",(0,i.jsx)(n.p,{children:"It is fairy straightforward to enable MLflow tracing for Vercel AI SDK if you are using NextJS."}),"\n",(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsxs)(n.p,{children:["If you don't have a handy app to test, you can use the ",(0,i.jsx)("ins",{children:(0,i.jsx)(n.a,{href:"https://vercel.com/templates/next.js/ai-chatbot-telemetry",children:"demo chatbot app"})})," provided by Vercel."]})}),"\n",(0,i.jsx)(n.h3,{id:"1-start-mlflow-tracking-server",children:"1. Start MLflow Tracking Server"}),"\n",(0,i.jsx)(n.p,{children:"Start MLflow Tracking Server if you don't have one already:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"mlflow server --backend-store-uri sqlite:///mlruns.db --port 5000\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Alternatively, you can use ",(0,i.jsx)(n.a,{href:"/self-hosting/#docker-compose",children:"Docker Compose"})," to start the server without setting up Python environment. See ",(0,i.jsx)(n.a,{href:"/self-hosting/architecture/backend-store",children:"Self-Hosting Guide"})," for more details."]}),"\n",(0,i.jsx)(n.h3,{id:"2-configure-environment-variables",children:"2. Configure Environment Variables"}),"\n",(0,i.jsxs)(n.p,{children:["Set the following environment variable in your ",(0,i.jsx)(n.code,{children:".env.local"})," file:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",metastring:'title=".env.local"',children:"OTEL_EXPORTER_OTLP_ENDPOINT=<your-mlflow-tracking-server-endpoint>\nOTEL_EXPORTER_OTLP_TRACES_HEADERS=x-mlflow-experiment-id=<your-experiment-id>\nOTEL_EXPORTER_OTLP_TRACES_PROTOCOL=http/protobuf\n"})}),"\n",(0,i.jsxs)(n.p,{children:["For example, ",(0,i.jsx)(n.code,{children:"OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:5000"}),"."]}),"\n",(0,i.jsx)(n.h3,{id:"3-enable-opentelemetry",children:"3. Enable OpenTelemetry"}),"\n",(0,i.jsx)(n.p,{children:"Install the following packages to use Vercel OpenTelemetry integration."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pnpm i @opentelemetry/api @vercel/otel\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Create a ",(0,i.jsx)(n.code,{children:"instrumentation.ts"})," file in your NextJS project root and add the following code:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",metastring:'title="instrumentation.ts"',children:"import { registerOTel } from '@vercel/otel';\n\nexport async function register() {\n  registerOTel({ serviceName: 'next-app' })\n}\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Then specify ",(0,i.jsx)(n.code,{children:"experimental_telemetry: {isEnabled: true}"})," wherever you are using the Vercel AI SDK in the app."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",metastring:'title="route.ts"',children:"import { openai } from '@ai-sdk/openai';\nimport { generateText } from 'ai';\n\nexport async function POST(req: Request) {\n  const { prompt } = await req.json();\n\nconst { text } = await generateText({\n  model: openai('gpt-4o-mini'),\n  maxOutputTokens: 100,\n  prompt,\n  experimental_telemetry: {isEnabled: true},\n});\n\n  return new Response(JSON.stringify({ text }), {\n    headers: { 'Content-Type': 'application/json' },\n  });\n}\n"})}),"\n",(0,i.jsxs)(n.p,{children:["See ",(0,i.jsx)(n.a,{href:"https://vercel.com/docs/tracing/instrumentation",children:"Vercel OpenTelemetry documentation"})," for advanced usage such as context propagation."]}),"\n",(0,i.jsx)(n.h3,{id:"5-run-the-application-and-view-traces",children:"5. Run the Application and View Traces"}),"\n",(0,i.jsxs)(n.p,{children:["Run the application and view traces in MLflow UI. The UI is available at the tracking server endpoint you specified in the environment variables, e.g., ",(0,i.jsx)(n.code,{children:"http://localhost:5000"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"other-nodejs-applications",children:"Other Node.js Applications"}),"\n",(0,i.jsx)(n.p,{children:"If you are using other Node.js frameworks, set the OpenTelemetry Node SDK and OTLP exporter manually to export traces to MLflow."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",metastring:'title="main.ts"',children:"import { init } from \"mlflow-tracing\";\nimport { generateText } from \"ai\";\nimport { openai } from \"@ai-sdk/openai\";\nimport { NodeSDK } from '@opentelemetry/sdk-node';\nimport { SimpleSpanProcessor } from '@opentelemetry/sdk-trace-node';\nimport { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-proto';\n\n\nconst sdk = new NodeSDK({\n  spanProcessors: [\n    new SimpleSpanProcessor(\n      new OTLPTraceExporter({\n        url: '<your-mlflow-tracking-server-endpoint>/v1/traces',\n        headers: { 'x-mlflow-experiment-id': '<your-experiment-id>' },\n      }),\n    ),\n  ],\n});\n\nsdk.start();\n\n// Make an AI SDK call with telemetry enabled\nconst result = await generateText({\n  model: openai('gpt-4o-mini'),\n  prompt: 'What is MLflow?',\n  // IMPORTANT: enable telemetry is required for tracing\n  experimental_telemetry: { isEnabled: true }\n});\n\nconsole.log(result.text);\nsdk.shutdown();\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"npx tsx main.ts\n"})}),"\n",(0,i.jsx)(n.h2,{id:"streaming",children:"Streaming"}),"\n",(0,i.jsxs)(n.p,{children:["Streaming is supported as well. Similarly to the ",(0,i.jsx)(n.code,{children:"generateText"})," function, specify the ",(0,i.jsx)(n.code,{children:"experimental_telemetry.isEnabled"})," option to ",(0,i.jsx)(n.code,{children:"true"})," to enable tracing."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"import { streamText } from 'ai';\nimport { openai } from '@ai-sdk/openai';\n\nconst stream = await streamText({\n  model: openai('gpt-4o-mini'),\n  prompt: 'Explain vector databases in one paragraph.',\n  experimental_telemetry: { isEnabled: true }\n});\n\nfor await (const part of stream.textStream) {\n  process.stdout.write(part);\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"token-usage",children:"Token usage"}),"\n",(0,i.jsx)(n.p,{children:"When the underlying provider supplies token usage (e.g., input and output tokens), MLflow aggregates it on the trace.\nYou can retrieve it from the trace info using the TypeScript SDK:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"// Flush any pending spans then fetch the most recent trace\nawait mlflow.flushTraces();\nconst lastTraceId = mlflow.getLastActiveTraceId();\n\nif (lastTraceId) {\n  const client = new mlflow.MlflowClient({ trackingUri: 'http://localhost:5000' });\n  const trace = await client.getTrace(lastTraceId);\n  console.log('Token usage:', trace.info.tokenUsage);  // { input_tokens, output_tokens, total_tokens }\n}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"disable-auto-tracing",children:"Disable auto-tracing"}),"\n",(0,i.jsxs)(n.p,{children:["Disable tracing for Vercel AI SDK, set ",(0,i.jsx)(n.code,{children:"experimental_telemetry: { isEnabled: false }"})," on the AI SDK call"]})]})}function h(e={}){let{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(p,{...e})}):p(e)}},28453(e,n,t){t.d(n,{R:()=>l,x:()=>s});var r=t(96540);let i={},a=r.createContext(i);function l(e){let n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);