"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["9406"],{23756(e,n,t){t.r(n),t.d(n,{metadata:()=>a,default:()=>h,frontMatter:()=>s,contentTitle:()=>c,toc:()=>p,assets:()=>m});var a=JSON.parse('{"id":"tracing/integrations/listing/agno","title":"Tracing Agno","description":"Agno is a flexible agent framework for orchestrating LLMs, reasoning steps, tools, and memory into a unified pipeline.","source":"@site/docs/genai/tracing/integrations/listing/agno.mdx","sourceDirName":"tracing/integrations/listing","slug":"/tracing/integrations/listing/agno","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/agno","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"sidebar_position":8,"sidebar_label":"Agno"},"sidebar":"genAISidebar","previous":{"title":"AG2","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/ag2"},"next":{"title":"Amazon Bedrock AgentCore","permalink":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/bedrock-agentcore"}}'),l=t(74848),o=t(28453),i=t(54725),r=t(46077);let s={sidebar_position:8,sidebar_label:"Agno"},c="Tracing Agno",m={},p=[{value:"Basic Example",id:"basic-example",level:3},{value:"Multi Agentic(Agents to Agents) Interaction",id:"multi-agenticagents-to-agents-interaction",level:2},{value:"Multi-agent Example",id:"multi-agent-example",level:3},{value:"Token usage",id:"token-usage",level:2},{value:"Disable auto-tracing",id:"disable-auto-tracing",level:3}];function f(e){let n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,o.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.header,{children:(0,l.jsx)(n.h1,{id:"tracing-agno",children:"Tracing Agno"})}),"\n",(0,l.jsx)(r.A,{src:"/images/llms/agno/agno-tracing-basic.png",alt:"Agno Tracing via autolog"}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.a,{href:"https://github.com/agno-agi/agno",children:"Agno"})," is a flexible agent framework for orchestrating LLMs, reasoning steps, tools, and memory into a unified pipeline."]}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.a,{href:"../../",children:"MLflow Tracing"})," provides automatic tracing capability for Agno. By enabling auto tracing\nfor Agno by calling the ",(0,l.jsx)(i.B,{fn:"mlflow.agno.autolog"})," function, MLflow will capture traces for Agent invocation and log them to the active MLflow Experiment."]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:"import mlflow\n\nmlflow.agno.autolog()\n"})}),"\n",(0,l.jsx)(n.p,{children:"MLflow trace automatically captures the following information about Agentic calls:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Prompts and completion responses"}),"\n",(0,l.jsx)(n.li,{children:"Latencies"}),"\n",(0,l.jsx)(n.li,{children:"Metadata about the different Agents, such as function names"}),"\n",(0,l.jsx)(n.li,{children:"Token usages and cost"}),"\n",(0,l.jsx)(n.li,{children:"Cache hit"}),"\n",(0,l.jsx)(n.li,{children:"Any exception if raised"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"basic-example",children:"Basic Example"}),"\n",(0,l.jsx)(n.p,{children:"Install the dependencies for the example:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"pip install 'mlflow[genai]>=3.3' agno anthropic yfinance\n"})}),"\n",(0,l.jsxs)(n.p,{children:["Run a simple agent with ",(0,l.jsx)(n.code,{children:"mlflow.agno.autolog()"})," enabled:"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'from agno.agent import Agent\nfrom agno.models.anthropic import Claude\nfrom agno.tools.yfinance import YFinanceTools\n\nagent = Agent(\n    model=Claude(id="claude-sonnet-4-20250514"),\n    tools=[YFinanceTools(stock_price=True)],\n    instructions="Use tables to display data. Don\'t include any other text.",\n    markdown=True,\n)\nagent.print_response("What is the stock price of Apple?", stream=False)\n'})}),"\n",(0,l.jsx)(n.h2,{id:"multi-agenticagents-to-agents-interaction",children:"Multi Agentic(Agents to Agents) Interaction"}),"\n",(0,l.jsx)(n.p,{children:"MLflow now makes it easier to track how multiple AI agents work together when using Agno API's non-streaming endpoints. It automatically\nrecords every handoff between agents, the messages they exchange, and details about any functions or tools they use\u2014like what went in, what\ncame out, and how long it took. This gives you a complete picture of the process, making it simpler to troubleshoot issues, measure performance,\nand repeat results."}),"\n",(0,l.jsx)(n.h3,{id:"multi-agent-example",children:"Multi-agent Example"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'import mlflow\n\nfrom agno.agent import Agent\nfrom agno.models.anthropic import Claude\nfrom agno.models.openai import OpenAIChat\nfrom agno.team.team import Team\nfrom agno.tools.duckduckgo import DuckDuckGoTools\nfrom agno.tools.reasoning import ReasoningTools\nfrom agno.tools.yfinance import YFinanceTools\n\n# Enable auto tracing for Agno\nmlflow.agno.autolog()\n\n\nweb_agent = Agent(\n    name="Web Search Agent",\n    role="Handle web search requests and general research",\n    model=OpenAIChat(id="gpt-4.1"),\n    tools=[DuckDuckGoTools()],\n    instructions="Always include sources",\n    add_datetime_to_instructions=True,\n)\n\nfinance_agent = Agent(\n    name="Finance Agent",\n    role="Handle financial data requests and market analysis",\n    model=OpenAIChat(id="gpt-4.1"),\n    tools=[\n        YFinanceTools(\n            stock_price=True,\n            stock_fundamentals=True,\n            analyst_recommendations=True,\n            company_info=True,\n        )\n    ],\n    instructions=[\n        "Use tables to display stock prices, fundamentals (P/E, Market Cap), and recommendations.",\n        "Clearly state the company name and ticker symbol.",\n        "Focus on delivering actionable financial insights.",\n    ],\n    add_datetime_to_instructions=True,\n)\n\nreasoning_finance_team = Team(\n    name="Reasoning Finance Team",\n    mode="coordinate",\n    model=Claude(id="claude-sonnet-4-20250514"),\n    members=[web_agent, finance_agent],\n    tools=[ReasoningTools(add_instructions=True)],\n    instructions=[\n        "Collaborate to provide comprehensive financial and investment insights",\n        "Consider both fundamental analysis and market sentiment",\n        "Use tables and charts to display data clearly and professionally",\n        "Present findings in a structured, easy-to-follow format",\n        "Only output the final consolidated analysis, not individual agent responses",\n    ],\n    markdown=True,\n    show_members_responses=True,\n    enable_agentic_context=True,\n    add_datetime_to_instructions=True,\n    success_criteria="The team has provided a complete financial analysis with data, visualizations, risk assessment, and actionable investment recommendations supported by quantitative analysis and market research.",\n)\n\nreasoning_finance_team.print_response(\n    """Compare the tech sector giants (AAPL, GOOGL, MSFT) performance:\n    1. Get financial data for all three companies\n    2. Analyze recent news affecting the tech sector\n    3. Calculate comparative metrics and correlations\n    4. Recommend portfolio allocation weights""",\n    show_full_reasoning=True,\n)\n'})}),"\n",(0,l.jsx)(r.A,{src:"/images/llms/agno/agno-tracing.png",alt:"Agno Tracing via autolog"}),"\n",(0,l.jsx)(n.h2,{id:"token-usage",children:"Token usage"}),"\n",(0,l.jsxs)(n.p,{children:["MLflow >= 3.3.0 supports token usage tracking for Agno. The token usage for each Agent call will be logged in the ",(0,l.jsx)(n.code,{children:"mlflow.chat.tokenUsage"})," attribute. The total token usage throughout the trace will be\navailable in the ",(0,l.jsx)(n.code,{children:"token_usage"})," field of the trace info object."]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'# Get the trace object just created\nlast_trace_id = mlflow.get_last_active_trace_id()\ntrace = mlflow.get_trace(trace_id=last_trace_id)\n\n# Print the token usage\ntotal_usage = trace.info.token_usage\nprint("== Total token usage: ==")\nprint(f"  Input tokens: {total_usage[\'input_tokens\']}")\nprint(f"  Output tokens: {total_usage[\'output_tokens\']}")\nprint(f"  Total tokens: {total_usage[\'total_tokens\']}")\n\n# Print the token usage for each LLM call\nprint("\\n== Detailed usage for each LLM call: ==")\nfor span in trace.data.spans:\n    if usage := span.get_attribute("mlflow.chat.tokenUsage"):\n        print(f"{span.name}:")\n        print(f"  Input tokens: {usage[\'input_tokens\']}")\n        print(f"  Output tokens: {usage[\'output_tokens\']}")\n        print(f"  Total tokens: {usage[\'total_tokens\']}")\n'})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"== Total token usage: ==\n  Input tokens: 45710\n  Output tokens: 3844\n  Total tokens: 49554\n\n== Detailed usage for each LLM call: ==\nTeam.run:\n  Input tokens: 45710\n  Output tokens: 3844\n  Total tokens: 49554\n\n... (other modules)\n"})}),"\n",(0,l.jsx)(n.h3,{id:"disable-auto-tracing",children:"Disable auto-tracing"}),"\n",(0,l.jsxs)(n.p,{children:["Auto tracing for LiteLLM can be disabled globally by calling ",(0,l.jsx)(n.code,{children:"mlflow.agno.autolog(disable=True)"})," or ",(0,l.jsx)(n.code,{children:"mlflow.autolog(disable=True)"}),"."]})]})}function h(e={}){let{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(f,{...e})}):f(e)}},54725(e,n,t){t.d(n,{B:()=>i});var a=t(74848);t(96540);var l=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}'),o=t(66497);function i({fn:e,children:n,hash:t}){let i=(e=>{let n=e.split(".");for(let e=n.length;e>0;e--){let t=n.slice(0,e).join(".");if(l[t])return t}return null})(e);if(!i)return(0,a.jsx)(a.Fragment,{children:n});let r=(0,o.default)(`/${l[i]}#${t??e}`);return(0,a.jsx)("a",{href:r,target:"_blank",children:n??(0,a.jsxs)("code",{children:[e,"()"]})})}},46077(e,n,t){t.d(n,{A:()=>o});var a=t(74848);t(96540);var l=t(66497);function o({src:e,alt:n,width:t,caption:o,className:i}){return(0,a.jsxs)("div",{className:`container_JwLF ${i||""}`,children:[(0,a.jsx)("div",{className:"imageWrapper_RfGN",style:t?{width:t}:{},children:(0,a.jsx)("img",{src:(0,l.default)(e),alt:n,className:"image_bwOA"})}),o&&(0,a.jsx)("p",{className:"caption_jo2G",children:o})]})}},28453(e,n,t){t.d(n,{R:()=>i,x:()=>r});var a=t(96540);let l={},o=a.createContext(l);function i(e){let n=a.useContext(o);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:i(e.components),a.createElement(o.Provider,{value:n},e.children)}}}]);