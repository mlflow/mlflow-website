"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[1201],{18700:(e,o,l)=>{l.d(o,{A:()=>n});const n=l.p+"assets/images/tensorflow-model-signature-b99a17dca0d6d45fc0e0663f41824bf1.png"},28453:(e,o,l)=>{l.d(o,{R:()=>r,x:()=>i});var n=l(96540);const a={},t=n.createContext(a);function r(e){const o=n.useContext(t);return n.useMemo((function(){return"function"==typeof e?e(o):{...o,...e}}),[o,e])}function i(e){let o;return o=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),n.createElement(t.Provider,{value:o},e.children)}},67756:(e,o,l)=>{l.d(o,{B:()=>s});l(96540);const n=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var a=l(29030),t=l(56289),r=l(74848);const i=e=>{const o=e.split(".");for(let l=o.length;l>0;l--){const e=o.slice(0,l).join(".");if(n[e])return e}return null};function s(e){let{fn:o,children:l}=e;const s=i(o);if(!s)return(0,r.jsx)(r.Fragment,{children:l});const m=(0,a.Ay)(`/${n[s]}#${o}`);return(0,r.jsx)(t.A,{to:m,target:"_blank",children:l??(0,r.jsxs)("code",{children:[o,"()"]})})}},91316:(e,o,l)=>{l.r(o),l.d(o,{assets:()=>m,contentTitle:()=>s,default:()=>c,frontMatter:()=>i,metadata:()=>n,toc:()=>f});const n=JSON.parse('{"id":"deep-learning/tensorflow/guide/index","title":"Tensorflow within MLflow","description":"In this guide we will walk you through how to use Tensorflow within MLflow. We will demonstrate","source":"@site/docs/deep-learning/tensorflow/guide/index.mdx","sourceDirName":"deep-learning/tensorflow/guide","slug":"/deep-learning/tensorflow/guide/","permalink":"/docs/latest/deep-learning/tensorflow/guide/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Tensorflow","permalink":"/docs/latest/deep-learning/tensorflow/"},"next":{"title":"Get Started with MLflow + Tensorflow","permalink":"/docs/latest/deep-learning/tensorflow/quickstart/quickstart_tensorflow"}}');var a=l(74848),t=l(28453),r=l(67756);const i={},s="Tensorflow within MLflow",m={},f=[{value:"Autologging Tensorflow Experiments",id:"autologging-tensorflow-experiments",level:2},{value:"What is Logged by Autologging?",id:"what-is-logged-by-autologging",level:3},{value:"Understanding Autologging",id:"understanding-autologging",level:3},{value:"Logging to MLflow with Keras Callback",id:"logging-to-mlflow-with-keras-callback",level:2},{value:"Using the Predefined Callback",id:"using-the-predefined-callback",level:3},{value:"Customizing MLflow Logging",id:"customizing-mlflow-logging",level:3},{value:"Saving Your Tensorflow Model to MLflow",id:"saving-your-tensorflow-model-to-mlflow",level:2},{value:"Diving into Saving",id:"diving-into-saving",level:3},{value:"Saving Format",id:"saving-format",level:4},{value:"Model Signature",id:"model-signature",level:4}];function d(e){const o={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,t.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(o.header,{children:(0,a.jsx)(o.h1,{id:"tensorflow-within-mlflow",children:"Tensorflow within MLflow"})}),"\n",(0,a.jsx)(o.p,{children:"In this guide we will walk you through how to use Tensorflow within MLflow. We will demonstrate\nhow to track your Tensorflow experiments and log your Tensorflow models to MLflow."}),"\n",(0,a.jsx)(o.h2,{id:"autologging-tensorflow-experiments",children:"Autologging Tensorflow Experiments"}),"\n",(0,a.jsx)(o.admonition,{title:"attention",type:"warning",children:(0,a.jsxs)(o.p,{children:["Autologging is only supported when you are using the ",(0,a.jsx)(o.code,{children:"model.fit()"})," Keras API to train\nthe model. Additionally only Tensorflow >= 2.3.0 is supported. If you are using an older version\nof Tensorflow or Tensorflow without Keras, please use manual logging."]})}),"\n",(0,a.jsxs)(o.p,{children:["MLflow can automatically log metrics and parameters from your Tensorflow training. To enable\nautologging, simply run ",(0,a.jsx)(r.B,{fn:"mlflow.tensorflow.autolog"})," or ",(0,a.jsx)(r.B,{fn:"mlflow.autolog"}),"."]}),"\n",(0,a.jsx)(o.pre,{children:(0,a.jsx)(o.code,{className:"language-python",children:"import mlflow\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\n\nmlflow.tensorflow.autolog()\n\n# Prepare data for a 2-class classification.\ndata = np.random.uniform(size=[20, 28, 28, 3])\nlabel = np.random.randint(2, size=20)\n\nmodel = keras.Sequential(\n    [\n        keras.Input([28, 28, 3]),\n        keras.layers.Conv2D(8, 2),\n        keras.layers.MaxPool2D(2),\n        keras.layers.Flatten(),\n        keras.layers.Dense(2),\n        keras.layers.Softmax(),\n    ]\n)\n\nmodel.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(),\n    optimizer=keras.optimizers.Adam(0.001),\n    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)\n\nwith mlflow.start_run():\n    model.fit(data, label, batch_size=5, epochs=2)\n"})}),"\n",(0,a.jsx)(o.h3,{id:"what-is-logged-by-autologging",children:"What is Logged by Autologging?"}),"\n",(0,a.jsx)(o.p,{children:"By default, autologging logs the following to MLflow:"}),"\n",(0,a.jsxs)(o.ul,{children:["\n",(0,a.jsxs)(o.li,{children:["The model summary as returned by ",(0,a.jsx)(o.code,{children:"model.summary()"}),"."]}),"\n",(0,a.jsx)(o.li,{children:"Training hyperparamers, e.g., batch size and epochs."}),"\n",(0,a.jsx)(o.li,{children:"Optimizer configs, e.g., optimizer name and learning rate."}),"\n",(0,a.jsx)(o.li,{children:"Dataset information."}),"\n",(0,a.jsxs)(o.li,{children:["Training and validation metrics, including loss and any metrics specified in ",(0,a.jsx)(o.code,{children:"model.compile()"}),"."]}),"\n",(0,a.jsx)(o.li,{children:"Saved model after training completes in the format of TF saved model (compiled graph)."}),"\n"]}),"\n",(0,a.jsxs)(o.p,{children:["You can customize autologging behavior by passing arguments to ",(0,a.jsx)(r.B,{fn:"mlflow.tensorflow.autolog"}),",\nfor example if you don't want to log the dataset information, then you can run\n",(0,a.jsx)(o.code,{children:"mlflow.tensorflow.autolog(log_dataset_info=False)"}),". Please refer to the API\ndocumentation ",(0,a.jsx)(r.B,{fn:"mlflow.tensorflow.autolog"})," for full customization options."]}),"\n",(0,a.jsx)(o.h3,{id:"understanding-autologging",children:"Understanding Autologging"}),"\n",(0,a.jsxs)(o.p,{children:["The way we autolog Tensorflow is by registering a custom callback to the Keras model via monkey patch.\nBriefly we attach a MLflow callback to the Keras model that works similarly to normal Keras callbacks.\nAt training start, training parameters including epochs, batch_size, learning_rate and model information\nsuch as model summary will be logged. In addition, the callback will be triggered per epoch or per\n",(0,a.jsx)(o.code,{children:"log_every_n_steps"})," steps to log the training metrics, and after the training finishes,\nthe trained model will be saved to MLflow."]}),"\n",(0,a.jsx)(o.h2,{id:"logging-to-mlflow-with-keras-callback",children:"Logging to MLflow with Keras Callback"}),"\n",(0,a.jsx)(o.p,{children:"As discussed in the previous section, MLflow autologging for Tensorflow is simply using a Keras\ncallback. If you wish to log additional information that isn't provided by the base autologging\nimplementation via this default callback, you can write your own callback to log custom information."}),"\n",(0,a.jsx)(o.h3,{id:"using-the-predefined-callback",children:"Using the Predefined Callback"}),"\n",(0,a.jsxs)(o.p,{children:["MLflow offers a predefined callback ",(0,a.jsx)(r.B,{fn:"mlflow.tensorflow.MlflowCallback",children:(0,a.jsx)(o.code,{children:"mlflow.tensorflow.MlflowCallback"})})," that you can use or\nextend to log information to MLflow. The callback function provides the same functionality as autologging\nand is suitable for users willing to have a better control of the experiment. Using ",(0,a.jsx)(o.code,{children:"mlflow.tensorflow.MlflowCallback"}),"\nis the same as other Keras callbacks:"]}),"\n",(0,a.jsx)(o.pre,{children:(0,a.jsx)(o.code,{className:"language-python",children:"with mlflow.start_run():\n    model.fit(\n        data,\n        label,\n        batch_size=5,\n        epochs=2,\n        callbacks=[mlflow.tensorflow.MlflowCallback()],\n    )\n"})}),"\n",(0,a.jsxs)(o.p,{children:["You can change the logging frequency in ",(0,a.jsx)(r.B,{fn:"mlflow.tensorflow.MlflowCallback",children:(0,a.jsx)(o.code,{children:"mlflow.tensorflow.MlflowCallback"})}),"\nby setting ",(0,a.jsx)(o.code,{children:"log_every_epoch"})," and ",(0,a.jsx)(o.code,{children:"log_every_n_steps"}),", by default metrics are logged per epoch. Please refer to\nthe API documentation for more details."]}),"\n",(0,a.jsx)(o.h3,{id:"customizing-mlflow-logging",children:"Customizing MLflow Logging"}),"\n",(0,a.jsxs)(o.p,{children:["You can also write your own callback to log information to MLflow. To do that, you need to define\na class subclassing from ",(0,a.jsx)(o.a,{href:"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback",children:"keras.callbacks.Callback"}),",\nwhich provides hooks at various stages of training and validation, e.g., ",(0,a.jsx)(o.code,{children:"on_epoch_end"})," and\n",(0,a.jsx)(o.code,{children:"on_train_end"})," are called separately at the end of each epoch and when the training is finished.\nYou can then use the callback in ",(0,a.jsx)(o.code,{children:"model.fit()"}),". Here is a simple example for logging the training metrics\nin log scale:"]}),"\n",(0,a.jsx)(o.pre,{children:(0,a.jsx)(o.code,{className:"language-python",children:'from tensorflow import keras\nimport math\nimport mlflow\n\n\nclass MlflowCallback(keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        logs = logs or {}\n        for k, v in logs.items():\n            mlflow.log_metric(f"log_{k}", math.log(v), step=epoch)\n'})}),"\n",(0,a.jsxs)(o.p,{children:["At the conclusion of each epoch, the ",(0,a.jsx)(o.code,{children:"logs"})," object will contain ",(0,a.jsx)(o.code,{children:"loss"})," and ",(0,a.jsx)(o.code,{children:"metrics"})," as defined\nin ",(0,a.jsx)(o.code,{children:"model.compile()"}),". For full documentation of the Keras callback API, please\nread ",(0,a.jsx)(o.a,{href:"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback",children:"keras.callbacks.Callback"}),"."]}),"\n",(0,a.jsx)(o.h2,{id:"saving-your-tensorflow-model-to-mlflow",children:"Saving Your Tensorflow Model to MLflow"}),"\n",(0,a.jsxs)(o.p,{children:["If you have turned on the autologging, your Tensorflow model will be automatically saved after the training\nis done. If you prefer to explicitly save your model, you can instead manually\ncall ",(0,a.jsx)(r.B,{fn:"mlflow.tensorflow.log_model"}),". After saving, you can load back the model\nusing ",(0,a.jsx)(r.B,{fn:"mlflow.tensorflow.load_model"}),". The loaded model can be used for inference by calling\nthe ",(0,a.jsx)(o.code,{children:"predict()"})," method."]}),"\n",(0,a.jsx)(o.pre,{children:(0,a.jsx)(o.code,{className:"language-python",children:'import mlflow\nimport tensorflow as tf\nfrom tensorflow import keras\n\nmodel = keras.Sequential(\n    [\n        keras.Input([28, 28, 3]),\n        keras.layers.Conv2D(8, 2),\n        keras.layers.MaxPool2D(2),\n        keras.layers.Flatten(),\n        keras.layers.Dense(2),\n        keras.layers.Softmax(),\n    ]\n)\n\nsave_path = "model"\nwith mlflow.start_run() as run:\n    mlflow.tensorflow.log_model(model, name="model")\n\n# Load back the model.\nloaded_model = mlflow.tensorflow.load_model(f"runs:/{run.info.run_id}/{save_path}")\n\nprint(loaded_model.predict(tf.random.uniform([1, 28, 28, 3])))\n'})}),"\n",(0,a.jsx)(o.h3,{id:"diving-into-saving",children:"Diving into Saving"}),"\n",(0,a.jsxs)(o.p,{children:["Under the hood of saving, we are converting the Tensorflow model into a pyfunc model, which is a generic\ntype of model in MLflow. The pyfunc model is saved to MLflow. You don't need to learn the basics of pyfunc\nmodel to use Tensorflow flavor, but if you are interested, please refer to ",(0,a.jsx)(o.a,{href:"/model#how-to-load-and-score-python-function-models",children:"MLflow pyfunc model"}),"."]}),"\n",(0,a.jsx)(o.h4,{id:"saving-format",children:"Saving Format"}),"\n",(0,a.jsxs)(o.p,{children:["By default, MLflow saves your Tensorflow model in the format of a TF saved model (compiled graph), which is\nsuitable for deployment across platforms. You can also save your model in other formats, i.e., ",(0,a.jsx)(o.code,{children:"h5"})," and\n",(0,a.jsx)(o.code,{children:"keras"})," by setting the ",(0,a.jsx)(o.code,{children:"keras_model_kwargs"})," parameter in ",(0,a.jsx)(r.B,{fn:"mlflow.tensorflow.log_model"}),". For\nexample, if you want to save your model in ",(0,a.jsx)(o.code,{children:"h5"})," format (which only saves model weights instead of the\ncompiled graph) you can run:"]}),"\n",(0,a.jsx)(o.pre,{children:(0,a.jsx)(o.code,{className:"language-python",children:'import mlflow\nimport tensorflow as tf\nfrom tensorflow import keras\n\nmodel = keras.Sequential(\n    [\n        keras.Input([28, 28, 3]),\n        keras.layers.Conv2D(8, 2),\n        keras.layers.MaxPool2D(2),\n        keras.layers.Flatten(),\n        keras.layers.Dense(2),\n        keras.layers.Softmax(),\n    ]\n)\n\nsave_path = "model"\nwith mlflow.start_run() as run:\n    mlflow.tensorflow.log_model(\n        model, name="model", keras_model_kwargs={"save_format": "h5"}\n    )\n\n# Load back the model.\nloaded_model = mlflow.tensorflow.load_model(f"runs:/{run.info.run_id}/{save_path}")\n\nprint(loaded_model.predict(tf.random.uniform([1, 28, 28, 3])))\n'})}),"\n",(0,a.jsxs)(o.p,{children:["For difference between the formats, please refer to ",(0,a.jsx)(o.a,{href:"https://www.tensorflow.org/guide/keras/save_and_serialize",children:"Tensorflow Save and Load Guide"}),".\nPlease note that if you want to deploy your model, you will need to save your model in the TF saved model format."]}),"\n",(0,a.jsx)(o.h4,{id:"model-signature",children:"Model Signature"}),"\n",(0,a.jsx)(o.p,{children:"A model signature is a description of a model's input and output. If you have enabled autologging and provided\na dataset, then the signature will be automatically inferred from the dataset. Otherwise, you need to provide\na signature in order to have the signature information viewable within the MLflow UI. A model signature will be\nshown in the MLflow UI as follows:"}),"\n",(0,a.jsx)("div",{className:"center-div",style:{width:"90%"},children:(0,a.jsx)(o.p,{children:(0,a.jsx)(o.img,{alt:"Tensorflow Model Signature",src:l(18700).A+"",width:"3410",height:"1604"})})}),"\n",(0,a.jsxs)(o.p,{children:["To manually set the signature for your model, you can pass a ",(0,a.jsx)(o.code,{children:"signature"})," parameter to ",(0,a.jsx)(r.B,{fn:"mlflow.tensorflow.log_model"}),".\nYou will need to set the input schema by specifying the ",(0,a.jsx)(o.code,{children:"dtype"})," and ",(0,a.jsx)(o.code,{children:"shape"})," of the input tensors,\nand wrap it with ",(0,a.jsx)(r.B,{fn:"mlflow.types.TensorSpec"}),". For example,"]}),"\n",(0,a.jsx)(o.pre,{children:(0,a.jsx)(o.code,{className:"language-python",children:'import mlflow\nimport tensorflow as tf\nimport numpy as np\n\nfrom tensorflow import keras\nfrom mlflow.types import Schema, TensorSpec\nfrom mlflow.models import ModelSignature\n\nmodel = keras.Sequential(\n    [\n        keras.Input([28, 28, 3]),\n        keras.layers.Conv2D(8, 2),\n        keras.layers.MaxPool2D(2),\n        keras.layers.Flatten(),\n        keras.layers.Dense(2),\n        keras.layers.Softmax(),\n    ]\n)\n\ninput_schema = Schema(\n    [\n        TensorSpec(np.dtype(np.float32), (-1, 28, 28, 3), "input"),\n    ]\n)\nsignature = ModelSignature(inputs=input_schema)\n\nwith mlflow.start_run() as run:\n    mlflow.tensorflow.log_model(model, name="model", signature=signature)\n\n# Load back the model.\nloaded_model = mlflow.tensorflow.load_model(f"runs:/{run.info.run_id}/{save_path}")\n\nprint(loaded_model.predict(tf.random.uniform([1, 28, 28, 3])))\n'})}),"\n",(0,a.jsx)(o.p,{children:"Please note that a model signature is not necessary for loading a model. You can still load the model\nand perform inferenece if you know the input format. However, it's a good practice to include the signature\nfor better model understanding."})]})}function c(e={}){const{wrapper:o}={...(0,t.R)(),...e.components};return o?(0,a.jsx)(o,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}}}]);