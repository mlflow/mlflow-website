"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[2811],{8493:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>d,contentTitle:()=>i,default:()=>x,frontMatter:()=>s,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"eval-monitor/notebooks/index","title":"LLM Evaluation Examples","description":"The notebooks listed below contain step-by-step tutorials on how to use MLflow to evaluate LLMs.","source":"@site/docs/genai/eval-monitor/notebooks/index.mdx","sourceDirName":"eval-monitor/notebooks","slug":"/eval-monitor/notebooks/","permalink":"/docs/latest/genai/eval-monitor/notebooks/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{}}');var n=t(74848),l=t(28453),r=t(10493);const s={},i="LLM Evaluation Examples",d={},c=[{value:"QA Evaluation Tutorial",id:"qa-evaluation-tutorial",level:2},{value:"RAG Evaluation Tutorials",id:"rag-evaluation-tutorials",level:2}];function u(e){const a={b:"b",h1:"h1",h2:"h2",header:"header",p:"p",...(0,l.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(a.header,{children:(0,n.jsx)(a.h1,{id:"llm-evaluation-examples",children:"LLM Evaluation Examples"})}),"\n",(0,n.jsx)(a.p,{children:"The notebooks listed below contain step-by-step tutorials on how to use MLflow to evaluate LLMs."}),"\n",(0,n.jsx)(a.p,{children:"The first set of notebooks is centered around evaluating an LLM for question-answering with a\nprompt engineering approach. The second set is centered around evaluating a RAG system."}),"\n",(0,n.jsx)(a.p,{children:"All the notebooks will demonstrate how to use MLflow's builtin metrics such as token_count and\ntoxicity as well as LLM-judged intelligent metrics such as answer_relevance."}),"\n",(0,n.jsx)(a.h2,{id:"qa-evaluation-tutorial",children:"QA Evaluation Tutorial"}),"\n",(0,n.jsxs)(r.AC,{children:[(0,n.jsx)(r._C,{link:"/genai/eval-monitor/notebooks/question-answering-evaluation",headerText:"LLM Question Answering Evaluation with MLflow",text:"Learn how to evaluate various LLMs and RAG systems with MLflow, leveraging simple metrics such as toxicity, as well as LLM-judged metrics as relevance, and even custom LLM-judged metrics such as professionalism."}),(0,n.jsx)(r._C,{link:"/genai/eval-monitor/notebooks/huggingface-evaluation",headerText:"Evaluating a \ud83e\udd17 Hugging Face LLMs with MLflow",text:"Learn how to evaluate various Open-Source LLMs available in Hugging Face, leveraging MLflow's built-in LLM metrics and experiment tracking to manage models and evaluation results."})]}),"\n",(0,n.jsx)(a.h2,{id:"rag-evaluation-tutorials",children:"RAG Evaluation Tutorials"}),"\n",(0,n.jsxs)(r.AC,{children:[(0,n.jsx)(r._C,{link:"/genai/eval-monitor/notebooks/rag-evaluation",headerText:"RAG Evaluation with MLflow and GPT-4 as Judge",text:["Learn how to evaluate RAG systems with MLflow, leveraging ",(0,n.jsx)(a.b,{children:"OpenAI GPT-4"})," model as a judge."]}),(0,n.jsx)(r._C,{link:"/genai/eval-monitor/notebooks/rag-evaluation-llama2",headerText:"RAG Evaluation with MLflow and Llama-2-70B as Judge",text:["Learn how to evaluate RAG systems with MLflow, leveraging ",(0,n.jsx)(a.b,{children:"Llama 2 70B model"})," hosted on Databricks serving endpoint."]})]})]})}function x(e={}){const{wrapper:a}={...(0,l.R)(),...e.components};return a?(0,n.jsx)(a,{...e,children:(0,n.jsx)(u,{...e})}):u(e)}},10493:(e,a,t)=>{t.d(a,{Zp:()=>i,AC:()=>s,WO:()=>c,_C:()=>d,$3:()=>u,jK:()=>x});var o=t(34164);const n={CardGroup:"CardGroup_P84T",MaxThreeColumns:"MaxThreeColumns_FO1r",AutofillColumns:"AutofillColumns_fKhQ",Card:"Card_aSCR",CardBordered:"CardBordered_glGF",CardBody:"CardBody_BhRs",TextColor:"TextColor_a8Tp",BoxRoot:"BoxRoot_Etgr",FlexWrapNowrap:"FlexWrapNowrap_f60k",FlexJustifyContentFlexStart:"FlexJustifyContentFlexStart_ZYv5",FlexDirectionRow:"FlexDirectionRow_T2qL",FlexAlignItemsCenter:"FlexAlignItemsCenter_EHVM",FlexFlex:"FlexFlex__JTE",Link:"Link_fVkl",MarginLeft4:"MarginLeft4_YQSJ",MarginTop4:"MarginTop4_jXKN",PaddingBottom4:"PaddingBottom4_O9gt",LogoCardContent:"LogoCardContent_kCQm",LogoCardImage:"LogoCardImage_JdcX",SmallLogoCardContent:"SmallLogoCardContent_LxhV",SmallLogoCardImage:"SmallLogoCardImage_tPZl",NewFeatureCardContent:"NewFeatureCardContent_Rq3d",NewFeatureCardHeading:"NewFeatureCardHeading_f6q3",NewFeatureCardHeadingSeparator:"NewFeatureCardHeadingSeparator_pSx8",NewFeatureCardTags:"NewFeatureCardTags_IFHO",NewFeatureCardWrapper:"NewFeatureCardWrapper_NQ0k",TitleCardContent:"TitleCardContent_l9MQ",TitleCardTitle:"TitleCardTitle__K8J",TitleCardSeparator:"TitleCardSeparator_IN2E",Cols1:"Cols1_Gr2U",Cols2:"Cols2_sRvc",Cols3:"Cols3_KjUS",Cols4:"Cols4_dKOj",Cols5:"Cols5_jDmj",Cols6:"Cols6_Q0OR"};var l=t(28774),r=t(74848);const s=({children:e,isSmall:a,cols:t})=>(0,r.jsx)("div",{className:(0,o.A)(n.CardGroup,a?n.AutofillColumns:t?n[`Cols${t}`]:n.MaxThreeColumns),children:e}),i=({children:e,link:a=""})=>a?(0,r.jsx)(l.A,{className:(0,o.A)(n.Link,n.Card,n.CardBordered),to:a,children:e}):(0,r.jsx)("div",{className:(0,o.A)(n.Card,n.CardBordered),children:e}),d=({headerText:e,link:a,text:t})=>(0,r.jsx)(i,{link:a,children:(0,r.jsxs)("span",{children:[(0,r.jsx)("div",{className:(0,o.A)(n.CardTitle,n.BoxRoot,n.PaddingBottom4),style:{pointerEvents:"none"},children:(0,r.jsx)("div",{className:(0,o.A)(n.BoxRoot,n.FlexFlex,n.FlexAlignItemsCenter,n.FlexDirectionRow,n.FlexJustifyContentFlexStart,n.FlexWrapNowrap),style:{marginLeft:"-4px",marginTop:"-4px"},children:(0,r.jsx)("div",{className:(0,o.A)(n.BoxRoot,n.BoxHideIfEmpty,n.MarginTop4,n.MarginLeft4),style:{pointerEvents:"auto"},children:(0,r.jsx)("span",{className:"",children:e})})})}),(0,r.jsx)("span",{className:(0,o.A)(n.TextColor,n.CardBody),children:(0,r.jsx)("p",{children:t})})]})}),c=({description:e,children:a,link:t})=>(0,r.jsx)(i,{link:t,children:(0,r.jsxs)("div",{className:n.LogoCardContent,children:[(0,r.jsx)("div",{className:n.LogoCardImage,children:a}),(0,r.jsx)("p",{className:n.TextColor,children:e})]})}),u=({children:e,link:a})=>(0,r.jsx)(i,{link:a,children:(0,r.jsx)("div",{className:n.SmallLogoCardContent,children:(0,r.jsx)("div",{className:(0,o.A)("max-height-img-container",n.SmallLogoCardImage),children:e})})}),x=({title:e,description:a,link:t=""})=>(0,r.jsx)(i,{link:t,children:(0,r.jsxs)("div",{className:n.TitleCardContent,children:[(0,r.jsx)("div",{className:(0,o.A)(n.TitleCardTitle),style:{textAlign:"left",fontWeight:"bold"},children:e}),(0,r.jsx)("hr",{className:(0,o.A)(n.TitleCardSeparator),style:{margin:"12px 0"}}),(0,r.jsx)("p",{className:(0,o.A)(n.TextColor),children:a})]})})},28453:(e,a,t)=>{t.d(a,{R:()=>r,x:()=>s});var o=t(96540);const n={},l=o.createContext(n);function r(e){const a=o.useContext(l);return o.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function s(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:r(e.components),o.createElement(l.Provider,{value:a},e.children)}}}]);