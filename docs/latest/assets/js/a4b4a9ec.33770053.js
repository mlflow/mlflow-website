"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[8984],{6789:(e,t,n)=>{n.d(t,{A:()=>c});n(96540);var i=n(28774),s=n(34164);const l={tileCard:"tileCard_NHsj",tileIcon:"tileIcon_pyoR",tileLink:"tileLink_iUbu",tileImage:"tileImage_O4So"};var r=n(86025),a=n(21122),o=n(74848);function c({icon:e,image:t,imageDark:n,imageWidth:c,imageHeight:d,iconSize:p=32,containerHeight:m,title:h,description:u,href:f,linkText:g="Learn more \u2192",className:_}){if(!e&&!t)throw new Error("TileCard requires either an icon or image prop");const w=m?{height:`${m}px`}:{},x={};return c&&(x.width=`${c}px`),d&&(x.height=`${d}px`),(0,o.jsxs)(i.A,{href:f,className:(0,s.A)(l.tileCard,_),children:[(0,o.jsx)("div",{className:l.tileIcon,style:w,children:e?(0,o.jsx)(e,{size:p}):n?(0,o.jsx)(a.A,{sources:{light:(0,r.Ay)(t),dark:(0,r.Ay)(n)},alt:h,className:l.tileImage,style:x}):(0,o.jsx)("img",{src:(0,r.Ay)(t),alt:h,className:l.tileImage,style:x})}),(0,o.jsx)("h3",{children:h}),(0,o.jsx)("p",{children:u}),(0,o.jsx)("div",{className:l.tileLink,children:g})]})}},37269:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>N,contentTitle:()=>k,default:()=>C,frontMatter:()=>b,metadata:()=>i,toc:()=>A});const i=JSON.parse('{"id":"eval-monitor/scorers/llm-judge/workflow","title":"End-to-End Judge Workflow","description":"Complete workflow for developing, testing, and deploying custom LLM judges","source":"@site/docs/genai/eval-monitor/scorers/llm-judge/workflow.mdx","sourceDirName":"eval-monitor/scorers/llm-judge","slug":"/eval-monitor/scorers/llm-judge/workflow","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/workflow","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"End-to-End Judge Workflow","sidebar_label":"End-to-End Workflow","description":"Complete workflow for developing, testing, and deploying custom LLM judges"}}');var s=n(74848),l=n(28453),r=n(11470),a=n(19365),o=(n(49374),n(66927)),c=n(47020),d=n(82238),p=(n(79206),n(65592)),m=n(6789),h=n(56955),u=n(47792),f=n(93893),g=n(15977),_=n(22492),w=n(93164),x=n(87073),j=n(96393),y=n(96844),v=n(80827);const b={title:"End-to-End Judge Workflow",sidebar_label:"End-to-End Workflow",description:"Complete workflow for developing, testing, and deploying custom LLM judges"},k="End-to-End Judge Workflow",N={},A=[{value:"Why This Workflow Matters",id:"why-this-workflow-matters",level:2},{value:"The Development Cycle",id:"the-development-cycle",level:2},{value:"Step 1: Create Initial Judge",id:"step-1-create-initial-judge",level:2},{value:"Step 2: Generate Traces and Collect Feedback",id:"step-2-generate-traces-and-collect-feedback",level:2},{value:"Collecting Human Feedback",id:"collecting-human-feedback",level:3},{value:"How to Collect Feedback",id:"how-to-collect-feedback",level:3},{value:"Who Should Provide Feedback?",id:"who-should-provide-feedback",level:3},{value:"Step 3: Align Judge with Human Feedback",id:"step-3-align-judge-with-human-feedback",level:2},{value:"Step 4: Test and Register",id:"step-4-test-and-register",level:2},{value:"Step 5: Use the Registered Judge in Production",id:"step-5-use-the-registered-judge-in-production",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"Next Steps",id:"next-steps",level:2}];function I(e){const t={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"end-to-end-judge-workflow",children:"End-to-End Judge Workflow"})}),"\n",(0,s.jsx)(t.p,{children:"This guide walks through the complete lifecycle of developing and optimizing custom LLM judges using MLflow's judge APIs."}),"\n",(0,s.jsx)(t.h2,{id:"why-this-workflow-matters",children:"Why This Workflow Matters"}),"\n",(0,s.jsx)(d.A,{features:[{icon:u.A,title:"Systematic Development",description:"Move from subjective evaluation to data-driven judge development with clear metrics and goals."},{icon:f.A,title:"Human-AI Alignment",description:"Ensure your judges reflect human expertise and domain knowledge through structured feedback."},{icon:g.A,title:"Continuous Improvement",description:"Iterate and improve judge accuracy based on real-world performance and changing requirements."},{icon:_.A,title:"Production Ready",description:"Deploy judges with confidence knowing they've been tested and aligned with your quality standards."}]}),"\n",(0,s.jsx)(t.h2,{id:"the-development-cycle",children:"The Development Cycle"}),"\n",(0,s.jsx)(h.A,{steps:[{icon:w.A,title:"Create Judge",description:"Define evaluation criteria",detailedDescription:"Start with clear instructions that capture your domain expertise and evaluation requirements.",isFocus:!0},{icon:f.A,title:"Collect Feedback",description:"Gather human assessments",detailedDescription:"Run the judge on real traces and collect human feedback to establish ground truth."},{icon:x.A,title:"Align with Humans",description:"Optimize instructions",detailedDescription:"Use SIMBA optimizer to refine judge instructions based on human feedback."},{icon:j.A,title:"Test & Register",description:"Validate and deploy",detailedDescription:"Test the aligned judge and register it for production use when accuracy meets requirements."}],loopBackIcon:y.A,loopBackText:"Iterate",loopBackDescription:"Continue refining based on new data and requirements",circleSize:400}),"\n",(0,s.jsx)(t.h2,{id:"step-1-create-initial-judge",children:"Step 1: Create Initial Judge"}),"\n",(0,s.jsx)(t.p,{children:"Start by defining your evaluation criteria:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'import mlflow\nfrom mlflow.genai.judges import make_judge\nfrom mlflow.entities import AssessmentSource, AssessmentSourceType\n\n# Create experiment for judge development\nexperiment_id = mlflow.create_experiment("support-judge-development")\nmlflow.set_experiment(experiment_id=experiment_id)\n\n# Create a judge for evaluating customer support responses\nsupport_judge = make_judge(\n    name="support_quality",\n    instructions="""\n    Evaluate the quality of this customer support response.\n\n    Rate as one of: excellent, good, needs_improvement, poor\n\n    Consider:\n    - Does it address the customer\'s issue?\n    - Is the tone professional and empathetic?\n    - Are next steps clear?\n\n    Focus on {{ outputs }} responding to {{ inputs }}.\n    """,\n    model="anthropic:/claude-opus-4-1-20250805",\n)\n'})}),"\n",(0,s.jsx)(t.h2,{id:"step-2-generate-traces-and-collect-feedback",children:"Step 2: Generate Traces and Collect Feedback"}),"\n",(0,s.jsx)(t.p,{children:"Run your application to generate traces, then collect human feedback:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# Generate traces from your application\n@mlflow.trace\ndef customer_support_app(issue):\n    # Your application logic here\n    return {"response": f"I\'ll help you with: {issue}"}\n\n\n# Run application to generate traces\nissues = [\n    "Password reset not working",\n    "Billing discrepancy",\n    "Feature request",\n    "Technical error",\n]\n\ntrace_ids = []\nfor issue in issues:\n    with mlflow.start_run(experiment_id=experiment_id):\n        result = customer_support_app(issue)\n        trace_id = mlflow.get_last_active_trace_id()\n        trace_ids.append(trace_id)\n\n        # Judge evaluates the trace\n        assessment = support_judge(inputs={"issue": issue}, outputs=result)\n\n        # Log judge\'s assessment\n        mlflow.log_assessment(trace_id=trace_id, assessment=assessment)\n'})}),"\n",(0,s.jsx)(t.h3,{id:"collecting-human-feedback",children:"Collecting Human Feedback"}),"\n",(0,s.jsx)(t.p,{children:"After running your judge on traces, collect human feedback to establish ground truth:"}),"\n",(0,s.jsx)(c.A,{children:(0,s.jsxs)(r.A,{children:[(0,s.jsxs)(a.A,{value:"ui",label:"MLflow UI (Recommended)",default:!0,children:[(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"When to use:"})," You need to collect human feedback for judge alignment."]}),(0,s.jsx)(t.p,{children:"The MLflow UI provides the most intuitive way to review traces and add feedback:"}),(0,s.jsx)(t.h3,{id:"how-to-collect-feedback",children:"How to Collect Feedback"}),(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Open the MLflow UI"})," and navigate to your experiment"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Go to the Traces tab"})," to see all generated traces"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Click on individual traces"})," to review:","\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Input data (customer issues)"}),"\n",(0,s.jsx)(t.li,{children:"Output responses"}),"\n",(0,s.jsx)(t.li,{children:"Judge's initial assessment"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Add your feedback"}),' by clicking "Add Feedback"']}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Select the assessment name"}),' matching your judge (e.g., "support_quality")']}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Provide your expert rating"})," (excellent, good, needs_improvement, or poor)"]}),"\n"]}),(0,s.jsx)(t.h3,{id:"who-should-provide-feedback",children:"Who Should Provide Feedback?"}),(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"If you're NOT the domain expert:"})}),(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Ask domain experts or other developers to provide labels through the MLflow UI"}),"\n",(0,s.jsx)(t.li,{children:"Distribute traces among team members with relevant expertise"}),"\n",(0,s.jsx)(t.li,{children:"Consider organizing feedback sessions where experts can review batches together"}),"\n"]}),(0,s.jsx)(t.p,{children:(0,s.jsx)(t.strong,{children:"If you ARE the domain expert:"})}),(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Review traces directly in the MLflow UI and add your expert assessments"}),"\n",(0,s.jsx)(t.li,{children:"Create a rubric or guidelines document to ensure consistency"}),"\n",(0,s.jsx)(t.li,{children:"Document your evaluation criteria for future reference"}),"\n"]}),(0,s.jsx)(t.p,{children:"The UI automatically logs feedback in the correct format for alignment."}),(0,s.jsx)(o.A,{src:"/images/assessments/add_feedback_ui.png",alt:"Adding feedback through MLflow UI",width:"800px"})]}),(0,s.jsxs)(a.A,{value:"programmatic",label:"Programmatic (Existing Labels)",children:[(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"When to use:"})," You already have ground truth labels from your data."]}),(0,s.jsx)(t.p,{children:"If you have existing ground truth labels, log them programmatically:"}),(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# Example: You have ground truth labels\nground_truth = {\n    trace_ids[0]: "excellent",  # Known good response\n    trace_ids[1]: "poor",  # Known bad response\n    trace_ids[2]: "good",  # Known acceptable response\n}\n\nfor trace_id, truth_value in ground_truth.items():\n    mlflow.log_feedback(\n        trace_id=trace_id,\n        name="support_quality",  # MUST match judge name\n        value=truth_value,\n        source=AssessmentSource(\n            source_type=AssessmentSourceType.HUMAN, source_id="ground_truth"\n        ),\n    )\n'})})]})]})}),"\n",(0,s.jsx)(t.h2,{id:"step-3-align-judge-with-human-feedback",children:"Step 3: Align Judge with Human Feedback"}),"\n",(0,s.jsx)(t.p,{children:"Use the SIMBA optimizer to improve judge accuracy:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# Retrieve traces with both judge and human assessments\ntraces = mlflow.search_traces(experiment_ids=[experiment_id], return_type="list")\n\n# Filter for traces with both assessments\naligned_traces = []\nfor trace in traces:\n    assessments = trace.search_assessments(name="support_quality")\n    has_judge = any(\n        a.source.source_type == AssessmentSourceType.LLM_JUDGE for a in assessments\n    )\n    has_human = any(\n        a.source.source_type == AssessmentSourceType.HUMAN for a in assessments\n    )\n\n    if has_judge and has_human:\n        aligned_traces.append(trace)\n\nprint(f"Found {len(aligned_traces)} traces with both assessments")\n\n# Align the judge (requires at least 10 traces)\nif len(aligned_traces) >= 10:\n    # Option 1: Use default optimizer (recommended for simplicity)\n    aligned_judge = support_judge.align(aligned_traces)\n\n    # Option 2: Explicitly specify optimizer with custom model\n    # from mlflow.genai.judges.optimizers import SIMBAAlignmentOptimizer\n    # optimizer = SIMBAAlignmentOptimizer(model="anthropic:/claude-opus-4-1-20250805")\n    # aligned_judge = support_judge.align(aligned_traces, optimizer)\n\n    print("Judge aligned successfully!")\nelse:\n    print(f"Need at least 10 traces (have {len(aligned_traces)})")\n'})}),"\n",(0,s.jsx)(t.h2,{id:"step-4-test-and-register",children:"Step 4: Test and Register"}),"\n",(0,s.jsx)(t.p,{children:"Test the aligned judge and register it when ready:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# Test the aligned judge on new data\ntest_cases = [\n    {\n        "inputs": {"issue": "Can\'t log in"},\n        "outputs": {"response": "Let me reset your password for you."},\n    },\n    {\n        "inputs": {"issue": "Refund request"},\n        "outputs": {"response": "I\'ll process that refund immediately."},\n    },\n]\n\n# Evaluate with aligned judge\nfor case in test_cases:\n    assessment = aligned_judge(**case)\n    print(f"Issue: {case[\'inputs\'][\'issue\']}")\n    print(f"Judge rating: {assessment.value}")\n    print(f"Rationale: {assessment.rationale}\\n")\n\n# Register the aligned judge for production use\naligned_judge.register(experiment_id=experiment_id)\nprint("Judge registered and ready for deployment!")\n'})}),"\n",(0,s.jsx)(t.h2,{id:"step-5-use-the-registered-judge-in-production",children:"Step 5: Use the Registered Judge in Production"}),"\n",(0,s.jsxs)(t.p,{children:["Retrieve and use your registered judge with ",(0,s.jsx)(t.code,{children:"mlflow.genai.evaluate()"}),":"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'from mlflow.genai.scorers import get_scorer\nimport pandas as pd\n\n# Retrieve the registered judge\nproduction_judge = get_scorer(name="support_quality", experiment_id=experiment_id)\n\n# Prepare evaluation data\neval_data = pd.DataFrame(\n    [\n        {\n            "inputs": {"issue": "Can\'t access my account"},\n            "outputs": {"response": "I\'ll help you regain access immediately."},\n        },\n        {\n            "inputs": {"issue": "Slow website performance"},\n            "outputs": {"response": "Let me investigate the performance issues."},\n        },\n    ]\n)\n\n# Run evaluation with the aligned judge\nresults = mlflow.genai.evaluate(data=eval_data, scorers=[production_judge])\n\n# View results and metrics\nprint("Evaluation metrics:", results.metrics)\nprint("\\nDetailed results:")\nprint(results.tables["eval_results_table"])\n\n# Assessments are automatically logged to the traces\n# You can view them in the MLflow UI Traces tab\n'})}),"\n",(0,s.jsx)(t.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,s.jsx)(d.A,{features:[{icon:u.A,title:"Clear Instructions",description:"Start with specific, unambiguous evaluation criteria that reflect your domain requirements."},{icon:f.A,title:"Quality Feedback",description:"Ensure human feedback comes from domain experts who understand your evaluation standards."},{icon:j.A,title:"Sufficient Data",description:"Collect at least 10-15 traces with both assessments for effective alignment."},{icon:g.A,title:"Iterate Often",description:"Regularly re-align judges as your application evolves and new edge cases emerge."}]}),"\n",(0,s.jsx)(t.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsxs)(p.A,{children:[(0,s.jsx)(m.A,{icon:x.A,iconSize:48,title:"Judge Alignment",description:"Deep dive into alignment techniques and optimization",link:"/genai/eval-monitor/scorers/llm-judge/alignment",linkText:"Learn alignment \u2192",containerHeight:64}),(0,s.jsx)(m.A,{icon:v.A,iconSize:48,title:"Dataset Integration",description:"Use judges with evaluation datasets for systematic testing",link:"/genai/eval-monitor/scorers/llm-judge/datasets",linkText:"Explore datasets \u2192",containerHeight:64}),(0,s.jsx)(m.A,{icon:w.A,iconSize:48,title:"Main Documentation",description:"Return to the custom judges overview",link:"/genai/eval-monitor/scorers/llm-judge/",linkText:"Back to overview \u2192",containerHeight:64})]})]})}function C(e={}){const{wrapper:t}={...(0,l.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(I,{...e})}):I(e)}},47020:(e,t,n)=>{n.d(t,{A:()=>l});n(96540);const i={wrapper:"wrapper_sf5q"};var s=n(74848);function l({children:e}){return(0,s.jsx)("div",{className:i.wrapper,children:e})}},49374:(e,t,n)=>{n.d(t,{B:()=>a});n(96540);const i=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}');var s=n(86025),l=n(74848);const r=e=>{const t=e.split(".");for(let n=t.length;n>0;n--){const e=t.slice(0,n).join(".");if(i[e])return e}return null};function a({fn:e,children:t,hash:n}){const a=r(e);if(!a)return(0,l.jsx)(l.Fragment,{children:t});const o=(0,s.Ay)(`/${i[a]}#${n??e}`);return(0,l.jsx)("a",{href:o,target:"_blank",children:t??(0,l.jsxs)("code",{children:[e,"()"]})})}},56955:(e,t,n)=>{n.d(t,{A:()=>J});var i=n(96540);const s="loopContainer_P7aD",l="loopTitle_JPUj",r="loopContent_d_OB",a="circleContainer_r3vu",o="svgCanvas_uDoP",c="arrowPath_C9al",d="arrowHead_pHvN",p="stepNode_dfTI",m="stepNodeContent_qttg",h="highlighted_oNtg",u="focusNode_z3RB",f="stepNumber_LNrP",g="stepLabel_vl8R",_="centerIcon_KAOa",w="loopIconWrapper_xBPW",x="loopText_T4eg",j="tooltip_UzKu",y="tooltipTitle_HAKW",v="tooltipDescription_EDYJ",b="tooltipArrow_WNhr",k="centerTooltip_R18b",N="centerTooltipDescription_ttXB",A="mobileLinearContent_PCYK",I="mobileStepItem_x9mX",C="mobileStepIndicator_zWzO",S="mobileStepNumber_HnjD",T="mobileFocusNode_FTRa",L="mobileStepConnector_kK9y",M="mobileStepContent_jmKx",D="mobileStepTitle_P2DM",R="mobileStepDescription_qbMN",z="mobileLoopBack_nXtn",E="mobileLoopIcon_FAGz",H="mobileLoopContent_BRFV",F="mobileLoopTitle_JcCt",W="mobileLoopDescription_5B8T";var $=n(74848);const J=({steps:e,title:t,loopBackIcon:n,loopBackText:J,loopBackDescription:B,circleSize:P=400})=>{const[q,U]=(0,i.useState)(null),[O,G]=(0,i.useState)(!1),[K,Y]=(0,i.useState)({x:0,y:0}),[X,V]=(0,i.useState)(!1),Z=(0,i.useRef)(null);i.useEffect(()=>{const e=()=>{V(window.innerWidth<=768)};return e(),window.addEventListener("resize",e),()=>window.removeEventListener("resize",e)},[]);const Q=X?280:P,ee=(()=>{const t=P/2,n=X?100:140,i=X?130:220,s=Math.min(1.2,.8+.05*e.length),l=(t-(X?50:80))*s;return Math.max(n,Math.min(i,l))})(),te=Q/2,ne=Q/2,ie=t=>{const n=2*t*Math.PI/e.length-Math.PI/2;return{x:te+ee*Math.cos(n),y:ne+ee*Math.sin(n)}},se=(e,t)=>{const n=ie(e),i=ie(t),s=i.x-n.x,l=i.y-n.y,r=(n.x+i.x)/2,a=(n.y+i.y)/2,o=Math.sqrt(s*s+l*l),c=s/o,d=l/o;return`M ${r-10*c} ${a-10*d} L ${r+10*c} ${a+10*d}`},le=()=>{U(null)};return X?(0,$.jsxs)("div",{className:s,children:[t&&(0,$.jsx)("h3",{className:l,children:t}),(0,$.jsxs)("div",{className:A,children:[e.map((t,n)=>(0,$.jsxs)("div",{className:I,children:[(0,$.jsxs)("div",{className:C,children:[(0,$.jsx)("div",{className:`${S} ${t.isFocus?T:""}`,children:t.icon?(0,$.jsx)(t.icon,{size:20}):(0,$.jsx)("span",{children:n+1})}),n<e.length-1&&(0,$.jsx)("div",{className:L})]}),(0,$.jsxs)("div",{className:M,children:[(0,$.jsx)("h4",{className:D,children:t.title}),(0,$.jsx)("p",{className:R,children:t.detailedDescription||t.description})]})]},n)),n&&B&&(0,$.jsxs)("div",{className:z,children:[(0,$.jsx)("div",{className:E,children:(0,$.jsx)(n,{size:24})}),(0,$.jsxs)("div",{className:H,children:[(0,$.jsx)("h4",{className:F,children:J||"Iterate"}),(0,$.jsx)("p",{className:W,children:B})]})]})]})]}):(0,$.jsxs)("div",{className:s,children:[t&&(0,$.jsx)("h3",{className:l,children:t}),(0,$.jsx)("div",{className:r,children:(0,$.jsxs)("div",{className:a,ref:Z,style:{width:`${Q}px`,height:`${Q}px`},children:[(0,$.jsxs)("svg",{width:Q,height:Q,className:o,children:[e.map((t,n)=>{const i=(n+1)%e.length;return(0,$.jsxs)("g",{children:[(0,$.jsx)("defs",{children:(0,$.jsx)("marker",{id:`arrowhead-${n}`,markerWidth:"6",markerHeight:"6",refX:"5",refY:"3",orient:"auto",children:(0,$.jsx)("path",{d:"M 0 0 L 6 3 L 0 6 L 1.5 3 Z",fill:"currentColor",opacity:"1",className:d})})}),(0,$.jsx)("path",{d:se(n,i),fill:"none",stroke:"currentColor",strokeWidth:"2",strokeDasharray:"0",opacity:"0.9",markerEnd:`url(#arrowhead-${n})`,className:c})]},`arrow-${n}`)}),n&&(0,$.jsxs)("g",{className:_,onMouseEnter:()=>G(!0),onMouseLeave:()=>G(!1),style:{cursor:"pointer"},children:[(0,$.jsx)("foreignObject",{x:te-35,y:ne-35,width:"70",height:"70",children:(0,$.jsx)("div",{className:w,children:(0,$.jsx)(n,{size:32})})}),J&&(0,$.jsx)("text",{x:te,y:ne+50,textAnchor:"middle",className:x,children:J})]})]}),e.map((e,t)=>{const n=ie(t);return(0,$.jsxs)("div",{className:`${p} ${e.highlight?h:""} ${e.isFocus?u:""}`,style:{left:`${n.x}px`,top:`${n.y}px`,transform:"translate(-50%, -50%)"},onMouseEnter:e=>(e=>{if(U(e),Z.current){Z.current.getBoundingClientRect();const t=ie(e);Y({x:t.x,y:t.y})}})(t),onMouseLeave:le,children:[(0,$.jsx)("div",{className:m,children:e.icon?(0,$.jsx)(e.icon,{size:24}):(0,$.jsx)("span",{className:f,children:t+1})}),(0,$.jsx)("div",{className:g,children:e.title})]},t)}),null!==q&&(0,$.jsxs)("div",{className:j,style:{left:`${K.x}px`,top:`${K.y}px`,transform:"translate(-50%, -120%)"},children:[(0,$.jsx)("h4",{className:y,children:e[q].title}),(0,$.jsx)("p",{className:v,children:e[q].detailedDescription||e[q].description}),(0,$.jsx)("div",{className:b})]}),O&&B&&(0,$.jsx)("div",{className:k,style:{left:`${te}px`,top:`${ne}px`,transform:"translate(-50%, -50%)"},children:(0,$.jsx)("p",{className:N,children:B})})]})})]})}},65592:(e,t,n)=>{n.d(t,{A:()=>r});n(96540);var i=n(34164);const s={tilesGrid:"tilesGrid_hB9N"};var l=n(74848);function r({children:e,className:t}){return(0,l.jsx)("div",{className:(0,i.A)(s.tilesGrid,t),children:e})}},66927:(e,t,n)=>{n.d(t,{A:()=>r});n(96540);const i={container:"container_JwLF",imageWrapper:"imageWrapper_RfGN",image:"image_bwOA",caption:"caption_jo2G"};var s=n(86025),l=n(74848);function r({src:e,alt:t,width:n,caption:r,className:a}){return(0,l.jsxs)("div",{className:`${i.container} ${a||""}`,children:[(0,l.jsx)("div",{className:i.imageWrapper,style:n?{width:n}:{},children:(0,l.jsx)("img",{src:(0,s.Ay)(e),alt:t,className:i.image})}),r&&(0,l.jsx)("p",{className:i.caption,children:r})]})}},79206:(e,t,n)=>{n.d(t,{A:()=>l});n(96540);const i={conceptOverview:"conceptOverview_x8T_",overviewTitle:"overviewTitle_HyAI",conceptGrid:"conceptGrid_uJNV",conceptCard:"conceptCard_oday",conceptHeader:"conceptHeader_HCk5",conceptIcon:"conceptIcon_gejw",conceptTitle:"conceptTitle_TGMM",conceptDescription:"conceptDescription_ZyDn"};var s=n(74848);function l({concepts:e,title:t}){return(0,s.jsxs)("div",{className:i.conceptOverview,children:[t&&(0,s.jsx)("h3",{className:i.overviewTitle,children:t}),(0,s.jsx)("div",{className:i.conceptGrid,children:e.map((e,t)=>(0,s.jsxs)("div",{className:i.conceptCard,children:[(0,s.jsxs)("div",{className:i.conceptHeader,children:[e.icon&&(0,s.jsx)("div",{className:i.conceptIcon,children:(0,s.jsx)(e.icon,{size:20})}),(0,s.jsx)("h4",{className:i.conceptTitle,children:e.title})]}),(0,s.jsx)("p",{className:i.conceptDescription,children:e.description})]},t))})]})}},82238:(e,t,n)=>{n.d(t,{A:()=>l});n(96540);const i={featureHighlights:"featureHighlights_Ardf",highlightItem:"highlightItem_XPnN",highlightIcon:"highlightIcon_SUR8",highlightContent:"highlightContent_d0XP"};var s=n(74848);function l({features:e}){return(0,s.jsx)("div",{className:i.featureHighlights,children:e.map((e,t)=>(0,s.jsxs)("div",{className:i.highlightItem,children:[e.icon&&(0,s.jsx)("div",{className:i.highlightIcon,children:(0,s.jsx)(e.icon,{size:24})}),(0,s.jsxs)("div",{className:i.highlightContent,children:[(0,s.jsx)("h4",{children:e.title}),(0,s.jsx)("p",{children:e.description})]})]},t))})}}}]);