"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[6944],{5347:(e,t,i)=>{i.d(t,{A:()=>n});const n=i.p+"assets/images/evaluation_dataset_ui-b4a751f7446218d0f2e7d640f395517d.png"},19989:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>p,contentTitle:()=>a,default:()=>d,frontMatter:()=>s,metadata:()=>n,toc:()=>m});const n=JSON.parse('{"id":"prompt-registry/rewrite-prompts","title":"Auto-rewrite Prompts for New Models (Experimental)","description":"When migrating to a new language model, you often discover that your carefully crafted prompts don\'t work as well with the new model. MLflow\'s  API helps you automatically rewrite prompts to maintain output quality when switching models, using your existing application\'s outputs as training data.","source":"@site/docs/genai/prompt-registry/rewrite-prompts.mdx","sourceDirName":"prompt-registry","slug":"/prompt-registry/rewrite-prompts","permalink":"/mlflow-website/docs/latest/genai/prompt-registry/rewrite-prompts","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6,"sidebar_label":"Auto-rewrite Prompts for New Models \ud83c\udd95"},"sidebar":"genAISidebar","previous":{"title":"Optimize Prompts","permalink":"/mlflow-website/docs/latest/genai/prompt-registry/optimize-prompts"},"next":{"title":"Prompt Engineering UI","permalink":"/mlflow-website/docs/latest/genai/prompt-registry/prompt-engineering"}}');var l=i(74848),o=i(28453),r=i(49374);const s={sidebar_position:6,sidebar_label:"Auto-rewrite Prompts for New Models \ud83c\udd95"},a="Auto-rewrite Prompts for New Models (Experimental)",p={},m=[{value:"Example: Simple Prompt \u2192 Optimized Prompt",id:"example-simple-prompt--optimized-prompt",level:3},{value:"When to Use Prompt Rewriting",id:"when-to-use-prompt-rewriting",level:2},{value:"Quick Start: Model Migration Workflow",id:"quick-start-model-migration-workflow",level:2},{value:"Step 1: Capture Outputs from Original Model",id:"step-1-capture-outputs-from-original-model",level:3},{value:"Step 2: Create Training Dataset from Traces",id:"step-2-create-training-dataset-from-traces",level:3},{value:"Step 3: Switch Model",id:"step-3-switch-model",level:3},{value:"Step 4: Optimize Prompts for Target Model",id:"step-4-optimize-prompts-for-target-model",level:3},{value:"Step 5: Use Optimized Prompt",id:"step-5-use-optimized-prompt",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"1. Collect Sufficient Data",id:"1-collect-sufficient-data",level:3},{value:"2. Use Representative Examples",id:"2-use-representative-examples",level:3},{value:"3. Verify Results",id:"3-verify-results",level:3},{value:"See Also",id:"see-also",level:2}];function c(e){const t={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(t.header,{children:(0,l.jsx)(t.h1,{id:"auto-rewrite-prompts-for-new-models-experimental",children:"Auto-rewrite Prompts for New Models (Experimental)"})}),"\n",(0,l.jsxs)(t.p,{children:["When migrating to a new language model, you often discover that your carefully crafted prompts don't work as well with the new model. MLflow's ",(0,l.jsx)(r.B,{fn:"mlflow.genai.optimize_prompts"})," API helps you ",(0,l.jsx)(t.strong,{children:"automatically rewrite prompts"})," to maintain output quality when switching models, using your existing application's outputs as training data."]}),"\n",(0,l.jsx)(t.admonition,{title:"Key Benefits",type:"tip",children:(0,l.jsxs)(t.ul,{children:["\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.strong,{children:"Model Migration"}),": Seamlessly switch between language models while maintaining output consistency"]}),"\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.strong,{children:"Automatic Optimization"}),": Automatically rewrites prompts based on your existing data"]}),"\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.strong,{children:"No Ground Truth Requirement"}),": No human labeling is required if you optimize prompts based on the existing outputs"]}),"\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.strong,{children:"Trace-Aware"}),": Leverages MLflow tracing to understand prompt usage patterns"]}),"\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.strong,{children:"Flexible"}),": Works with any function that uses MLflow Prompt Registry"]}),"\n"]})}),"\n",(0,l.jsx)(t.admonition,{title:"Version Requirements",type:"note",children:(0,l.jsxs)(t.p,{children:["The ",(0,l.jsx)(t.code,{children:"optimize_prompts"})," API requires ",(0,l.jsx)(t.strong,{children:"MLflow >= 3.5.0"}),"."]})}),"\n",(0,l.jsx)(t.p,{children:(0,l.jsx)(t.img,{alt:"Model Migration Workflow",src:i(72066).A+"",width:"1000",height:"450"})}),"\n",(0,l.jsx)(t.h3,{id:"example-simple-prompt--optimized-prompt",children:"Example: Simple Prompt \u2192 Optimized Prompt"}),"\n",(0,l.jsx)("table",{children:(0,l.jsxs)("tr",{children:[(0,l.jsxs)("td",{width:"50%",valign:"top",children:[(0,l.jsx)(t.p,{children:(0,l.jsx)(t.strong,{children:"Before Optimization:"})}),(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-text",children:"Classify the sentiment. Answer 'positive'\nor 'negative' or 'neutral'.\n\nText: {{text}}\n"})})]}),(0,l.jsxs)("td",{width:"50%",valign:"top",children:[(0,l.jsx)(t.p,{children:(0,l.jsx)(t.strong,{children:"After Optimization:"})}),(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-text",children:"Classify the sentiment of the provided text.\nYour response must be one of the following:\n- 'positive'\n- 'negative'\n- 'neutral'\n\nEnsure your response is lowercase and contains\nonly one of these three words.\n\nText: {{text}}\n\nGuidelines:\n- 'positive': The text expresses satisfaction,\n  happiness, or approval\n- 'negative': The text expresses dissatisfaction,\n  anger, or disapproval\n- 'neutral': The text is factual or balanced\n  without strong emotion\n\nYour response must match this exact format with\nno additional explanation.\n"})})]})]})}),"\n",(0,l.jsx)(t.h2,{id:"when-to-use-prompt-rewriting",children:"When to Use Prompt Rewriting"}),"\n",(0,l.jsx)(t.p,{children:"This approach is ideal when:"}),"\n",(0,l.jsxs)(t.ul,{children:["\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.strong,{children:"Downgrading Models"}),": Moving from ",(0,l.jsx)(t.code,{children:"gpt-5"})," \u2192 ",(0,l.jsx)(t.code,{children:"gpt-4o-mini"})," to reduce costs"]}),"\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.strong,{children:"Switching Providers"}),": Changing from OpenAI to Anthropic or vice versa"]}),"\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.strong,{children:"Performance Optimization"}),": Moving to faster models while maintaining quality"]}),"\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.strong,{children:"You Have Existing Outputs"}),": Your current system already produces good results"]}),"\n"]}),"\n",(0,l.jsx)(t.h2,{id:"quick-start-model-migration-workflow",children:"Quick Start: Model Migration Workflow"}),"\n",(0,l.jsxs)(t.p,{children:["Here's a complete example of migrating from ",(0,l.jsx)(t.code,{children:"gpt-5"})," to ",(0,l.jsx)(t.code,{children:"gpt-4o-mini"})," while maintaining output consistency:"]}),"\n",(0,l.jsx)(t.h3,{id:"step-1-capture-outputs-from-original-model",children:"Step 1: Capture Outputs from Original Model"}),"\n",(0,l.jsx)(t.p,{children:"First, collect outputs from your existing model using MLflow tracing:"}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-python",children:'import mlflow\nimport openai\nfrom mlflow.genai.optimize import GepaPromptOptimizer\nfrom mlflow.genai.datasets import create_dataset\nfrom mlflow.genai.scorers import Equivalence\n\n# Register your current prompt\nprompt = mlflow.genai.register_prompt(\n    name="sentiment",\n    template="""Classify the sentiment. Answer \'positive\' or \'negative\' or \'neutral\'.\nText: {{text}}""",\n)\n\n\n# Define your prediction function using the original model and base prompt\n@mlflow.trace\ndef predict_fn_base_model(text: str) -> str:\n    completion = openai.OpenAI().chat.completions.create(\n        model="gpt-5",  # Original model\n        messages=[{"role": "user", "content": prompt.format(text=text)}],\n    )\n    return completion.choices[0].message.content.lower()\n\n\n# Example inputs - each record contains an "inputs" dict with the function\'s input parameters\ninputs = [\n    {\n        "inputs": {\n            "text": "This movie was absolutely fantastic! I loved every minute of it."\n        }\n    },\n    {"inputs": {"text": "The service was terrible and the food arrived cold."}},\n    {"inputs": {"text": "It was okay, nothing special but not bad either."}},\n    {\n        "inputs": {\n            "text": "I\'m so disappointed with this purchase. Complete waste of money."\n        }\n    },\n    {"inputs": {"text": "Best experience ever! Highly recommend to everyone."}},\n    {"inputs": {"text": "The product works as described. No complaints."}},\n    {"inputs": {"text": "I can\'t believe how amazing this turned out to be!"}},\n    {"inputs": {"text": "Worst customer support I\'ve ever dealt with."}},\n    {"inputs": {"text": "It\'s fine for the price. Gets the job done."}},\n    {"inputs": {"text": "This exceeded all my expectations. Truly wonderful!"}},\n]\n\n# Collect outputs from source model\nwith mlflow.start_run() as run:\n    for record in inputs:\n        predict_fn_base_model(**record["inputs"])\n'})}),"\n",(0,l.jsx)(t.h3,{id:"step-2-create-training-dataset-from-traces",children:"Step 2: Create Training Dataset from Traces"}),"\n",(0,l.jsx)(t.p,{children:"Convert the traced outputs into a training dataset:"}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-python",children:'# Create dataset\ndataset = create_dataset(name="sentiment_migration_dataset")\n\n# Retrieve traces from the run\ntraces = mlflow.search_traces(return_type="list", run_id=run.info.run_id)\n\n# Merge traces into dataset\ndataset.merge_records(traces)\n'})}),"\n",(0,l.jsx)(t.p,{children:"This automatically creates a dataset with:"}),"\n",(0,l.jsxs)(t.ul,{children:["\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.code,{children:"inputs"}),": The input variables (",(0,l.jsx)(t.code,{children:"text"})," in this case)"]}),"\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.code,{children:"outputs"}),": The actual outputs from your source model (",(0,l.jsx)(t.code,{children:"gpt-5"}),")"]}),"\n"]}),"\n",(0,l.jsx)(t.p,{children:"You can view the created dataset in the MLflow UI by navigating to:"}),"\n",(0,l.jsxs)(t.ol,{children:["\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.strong,{children:"Experiments"})," tab \u2192 Select your experiment"]}),"\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.strong,{children:"Evaluations"})," tab \u2192 View your evaluation runs"]}),"\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.strong,{children:"Dataset"})," tab \u2192 Inspect the input/output pairs"]}),"\n"]}),"\n",(0,l.jsx)(t.p,{children:"The dataset view shows all the inputs and outputs collected from your traces, making it easy to verify the training data before optimization."}),"\n",(0,l.jsx)(t.p,{children:(0,l.jsx)(t.img,{src:i(5347).A+"",width:"2238",height:"974"})}),"\n",(0,l.jsx)(t.h3,{id:"step-3-switch-model",children:"Step 3: Switch Model"}),"\n",(0,l.jsx)(t.p,{children:"Switch your LM to the target model:"}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-python",children:'# Define function using target model\n@mlflow.trace\ndef predict_fn(text: str) -> str:\n    completion = openai.OpenAI().chat.completions.create(\n        model="gpt-4o-mini",  # Target model\n        messages=[{"role": "user", "content": prompt.format(text=text)}],\n        temperature=0,\n    )\n    return completion.choices[0].message.content.lower()\n'})}),"\n",(0,l.jsx)(t.p,{children:"You might notice the target model doesn't follow the format as consistently as the source model."}),"\n",(0,l.jsx)(t.h3,{id:"step-4-optimize-prompts-for-target-model",children:"Step 4: Optimize Prompts for Target Model"}),"\n",(0,l.jsx)(t.p,{children:"Use the collected dataset to optimize prompts for the target model:"}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-python",children:'# Optimize prompts for the target model\nresult = mlflow.genai.optimize_prompts(\n    predict_fn=predict_fn,\n    train_data=dataset,\n    prompt_uris=[prompt.uri],\n    optimizer=GepaPromptOptimizer(reflection_model="openai:/gpt-5"),\n    scorers=[Equivalence(model="openai:/gpt-5")],\n)\n\n# View the optimized prompt\noptimized_prompt = result.optimized_prompts[0]\nprint(f"Optimized template: {optimized_prompt.template}")\n'})}),"\n",(0,l.jsxs)(t.p,{children:["The optimized prompt will include additional instructions to help ",(0,l.jsx)(t.code,{children:"gpt-4o-mini"})," match the behavior of ",(0,l.jsx)(t.code,{children:"gpt-5"}),":"]}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{children:"Optimized template:\nClassify the sentiment of the provided text. Your response must be one of the following:\n- 'positive'\n- 'negative'\n- 'neutral'\n\nEnsure your response is lowercase and contains only one of these three words.\n\nText: {{text}}\n\nGuidelines:\n- 'positive': The text expresses satisfaction, happiness, or approval\n- 'negative': The text expresses dissatisfaction, anger, or disapproval\n- 'neutral': The text is factual or balanced without strong emotion\n\nYour response must match this exact format with no additional explanation.\n"})}),"\n",(0,l.jsx)(t.h3,{id:"step-5-use-optimized-prompt",children:"Step 5: Use Optimized Prompt"}),"\n",(0,l.jsx)(t.p,{children:"Deploy the optimized prompt in your application:"}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-python",children:'# Load the optimized prompt\noptimized = mlflow.genai.load_prompt(optimized_prompt.uri)\n\n\n# Use in production\n@mlflow.trace\ndef predict_fn_optimized(text: str) -> str:\n    completion = openai.OpenAI().chat.completions.create(\n        model="gpt-4o-mini",\n        messages=[{"role": "user", "content": optimized.format(text=text)}],\n        temperature=0,\n    )\n    return completion.choices[0].message.content.lower()\n\n\n# Test with new inputs\ntest_result = predict_fn_optimized("This product is amazing!")\nprint(test_result)  # Output: positive\n'})}),"\n",(0,l.jsx)(t.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,l.jsx)(t.h3,{id:"1-collect-sufficient-data",children:"1. Collect Sufficient Data"}),"\n",(0,l.jsx)(t.p,{children:"For best results, collect outputs from at least 20-50 diverse examples:"}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-python",children:'# \u2705 Good: Diverse examples\ninputs = [\n    {"inputs": {"text": "Great product!"}},\n    {\n        "inputs": {\n            "text": "The delivery was delayed by three days and the packaging was damaged. The product itself works fine but the experience was disappointing overall."\n        }\n    },\n    {\n        "inputs": {\n            "text": "It meets the basic requirements. Nothing more, nothing less."\n        }\n    },\n    # ... more varied examples\n]\n\n# \u274c Poor: Too few, too similar\ninputs = [\n    {"inputs": {"text": "Good"}},\n    {"inputs": {"text": "Bad"}},\n]\n'})}),"\n",(0,l.jsx)(t.h3,{id:"2-use-representative-examples",children:"2. Use Representative Examples"}),"\n",(0,l.jsx)(t.p,{children:"Include edge cases and challenging inputs:"}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-python",children:'inputs = [\n    {"inputs": {"text": "Absolutely fantastic!"}},  # Clear positive\n    {"inputs": {"text": "It\'s not bad, I guess."}},  # Ambiguous\n    {"inputs": {"text": "The food was good but service terrible."}},  # Mixed sentiment\n]\n'})}),"\n",(0,l.jsx)(t.h3,{id:"3-verify-results",children:"3. Verify Results"}),"\n",(0,l.jsxs)(t.p,{children:["Always test optimized prompts using ",(0,l.jsx)(r.B,{fn:"mlflow.genai.evaluate"})," before production deployment."]}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-python",children:"# Evaluate optimized prompt\nresults = mlflow.genai.evaluate(\n    data=test_dataset,\n    predict_fn=predict_fn_optimized,\n    scorers=[accuracy_scorer, format_scorer],\n)\n\nprint(f\"Accuracy: {results.metrics['accuracy']}\")\nprint(f\"Format compliance: {results.metrics['format_scorer']}\")\n"})}),"\n",(0,l.jsx)(t.h2,{id:"see-also",children:"See Also"}),"\n",(0,l.jsxs)(t.ul,{children:["\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.a,{href:"/genai/prompt-registry/optimize-prompts",children:"Optimize Prompts"}),": General prompt optimization guide"]}),"\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.a,{href:"/genai/prompt-registry/create-and-edit-prompts",children:"Create and Edit Prompts"}),": Prompt Registry basics"]}),"\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.a,{href:"/genai/eval-monitor/running-evaluation/prompts",children:"Evaluate Prompts"}),": Evaluate prompt performance"]}),"\n",(0,l.jsxs)(t.li,{children:[(0,l.jsx)(t.a,{href:"/genai/tracing/",children:"MLflow Tracing"}),": Understanding MLflow tracing"]}),"\n"]})]})}function d(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,l.jsx)(t,{...e,children:(0,l.jsx)(c,{...e})}):c(e)}},28453:(e,t,i)=>{i.d(t,{R:()=>r,x:()=>s});var n=i(96540);const l={},o=n.createContext(l);function r(e){const t=n.useContext(o);return n.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:r(e.components),n.createElement(o.Provider,{value:t},e.children)}},49374:(e,t,i)=>{i.d(t,{B:()=>s});i(96540);const n=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}');var l=i(86025),o=i(74848);const r=e=>{const t=e.split(".");for(let i=t.length;i>0;i--){const e=t.slice(0,i).join(".");if(n[e])return e}return null};function s({fn:e,children:t,hash:i}){const s=r(e);if(!s)return(0,o.jsx)(o.Fragment,{children:t});const a=(0,l.Ay)(`/${n[s]}#${i??e}`);return(0,o.jsx)("a",{href:a,target:"_blank",children:t??(0,o.jsxs)("code",{children:[e,"()"]})})}},72066:(e,t,i)=>{i.d(t,{A:()=>n});const n="data:image/svg+xml;base64,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"}}]);