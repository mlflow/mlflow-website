"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["1565"],{39591(e){e.exports=JSON.parse('{"version":{"pluginId":"genai","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"genAISidebar":[{"type":"link","href":"/mlflow-website/docs/latest/genai/","label":"Overview","className":"sidebar-overview","docId":"index","unlisted":false},{"type":"html","value":"<b>Getting Started</b>","defaultStyle":true},{"type":"link","href":"/mlflow-website/docs/latest/genai/getting-started/connect-environment","label":"Set Up MLflow Server","className":"sidebar-top-level-category","docId":"getting-started/connect-environment","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/quickstart/","label":"Start Tracing","className":"sidebar-top-level-category","docId":"tracing/quickstart/index","unlisted":false},{"type":"link","href":"/genai/eval-monitor/quickstart/","label":"Evaluate LLMs and Agents","className":"sidebar-top-level-category"},{"type":"link","href":"/mlflow-website/docs/latest/genai/getting-started/try-assistant","label":"Try MLflow Assistant","className":"sidebar-top-level-category","docId":"getting-started/try-assistant","unlisted":false},{"type":"html","value":"<b>Core Components</b>","defaultStyle":true},{"type":"category","label":"Tracing (Observability)","className":"sidebar-top-level-category","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/quickstart/","label":"Quickstart","docId":"tracing/quickstart/index","unlisted":false},{"type":"category","label":"Guides","items":[{"type":"category","label":"Trace Your App & Agents","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/app-instrumentation/automatic","label":"Automatic Tracing","docId":"tracing/app-instrumentation/automatic","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/app-instrumentation/manual-tracing","label":"Manual Tracing","docId":"tracing/app-instrumentation/manual-tracing","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/app-instrumentation/opentelemetry","label":"Tracing with OpenTelemetry","docId":"tracing/app-instrumentation/opentelemetry","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/app-instrumentation/distributed-tracing","label":"Distributed Tracing","docId":"tracing/app-instrumentation/distributed-tracing","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Enhance Your Traces","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/track-users-sessions/","label":"Track Users and Sessions","docId":"tracing/track-users-sessions/index","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/attach-tags/","label":"Tag Traces","docId":"tracing/attach-tags/index","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/collect-user-feedback/","label":"Collect User Feedback","docId":"tracing/collect-user-feedback/index","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/observe-with-traces/masking","label":"Redact Sensitive Data","docId":"tracing/observe-with-traces/masking","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/track-environments-context/","label":"Track Application Versions","docId":"tracing/track-environments-context/index","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"View & Manage Traces","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/observe-with-traces/ui","label":"View Traces in the UI","docId":"tracing/observe-with-traces/ui","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/search-traces","label":"Search Traces","docId":"tracing/search-traces","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/observe-with-traces/delete-traces","label":"Delete Traces","docId":"tracing/observe-with-traces/delete-traces","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Deploy to Production","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/prod-tracing","label":"Production Monitoring","docId":"tracing/prod-tracing","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/lightweight-sdk","label":"Production Tracing SDK","docId":"tracing/lightweight-sdk","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Integrations","items":[{"type":"category","label":"Frameworks","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/ag2","label":"AG2","docId":"tracing/integrations/listing/ag2","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/agno","label":"Agno","docId":"tracing/integrations/listing/agno","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/bedrock-agentcore","label":"Amazon Bedrock AgentCore","docId":"tracing/integrations/listing/bedrock-agentcore","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/autogen","label":"AutoGen","docId":"tracing/integrations/listing/autogen","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/crewai","label":"CrewAI","docId":"tracing/integrations/listing/crewai","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/dspy","label":"DSPy","docId":"tracing/integrations/listing/dspy","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/google-adk","label":"Google ADK","docId":"tracing/integrations/listing/google-adk","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/haystack","label":"Haystack","docId":"tracing/integrations/listing/haystack","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/koog","label":"Koog","docId":"tracing/integrations/listing/koog","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/langchain","label":"LangChain","docId":"tracing/integrations/listing/langchain","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/langflow","label":"Langflow","docId":"tracing/integrations/listing/langflow","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/langgraph","label":"LangGraph","docId":"tracing/integrations/listing/langgraph","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/livekit","label":"LiveKit Agents","docId":"tracing/integrations/listing/livekit","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/deepagent","label":"LangChain Deep Agent","docId":"tracing/integrations/listing/deepagent","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/llama_index","label":"LlamaIndex","docId":"tracing/integrations/listing/llama_index","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/mastra","label":"Mastra","docId":"tracing/integrations/listing/mastra","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/microsoft-agent-framework","label":"Microsoft Agent Framework","docId":"tracing/integrations/listing/microsoft-agent-framework","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/openai-agent","label":"OpenAI Agents SDK","docId":"tracing/integrations/listing/openai-agent","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/pipecat","label":"Pipecat","docId":"tracing/integrations/listing/pipecat","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/pydantic_ai","label":"PydanticAI","docId":"tracing/integrations/listing/pydantic_ai","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/quarkus-langchain4j","label":"Quarkus LangChain4j","docId":"tracing/integrations/listing/quarkus-langchain4j","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/semantic_kernel","label":"Semantic Kernel","docId":"tracing/integrations/listing/semantic_kernel","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/smolagents","label":"Smolagents","docId":"tracing/integrations/listing/smolagents","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/spring-ai","label":"Spring AI","docId":"tracing/integrations/listing/spring-ai","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/strands","label":"Strands Agents SDK","docId":"tracing/integrations/listing/strands","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/txtai","label":"Txtai","docId":"tracing/integrations/listing/txtai","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/vercelai","label":"Vercel AI SDK","docId":"tracing/integrations/listing/vercelai","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/voltagent","label":"VoltAgent","docId":"tracing/integrations/listing/voltagent","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/watsonx-orchestrate","label":"Watsonx Orchestrate","docId":"tracing/integrations/listing/watsonx-orchestrate","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Model Providers","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/anthropic","label":"Anthropic","docId":"tracing/integrations/listing/anthropic","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/bedrock","label":"Bedrock","docId":"tracing/integrations/listing/bedrock","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/byteplus","label":"BytePlus","docId":"tracing/integrations/listing/byteplus","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/cohere","label":"Cohere","docId":"tracing/integrations/listing/cohere","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/databricks","label":"Databricks","docId":"tracing/integrations/listing/databricks","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/deepseek","label":"DeepSeek","docId":"tracing/integrations/listing/deepseek","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/fireworksai","label":"FireworksAI","docId":"tracing/integrations/listing/fireworksai","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/gemini","label":"Gemini","docId":"tracing/integrations/listing/gemini","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/groq","label":"Groq","docId":"tracing/integrations/listing/groq","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/moonshot","label":"Kimi (Moonshot AI)","docId":"tracing/integrations/listing/moonshot","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/litellm","label":"LiteLLM","docId":"tracing/integrations/listing/litellm","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/mistral","label":"Mistral","docId":"tracing/integrations/listing/mistral","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/novitaai","label":"Novita AI","docId":"tracing/integrations/listing/novitaai","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/ollama","label":"Ollama","docId":"tracing/integrations/listing/ollama","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/openai","label":"OpenAI","docId":"tracing/integrations/listing/openai","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/qwen","label":"Qwen","docId":"tracing/integrations/listing/qwen","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/togetherai","label":"Together AI","docId":"tracing/integrations/listing/togetherai","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/xai-grok","label":"xAI / Grok","docId":"tracing/integrations/listing/xai-grok","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Tools","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/claude_code","label":"Claude Code","docId":"tracing/integrations/listing/claude_code","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/instructor","label":"Instructor","docId":"tracing/integrations/listing/instructor","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Gateways","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/mlflow-ai-gateway","label":"MLflow AI Gateway","docId":"tracing/integrations/listing/mlflow-ai-gateway","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/databricks-ai-gateway","label":"Databricks","docId":"tracing/integrations/listing/databricks-ai-gateway","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/helicone","label":"Helicone","docId":"tracing/integrations/listing/helicone","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/kong","label":"Kong AI Gateway","docId":"tracing/integrations/listing/kong","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/litellm-proxy","label":"LiteLLM Proxy","docId":"tracing/integrations/listing/litellm-proxy","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/openrouter","label":"OpenRouter","docId":"tracing/integrations/listing/openrouter","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/portkey","label":"Portkey","docId":"tracing/integrations/listing/portkey","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/pydantic-ai-gateway","label":"Pydantic AI Gateway","docId":"tracing/integrations/listing/pydantic-ai-gateway","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/truefoundry","label":"TrueFoundry","docId":"tracing/integrations/listing/truefoundry","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/listing/vercel-ai-gateway","label":"Vercel AI Gateway","docId":"tracing/integrations/listing/vercel-ai-gateway","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/integrations/contribute","label":"Add New Integration","docId":"tracing/integrations/contribute","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/tracing/integrations/"},{"type":"category","label":"OpenTelemetry","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/opentelemetry/","label":"Overview","docId":"tracing/opentelemetry/index","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/opentelemetry/ingest","label":"Collect OpenTelemetry Traces into MLflow","docId":"tracing/opentelemetry/ingest","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/opentelemetry/export","label":"Export MLflow Traces/Metrics via OTLP","docId":"tracing/opentelemetry/export","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","href":"/mlflow-website/docs/latest/genai/tracing/faq","label":"FAQ","docId":"tracing/faq","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/tracing/"},{"type":"category","label":"Evaluate & Monitor","className":"sidebar-top-level-category","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/quickstart","label":"Quickstart","docId":"eval-monitor/quickstart","unlisted":false},{"type":"category","label":"Running Evaluations","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/running-evaluation/eval-examples","label":"Examples","docId":"eval-monitor/running-evaluation/eval-examples","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/running-evaluation/prompts","label":"Evaluate Prompts","docId":"eval-monitor/running-evaluation/prompts","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/running-evaluation/agents","label":"Evaluate Agents","docId":"eval-monitor/running-evaluation/agents","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/running-evaluation/traces","label":"Evaluate Traces","docId":"eval-monitor/running-evaluation/traces","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/running-evaluation/multi-turn","label":"Evaluate Conversations","docId":"eval-monitor/running-evaluation/multi-turn","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/automatic-evaluations/","label":"Automatic Evaluation","docId":"eval-monitor/automatic-evaluations/index","unlisted":false},{"type":"category","label":"Judges and Scorers","items":[{"type":"category","label":"Built-in Judges","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/guidelines","label":"Guidelines","docId":"eval-monitor/scorers/llm-judge/guidelines","unlisted":false},{"type":"category","label":"RAG","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/rag/relevance","label":"Answer and Context Relevance","docId":"eval-monitor/scorers/llm-judge/rag/relevance","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/rag/groundedness","label":"Groundedness","docId":"eval-monitor/scorers/llm-judge/rag/groundedness","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/rag/context-sufficiency","label":"Context Sufficiency","docId":"eval-monitor/scorers/llm-judge/rag/context-sufficiency","unlisted":false}],"collapsed":false,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/rag/"},{"type":"category","label":"Response Quality","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/response-quality/safety","label":"Safety","docId":"eval-monitor/scorers/llm-judge/response-quality/safety","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/response-quality/correctness","label":"Correctness","docId":"eval-monitor/scorers/llm-judge/response-quality/correctness","unlisted":false}],"collapsed":false,"collapsible":true},{"type":"category","label":"Tool Call","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/tool-call/correctness","label":"ToolCallCorrectness","docId":"eval-monitor/scorers/llm-judge/tool-call/correctness","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/tool-call/efficiency","label":"ToolCallEfficiency","docId":"eval-monitor/scorers/llm-judge/tool-call/efficiency","unlisted":false}],"collapsed":false,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/tool-call/"},{"type":"category","label":"Third-party Judges","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/third-party/deepeval","label":"DeepEval","docId":"eval-monitor/scorers/third-party/deepeval","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/third-party/ragas","label":"RAGAS","docId":"eval-monitor/scorers/third-party/ragas","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/third-party/phoenix","label":"Arize Phoenix","docId":"eval-monitor/scorers/third-party/phoenix","unlisted":false}],"collapsed":false,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/third-party/"}],"collapsed":true,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/predefined"},{"type":"category","label":"Custom Judges","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/custom-judges/supported-models","label":"Supported Judge Models","docId":"eval-monitor/scorers/llm-judge/custom-judges/supported-models","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/custom-judges/create-custom-judge","label":"Create a Custom Judge","docId":"eval-monitor/scorers/llm-judge/custom-judges/create-custom-judge","unlisted":false}],"collapsed":false,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/custom-judges/"},{"type":"category","label":"Code-based Scorers","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/custom/code-examples","label":"Code-based Scorer Examples","docId":"eval-monitor/scorers/custom/code-examples","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/custom/tutorial","label":"Tutorial: Develop code-based scorers","docId":"eval-monitor/scorers/custom/tutorial","unlisted":false}],"collapsed":false,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/custom/"},{"type":"category","label":"Align with Human Feedback","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/simba","label":"SIMBA Optimizer","docId":"eval-monitor/scorers/llm-judge/simba","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/memalign","label":"MemAlign Optimizer","docId":"eval-monitor/scorers/llm-judge/memalign","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/custom-optimizers","label":"Custom Optimizers","docId":"eval-monitor/scorers/llm-judge/custom-optimizers","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/alignment"},{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/versioning","label":"Versioning Scorers","docId":"eval-monitor/scorers/versioning","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/"},{"type":"category","label":"Evaluation Datasets","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/datasets/sdk-guide","label":"SDK Guide","docId":"datasets/sdk-guide","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/datasets/end-to-end-workflow","label":"End-to-End Workflow","docId":"datasets/end-to-end-workflow","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/datasets/"},{"type":"category","label":"Annotation","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/assessments/feedback","label":"Feedback Collection","docId":"assessments/feedback","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/assessments/expectations","label":"Ground Truth Expectations","docId":"assessments/expectations","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"AI Insights","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/ai-insights/ai-issue-discovery","label":"AI Issue Discovery","docId":"eval-monitor/ai-insights/ai-issue-discovery","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/legacy-llm-evaluation","label":"Migrating from MLflow 2 LLM Evaluation","docId":"eval-monitor/legacy-llm-evaluation","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/eval-monitor/faq","label":"FAQ","docId":"eval-monitor/faq","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/eval-monitor/"},{"type":"category","label":"Prompt Management","className":"sidebar-top-level-category","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/prompt-registry/create-and-edit-prompts","label":"Create and Edit Prompts","docId":"prompt-registry/create-and-edit-prompts","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/prompt-registry/evaluate-prompts","label":"Evaluating Prompts","docId":"prompt-registry/evaluate-prompts","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/prompt-registry/manage-prompt-lifecycles-with-aliases","label":"Manage Prompt Lifecycles","docId":"prompt-registry/manage-prompt-lifecycles-with-aliases","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/prompt-registry/use-prompts-in-apps","label":"Use Prompts in Apps","docId":"prompt-registry/use-prompts-in-apps","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/prompt-registry/log-with-model","label":"Log Prompts with Models","docId":"prompt-registry/log-with-model","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/prompt-registry/structured-output","label":"Structured Output","docId":"prompt-registry/structured-output","unlisted":false},{"type":"category","label":"Optimize Prompts","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/prompt-registry/optimize-prompts/langchain-optimization","label":"LangChain Optimization","docId":"prompt-registry/optimize-prompts/langchain-optimization","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/prompt-registry/optimize-prompts/langgraph-optimization","label":"LangGraph Optimization","docId":"prompt-registry/optimize-prompts/langgraph-optimization","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/prompt-registry/optimize-prompts/openai-agent-optimization","label":"OpenAI Agent Optimization","docId":"prompt-registry/optimize-prompts/openai-agent-optimization","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/prompt-registry/optimize-prompts/pydantic-ai-optimization","label":"Pydantic AI Optimization","docId":"prompt-registry/optimize-prompts/pydantic-ai-optimization","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/prompt-registry/optimize-prompts"},{"type":"link","href":"/mlflow-website/docs/latest/genai/prompt-registry/rewrite-prompts","label":"Auto-rewrite Prompts for New Models \u{1F195}","docId":"prompt-registry/rewrite-prompts","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/prompt-registry/prompt-engineering","label":"Prompt Engineering UI","docId":"prompt-registry/prompt-engineering","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/prompt-registry/"},{"type":"category","label":"AI Gateway","className":"sidebar-top-level-category","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/governance/ai-gateway/quickstart","label":"Quickstart","docId":"governance/ai-gateway/quickstart","unlisted":false},{"type":"category","label":"API Keys","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/governance/ai-gateway/api-keys/create-and-manage","label":"Create and Manage API Keys","docId":"governance/ai-gateway/api-keys/create-and-manage","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/governance/ai-gateway/api-keys/key-rotation","label":"Encryption & Rotation","docId":"governance/ai-gateway/api-keys/key-rotation","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Endpoints","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/governance/ai-gateway/endpoints/create-and-manage","label":"Create and Manage Endpoints","docId":"governance/ai-gateway/endpoints/create-and-manage","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/governance/ai-gateway/endpoints/query-endpoints","label":"Query Endpoints","docId":"governance/ai-gateway/endpoints/query-endpoints","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/governance/ai-gateway/endpoints/model-providers","label":"Model Providers","docId":"governance/ai-gateway/endpoints/model-providers","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","href":"/mlflow-website/docs/latest/genai/governance/ai-gateway/traffic-routing-fallbacks","label":"Traffic Routing & Fallbacks","docId":"governance/ai-gateway/traffic-routing-fallbacks","unlisted":false},{"type":"category","label":"Gateway Server (Legacy)","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/governance/ai-gateway/legacy/setup","label":"Setup","docId":"governance/ai-gateway/legacy/setup","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/governance/ai-gateway/legacy/configuration","label":"Configuration","docId":"governance/ai-gateway/legacy/configuration","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/governance/ai-gateway/legacy/usage","label":"Usage","docId":"governance/ai-gateway/legacy/usage","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/governance/ai-gateway/legacy/"}],"collapsed":true,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/governance/ai-gateway/"},{"type":"html","value":"<b>More Features</b>","defaultStyle":true},{"type":"category","label":"Version Tracking","className":"sidebar-top-level-category","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/version-tracking/quickstart","label":"Quickstart","docId":"version-tracking/quickstart","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/version-tracking/track-application-versions-with-mlflow","label":"Track versions of Git-based applications with MLflow","docId":"version-tracking/track-application-versions-with-mlflow","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/version-tracking/compare-app-versions","label":"Compare App Versions","docId":"version-tracking/compare-app-versions","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/version-tracking/"},{"type":"category","label":"Packaging & Deployment","className":"sidebar-top-level-category","items":[{"type":"category","label":"DSPy","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/flavors/dspy/notebooks/dspy_quickstart","label":"DSPy Quickstart","docId":"flavors/dspy/notebooks/dspy_quickstart-ipynb","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/flavors/dspy/optimizer","label":"Using DSPy Optimizers","docId":"flavors/dspy/optimizer","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/flavors/dspy/"},{"type":"category","label":"LangChain","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/flavors/langchain/guide/","label":"Guide to using LangChain with MLflow","docId":"flavors/langchain/guide/index","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/flavors/langchain/notebooks/langchain-quickstart","label":"LangChain Quickstart","docId":"flavors/langchain/notebooks/langchain-quickstart-ipynb","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/flavors/langchain/notebooks/langchain-retriever","label":"Retrievers with LangChain","docId":"flavors/langchain/notebooks/langchain-retriever-ipynb","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/flavors/langchain/"},{"type":"category","label":"LlamaIndex","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/flavors/llama-index/notebooks/llama_index_quickstart","label":"LlamaIndex Quickstart","docId":"flavors/llama-index/notebooks/llama_index_quickstart-ipynb","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/flavors/llama-index/notebooks/llama_index_workflow_tutorial","label":"Agents with LlamaIndex","docId":"flavors/llama-index/notebooks/llama_index_workflow_tutorial-ipynb","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/flavors/llama-index/"},{"type":"category","label":"Custom Applications","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/flavors/custom-pyfunc-for-llms/notebooks/custom-pyfunc-advanced-llm","label":"Custom App Development Guide","docId":"flavors/custom-pyfunc-for-llms/notebooks/custom-pyfunc-advanced-llm-ipynb","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/flavors/custom-pyfunc-for-llms/"},{"type":"link","href":"/mlflow-website/docs/latest/genai/flavors/chat-model-intro/","label":"Intro to ChatModel","docId":"flavors/chat-model-intro/index","unlisted":false},{"type":"category","label":"Building with ChatModel","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/flavors/chat-model-guide/chat-model-tool-calling","label":"ChatModel Tool Calling Example","docId":"flavors/chat-model-guide/chat-model-tool-calling-ipynb","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/flavors/chat-model-guide/"},{"type":"link","href":"/mlflow-website/docs/latest/genai/flavors/responses-agent-intro","label":"Building with ResponsesAgent","docId":"flavors/responses-agent-intro","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/flavors/"},{"type":"category","label":"MCP","className":"sidebar-top-level-category","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/mcp/","label":"MLflow MCP Server","docId":"mcp/index","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Model Serving","className":"sidebar-top-level-category","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/serving/agent-server","label":"Agent Server","docId":"serving/agent-server","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/serving/responses-agent","label":"Responses Agent","docId":"serving/responses-agent","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/serving/custom-apps","label":"Custom Apps","docId":"serving/custom-apps","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/mlflow-website/docs/latest/genai/serving/"},{"type":"html","value":"<b>References</b>","defaultStyle":true},{"type":"category","label":"Concepts","className":"sidebar-top-level-category","items":[{"type":"link","href":"/mlflow-website/docs/latest/genai/concepts/trace","label":"Trace","docId":"concepts/trace","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/concepts/span","label":"Span","docId":"concepts/span","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/concepts/feedback","label":"Feedback","docId":"concepts/feedback","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/concepts/expectations","label":"Expectations","docId":"concepts/expectations","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/concepts/scorers","label":"Scorers","docId":"concepts/scorers","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/concepts/evaluation-datasets","label":"Evaluation Datasets","docId":"concepts/evaluation-datasets","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","href":"/mlflow-website/docs/latest/genai/references/request-features","label":"Request Features","className":"sidebar-top-level-category","docId":"references/request-features","unlisted":false},{"type":"link","href":"/mlflow-website/docs/latest/genai/getting-started/databricks-trial/","label":"Managed MLflow","className":"sidebar-top-level-category","docId":"getting-started/databricks-trial/index","unlisted":false}]},"docs":{"assessments/expectations":{"id":"assessments/expectations","title":"Ground Truth Expectations","description":"MLflow Expectations provide a systematic way to capture ground truth - the correct or desired outputs that your AI should produce. By establishing these reference points, you create the foundation for meaningful evaluation and continuous improvement of your GenAI applications.","sidebar":"genAISidebar"},"assessments/feedback":{"id":"assessments/feedback","title":"Feedback Collection","description":"MLflow Feedback provides a comprehensive system for capturing quality evaluations from multiple sources - whether automated AI judges, programmatic rules, or human reviewers. This systematic approach to feedback collection enables you to understand and improve your GenAI application\'s performance at scale.","sidebar":"genAISidebar"},"concepts/evaluation-datasets":{"id":"concepts/evaluation-datasets","title":"Evaluation Dataset Concepts","description":"Evaluation Datasets require an MLflow Tracking Server with a SQL backend (PostgreSQL, MySQL, SQLite, or MSSQL).","sidebar":"genAISidebar"},"concepts/expectations":{"id":"concepts/expectations","title":"Expectation Concepts","description":"What are Expectations?","sidebar":"genAISidebar"},"concepts/feedback":{"id":"concepts/feedback","title":"Feedback Concepts","description":"What is Feedback?","sidebar":"genAISidebar"},"concepts/scorers":{"id":"concepts/scorers","title":"Scorer Concepts","description":"What are Scorers?","sidebar":"genAISidebar"},"concepts/span":{"id":"concepts/span","title":"Spans","description":"What is a Span?","sidebar":"genAISidebar"},"concepts/trace":{"id":"concepts/trace","title":"Trace Concepts","description":"What is Tracing?","sidebar":"genAISidebar"},"concepts/trace/feedback":{"id":"concepts/trace/feedback","title":"Feedback Concepts","description":"This guide introduces the core concepts of feedback and assessment in MLflow\'s GenAI evaluation framework. Understanding these concepts is essential for effectively measuring and improving the quality of your GenAI applications."},"datasets/end-to-end-workflow":{"id":"datasets/end-to-end-workflow","title":"End-to-End Workflow: Evaluation-Driven Development","description":"This guide demonstrates the complete workflow for building and evaluating GenAI applications using MLflow\'s evaluation-driven development approach.","sidebar":"genAISidebar"},"datasets/index":{"id":"datasets/index","title":"Building MLflow evaluation datasets","description":"To systematically test and improve a GenAI application, you use an evaluation dataset. An evaluation dataset is a selected set of example inputs \u2014 either labeled (with known expected outputs, i.e. ground-truth expectations) or unlabeled (without ground-truth). Evaluation datasets help you improve your app\'s performance in the following ways:","sidebar":"genAISidebar"},"datasets/sdk-guide":{"id":"datasets/sdk-guide","title":"Evaluation Datasets SDK Reference","description":"Complete API reference for creating, managing, and querying evaluation datasets programmatically.","sidebar":"genAISidebar"},"eval-monitor/ai-insights/ai-issue-discovery":{"id":"eval-monitor/ai-insights/ai-issue-discovery","title":"AI Issue Discovery","description":"Automatically analyze traces in your MLflow experiments to find operational issues, quality problems, and performance patterns. The Analyze Experiment tool uses hypothesis-driven analysis to systematically examine your GenAI application\'s behavior, identify the most important problems, and create a plan for addressing them in the form of a comprehensive markdown report.","sidebar":"genAISidebar"},"eval-monitor/automatic-evaluations/index":{"id":"eval-monitor/automatic-evaluations/index","title":"Automatic Evaluation","description":"Automatically evaluate traces and multi-turn conversations as they\'re logged - no code required","sidebar":"genAISidebar"},"eval-monitor/faq":{"id":"eval-monitor/faq","title":"Evaluate & Monitor FAQ","description":"This page addresses frequently asked questions about MLflow\'s GenAI evaluation.","sidebar":"genAISidebar"},"eval-monitor/index":{"id":"eval-monitor/index","title":"Evaluating LLMs/Agents with MLflow","description":"This documentation covers MLflow\'s GenAI evaluation system which uses:","sidebar":"genAISidebar"},"eval-monitor/legacy-llm-evaluation":{"id":"eval-monitor/legacy-llm-evaluation","title":"Migrating from Legacy LLM Evaluation","description":"LLM evaluation involves assessing how well a model performs on a task. MLflow provides a simple API to evaluate your LLMs with popular metrics.","sidebar":"genAISidebar"},"eval-monitor/notebooks/quickstart-eval-ipynb":{"id":"eval-monitor/notebooks/quickstart-eval-ipynb","title":"GenAI Evaluation Quickstart","description":"Download this notebook"},"eval-monitor/quickstart":{"id":"eval-monitor/quickstart","title":"GenAI Evaluation Quickstart","description":"Need help setting up evaluation? Try MLflow Assistant - a powerful AI assistant that can help you set up evaluation for your project.","sidebar":"genAISidebar"},"eval-monitor/running-evaluation/agents":{"id":"eval-monitor/running-evaluation/agents","title":"Evaluating Agents","description":"AI Agents are an emerging pattern of GenAI applications that can use tools, make decisions, and execute multi-step workflows. However, evaluating the performance of those complex agents is challenging. MLflow provides a powerful toolkit to systematically evaluate the agent behavior precisely using traces and scorers.","sidebar":"genAISidebar"},"eval-monitor/running-evaluation/eval-examples":{"id":"eval-monitor/running-evaluation/eval-examples","title":"MLflow evaluation examples for GenAI","description":"This page presents some common usage patterns for the evaluation harness, including data patterns and predict_fn patterns.","sidebar":"genAISidebar"},"eval-monitor/running-evaluation/multi-turn":{"id":"eval-monitor/running-evaluation/multi-turn","title":"Evaluate Conversations","description":"Conversation evaluation enables you to assess entire conversation sessions rather than individual turns. This is essential for evaluating conversational AI systems where quality emerges over multiple interactions, such as user frustration patterns, conversation completeness, or overall dialogue coherence.","sidebar":"genAISidebar"},"eval-monitor/running-evaluation/prompts":{"id":"eval-monitor/running-evaluation/prompts","title":"Evaluating Prompts","description":"Prompts are the core components of GenAI applications. However, iterating over prompts can be challenging because it is hard to know if the new prompt is better than the old one. MLflow provides a framework to systematically evaluate prompt templates and track performance over time.","sidebar":"genAISidebar"},"eval-monitor/running-evaluation/traces":{"id":"eval-monitor/running-evaluation/traces","title":"Evaluating (Production) Traces","description":"Traces are the core data of MLflow. They capture the complete execution flow of your LLM applications. Evaluating traces is a powerful way to understand the performance of your LLM applications and get insights for quality improvement.","sidebar":"genAISidebar"},"eval-monitor/scorers/custom/code-examples":{"id":"eval-monitor/scorers/custom/code-examples","title":"Code-based scorer examples","description":"In MLflow Evaluation for GenAI, custom code-based scorers allow you to define flexible evaluation metrics for your AI agent or application. This set of examples illustrate many patterns for using code-based scorers with different options for inputs, outputs, implementation, and error handling.","sidebar":"genAISidebar"},"eval-monitor/scorers/custom/index":{"id":"eval-monitor/scorers/custom/index","title":"Create custom code-based scorers","description":"Custom code-based scorers offer the ultimate flexibility to define precisely how your GenAI application\'s quality is measured. You can define evaluation metrics tailored to your specific business use case, whether based on simple heuristics, advanced logic, or programmatic evaluations.","sidebar":"genAISidebar"},"eval-monitor/scorers/custom/tutorial":{"id":"eval-monitor/scorers/custom/tutorial","title":"Develop code-based scorers","description":"In MLflow Evaluation for GenAI, custom code-based scorers allow you to define flexible evaluation metrics for your AI agent or application.","sidebar":"genAISidebar"},"eval-monitor/scorers/index":{"id":"eval-monitor/scorers/index","title":"LLM Judges and Scorers","description":"Judges are a key component of the MLflow GenAI evaluation framework. They provide a unified interface to define evaluation criteria for your models, agents, and applications. Like their name suggests, judges judge how well your application did based on the evaluation criteria. This could be a pass/fail, true/false, numerical value, or a categorical value.","sidebar":"genAISidebar"},"eval-monitor/scorers/llm-judge/alignment":{"id":"eval-monitor/scorers/llm-judge/alignment","title":"Judge Alignment: Teaching AI to Match Human Preferences","description":"Transform Generic Judges into Domain Experts","sidebar":"genAISidebar"},"eval-monitor/scorers/llm-judge/custom-judges/create-custom-judge":{"id":"eval-monitor/scorers/llm-judge/custom-judges/create-custom-judge","title":"Create a custom judge using make_judge()","description":"Custom judges are LLM-based judges that evaluate your GenAI agents against specific quality criteria. This tutorial shows you how to create custom judges and use them to evaluate a customer support agent using make_judge().","sidebar":"genAISidebar"},"eval-monitor/scorers/llm-judge/custom-judges/index":{"id":"eval-monitor/scorers/llm-judge/custom-judges/index","title":"Custom Judges","description":"Custom LLM judges let you define complex and nuanced judging guidelines for GenAI applications using natural language.","sidebar":"genAISidebar"},"eval-monitor/scorers/llm-judge/custom-judges/supported-models":{"id":"eval-monitor/scorers/llm-judge/custom-judges/supported-models","title":"Supported Models","description":"AI Gateway Endpoints","sidebar":"genAISidebar"},"eval-monitor/scorers/llm-judge/custom-optimizers":{"id":"eval-monitor/scorers/llm-judge/custom-optimizers","title":"Custom Alignment Optimizers","description":"MLflow\'s alignment system is designed as a plugin architecture, allowing you to create custom optimizers for different alignment strategies. This extensibility enables you to implement domain-specific optimization approaches while leveraging MLflow\'s judge infrastructure.","sidebar":"genAISidebar"},"eval-monitor/scorers/llm-judge/gepa":{"id":"eval-monitor/scorers/llm-judge/gepa","title":"GEPA Alignment Optimizer","description":"MLflow provides the GEPA alignment optimizer using DSPy\'s implementation of GEPA (Genetic-Pareto). GEPA uses LLM-driven reflection to analyze execution traces and iteratively propose improved judge instructions based on human feedback."},"eval-monitor/scorers/llm-judge/guidelines":{"id":"eval-monitor/scorers/llm-judge/guidelines","title":"Create a guidelines LLM Judge","description":"Guidelines LLM judges use pass/fail natural language criteria to evaluate GenAI outputs. They excel at evaluating:","sidebar":"genAISidebar"},"eval-monitor/scorers/llm-judge/memalign":{"id":"eval-monitor/scorers/llm-judge/memalign","title":"MemAlign Optimizer (Experimental)","description":"MemAlign is an experimental optimizer. The API may change in future releases.","sidebar":"genAISidebar"},"eval-monitor/scorers/llm-judge/predefined":{"id":"eval-monitor/scorers/llm-judge/predefined","title":"Built-in LLM Judges","description":"MLflow provides several pre-configured LLM judges optimized for common evaluation scenarios.","sidebar":"genAISidebar"},"eval-monitor/scorers/llm-judge/prompt":{"id":"eval-monitor/scorers/llm-judge/prompt","title":"Bring Your Own Prompts","description":"The custompromptjudge API is being phased out. We strongly recommend using the make_judge API instead, which provides:"},"eval-monitor/scorers/llm-judge/rag/context-sufficiency":{"id":"eval-monitor/scorers/llm-judge/rag/context-sufficiency","title":"RetrievalSufficiency judge","description":"The RetrievalSufficiency judge evaluates whether the retrieved context (from RAG applications, agents, or any system that retrieves documents) contains enough information to adequately answer the user\'s request based on the ground truth label provided as expectedfacts or an expectedresponse.","sidebar":"genAISidebar"},"eval-monitor/scorers/llm-judge/rag/groundedness":{"id":"eval-monitor/scorers/llm-judge/rag/groundedness","title":"RetrievalGroundedness judge","description":"The RetrievalGroundedness judge assesses whether your application\'s response is factually supported by the provided context (either from a RAG system or generated by a tool call), helping detect hallucinations or statements not backed by that context.","sidebar":"genAISidebar"},"eval-monitor/scorers/llm-judge/rag/index":{"id":"eval-monitor/scorers/llm-judge/rag/index","title":"RAG Evaluation with Built-in Judges","description":"Retrieval-Augmented Generation (RAG) systems combine retrieval and generation to provide contextually relevant responses. Evaluating RAG applications requires assessing both the retrieval quality (are the right documents retrieved?) and the generation quality (is the response grounded in those documents?).","sidebar":"genAISidebar"},"eval-monitor/scorers/llm-judge/rag/relevance":{"id":"eval-monitor/scorers/llm-judge/rag/relevance","title":"Answer and Context Relevance Judges","description":"MLflow provides two built-in LLM judges to assess relevance in your GenAI applications. These judges help diagnose quality issues - if context isn\'t relevant, the generation step cannot produce a helpful response.","sidebar":"genAISidebar"},"eval-monitor/scorers/llm-judge/response-quality/correctness":{"id":"eval-monitor/scorers/llm-judge/response-quality/correctness","title":"Correctness Judge","description":"The Correctness judge assesses whether your GenAI application\'s response is factually correct by comparing it against provided ground truth information (expectedfacts or expectedresponse).","sidebar":"genAISidebar"},"eval-monitor/scorers/llm-judge/response-quality/safety":{"id":"eval-monitor/scorers/llm-judge/response-quality/safety","title":"Safety Judge","description":"The Safety judge assesses the safety of given content (whether generated by the application or provided by a user), checking for harmful, unethical, or inappropriate material.","sidebar":"genAISidebar"},"eval-monitor/scorers/llm-judge/simba":{"id":"eval-monitor/scorers/llm-judge/simba","title":"SIMBA Alignment Optimizer","description":"MLflow provides the default alignment optimizer using DSPy\'s implementation of SIMBA (Simplified Multi-Bootstrap Aggregation). When you call align() without specifying an optimizer, the SIMBA optimizer is used automatically.","sidebar":"genAISidebar"},"eval-monitor/scorers/llm-judge/tool-call/correctness":{"id":"eval-monitor/scorers/llm-judge/tool-call/correctness","title":"ToolCallCorrectness Judge","description":"The ToolCallCorrectness judge evaluates whether the tools called by an agent and the arguments they are called with are correct given the user request.","sidebar":"genAISidebar"},"eval-monitor/scorers/llm-judge/tool-call/efficiency":{"id":"eval-monitor/scorers/llm-judge/tool-call/efficiency","title":"ToolCallEfficiency Judge","description":"The ToolCallEfficiency judge evaluates the agent\'s trajectory for redundancy in tool usage, such as tool calls with the same or similar arguments.","sidebar":"genAISidebar"},"eval-monitor/scorers/llm-judge/tool-call/index":{"id":"eval-monitor/scorers/llm-judge/tool-call/index","title":"Tool Call Evaluation with Built-in Judges","description":"AI agents often use tools (functions) to complete tasks - from fetching data to performing calculations. Evaluating tool-calling applications requires assessing whether agents select appropriate tools and provide correct arguments to fulfill user requests.","sidebar":"genAISidebar"},"eval-monitor/scorers/llm-judge/workflow":{"id":"eval-monitor/scorers/llm-judge/workflow","title":"End-to-End Judge Workflow","description":"Complete workflow for developing, testing, and deploying custom LLM judges"},"eval-monitor/scorers/third-party/deepeval":{"id":"eval-monitor/scorers/third-party/deepeval","title":"DeepEval","description":"DeepEval is a comprehensive evaluation framework for LLM applications that provides metrics for RAG systems, agents, conversational AI, and safety evaluation. MLflow\'s DeepEval integration allows you to use most DeepEval metrics as MLflow scorers.","sidebar":"genAISidebar"},"eval-monitor/scorers/third-party/index":{"id":"eval-monitor/scorers/third-party/index","title":"Third-party Scorers","description":"MLflow integrates with popular third-party evaluation frameworks, allowing you to leverage their specialized metrics within MLflow\'s evaluation workflow. This provides access to third party library\'s evaluation metrics while maintaining a consistent MLflow interface.","sidebar":"genAISidebar"},"eval-monitor/scorers/third-party/phoenix":{"id":"eval-monitor/scorers/third-party/phoenix","title":"Arize Phoenix","description":"Arize Phoenix is an open-source LLM observability and evaluation framework from Arize AI. MLflow\'s Phoenix integration allows you to use Phoenix evaluators as MLflow scorers for detecting hallucinations, evaluating relevance, identifying toxicity, and more.","sidebar":"genAISidebar"},"eval-monitor/scorers/third-party/ragas":{"id":"eval-monitor/scorers/third-party/ragas","title":"RAGAS","description":"RAGAS (Retrieval Augmented Generation Assessment) is an evaluation framework designed for LLM applications. MLflow\'s RAGAS integration allows you to use RAGAS metrics as MLflow judges for evaluating retrieval quality, answer generation, and other aspects of LLM applications.","sidebar":"genAISidebar"},"eval-monitor/scorers/versioning":{"id":"eval-monitor/scorers/versioning","title":"Registering and Versioning Scorers","description":"Scorers can be registered to MLflow experiments for version control and team collaboration.","sidebar":"genAISidebar"},"flavors/chat-model-guide/chat-model-tool-calling-ipynb":{"id":"flavors/chat-model-guide/chat-model-tool-calling-ipynb","title":"Build a tool-calling model with mlflow.pyfunc.ChatModel","description":"Download this notebook","sidebar":"genAISidebar"},"flavors/chat-model-guide/index":{"id":"flavors/chat-model-guide/index","title":"Tutorial: Custom GenAI Models using ChatModel","description":"Starting in MLflow 3.0.0, we recommend ResponsesAgent instead of ChatModel. See more details in the ResponsesAgent Introduction.","sidebar":"genAISidebar"},"flavors/chat-model-intro/index":{"id":"flavors/chat-model-intro/index","title":"Tutorial: Getting Started with ChatModel","description":"Starting in MLflow 3.0.0, we recommend ResponsesAgent instead of ChatModel. See more details in the ResponsesAgent Introduction.","sidebar":"genAISidebar"},"flavors/custom-pyfunc-for-llms/index":{"id":"flavors/custom-pyfunc-for-llms/index","title":"Deploying Advanced LLMs with Custom PyFuncs in MLflow","description":"Starting in MLflow 3.0.0, we recommend ResponsesAgent instead of ChatModel. See more details in the ResponsesAgent Introduction.","sidebar":"genAISidebar"},"flavors/custom-pyfunc-for-llms/notebooks/custom-pyfunc-advanced-llm-ipynb":{"id":"flavors/custom-pyfunc-for-llms/notebooks/custom-pyfunc-advanced-llm-ipynb","title":"Serving LLMs with MLflow: Leveraging Custom PyFunc","description":"Download this notebook","sidebar":"genAISidebar"},"flavors/dspy/index":{"id":"flavors/dspy/index","title":"MLflow DSPy Flavor","description":"The dspy flavor is under active development and is marked as Experimental. Public APIs are","sidebar":"genAISidebar"},"flavors/dspy/notebooks/dspy_quickstart-ipynb":{"id":"flavors/dspy/notebooks/dspy_quickstart-ipynb","title":"DSPy Quickstart","description":"Download this notebook","sidebar":"genAISidebar"},"flavors/dspy/optimizer":{"id":"flavors/dspy/optimizer","title":"DSPy Optimizer Autologging","description":"A DSPy optimizer is an algorithm that tunes the parameters of a DSPy program (i.e., the prompts and/or the LM weights) to maximize the metrics you specify.","sidebar":"genAISidebar"},"flavors/index":{"id":"flavors/index","title":"MLflow GenAI Packaging Integrations","description":"MLflow 3 delivers built-in support for packaging and deploying applications written with the GenAI frameworks you depend on. Whether you\'re orchestrating chains with LangChain or LangGraph, indexing documents in LlamaIndex, wiring up agent patterns via ChatModel and ResponseAgent, or rolling your own with a PythonModel, MLflow provides native packaging and deployment APIs (\\"flavors\\") to streamline your path to production.","sidebar":"genAISidebar"},"flavors/langchain/autologging":{"id":"flavors/langchain/autologging","title":"MLflow Langchain Autologging","description":"MLflow LangChain flavor supports autologging, a powerful feature that allows you to log crucial details about the LangChain model and execution without the need for explicit logging statements. MLflow LangChain autologging covers various aspects of the model, including traces, models, signatures and more."},"flavors/langchain/guide/index":{"id":"flavors/langchain/guide/index","title":"LangChain within MLflow (Experimental)","description":"The langchain flavor is currently under active development and is marked as Experimental. Public APIs are evolving, and new features are being added to enhance its functionality.","sidebar":"genAISidebar"},"flavors/langchain/index":{"id":"flavors/langchain/index","title":"MLflow LangChain Flavor","description":"The langchain flavor is under active development and is marked as Experimental. Public APIs are","sidebar":"genAISidebar"},"flavors/langchain/notebooks/langchain-quickstart-ipynb":{"id":"flavors/langchain/notebooks/langchain-quickstart-ipynb","title":"Introduction to Using LangChain with MLflow","description":"Download this notebook","sidebar":"genAISidebar"},"flavors/langchain/notebooks/langchain-retriever-ipynb":{"id":"flavors/langchain/notebooks/langchain-retriever-ipynb","title":"Introduction to RAG with MLflow and LangChain","description":"Download this notebook","sidebar":"genAISidebar"},"flavors/llama-index/index":{"id":"flavors/llama-index/index","title":"MLflow LlamaIndex Flavor","description":"Introduction","sidebar":"genAISidebar"},"flavors/llama-index/notebooks/llama_index_quickstart-ipynb":{"id":"flavors/llama-index/notebooks/llama_index_quickstart-ipynb","title":"Introduction to Using LlamaIndex with MLflow","description":"Download this notebook","sidebar":"genAISidebar"},"flavors/llama-index/notebooks/llama_index_workflow_tutorial-ipynb":{"id":"flavors/llama-index/notebooks/llama_index_workflow_tutorial-ipynb","title":"Building a Tool-calling Agent with LlamaIndex Workflow and MLflow","description":"Download this notebook","sidebar":"genAISidebar"},"flavors/responses-agent-intro":{"id":"flavors/responses-agent-intro","title":"ResponsesAgent Introduction","description":"What is a ResponsesAgent?","sidebar":"genAISidebar"},"getting-started/connect-environment":{"id":"getting-started/connect-environment","title":"Set Up MLflow Server","description":"Learn how to setup the MLflow server for GenAI application development.","sidebar":"genAISidebar"},"getting-started/databricks-trial/index":{"id":"getting-started/databricks-trial/index","title":"Try Managed MLflow","description":"The Databricks Free Trial offers an opportunity to experience the Databricks platform without prior cloud provider access.","sidebar":"genAISidebar"},"getting-started/index":{"id":"getting-started/index","title":"Getting Started with MLflow for GenAI","description":"Build, evaluate, and deploy production-ready GenAI applications with MLflow\'s comprehensive LLMOps platform"},"getting-started/try-assistant":{"id":"getting-started/try-assistant","title":"MLflow Assistant","description":"Supercharge your MLflow workflow with AI-powered coding assistants that understand your codebase and can set up MLflow automatically.","sidebar":"genAISidebar"},"governance/ai-gateway/api-keys/create-and-manage":{"id":"governance/ai-gateway/api-keys/create-and-manage","title":"Create and Manage API Keys","description":"API keys serve as reusable credentials that can be shared across multiple endpoints. When you have several endpoints using the same provider, this approach simplifies both initial setup and ongoing credential management.","sidebar":"genAISidebar"},"governance/ai-gateway/api-keys/key-rotation":{"id":"governance/ai-gateway/api-keys/key-rotation","title":"Encryption & Rotation","description":"This page covers API key security, including encryption configuration and credential rotation best practices.","sidebar":"genAISidebar"},"governance/ai-gateway/endpoints/create-and-manage":{"id":"governance/ai-gateway/endpoints/create-and-manage","title":"Create and Manage Endpoints","description":"Endpoints define how requests are routed to AI models. Each endpoint can use a single model or leverage advanced routing features like traffic splitting and fallbacks.","sidebar":"genAISidebar"},"governance/ai-gateway/endpoints/model-providers":{"id":"governance/ai-gateway/endpoints/model-providers","title":"Model Providers","description":"MLflow AI Gateway supports 100+ model providers through the LiteLLM integration. This page covers the major providers, their capabilities, and how to use their passthrough APIs.","sidebar":"genAISidebar"},"governance/ai-gateway/endpoints/query-endpoints":{"id":"governance/ai-gateway/endpoints/query-endpoints","title":"Query Endpoints","description":"Once you\'ve created an endpoint, you can call it through several different API styles depending on your needs.","sidebar":"genAISidebar"},"governance/ai-gateway/index":{"id":"governance/ai-gateway/index","title":"MLflow AI Gateway","description":"MLflow AI Gateway provides a unified interface for deploying and managing multiple LLM providers within your organization. It simplifies interactions with services like OpenAI, Anthropic, and others through a single, secure endpoint.","sidebar":"genAISidebar"},"governance/ai-gateway/legacy/configuration":{"id":"governance/ai-gateway/legacy/configuration","title":"AI Gateway Server Configuration","description":"Configure providers, endpoints, and advanced settings for your MLflow AI Gateway.","sidebar":"genAISidebar"},"governance/ai-gateway/legacy/index":{"id":"governance/ai-gateway/legacy/index","title":"Gateway Server (Legacy)","description":"The Gateway Server provides a YAML-based configuration approach for deploying and managing LLM endpoints. This legacy method offers flexibility for users who prefer file-based configuration and command-line server management.","sidebar":"genAISidebar"},"governance/ai-gateway/legacy/setup":{"id":"governance/ai-gateway/legacy/setup","title":"AI Gateway Server Setup","description":"Get your MLflow AI Gateway up and running quickly with this step-by-step setup guide.","sidebar":"genAISidebar"},"governance/ai-gateway/legacy/usage":{"id":"governance/ai-gateway/legacy/usage","title":"AI Gateway Server Usage","description":"Learn how to query your AI Gateway endpoints, integrate with applications, and leverage different APIs and tools.","sidebar":"genAISidebar"},"governance/ai-gateway/quickstart":{"id":"governance/ai-gateway/quickstart","title":"Quickstart","description":"Get your AI Gateway running in minutes with this simple walkthrough.","sidebar":"genAISidebar"},"governance/ai-gateway/traffic-routing-fallbacks":{"id":"governance/ai-gateway/traffic-routing-fallbacks","title":"Traffic Routing & Fallbacks","description":"Beyond basic endpoint configuration, MLflow AI Gateway supports advanced routing features that enable traffic splitting for A/B testing and automatic fallbacks for high availability.","sidebar":"genAISidebar"},"index":{"id":"index","title":"MLflow GenAI: Ship High-quality GenAI, Fast","description":"MLflow GenAI is an open-source, all-in-one integrated platform that helps enhance your Agent & GenAI applications with end-to-end observability, evaluations, AI gateway, prompt management & optimization and tracking.","sidebar":"genAISidebar"},"mcp/index":{"id":"mcp/index","title":"MLflow MCP Server","description":"- This feature is experimental and may change in future releases.","sidebar":"genAISidebar"},"prompt-registry/create-and-edit-prompts":{"id":"prompt-registry/create-and-edit-prompts","title":"Create and Edit Prompts","description":"Learn how to create new prompts and edit existing ones in the MLflow Prompt Registry using both the UI and Python APIs.","sidebar":"genAISidebar"},"prompt-registry/evaluate-prompts":{"id":"prompt-registry/evaluate-prompts","title":"Evaluating Prompts","description":"Combining MLflow Prompt Registry with MLflow LLM Evaluation enables you to evaluate prompt performance across different models and datasets, and track the evaluation results in a centralized registry. You can also inspect model outputs from the traces logged during evaluation to understand how the model responds to different prompts.","sidebar":"genAISidebar"},"prompt-registry/index":{"id":"prompt-registry/index","title":"Prompt Registry","description":"MLflow Prompt Registry","sidebar":"genAISidebar"},"prompt-registry/log-with-model":{"id":"prompt-registry/log-with-model","title":"Log Prompts with Models","description":"Prompts are often used as a part of GenAI applications. Managing the association between prompts and models is crucial for tracking the evolution of models and ensuring consistency across different environments. MLflow Prompt Registry is integrated with MLflow\'s model tracking capability, allowing you to track which prompts (and versions) are used by your models and applications.","sidebar":"genAISidebar"},"prompt-registry/manage-prompt-lifecycles-with-aliases":{"id":"prompt-registry/manage-prompt-lifecycles-with-aliases","title":"Manage Prompt Lifecycles","description":"Discover how to use aliases in the MLflow Prompt Registry to manage the lifecycle of your prompts, from development to production, and for implementing governance.","sidebar":"genAISidebar"},"prompt-registry/optimize-prompts":{"id":"prompt-registry/optimize-prompts","title":"Optimize Prompts","description":"The simple way to continuously improve your AI agents and prompts.","sidebar":"genAISidebar"},"prompt-registry/optimize-prompts/langchain-optimization":{"id":"prompt-registry/optimize-prompts/langchain-optimization","title":"Optimizing Prompts for LangChain","description":"This guide demonstrates how to leverage  alongside LangChain to enhance your chain\'s prompts automatically. The  API is framework-agnostic, enabling you to perform end-to-end prompt optimization of your chains from any framework using state-of-the-art techniques. For more information about the API, please visit Optimize Prompts.","sidebar":"genAISidebar"},"prompt-registry/optimize-prompts/langgraph-optimization":{"id":"prompt-registry/optimize-prompts/langgraph-optimization","title":"Optimizing Prompts for LangGraph","description":"This guide demonstrates how to leverage  alongside LangGraph to enhance your agent\'s prompts automatically. The  API is framework-agnostic, enabling you to perform end-to-end prompt optimization of your graphs from any framework using state-of-the-art techniques. For more information about the API, please visit Optimize Prompts.","sidebar":"genAISidebar"},"prompt-registry/optimize-prompts/openai-agent-optimization":{"id":"prompt-registry/optimize-prompts/openai-agent-optimization","title":"Optimizing Prompts for OpenAI Agents","description":"This guide demonstrates how to leverage  alongside the OpenAI Agent framework to enhance your agent\'s prompts automatically. The  API is framework-agnostic, enabling you to perform end-to-end prompt optimization of your agents from any framework using state-of-the-art techniques. For more information about the API, please visit Optimize Prompts.","sidebar":"genAISidebar"},"prompt-registry/optimize-prompts/pydantic-ai-optimization":{"id":"prompt-registry/optimize-prompts/pydantic-ai-optimization","title":"Optimizing Prompts for Pydantic AI","description":"This guide demonstrates how to leverage  alongside Pydantic AI to enhance your agent\'s prompts automatically. The  API is framework-agnostic, enabling you to perform end-to-end prompt optimization of your agents from any framework using state-of-the-art techniques. For more information about the API, please visit Optimize Prompts.","sidebar":"genAISidebar"},"prompt-registry/prompt-engineering":{"id":"prompt-registry/prompt-engineering","title":"Prompt Engineering UI (Experimental)","description":"Starting in MLflow 2.7, the MLflow Tracking UI provides a best-in-class experience for prompt","sidebar":"genAISidebar"},"prompt-registry/rewrite-prompts":{"id":"prompt-registry/rewrite-prompts","title":"Auto-rewrite Prompts for New Models (Experimental)","description":"When migrating to a new language model, you often discover that your carefully crafted prompts don\'t work as well with the new model. MLflow\'s  API helps you automatically rewrite prompts to maintain output quality when switching models, using your existing application\'s outputs as training data.","sidebar":"genAISidebar"},"prompt-registry/structured-output":{"id":"prompt-registry/structured-output","title":"Structured Output","description":"Learn how to define structured output schemas for your prompts to ensure consistent and validated responses from language models.","sidebar":"genAISidebar"},"prompt-registry/use-prompts-in-apps":{"id":"prompt-registry/use-prompts-in-apps","title":"Use Prompts in Apps","description":"Learn how to integrate prompts from the MLflow Prompt Registry into your applications and link them to MLflow Models for end-to-end lineage.","sidebar":"genAISidebar"},"references/request-features":{"id":"references/request-features","title":"Request Features","description":"Your feedback drives our roadmap! Vote on the most requested features (\u{1F44D}) and share your ideas to help us build what matters most to you.","sidebar":"genAISidebar"},"serving/agent-server":{"id":"serving/agent-server","title":"MLflow Agent Server","description":"Agent Server Features","sidebar":"genAISidebar"},"serving/custom-apps":{"id":"serving/custom-apps","title":"Custom Serving Applications","description":"MLflow\'s custom serving applications allow you to build sophisticated model serving solutions that go beyond simple prediction endpoints. Using the PyFunc framework, you can create custom applications with complex preprocessing, postprocessing, multi-model inference, and business logic integration.","sidebar":"genAISidebar"},"serving/index":{"id":"serving/index","title":"MLflow Model Serving","description":"Transform your trained models into production-ready inference servers with MLflow\'s comprehensive serving capabilities. Deploy locally, in the cloud, or through managed endpoints with standardized REST APIs.","sidebar":"genAISidebar"},"serving/responses-agent":{"id":"serving/responses-agent","title":"ResponsesAgent for Model Serving","description":"The ResponsesAgent class in MLflow provides a specialized interface for serving generative AI models that handle structured responses with tool calling capabilities. This agent is designed to work seamlessly with MLflow\'s serving infrastructure while providing compatibility with OpenAI-style APIs.","sidebar":"genAISidebar"},"tracing/app-instrumentation/automatic":{"id":"tracing/app-instrumentation/automatic","title":"Automatic Tracing","description":"MLflow Tracing is integrated with various GenAI libraries and provides one-line automatic tracing experience for each library (and the combination of them!). This page shows detailed examples to integrate MLflow with popular GenAI libraries.","sidebar":"genAISidebar"},"tracing/app-instrumentation/distributed-tracing":{"id":"tracing/app-instrumentation/distributed-tracing","title":"Propagate Trace Context Across Services","description":"When your application spans multiple services, you may want to connect spans from these services into a single trace for tracking the end to end execution in one place. MLflow support this via Distributed Tracing, by propagating the active trace context over HTTP so spans recorded in different services.","sidebar":"genAISidebar"},"tracing/app-instrumentation/manual-tracing":{"id":"tracing/app-instrumentation/manual-tracing","title":"Manual Tracing","description":"In addition to the Auto Tracing integrations, you can instrument your GenAI application by using MLflow\'s manual tracing APIs.","sidebar":"genAISidebar"},"tracing/app-instrumentation/opentelemetry":{"id":"tracing/app-instrumentation/opentelemetry","title":"Tracing with OpenTelemetry","description":"OpenTelemetry is a CNCF-backed project that provides vendor-neutral observability APIs and SDKs to collect telemetry data from your applications. MLflow Tracing is fully compatible with OpenTelemetry, making it free from vendor lock-in.","sidebar":"genAISidebar"},"tracing/attach-tags/index":{"id":"tracing/attach-tags/index","title":"Setting Trace Tags","description":"Tags are mutable key-value pairs that you can attach to traces to add valuable labels and context for grouping and filtering traces. For example, you can tag traces based on the topic of the user\'s input or the type of request being processed and group them together for analysis and quality evaluation.","sidebar":"genAISidebar"},"tracing/collect-user-feedback/index":{"id":"tracing/collect-user-feedback/index","title":"Collect User Feedback","description":"Capturing user feedback is critical for understanding the real-world quality of your GenAI application. MLflow\'s Feedback API provides a structured, standardized approach to collecting, storing, and analyzing user feedback directly within your traces.","sidebar":"genAISidebar"},"tracing/faq":{"id":"tracing/faq","title":"Tracing FAQ","description":"Getting Started and Basic Usage","sidebar":"genAISidebar"},"tracing/index":{"id":"tracing/index","title":"MLflow Tracing for LLM Observability","description":"MLflow Tracing is a fully OpenTelemetry-compatible LLM observability solution for your applications. It captures the inputs, outputs, and metadata associated with each intermediate step of a request, enabling you to easily pinpoint the source of bugs and unexpected behaviors.","sidebar":"genAISidebar"},"tracing/integrations/contribute":{"id":"tracing/integrations/contribute","title":"Contributing to MLflow Tracing","description":"Welcome to the MLflow Tracing contribution guide! This step-by-step resource will assist you in implementing additional GenAI library integrations for tracing into MLflow.","sidebar":"genAISidebar"},"tracing/integrations/index":{"id":"tracing/integrations/index","title":"Auto Tracing Integrations","description":"MLflow Tracing is integrated with 40+ popular Generative AI libraries and frameworks, offering one-line automatic tracing experience. This allows you to gain immediate observability into your GenAI applications with minimal setup.","sidebar":"genAISidebar"},"tracing/integrations/listing/ag2":{"id":"tracing/integrations/listing/ag2","title":"Tracing AG2\u{1F916}","description":"AG2 Tracing via autolog","sidebar":"genAISidebar"},"tracing/integrations/listing/agno":{"id":"tracing/integrations/listing/agno","title":"Tracing Agno","description":"Agno is a flexible agent framework for orchestrating LLMs, reasoning steps, tools, and memory into a unified pipeline.","sidebar":"genAISidebar"},"tracing/integrations/listing/anthropic":{"id":"tracing/integrations/listing/anthropic","title":"Tracing Anthropic","description":"MLflow Tracing provides automatic tracing capability for Anthropic LLMs. By enabling auto tracing","sidebar":"genAISidebar"},"tracing/integrations/listing/autogen":{"id":"tracing/integrations/listing/autogen","title":"Tracing AutoGen","description":"AutoGen tracing via autolog","sidebar":"genAISidebar"},"tracing/integrations/listing/bedrock":{"id":"tracing/integrations/listing/bedrock","title":"Tracing Amazon Bedrock with MLflow","description":"MLflow supports automatic tracing for Amazon Bedrock, a fully managed service on AWS that provides high-performing","sidebar":"genAISidebar"},"tracing/integrations/listing/bedrock-agentcore":{"id":"tracing/integrations/listing/bedrock-agentcore","title":"Tracing Amazon Bedrock AgentCore","description":"Enable OpenTelemetry in Amazon Bedrock AgentCore","sidebar":"genAISidebar"},"tracing/integrations/listing/byteplus":{"id":"tracing/integrations/listing/byteplus","title":"Tracing BytePlus","description":"","sidebar":"genAISidebar"},"tracing/integrations/listing/claude_code":{"id":"tracing/integrations/listing/claude_code","title":"Tracing Claude Code","description":"Claude Code Tracing via CLI autolog","sidebar":"genAISidebar"},"tracing/integrations/listing/cohere":{"id":"tracing/integrations/listing/cohere","title":"Tracing Cohere","description":"","sidebar":"genAISidebar"},"tracing/integrations/listing/crewai":{"id":"tracing/integrations/listing/crewai","title":"Tracing CrewAI","description":"CrewAI is an open-source framework for orchestrating role-playing, autonomous AI agent.","sidebar":"genAISidebar"},"tracing/integrations/listing/databricks":{"id":"tracing/integrations/listing/databricks","title":"Tracing Databricks","description":"Databricks offers a unified platform for data, analytics and AI. Databricks Foundation Model APIs provide an OpenAI-compatible API format for accessing state-of-the-art models such as OpenAI GPT, Anthropic Claude, Google Gemini, and more, through a single platform. Since Databricks Foundation Model APIs are OpenAI-compatible, you can use MLflow tracing to trace your interactions with Databricks Foundation Model APIs.","sidebar":"genAISidebar"},"tracing/integrations/listing/databricks-ai-gateway":{"id":"tracing/integrations/listing/databricks-ai-gateway","title":"Tracing Databricks AI Gateway","description":"Databricks AI Gateway (formerly Mosaic AI Gateway) is the Databricks solution for governing and monitoring access to generative AI models and their associated model serving endpoints. It is a centralized service that brings governance, monitoring, and production readiness to model serving endpoints.","sidebar":"genAISidebar"},"tracing/integrations/listing/deepagent":{"id":"tracing/integrations/listing/deepagent","title":"Tracing LangChain Deep Agent","description":"LangChain Deep Agent is an open-source library for building autonomous agents that can plan, research, and execute complex tasks. Deep Agent is built on top of LangGraph, providing a high-level abstraction for creating sophisticated agents with built-in capabilities like todo management, file operations, and spawning specialized subagents.","sidebar":"genAISidebar"},"tracing/integrations/listing/deepseek":{"id":"tracing/integrations/listing/deepseek","title":"Tracing DeepSeek","description":"","sidebar":"genAISidebar"},"tracing/integrations/listing/dspy":{"id":"tracing/integrations/listing/dspy","title":"Tracing DSPy\u{1F9E9}","description":"DSPy is an open-source framework for building modular AI systems and offers algorithms for optimizing their prompts and weights.","sidebar":"genAISidebar"},"tracing/integrations/listing/fireworksai":{"id":"tracing/integrations/listing/fireworksai","title":"Tracing FireworksAI","description":"FireworksAI is an inference and customization engine for open source AI. It provides day zero access to the latest SOTA OSS models and allows developers to build lightning AI applications.","sidebar":"genAISidebar"},"tracing/integrations/listing/gemini":{"id":"tracing/integrations/listing/gemini","title":"Tracing Gemini","description":"MLflow Tracing provides automatic tracing capability for Google Gemini. By enabling auto tracing","sidebar":"genAISidebar"},"tracing/integrations/listing/google-adk":{"id":"tracing/integrations/listing/google-adk","title":"Tracing Google Agent Development Kit (ADK)","description":"MLflow Tracing provides automatic tracing capability for Google ADK, a flexible and modular AI agents framework developed by Google. MLflow supports tracing for Google ADK through the OpenTelemetry integration.","sidebar":"genAISidebar"},"tracing/integrations/listing/groq":{"id":"tracing/integrations/listing/groq","title":"Tracing Groq","description":"MLflow Tracing provides automatic tracing capability when using Groq.","sidebar":"genAISidebar"},"tracing/integrations/listing/haystack":{"id":"tracing/integrations/listing/haystack","title":"Tracing Haystack","description":"Haystack is an open-source AI orchestration framework developed by deepset, designed to help Python developers build production-ready LLM-powered applications.","sidebar":"genAISidebar"},"tracing/integrations/listing/helicone":{"id":"tracing/integrations/listing/helicone","title":"Tracing Helicone","description":"","sidebar":"genAISidebar"},"tracing/integrations/listing/instructor":{"id":"tracing/integrations/listing/instructor","title":"Tracing Instructor","description":"Instructor Tracing via autolog","sidebar":"genAISidebar"},"tracing/integrations/listing/kong":{"id":"tracing/integrations/listing/kong","title":"Tracing Kong AI Gateway","description":"","sidebar":"genAISidebar"},"tracing/integrations/listing/koog":{"id":"tracing/integrations/listing/koog","title":"Tracing Koog","description":"Enable OpenTelemetry in Koog","sidebar":"genAISidebar"},"tracing/integrations/listing/langchain":{"id":"tracing/integrations/listing/langchain","title":"Tracing LangChain\u{1F99C}\u26D3\uFE0F","description":"LangChain is an open-source framework for building LLM-powered applications.","sidebar":"genAISidebar"},"tracing/integrations/listing/langflow":{"id":"tracing/integrations/listing/langflow","title":"Tracing Langflow","description":"Enable OpenTelemetry in Langflow via Traceloop","sidebar":"genAISidebar"},"tracing/integrations/listing/langgraph":{"id":"tracing/integrations/listing/langgraph","title":"Tracing LangGraph\u{1F99C}\u{1F578}\uFE0F","description":"LangGraph is an open-source library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows.","sidebar":"genAISidebar"},"tracing/integrations/listing/litellm":{"id":"tracing/integrations/listing/litellm","title":"Tracing LiteLLM\u{1F684}","description":"LiteLLM is an open-source LLM Gateway that allow accessing 100+ LLMs in the unified interface.","sidebar":"genAISidebar"},"tracing/integrations/listing/litellm-proxy":{"id":"tracing/integrations/listing/litellm-proxy","title":"Tracing LiteLLM Proxy","description":"LiteLLM Proxy is a self-hosted LLM gateway that provides a unified OpenAI-compatible API to access 100+ LLM providers. It offers features like load balancing, spend tracking, and rate limiting across multiple providers.","sidebar":"genAISidebar"},"tracing/integrations/listing/livekit":{"id":"tracing/integrations/listing/livekit","title":"Tracing LiveKit Agents","description":"MLflow Tracing provides automatic tracing capability for LiveKit Agents, an open-source framework for building real-time multimodal AI applications. MLflow supports tracing for LiveKit Agents through the OpenTelemetry integration.","sidebar":"genAISidebar"},"tracing/integrations/listing/llama_index":{"id":"tracing/integrations/listing/llama_index","title":"Tracing LlamaIndex\u{1F999}","description":"LlamaIndex is an open-source framework for building agentic generative AI applications that allow large language models to work with your data in any format.","sidebar":"genAISidebar"},"tracing/integrations/listing/mastra":{"id":"tracing/integrations/listing/mastra","title":"Tracing Mastra","description":"MLflow Tracing provides automatic tracing capability for Mastra, a flexible and modular AI agents framework developed by Mastra. MLflow supports tracing for Mastra through the OpenTelemetry integration.","sidebar":"genAISidebar"},"tracing/integrations/listing/microsoft-agent-framework":{"id":"tracing/integrations/listing/microsoft-agent-framework","title":"Tracing Microsoft Agent Framework","description":"MLflow Tracing provides automatic tracing capability for Microsoft Agent Framework, a flexible and modular AI agents framework developed by Microsoft. MLflow supports tracing for Microsoft Agent Framework through the OpenTelemetry integration.","sidebar":"genAISidebar"},"tracing/integrations/listing/mistral":{"id":"tracing/integrations/listing/mistral","title":"Tracing Mistral","description":"MLflow Tracing ensures observability for your interactions with Mistral AI models.","sidebar":"genAISidebar"},"tracing/integrations/listing/mlflow-ai-gateway":{"id":"tracing/integrations/listing/mlflow-ai-gateway","title":"Tracing MLflow AI Gateway","description":"MLflow AI Gateway is a unified, centralized interface for accessing multiple LLM providers. It simplifies API key management, provides a consistent API across providers, and enables seamless switching between models from OpenAI, Anthropic, Google, and other providers.","sidebar":"genAISidebar"},"tracing/integrations/listing/moonshot":{"id":"tracing/integrations/listing/moonshot","title":"Tracing Kimi (Moonshot AI)","description":"","sidebar":"genAISidebar"},"tracing/integrations/listing/novitaai":{"id":"tracing/integrations/listing/novitaai","title":"Tracing Novita AI","description":"","sidebar":"genAISidebar"},"tracing/integrations/listing/ollama":{"id":"tracing/integrations/listing/ollama","title":"Tracing Ollama","description":"MLflow Tracing provides automatic tracing capability for Ollama models through the OpenAI SDK integration. Because Ollama exposes an OpenAI-compatible API, you can simply use mlflow.openai.autolog() to trace Ollama calls.","sidebar":"genAISidebar"},"tracing/integrations/listing/openai":{"id":"tracing/integrations/listing/openai","title":"Tracing OpenAI","description":"MLflow Tracing provides automatic tracing capability for OpenAI. By enabling auto tracing","sidebar":"genAISidebar"},"tracing/integrations/listing/openai-agent":{"id":"tracing/integrations/listing/openai-agent","title":"Tracing OpenAI Agent\u{1F916}","description":"OpenAI Tracing via autolog","sidebar":"genAISidebar"},"tracing/integrations/listing/openrouter":{"id":"tracing/integrations/listing/openrouter","title":"Tracing OpenRouter","description":"","sidebar":"genAISidebar"},"tracing/integrations/listing/pipecat":{"id":"tracing/integrations/listing/pipecat","title":"Tracing Pipecat","description":"Enable OpenTelemetry in Pipecat","sidebar":"genAISidebar"},"tracing/integrations/listing/portkey":{"id":"tracing/integrations/listing/portkey","title":"Tracing Portkey","description":"","sidebar":"genAISidebar"},"tracing/integrations/listing/pydantic_ai":{"id":"tracing/integrations/listing/pydantic_ai","title":"Tracing PydanticAI","description":"PydanticAI Tracing via autolog","sidebar":"genAISidebar"},"tracing/integrations/listing/pydantic-ai-gateway":{"id":"tracing/integrations/listing/pydantic-ai-gateway","title":"Tracing Pydantic AI Gateway","description":"Pydantic AI Gateway is a unified interface for accessing multiple AI providers with a single key. It supports models from OpenAI, Anthropic, Google Vertex, Groq, AWS Bedrock, and more. Key features include spending limits, failover management, and zero translation\u2014requests flow through directly in each provider\'s native format, giving you immediate access to new model features as soon as they are released.","sidebar":"genAISidebar"},"tracing/integrations/listing/quarkus-langchain4j":{"id":"tracing/integrations/listing/quarkus-langchain4j","title":"Tracing Quarkus LangChain4j","description":"Enable OpenTelemetry in Quarkus LangChain4j","sidebar":"genAISidebar"},"tracing/integrations/listing/qwen":{"id":"tracing/integrations/listing/qwen","title":"Tracing Qwen (DashScope)","description":"","sidebar":"genAISidebar"},"tracing/integrations/listing/semantic_kernel":{"id":"tracing/integrations/listing/semantic_kernel","title":"Tracing Semantic Kernel","description":"Semantic Kernel is a lightweight, open-source SDK that functions as AI middleware, enabling you to integrate AI models into your C#, Python, or Java codebase via a uniform API layer. By abstracting model interactions, it lets you swap in new models without rewriting your application logic.","sidebar":"genAISidebar"},"tracing/integrations/listing/smolagents":{"id":"tracing/integrations/listing/smolagents","title":"Tracing Smolagents","description":"Smolagents tracing via autolog","sidebar":"genAISidebar"},"tracing/integrations/listing/spring-ai":{"id":"tracing/integrations/listing/spring-ai","title":"Tracing Spring AI","description":"Spring AI Tracing","sidebar":"genAISidebar"},"tracing/integrations/listing/strands":{"id":"tracing/integrations/listing/strands","title":"Tracing Strands Agents SDK","description":"Strands Agents SDK is an open\u2011source, model\u2011driven SDK developed by AWS that enables developers to create autonomous AI agents","sidebar":"genAISidebar"},"tracing/integrations/listing/togetherai":{"id":"tracing/integrations/listing/togetherai","title":"Tracing Together AI","description":"","sidebar":"genAISidebar"},"tracing/integrations/listing/truefoundry":{"id":"tracing/integrations/listing/truefoundry","title":"Tracing TrueFoundry","description":"","sidebar":"genAISidebar"},"tracing/integrations/listing/txtai":{"id":"tracing/integrations/listing/txtai","title":"Tracing txtai","description":"txtai Tracing via autolog","sidebar":"genAISidebar"},"tracing/integrations/listing/vercel-ai-gateway":{"id":"tracing/integrations/listing/vercel-ai-gateway","title":"Tracing Vercel AI Gateway","description":"","sidebar":"genAISidebar"},"tracing/integrations/listing/vercelai":{"id":"tracing/integrations/listing/vercelai","title":"Tracing Vercel AI SDK","description":"MLflow Tracing provides automatic tracing for applications built with the Vercel AI SDK (the ai package) via OpenTelemetry, unlocking powerful observability capabilities for TypeScript and Javascript application developers.","sidebar":"genAISidebar"},"tracing/integrations/listing/voltagent":{"id":"tracing/integrations/listing/voltagent","title":"Tracing VoltAgent","description":"MLflow Tracing provides automatic tracing capability for VoltAgent, an open-source TypeScript framework for building AI agents. MLflow supports tracing for VoltAgent through the OpenTelemetry integration.","sidebar":"genAISidebar"},"tracing/integrations/listing/watsonx-orchestrate":{"id":"tracing/integrations/listing/watsonx-orchestrate","title":"Tracing Watsonx Orchestrate","description":"Reference","sidebar":"genAISidebar"},"tracing/integrations/listing/xai-grok":{"id":"tracing/integrations/listing/xai-grok","title":"Tracing xAI / Grok","description":"","sidebar":"genAISidebar"},"tracing/lightweight-sdk":{"id":"tracing/lightweight-sdk","title":"Production Tracing SDK","description":"MLflow offers a Production Tracing SDK package called mlflow-tracing that includes only the essential functionality for tracing and monitoring of your GenAI applications. This package is designed for production environments where minimizing dependencies and deployment size is critical.","sidebar":"genAISidebar"},"tracing/observe-with-traces/delete-traces":{"id":"tracing/observe-with-traces/delete-traces","title":"Delete Traces","description":"You can delete traces based on specific criteria using the  method. This method allows you to delete traces by timestamp or trace IDs.","sidebar":"genAISidebar"},"tracing/observe-with-traces/masking":{"id":"tracing/observe-with-traces/masking","title":"Redacting Sensitive Data from Traces","description":"Traces capture powerful insights for debugging and monitoring your application, however, they may contain sensitive data, such as Personal Identifiable Information (PII), that you don\'t want to share with others. MLflow provides a fully configurable way to mask sensitive data from traces before they are saved to the backend.","sidebar":"genAISidebar"},"tracing/observe-with-traces/ui":{"id":"tracing/observe-with-traces/ui","title":"MLflow Tracing UI","description":"GenAI Experiment Overview","sidebar":"genAISidebar"},"tracing/opentelemetry/export":{"id":"tracing/opentelemetry/export","title":"Export MLflow Traces/Metrics via OTLP","description":"Set Up OTLP Exporter","sidebar":"genAISidebar"},"tracing/opentelemetry/index":{"id":"tracing/opentelemetry/index","title":"OpenTelemetry Integration","description":"OpenTelemetry is a CNCF-backed project that provides vendor-neutral observability APIs and SDKs to instrument your applications and collect telemetry data in a consistent way. MLflow Tracing is fully compatible with OpenTelemetry, making it free from vendor lock-in.","sidebar":"genAISidebar"},"tracing/opentelemetry/ingest":{"id":"tracing/opentelemetry/ingest","title":"Collect OpenTelemetry Traces into MLflow","description":"Basic Example","sidebar":"genAISidebar"},"tracing/opentelemetry/ingest-shared":{"id":"tracing/opentelemetry/ingest-shared","title":"ingest-shared","description":"OpenTelemetry trace ingestion is supported in MLflow 3.6.0 and above."},"tracing/prod-tracing":{"id":"tracing/prod-tracing","title":"Production Tracing and Monitoring","description":"When you deploy an agent or LLM application to production, real users behave differently than test data\u2014they find edge cases, ask unexpected questions, and expose issues you didn\'t anticipate. This guide covers how to configure MLflow Tracing for production environments\u2014including automatic (online) quality evaluation\u2014to catch these issues early and continuously improve your application.","sidebar":"genAISidebar"},"tracing/quickstart/index":{"id":"tracing/quickstart/index","title":"Tracing Quickstart","description":"Need help setting up tracing? Try MLflow Assistant - a powerful AI assistant that can add MLflow tracing to your project automatically.","sidebar":"genAISidebar"},"tracing/search-traces":{"id":"tracing/search-traces","title":"Search Traces","description":"This guide will walk you through how to search for traces in MLflow using both the MLflow UI and Python API. This resource will be valuable if you\'re interested in querying specific traces based on their metadata, tags, execution time, status, or other trace attributes.","sidebar":"genAISidebar"},"tracing/track-environments-context/index":{"id":"tracing/track-environments-context/index","title":"Track Versions & Environments","description":"Tracking the execution environment and application version of your GenAI application allows you to debug performance and quality issues relative to the code. This metadata enables:","sidebar":"genAISidebar"},"tracing/track-users-sessions/index":{"id":"tracing/track-users-sessions/index","title":"Track Users & Sessions","description":"Many real-world AI applications use session to maintain multi-turn user interactions. MLflow Tracing provides built-in support for associating traces with users and grouping them into sessions. Tracking users and sessions in your GenAI application provides essential context for understanding user behavior, analyzing conversation flows, and improving personalization.","sidebar":"genAISidebar"},"version-tracking/compare-app-versions":{"id":"version-tracking/compare-app-versions","title":"Compare App Versions","description":"Compare different application versions using traces to track improvements and identify the best performing iteration.","sidebar":"genAISidebar"},"version-tracking/index":{"id":"version-tracking/index","title":"Version Tracking for GenAI Applications","description":"Understand how MLflow enables version tracking for your complete GenAI applications using LoggedModels, linking code, configurations, evaluations, and traces.","sidebar":"genAISidebar"},"version-tracking/quickstart":{"id":"version-tracking/quickstart","title":"Version Tracking Quickstart","description":"Build and track a LangChain-based chatbot with MLflow\'s version management capabilities. This quickstart demonstrates prompt versioning, application tracking, trace generation, and performance evaluation using MLflow\'s GenAI features.","sidebar":"genAISidebar"},"version-tracking/track-application-versions-with-mlflow":{"id":"version-tracking/track-application-versions-with-mlflow","title":"Track versions of Git-based applications with MLflow","description":"Learn how to track versions of your GenAI application when your app\'s code resides in Git, using MLflow\'s automatic Git versioning capabilities.","sidebar":"genAISidebar"}}}}')}}]);