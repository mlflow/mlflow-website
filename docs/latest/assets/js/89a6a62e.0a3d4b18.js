"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["1074"],{4074(e,l,n){n.r(l),n.d(l,{metadata:()=>t,default:()=>g,frontMatter:()=>d,contentTitle:()=>u,toc:()=>_,assets:()=>w});var t=JSON.parse('{"id":"eval-monitor/scorers/custom/tutorial","title":"Develop code-based scorers","description":"In MLflow Evaluation for GenAI, custom code-based scorers allow you to define flexible evaluation metrics for your AI agent or application.","source":"@site/docs/genai/eval-monitor/scorers/custom/tutorial.mdx","sourceDirName":"eval-monitor/scorers/custom","slug":"/eval-monitor/scorers/custom/tutorial","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/custom/tutorial","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"genAISidebar","previous":{"title":"Code-based Scorer Examples","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/custom/code-examples"},"next":{"title":"Judge Alignment: Teaching AI to Match Human Preferences","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/alignment"}}'),r=n(74848),a=n(28453),o=n(54725),s=n(46077),i=n(77541),p=n(10440),c=n(93164),m=n(87073),h=n(51004),f=n(83884);let d={},u="Develop code-based scorers",w={},_=[...f.RM,{value:"Step 1: Define evaluation data",id:"step-1-define-evaluation-data",level:2},{value:"Step 2: Generate traces from your app",id:"step-2-generate-traces-from-your-app",level:2},{value:"Step 3: Query and store the resulting traces",id:"step-3-query-and-store-the-resulting-traces",level:2},{value:"Step 4: As you iterate on your scorer, call <code>evaluate()</code> using the stored traces",id:"step-4-as-you-iterate-on-your-scorer-call-evaluate-using-the-stored-traces",level:2},{value:"Next steps",id:"next-steps",level:2}];function y(e){let l={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(l.header,{children:(0,r.jsx)(l.h1,{id:"develop-code-based-scorers",children:"Develop code-based scorers"})}),"\n",(0,r.jsxs)(l.p,{children:["In MLflow Evaluation for GenAI, ",(0,r.jsx)(l.a,{href:"/genai/eval-monitor/scorers/custom",children:"custom code-based scorers"})," allow you to define flexible evaluation metrics for your AI agent or application."]}),"\n",(0,r.jsx)(l.p,{children:"As you develop scorers, you will often need to iterate quickly. Use this developer workflow to update your scorer without rerunning your entire app each time:"}),"\n",(0,r.jsxs)(l.ol,{children:["\n",(0,r.jsx)(l.li,{children:"Define evaluation data"}),"\n",(0,r.jsx)(l.li,{children:"Generate traces from your app"}),"\n",(0,r.jsx)(l.li,{children:"Query and store the resulting traces"}),"\n",(0,r.jsx)(l.li,{children:"As you iterate on your scorer, evaluate using the stored traces"}),"\n"]}),"\n",(0,r.jsx)(f.Ay,{}),"\n",(0,r.jsxs)(l.ol,{start:"4",children:["\n",(0,r.jsxs)(l.li,{children:["\n",(0,r.jsx)(l.p,{children:"Create a simple question-answering assistant app for this tutorial:"}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-python",children:'@mlflow.trace\ndef sample_app(messages: list[dict[str, str]]):\n    # 1. Prepare messages for the LLM\n    messages_for_llm = [\n        {"role": "system", "content": "You are a helpful assistant."},\n        *messages,\n    ]\n\n    # 2. Call LLM to generate a response\n    response = client.chat.completions.create(\n        model=model_name,\n        messages=messages_for_llm,\n    )\n    return response.choices[0].message.content\n\n\nsample_app([{"role": "user", "content": "What is the capital of France?"}])\n'})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(l.h2,{id:"step-1-define-evaluation-data",children:"Step 1: Define evaluation data"}),"\n",(0,r.jsx)(l.p,{children:"The evaluation data below is a list of requests for the LLM to answer. For this app, the requests can be simple questions or conversations with multiple messages."}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-python",children:'eval_dataset = [\n    {\n        "inputs": {\n            "messages": [\n                {"role": "user", "content": "How much does a microwave cost?"},\n            ]\n        },\n    },\n    {\n        "inputs": {\n            "messages": [\n                {\n                    "role": "user",\n                    "content": "Can I return the microwave I bought 2 months ago?",\n                },\n            ]\n        },\n    },\n    {\n        "inputs": {\n            "messages": [\n                {\n                    "role": "user",\n                    "content": "I\'m having trouble with my account.  I can\'t log in.",\n                },\n                {\n                    "role": "assistant",\n                    "content": "I\'m sorry to hear that you\'re having trouble with your account.  Are you using our website or mobile app?",\n                },\n                {"role": "user", "content": "Website"},\n            ]\n        },\n    },\n]\n'})}),"\n",(0,r.jsx)(l.h2,{id:"step-2-generate-traces-from-your-app",children:"Step 2: Generate traces from your app"}),"\n",(0,r.jsxs)(l.p,{children:["Use ",(0,r.jsx)(o.B,{fn:"mlflow.genai.evaluate",children:"mlflow.genai.evaluate()"})," to generate traces from the app. Since ",(0,r.jsx)(l.code,{children:"evaluate()"})," requires at least one scorer, define a placeholder scorer for this initial trace generation:"]}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-python",children:"from mlflow.genai.scorers import scorer\n\n\n@scorer\ndef placeholder_metric() -> int:\n    # placeholder return value\n    return 1\n"})}),"\n",(0,r.jsx)(l.p,{children:"Run evaluation using the placeholder scorer:"}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-python",children:"eval_results = mlflow.genai.evaluate(\n    data=eval_dataset, predict_fn=sample_app, scorers=[placeholder_metric]\n)\n"})}),"\n",(0,r.jsxs)(l.p,{children:["After running the above code, you should have one trace in your experiment for each row in your evaluation dataset. Databricks Notebooks also display trace visualizations as part of cell results. The LLM's response generated by the ",(0,r.jsx)(l.code,{children:"sample_app"})," during evaluation appears in the notebook Trace UI's ",(0,r.jsx)(l.strong,{children:"Outputs"})," field and in the MLflow Experiment UI's ",(0,r.jsx)(l.strong,{children:"Response"})," column."]}),"\n",(0,r.jsx)(s.A,{src:"/images/genai/eval-monitor/trace-visualization.png",alt:"Trace visualization in notebook",width:"800px"}),"\n",(0,r.jsx)(l.h2,{id:"step-3-query-and-store-the-resulting-traces",children:"Step 3: Query and store the resulting traces"}),"\n",(0,r.jsxs)(l.p,{children:["Store the generated traces in a local variable. The ",(0,r.jsx)(o.B,{fn:"mlflow.search_traces",children:(0,r.jsx)(l.code,{children:"mlflow.search_traces()"})})," function returns a Pandas DataFrame of traces."]}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-python",children:"generated_traces = mlflow.search_traces(run_id=eval_results.run_id)\ngenerated_traces\n"})}),"\n",(0,r.jsxs)(l.h2,{id:"step-4-as-you-iterate-on-your-scorer-call-evaluate-using-the-stored-traces",children:["Step 4: As you iterate on your scorer, call ",(0,r.jsx)(l.code,{children:"evaluate()"})," using the stored traces"]}),"\n",(0,r.jsxs)(l.p,{children:["Pass the Pandas DataFrame of traces directly to ",(0,r.jsx)(l.code,{children:"evaluate()"})," as an input dataset. This allows you to quickly iterate on your metric without having to re-run your app. The code below runs a new scorer on the precomputed ",(0,r.jsx)(l.code,{children:"generated_traces"}),"."]}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-python",children:"from mlflow.genai.scorers import scorer\n\n\n@scorer\ndef response_length(outputs: str) -> int:\n    # Example metric.\n    # Implement your actual metric logic here.\n    return len(outputs)\n\n\n# Note the lack of a predict_fn parameter.\nmlflow.genai.evaluate(\n    data=generated_traces,\n    scorers=[response_length],\n)\n"})}),"\n",(0,r.jsx)(l.h2,{id:"next-steps",children:"Next steps"}),"\n",(0,r.jsxs)(p.A,{children:[(0,r.jsx)(i.A,{icon:c.A,title:"Code-based scorer examples",description:"See many examples of code-based scorers",href:"/genai/eval-monitor/scorers/custom/code-examples"}),(0,r.jsx)(i.A,{icon:m.A,title:"Custom LLM judges",description:"Learn about semantic evaluation using LLM-as-a-judge metrics",href:"/genai/eval-monitor/scorers/llm-judge/custom-judges"}),(0,r.jsx)(i.A,{icon:h.A,title:"Build evaluation datasets",description:"Create test data for your scorers",href:"/genai/datasets/"})]})]})}function g(e={}){let{wrapper:l}={...(0,a.R)(),...e.components};return l?(0,r.jsx)(l,{...e,children:(0,r.jsx)(y,{...e})}):y(e)}},83884(e,l,n){n.d(l,{Ay:()=>s,RM:()=>a});var t=n(74848),r=n(28453);let a=[{value:"Prerequisites for running the examples",id:"prerequisites-for-running-the-examples",level:2}];function o(e){let l={a:"a",code:"code",h2:"h2",li:"li",ol:"ol",p:"p",pre:"pre",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(l.h2,{id:"prerequisites-for-running-the-examples",children:"Prerequisites for running the examples"}),"\n",(0,t.jsxs)(l.ol,{children:["\n",(0,t.jsxs)(l.li,{children:["\n",(0,t.jsx)(l.p,{children:"Install MLflow and required packages"}),"\n",(0,t.jsx)(l.pre,{children:(0,t.jsx)(l.code,{className:"language-bash",children:"pip install --upgrade mlflow\n"})}),"\n"]}),"\n",(0,t.jsxs)(l.li,{children:["\n",(0,t.jsxs)(l.p,{children:["Create an MLflow experiment by following the ",(0,t.jsx)(l.a,{href:"/genai/getting-started/connect-environment/",children:"setup your environment quickstart"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(l.li,{children:["\n",(0,t.jsxs)(l.p,{children:["(Optional, if using OpenAI models) Use the native OpenAI SDK to connect to OpenAI-hosted models. Select a model from the ",(0,t.jsx)(l.a,{href:"https://platform.openai.com/docs/models",children:"available OpenAI models"}),"."]}),"\n",(0,t.jsx)(l.pre,{children:(0,t.jsx)(l.code,{className:"language-python",children:'import mlflow\nimport os\nimport openai\n\n# Ensure your OPENAI_API_KEY is set in your environment\n# os.environ["OPENAI_API_KEY"] = "<YOUR_API_KEY>" # Uncomment and set if not globally configured\n\n# Enable auto-tracing for OpenAI\nmlflow.openai.autolog()\n\n# Create an OpenAI client\nclient = openai.OpenAI()\n\n# Select an LLM\nmodel_name = "gpt-4o-mini"\n'})}),"\n"]}),"\n"]})]})}function s(e={}){let{wrapper:l}={...(0,r.R)(),...e.components};return l?(0,t.jsx)(l,{...e,children:(0,t.jsx)(o,{...e})}):o(e)}},75689(e,l,n){n.d(l,{A:()=>i});var t=n(96540);let r=e=>{let l=e.replace(/^([A-Z])|[\s-_]+(\w)/g,(e,l,n)=>n?n.toUpperCase():l.toLowerCase());return l.charAt(0).toUpperCase()+l.slice(1)},a=(...e)=>e.filter((e,l,n)=>!!e&&""!==e.trim()&&n.indexOf(e)===l).join(" ").trim();var o={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};let s=(0,t.forwardRef)(({color:e="currentColor",size:l=24,strokeWidth:n=2,absoluteStrokeWidth:r,className:s="",children:i,iconNode:p,...c},m)=>(0,t.createElement)("svg",{ref:m,...o,width:l,height:l,stroke:e,strokeWidth:r?24*Number(n)/Number(l):n,className:a("lucide",s),...!i&&!(e=>{for(let l in e)if(l.startsWith("aria-")||"role"===l||"title"===l)return!0})(c)&&{"aria-hidden":"true"},...c},[...p.map(([e,l])=>(0,t.createElement)(e,l)),...Array.isArray(i)?i:[i]])),i=(e,l)=>{let n=(0,t.forwardRef)(({className:n,...o},i)=>(0,t.createElement)(s,{ref:i,iconNode:l,className:a(`lucide-${r(e).replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()}`,`lucide-${e}`,n),...o}));return n.displayName=r(e),n}},87073(e,l,n){n.d(l,{A:()=>t});let t=(0,n(75689).A)("brain",[["path",{d:"M12 5a3 3 0 1 0-5.997.125 4 4 0 0 0-2.526 5.77 4 4 0 0 0 .556 6.588A4 4 0 1 0 12 18Z",key:"l5xja"}],["path",{d:"M12 5a3 3 0 1 1 5.997.125 4 4 0 0 1 2.526 5.77 4 4 0 0 1-.556 6.588A4 4 0 1 1 12 18Z",key:"ep3f8r"}],["path",{d:"M15 13a4.5 4.5 0 0 1-3-4 4.5 4.5 0 0 1-3 4",key:"1p4c4q"}],["path",{d:"M17.599 6.5a3 3 0 0 0 .399-1.375",key:"tmeiqw"}],["path",{d:"M6.003 5.125A3 3 0 0 0 6.401 6.5",key:"105sqy"}],["path",{d:"M3.477 10.896a4 4 0 0 1 .585-.396",key:"ql3yin"}],["path",{d:"M19.938 10.5a4 4 0 0 1 .585.396",key:"1qfode"}],["path",{d:"M6 18a4 4 0 0 1-1.967-.516",key:"2e4loj"}],["path",{d:"M19.967 17.484A4 4 0 0 1 18 18",key:"159ez6"}]])},93164(e,l,n){n.d(l,{A:()=>t});let t=(0,n(75689).A)("code",[["path",{d:"m16 18 6-6-6-6",key:"eg8j8"}],["path",{d:"m8 6-6 6 6 6",key:"ppft3o"}]])},51004(e,l,n){n.d(l,{A:()=>t});let t=(0,n(75689).A)("database",[["ellipse",{cx:"12",cy:"5",rx:"9",ry:"3",key:"msslwz"}],["path",{d:"M3 5V19A9 3 0 0 0 21 19V5",key:"1wlel7"}],["path",{d:"M3 12A9 3 0 0 0 21 12",key:"mv7ke4"}]])},54725(e,l,n){n.d(l,{B:()=>o});var t=n(74848);n(96540);var r=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}'),a=n(66497);function o({fn:e,children:l,hash:n}){let o=(e=>{let l=e.split(".");for(let e=l.length;e>0;e--){let n=l.slice(0,e).join(".");if(r[n])return n}return null})(e);if(!o)return(0,t.jsx)(t.Fragment,{children:l});let s=(0,a.default)(`/${r[o]}#${n??e}`);return(0,t.jsx)("a",{href:s,target:"_blank",children:l??(0,t.jsxs)("code",{children:[e,"()"]})})}},46077(e,l,n){n.d(l,{A:()=>a});var t=n(74848);n(96540);var r=n(66497);function a({src:e,alt:l,width:n,caption:a,className:o}){return(0,t.jsxs)("div",{className:`container_JwLF ${o||""}`,children:[(0,t.jsx)("div",{className:"imageWrapper_RfGN",style:n?{width:n}:{},children:(0,t.jsx)("img",{src:(0,r.default)(e),alt:l,className:"image_bwOA"})}),a&&(0,t.jsx)("p",{className:"caption_jo2G",children:a})]})}},77541(e,l,n){n.d(l,{A:()=>p});var t=n(74848);n(96540);var r=n(95310),a=n(34164);let o="tileImage_O4So";var s=n(66497),i=n(92802);function p({icon:e,image:l,imageDark:n,imageWidth:p,imageHeight:c,iconSize:m=32,containerHeight:h,title:f,description:d,href:u,linkText:w="Learn more \u2192",className:_}){if(!e&&!l)throw Error("TileCard requires either an icon or image prop");let y=h?{height:`${h}px`}:{},g={};return p&&(g.width=`${p}px`),c&&(g.height=`${c}px`),(0,t.jsxs)(r.A,{href:u,className:(0,a.A)("tileCard_NHsj",_),children:[(0,t.jsx)("div",{className:"tileIcon_pyoR",style:y,children:e?(0,t.jsx)(e,{size:m}):n?(0,t.jsx)(i.A,{sources:{light:(0,s.default)(l),dark:(0,s.default)(n)},alt:f,className:o,style:g}):(0,t.jsx)("img",{src:(0,s.default)(l),alt:f,className:o,style:g})}),(0,t.jsx)("h3",{children:f}),(0,t.jsx)("p",{children:d}),(0,t.jsx)("div",{className:"tileLink_iUbu",children:w})]})}},10440(e,l,n){n.d(l,{A:()=>a});var t=n(74848);n(96540);var r=n(34164);function a({children:e,className:l}){return(0,t.jsx)("div",{className:(0,r.A)("tilesGrid_hB9N",l),children:e})}},28453(e,l,n){n.d(l,{R:()=>o,x:()=>s});var t=n(96540);let r={},a=t.createContext(r);function o(e){let l=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(l):{...l,...e}},[l,e])}function s(e){let l;return l=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),t.createElement(a.Provider,{value:l},e.children)}}}]);