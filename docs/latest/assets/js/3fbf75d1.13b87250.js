"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[1897],{28453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>p});var o=n(96540);const l={},r=o.createContext(l);function i(e){const t=o.useContext(r);return o.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function p(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:i(e.components),o.createElement(r.Provider,{value:t},e.children)}},49374:(e,t,n)=>{n.d(t,{B:()=>p});n(96540);const o=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}');var l=n(86025),r=n(74848);const i=e=>{const t=e.split(".");for(let n=t.length;n>0;n--){const e=t.slice(0,n).join(".");if(o[e])return e}return null};function p({fn:e,children:t,hash:n}){const p=i(e);if(!p)return(0,r.jsx)(r.Fragment,{children:t});const a=(0,l.default)(`/${o[p]}#${n??e}`);return(0,r.jsx)("a",{href:a,target:"_blank",children:t??(0,r.jsxs)("code",{children:[e,"()"]})})}},94535:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>m,default:()=>h,frontMatter:()=>a,metadata:()=>o,toc:()=>f});const o=JSON.parse('{"id":"prompt-registry/optimize-prompts/openai-agent-optimization","title":"Optimizing Prompts for OpenAI Agents","description":"This guide demonstrates how to leverage  alongside the OpenAI Agent framework to enhance your agent\'s prompts automatically. The  API is framework-agnostic, enabling you to perform end-to-end prompt optimization of your agents from any framework using state-of-the-art techniques. For more information about the API, please visit Optimize Prompts.","source":"@site/docs/genai/prompt-registry/optimize-prompts/openai-agent-optimization.mdx","sourceDirName":"prompt-registry/optimize-prompts","slug":"/prompt-registry/optimize-prompts/openai-agent-optimization","permalink":"/mlflow-website/docs/latest/genai/prompt-registry/optimize-prompts/openai-agent-optimization","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6,"sidebar_label":"OpenAI Agent Optimization"},"sidebar":"genAISidebar","previous":{"title":"Optimize Prompts","permalink":"/mlflow-website/docs/latest/genai/prompt-registry/optimize-prompts"},"next":{"title":"Auto-rewrite Prompts for New Models \ud83c\udd95","permalink":"/mlflow-website/docs/latest/genai/prompt-registry/rewrite-prompts"}}');var l=n(74848),r=n(28453),i=n(49374),p=n(86025);const a={sidebar_position:6,sidebar_label:"OpenAI Agent Optimization"},m="Optimizing Prompts for OpenAI Agents",s={},f=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Basic Example",id:"basic-example",level:2}];function c(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,r.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(t.header,{children:(0,l.jsx)(t.h1,{id:"optimizing-prompts-for-openai-agents",children:"Optimizing Prompts for OpenAI Agents"})}),"\n",(0,l.jsx)("p",{style:{display:"flex",justifyContent:"center",margin:"1em 0"},children:(0,l.jsx)("img",{src:(0,p.default)("/images/logos/openai-agent-logo.png"),alt:"OpenAI Agent Logo",style:{width:300,objectFit:"contain"}})}),"\n",(0,l.jsxs)(t.p,{children:["This guide demonstrates how to leverage ",(0,l.jsx)(i.B,{fn:"mlflow.genai.optimize_prompts"})," alongside the ",(0,l.jsx)(t.a,{href:"https://github.com/openai/openai-agents-python",children:"OpenAI Agent framework"})," to enhance your agent's prompts automatically. The ",(0,l.jsx)(i.B,{fn:"mlflow.genai.optimize_prompts"})," API is framework-agnostic, enabling you to perform end-to-end prompt optimization of your agents from any framework using state-of-the-art techniques. For more information about the API, please visit ",(0,l.jsx)(t.a,{href:"/genai/prompt-registry/optimize-prompts",children:"Optimize Prompts"}),"."]}),"\n",(0,l.jsx)(t.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-bash",children:"pip install openai-agents mlflow gepa nest_asyncio\n"})}),"\n",(0,l.jsx)(t.p,{children:"Set your OpenAI API key:"}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-bash",children:'export OPENAI_API_KEY="your-api-key"\n'})}),"\n",(0,l.jsx)(t.p,{children:"Set tracking server and MLflow experiment:"}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-python",children:'import mlflow\n\nmlflow.set_tracking_uri("http://localhost:5000")\nmlflow.set_experiment("OpenAI Agents")\n'})}),"\n",(0,l.jsx)(t.h2,{id:"basic-example",children:"Basic Example"}),"\n",(0,l.jsx)(t.p,{children:"Here's a complete example of optimizing a question-answering agent:"}),"\n",(0,l.jsx)(t.pre,{children:(0,l.jsx)(t.code,{className:"language-python",children:'import mlflow\nfrom typing import Any\nfrom agents import Agent, Runner\nfrom mlflow.genai.optimize import GepaPromptOptimizer\nfrom mlflow.genai.scorers import scorer\n\n# If you\'re inside notebooks, please uncomment the following lines.\n# import nest_asyncio\n# nest_asyncio.apply()\n\n# Step 1: Register your initial prompt\nsystem_prompt = mlflow.genai.register_prompt(\n    name="qa-agent-system-prompt",\n    template="You\'re a helpful agent. Follow the user instruction precisely.",\n)\n\nuser_prompt = mlflow.genai.register_prompt(\n    name="qa-agent-user-prompt",\n    template="""Answer the question based on the context provided.\n\nContext: {{context}}\nQuestion: {{question}}\n\nAnswer:""",\n)\n\n\n# Step 2: Create a prediction function\n@mlflow.trace\ndef predict_fn(context: str, question: str) -> str:\n    # Load prompt from registry\n    system_prompt = mlflow.genai.load_prompt("prompts:/qa-agent-system-prompt@latest")\n    user_prompt = mlflow.genai.load_prompt("prompts:/qa-agent-user-prompt@latest")\n\n    # This is your agent\n    agent = Agent(\n        name="Question Answerer",\n        instructions=system_prompt.template,\n        model="gpt-4o-mini",\n    )\n\n    # Format the user message\n    user_message = user_prompt.format(context=context, question=question)\n\n    # Run the agent\n    result = Runner.run_sync(agent, user_message)\n    return result.final_output\n\n\n# Step 3: Prepare training data\ntrain_data = [\n    {\n        "inputs": {\n            "context": "Paris is the capital of France.",\n            "question": "What is the capital of France?",\n        },\n        "expectations": {"expected_response": "Paris"},\n    },\n    {\n        "inputs": {\n            "context": "The Eiffel Tower was completed in 1889.",\n            "question": "When was the Eiffel Tower completed?",\n        },\n        "expectations": {"expected_response": "1889"},\n    },\n    # Add more examples...\n]\n\n\n# Step 4: Prepare scorer\n@scorer\ndef exact_match(outputs: str, expectations: dict[str, Any]) -> bool:\n    return outputs == expectations["expected_response"]\n\n\n# Step 5: Optimize the prompt\nresult = mlflow.genai.optimize_prompts(\n    predict_fn=predict_fn,\n    train_data=train_data,\n    prompt_uris=[system_prompt.uri, user_prompt.uri],\n    optimizer=GepaPromptOptimizer(\n        reflection_model="openai:/gpt-5",\n        max_metric_calls=100,\n    ),\n    scorers=[exact_match],\n)\n\n# Step 6: Use the optimized prompt\noptimized_system_prompt = result.optimized_prompts[0]\nprint(f"Optimized system prompt URI: {optimized_system_prompt.uri}")\n\n# Since your agent already use @latest, it will automatically use the optimized prompts.\npredict_fn(\n    context="MLflow is an open-source platform for managing the machine learning lifecycle, providing tools to streamline the development, training, and deployment of models",\n    question="What is MLflow",\n)\n'})})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,l.jsx)(t,{...e,children:(0,l.jsx)(c,{...e})}):c(e)}}}]);