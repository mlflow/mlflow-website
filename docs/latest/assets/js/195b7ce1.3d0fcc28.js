"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8720],{18580:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>p,frontMatter:()=>i,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"traditional-ml/prophet/guide/index","title":"Prophet with MLflow","description":"In this comprehensive guide, we\'ll explore how to use Prophet with MLflow for time series forecasting, experiment tracking, and model deployment. We\'ll cover everything from basic forecasting workflows to advanced business scenario modeling and production deployment patterns.","source":"@site/docs/classic-ml/traditional-ml/prophet/guide/index.mdx","sourceDirName":"traditional-ml/prophet/guide","slug":"/traditional-ml/prophet/guide/","permalink":"/docs/latest/ml/traditional-ml/prophet/guide/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"classicMLSidebar","previous":{"title":"MLflow Prophet Integration","permalink":"/docs/latest/ml/traditional-ml/prophet/"},"next":{"title":"Overview","permalink":"/docs/latest/ml/deep-learning/"}}');var r=a(74848),o=a(28453);a(49374);const i={},s="Prophet with MLflow",l={},d=[{value:"Quick Start with Prophet and MLflow",id:"quick-start-with-prophet-and-mlflow",level:2},{value:"Understanding Prophet&#39;s Data Requirements",id:"understanding-prophets-data-requirements",level:2},{value:"Data Format and Preparation",id:"data-format-and-preparation",level:3},{value:"Handling Different Time Series Patterns",id:"handling-different-time-series-patterns",level:3},{value:"Multiple Time Series",id:"multiple-time-series",level:4},{value:"Irregular Time Series",id:"irregular-time-series",level:4},{value:"Advanced Prophet Configuration",id:"advanced-prophet-configuration",level:2},{value:"Seasonality and Trend Configuration",id:"seasonality-and-trend-configuration",level:3},{value:"Custom Seasonalities and Events",id:"custom-seasonalities-and-events",level:3},{value:"Built-in Holiday Support",id:"built-in-holiday-support",level:4},{value:"Business Calendar Integration",id:"business-calendar-integration",level:4},{value:"Model Validation and Performance Assessment",id:"model-validation-and-performance-assessment",level:2},{value:"Cross-Validation Best Practices",id:"cross-validation-best-practices",level:3},{value:"Forecast Quality Assessment",id:"forecast-quality-assessment",level:3},{value:"Hyperparameter Optimization",id:"hyperparameter-optimization",level:2},{value:"Systematic Parameter Tuning",id:"systematic-parameter-tuning",level:3},{value:"Advanced Optimization with Optuna",id:"advanced-optimization-with-optuna",level:3},{value:"Model Deployment and Serving",id:"model-deployment-and-serving",level:2},{value:"Model Loading and Prediction",id:"model-loading-and-prediction",level:3},{value:"Production Deployment Patterns",id:"production-deployment-patterns",level:3},{value:"Model Monitoring and Maintenance",id:"model-monitoring-and-maintenance",level:2},{value:"Forecast Accuracy Monitoring",id:"forecast-accuracy-monitoring",level:3},{value:"Automated Model Retraining",id:"automated-model-retraining",level:3},{value:"Best Practices and Tips",id:"best-practices-and-tips",level:2},{value:"Data Preparation Best Practices",id:"data-preparation-best-practices",level:3},{value:"Performance Optimization",id:"performance-optimization",level:3},{value:"Conclusion",id:"conclusion",level:2}];function m(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components},{Details:a}=n;return a||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"prophet-with-mlflow",children:"Prophet with MLflow"})}),"\n",(0,r.jsx)(n.p,{children:"In this comprehensive guide, we'll explore how to use Prophet with MLflow for time series forecasting, experiment tracking, and model deployment. We'll cover everything from basic forecasting workflows to advanced business scenario modeling and production deployment patterns."}),"\n",(0,r.jsx)(n.h2,{id:"quick-start-with-prophet-and-mlflow",children:"Quick Start with Prophet and MLflow"}),"\n",(0,r.jsx)(n.p,{children:"Prophet works seamlessly with MLflow to track your forecasting experiments:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport mlflow.prophet\nimport pandas as pd\nimport numpy as np\nfrom prophet import Prophet\nfrom prophet.diagnostics import cross_validation, performance_metrics\n\n# Load sample time series data (Prophet expects \'ds\' and \'y\' columns)\n# This example uses the classic Peyton Manning Wikipedia page views dataset\nurl = "https://raw.githubusercontent.com/facebook/prophet/main/examples/example_wp_log_peyton_manning.csv"\ndf = pd.read_csv(url)\n\nprint(f"Data shape: {df.shape}")\nprint(f"Date range: {df[\'ds\'].min()} to {df[\'ds\'].max()}")\nprint(f"Data preview:\\n{df.head()}")\n\nwith mlflow.start_run(run_name="Basic Prophet Forecast"):\n    # Create Prophet model with specific parameters\n    model = Prophet(\n        changepoint_prior_scale=0.05,  # Flexibility of trend changes\n        seasonality_prior_scale=10,  # Strength of seasonality\n        holidays_prior_scale=10,  # Strength of holiday effects\n        yearly_seasonality=True,\n        weekly_seasonality=True,\n        daily_seasonality=False,\n    )\n\n    # Fit the model\n    model.fit(df)\n\n    # Extract and log model parameters\n    def extract_prophet_params(prophet_model):\n        """Extract Prophet model parameters for logging."""\n        from prophet.serialize import SIMPLE_ATTRIBUTES\n\n        params = {}\n        for attr in SIMPLE_ATTRIBUTES:\n            if hasattr(prophet_model, attr):\n                value = getattr(prophet_model, attr)\n                if isinstance(value, (int, float, str, bool)):\n                    params[attr] = value\n        return params\n\n    params = extract_prophet_params(model)\n    mlflow.log_params(params)\n\n    # Create future dataframe for forecasting\n    future = model.make_future_dataframe(periods=365)  # Forecast 1 year ahead\n    forecast = model.predict(future)\n\n    # Cross-validation for model evaluation\n    cv_results = cross_validation(\n        model,\n        initial="730 days",  # Initial training period\n        period="180 days",  # Spacing between cutoff dates\n        horizon="365 days",  # Forecast horizon\n        parallel="threads",  # Use threading for speed\n    )\n\n    # Calculate performance metrics\n    metrics = performance_metrics(cv_results)\n    avg_metrics = metrics[["mse", "rmse", "mae", "mape"]].mean().to_dict()\n    mlflow.log_metrics(avg_metrics)\n\n    # Log the model with input example\n    mlflow.prophet.log_model(\n        pr_model=model, name="prophet_model", input_example=df[["ds"]].head(10)\n    )\n\n    print(f"Model trained and logged successfully!")\n    print(f"Average MAPE: {avg_metrics[\'mape\']:.2f}%")\n'})}),"\n",(0,r.jsx)(n.p,{children:"This example automatically captures:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"All Prophet model parameters and configuration"}),"\n",(0,r.jsx)(n.li,{children:"Cross-validation performance metrics"}),"\n",(0,r.jsx)(n.li,{children:"The trained model ready for deployment"}),"\n",(0,r.jsx)(n.li,{children:"Sample input data for model documentation"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"understanding-prophets-data-requirements",children:"Understanding Prophet's Data Requirements"}),"\n",(0,r.jsx)(n.p,{children:"Prophet has specific data format requirements that are important to understand:"}),"\n",(0,r.jsx)(n.h3,{id:"data-format-and-preparation",children:"Data Format and Preparation"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import pandas as pd\nfrom datetime import datetime, timedelta\n\n\ndef prepare_prophet_data(data, date_col, value_col, freq="D"):\n    """\n    Prepare data for Prophet training.\n\n    Args:\n        data: DataFrame with time series data\n        date_col: Name of date column\n        value_col: Name of value column\n        freq: Frequency of the time series\n    """\n\n    # Prophet requires columns named \'ds\' (datestamp) and \'y\' (value)\n    prophet_df = data[[date_col, value_col]].copy()\n    prophet_df.columns = ["ds", "y"]\n\n    # Ensure ds is datetime\n    prophet_df["ds"] = pd.to_datetime(prophet_df["ds"])\n\n    # Sort by date\n    prophet_df = prophet_df.sort_values("ds").reset_index(drop=True)\n\n    # Handle missing dates if needed\n    if freq:\n        full_date_range = pd.date_range(\n            start=prophet_df["ds"].min(), end=prophet_df["ds"].max(), freq=freq\n        )\n\n        # Reindex to fill missing dates\n        prophet_df = prophet_df.set_index("ds").reindex(full_date_range).reset_index()\n        prophet_df.columns = ["ds", "y"]\n\n        # Log data quality metrics\n        missing_dates = prophet_df["y"].isna().sum()\n        print(f"Missing dates filled: {missing_dates}")\n\n    return prophet_df\n\n\n# Example usage\n# Assuming you have a DataFrame with \'date\' and \'sales\' columns\n# df_prepared = prepare_prophet_data(raw_data, \'date\', \'sales\', freq=\'D\')\n'})}),"\n",(0,r.jsx)(n.h3,{id:"handling-different-time-series-patterns",children:"Handling Different Time Series Patterns"}),"\n",(0,r.jsxs)(a,{children:[(0,r.jsx)("summary",{children:"Data Preparation Patterns"}),(0,r.jsx)(n.h4,{id:"multiple-time-series",children:"Multiple Time Series"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def prepare_multiple_series(data, date_col, value_col, series_col):\n    """Prepare multiple time series for separate Prophet models."""\n\n    results = {}\n\n    for series_name in data[series_col].unique():\n        series_data = data[data[series_col] == series_name]\n        prophet_data = prepare_prophet_data(series_data, date_col, value_col)\n        results[series_name] = prophet_data\n\n    return results\n\n\n# Train separate models for each series\ndef train_multiple_prophet_models(series_dict):\n    """Train Prophet models for multiple time series."""\n\n    models = {}\n\n    with mlflow.start_run(run_name="Multiple Series Forecasting"):\n        for series_name, data in series_dict.items():\n            with mlflow.start_run(run_name=f"Series_{series_name}", nested=True):\n                model = Prophet()\n                model.fit(data)\n\n                # Log series-specific metrics\n                mlflow.log_param("series_name", series_name)\n                mlflow.log_param("data_points", len(data))\n\n                models[series_name] = model\n\n                # Log individual model\n                mlflow.prophet.log_model(pr_model=model, name=f"model_{series_name}")\n\n    return models\n'})}),(0,r.jsx)(n.h4,{id:"irregular-time-series",children:"Irregular Time Series"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def handle_irregular_timeseries(df, min_frequency="W"):\n    """Handle irregular time series data."""\n\n    # Aggregate to regular frequency if needed\n    df["ds"] = pd.to_datetime(df["ds"])\n    df.set_index("ds", inplace=True)\n\n    # Resample to regular frequency\n    if min_frequency == "W":\n        df_regular = (\n            df.resample("W")\n            .agg(\n                {\n                    "y": "sum",  # or \'mean\' depending on your use case\n                }\n            )\n            .reset_index()\n        )\n    elif min_frequency == "M":\n        df_regular = (\n            df.resample("M")\n            .agg(\n                {\n                    "y": "sum",\n                }\n            )\n            .reset_index()\n        )\n\n    # Remove any remaining NaN values\n    df_regular = df_regular.dropna()\n\n    return df_regular\n'})})]}),"\n",(0,r.jsx)(n.h2,{id:"advanced-prophet-configuration",children:"Advanced Prophet Configuration"}),"\n",(0,r.jsx)(n.h3,{id:"seasonality-and-trend-configuration",children:"Seasonality and Trend Configuration"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def advanced_prophet_configuration():\n    """Demonstrate advanced Prophet configuration options."""\n\n    with mlflow.start_run(run_name="Advanced Prophet Configuration"):\n        # Create Prophet model with advanced settings\n        model = Prophet(\n            # Trend configuration\n            growth="logistic",  # or \'linear\'\n            changepoints=None,  # Let Prophet auto-detect, or specify dates\n            n_changepoints=25,  # Number of potential changepoints\n            changepoint_range=0.8,  # Proportion of history for changepoints\n            changepoint_prior_scale=0.05,  # Flexibility of trend changes\n            # Seasonality configuration\n            yearly_seasonality="auto",  # or True/False/number\n            weekly_seasonality="auto",\n            daily_seasonality="auto",\n            seasonality_mode="additive",  # or \'multiplicative\'\n            seasonality_prior_scale=10,\n            # Holiday configuration\n            holidays_prior_scale=10,\n            # Uncertainty configuration\n            interval_width=0.80,  # Width of uncertainty intervals\n            uncertainty_samples=1000,  # Monte Carlo samples for uncertainty\n            # Stan configuration\n            mcmc_samples=0,  # Use MAP instead of MCMC\n            stan_backend="CMDSTANPY",  # Stan backend\n        )\n\n        # For logistic growth, need to specify capacity\n        if model.growth == "logistic":\n            df["cap"] = df["y"].max() * 1.2  # Set capacity 20% above max observed\n            df["floor"] = 0  # Optional floor\n\n        # Fit the model\n        model.fit(df)\n\n        # Log configuration parameters\n        config_params = {\n            "growth": model.growth,\n            "n_changepoints": model.n_changepoints,\n            "changepoint_range": model.changepoint_range,\n            "seasonality_mode": model.seasonality_mode,\n            "interval_width": model.interval_width,\n        }\n        mlflow.log_params(config_params)\n\n        return model\n\n\n# Usage\nadvanced_model = advanced_prophet_configuration()\n'})}),"\n",(0,r.jsx)(n.h3,{id:"custom-seasonalities-and-events",children:"Custom Seasonalities and Events"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def add_custom_components(model, df):\n    """Add custom seasonalities and regressors to Prophet model."""\n\n    with mlflow.start_run(run_name="Custom Prophet Components"):\n        # Add custom seasonalities\n        model.add_seasonality(\n            name="monthly",\n            period=30.5,  # Monthly seasonality\n            fourier_order=5,  # Number of Fourier terms\n        )\n\n        model.add_seasonality(\n            name="quarterly", period=91.25, fourier_order=8  # Quarterly seasonality\n        )\n\n        # Add conditional seasonalities (e.g., different patterns for weekdays/weekends)\n        def is_weekend(ds):\n            date = pd.to_datetime(ds)\n            return date.weekday() >= 5\n\n        df["weekend"] = df["ds"].apply(is_weekend)\n\n        model.add_seasonality(\n            name="weekend_seasonality",\n            period=7,\n            fourier_order=3,\n            condition_name="weekend",\n        )\n\n        # Add external regressors\n        # Example: Add economic indicator or marketing spend\n        np.random.seed(42)\n        df["marketing_spend"] = np.random.normal(1000, 200, len(df))\n        df["economic_indicator"] = np.random.normal(50, 10, len(df))\n\n        model.add_regressor("marketing_spend", prior_scale=0.5)\n        model.add_regressor("economic_indicator", prior_scale=0.3)\n\n        # Fit model with custom components\n        model.fit(df)\n\n        # Log custom component information\n        mlflow.log_params(\n            {\n                "custom_seasonalities": ["monthly", "quarterly", "weekend_seasonality"],\n                "external_regressors": ["marketing_spend", "economic_indicator"],\n                "total_components": len(model.extra_seasonalities)\n                + len(model.extra_regressors),\n            }\n        )\n\n        return model, df\n\n\n# Usage\nmodel_with_custom = Prophet()\nmodel_with_custom, enhanced_df = add_custom_components(model_with_custom, df.copy())\n'})}),"\n",(0,r.jsxs)(a,{children:[(0,r.jsx)("summary",{children:"Holiday and Event Modeling"}),(0,r.jsx)(n.h4,{id:"built-in-holiday-support",children:"Built-in Holiday Support"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from prophet.make_holidays import make_holidays_df\n\n\ndef add_holiday_effects():\n    """Add holiday effects to Prophet model."""\n\n    with mlflow.start_run(run_name="Holiday Modeling"):\n        # Create holidays dataframe for specific countries\n        holidays = make_holidays_df(\n            year_list=range(2010, 2025),\n            country="US",  # Built-in support for many countries\n        )\n\n        # Add custom holidays/events\n        custom_events = pd.DataFrame(\n            {\n                "holiday": "black_friday",\n                "ds": pd.to_datetime(\n                    ["2020-11-27", "2021-11-26", "2022-11-25", "2023-11-24"]\n                ),\n                "lower_window": -1,  # Effect starts 1 day before\n                "upper_window": 2,  # Effect lasts 2 days after\n            }\n        )\n\n        # Combine built-in and custom holidays\n        all_holidays = pd.concat([holidays, custom_events])\n\n        # Create model with holidays\n        model = Prophet(\n            holidays=all_holidays,\n            holidays_prior_scale=15,  # Increase for stronger holiday effects\n        )\n\n        model.fit(df)\n\n        # Log holiday information\n        mlflow.log_params(\n            {\n                "country_holidays": "US",\n                "custom_events": ["black_friday"],\n                "total_holidays": len(all_holidays),\n                "holidays_prior_scale": 15,\n            }\n        )\n\n        return model\n'})}),(0,r.jsx)(n.h4,{id:"business-calendar-integration",children:"Business Calendar Integration"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def create_business_calendar(start_date, end_date):\n    """Create business-specific calendar events."""\n\n    business_events = []\n\n    # Quarterly business reviews\n    for year in range(start_date.year, end_date.year + 1):\n        for quarter in [1, 2, 3, 4]:\n            if quarter == 1:\n                date = f"{year}-03-31"\n            elif quarter == 2:\n                date = f"{year}-06-30"\n            elif quarter == 3:\n                date = f"{year}-09-30"\n            else:\n                date = f"{year}-12-31"\n\n            business_events.append(\n                {\n                    "holiday": "quarterly_review",\n                    "ds": pd.to_datetime(date),\n                    "lower_window": -7,  # Week before\n                    "upper_window": 0,\n                }\n            )\n\n    # Annual planning periods\n    for year in range(start_date.year, end_date.year + 1):\n        business_events.append(\n            {\n                "holiday": "annual_planning",\n                "ds": pd.to_datetime(f"{year}-11-15"),\n                "lower_window": -14,  # Two weeks of planning\n                "upper_window": 14,\n            }\n        )\n\n    return pd.DataFrame(business_events)\n'})})]}),"\n",(0,r.jsx)(n.h2,{id:"model-validation-and-performance-assessment",children:"Model Validation and Performance Assessment"}),"\n",(0,r.jsx)(n.h3,{id:"cross-validation-best-practices",children:"Cross-Validation Best Practices"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def comprehensive_model_validation(model, df):\n    """Perform comprehensive Prophet model validation."""\n\n    with mlflow.start_run(run_name="Comprehensive Model Validation"):\n        # Multiple cross-validation configurations\n        cv_configs = [\n            {\n                "name": "short_horizon",\n                "initial": "365 days",\n                "period": "90 days",\n                "horizon": "90 days",\n            },\n            {\n                "name": "medium_horizon",\n                "initial": "730 days",\n                "period": "180 days",\n                "horizon": "180 days",\n            },\n            {\n                "name": "long_horizon",\n                "initial": "1095 days",\n                "period": "180 days",\n                "horizon": "365 days",\n            },\n        ]\n\n        all_metrics = {}\n\n        for config in cv_configs:\n            try:\n                # Perform cross-validation\n                cv_results = cross_validation(\n                    model,\n                    initial=config["initial"],\n                    period=config["period"],\n                    horizon=config["horizon"],\n                    parallel="threads",\n                )\n\n                # Calculate metrics\n                metrics = performance_metrics(cv_results)\n                avg_metrics = metrics[["mse", "rmse", "mae", "mape", "coverage"]].mean()\n\n                # Store metrics with configuration prefix\n                for metric, value in avg_metrics.items():\n                    metric_name = f"{config[\'name\']}_{metric}"\n                    all_metrics[metric_name] = value\n                    mlflow.log_metric(metric_name, value)\n\n                # Log additional statistics\n                mlflow.log_metrics(\n                    {\n                        f"{config[\'name\']}_cv_folds": len(cv_results),\n                        f"{config[\'name\']}_mape_std": metrics["mape"].std(),\n                    }\n                )\n\n            except Exception as e:\n                print(f"Cross-validation failed for {config[\'name\']}: {e}")\n                mlflow.log_param(f"{config[\'name\']}_error", str(e))\n\n        return all_metrics\n\n\n# Usage\nvalidation_metrics = comprehensive_model_validation(model, df)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"forecast-quality-assessment",children:"Forecast Quality Assessment"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import matplotlib.pyplot as plt\nimport seaborn as sns\n\n\ndef analyze_forecast_quality(model, df):\n    """Analyze forecast quality with visualizations."""\n\n    with mlflow.start_run(run_name="Forecast Quality Analysis"):\n        # Generate forecast\n        future = model.make_future_dataframe(periods=365)\n        if model.growth == "logistic":\n            future["cap"] = df["cap"].iloc[-1]  # Use last known capacity\n            future["floor"] = df["floor"].iloc[-1] if "floor" in df.columns else 0\n\n        forecast = model.predict(future)\n\n        # Component analysis\n        fig = model.plot_components(forecast, figsize=(12, 8))\n        plt.tight_layout()\n        plt.savefig("forecast_components.png", dpi=300, bbox_inches="tight")\n        mlflow.log_artifact("forecast_components.png")\n        plt.close()\n\n        # Forecast plot\n        fig = model.plot(forecast, figsize=(12, 6))\n        plt.title("Prophet Forecast")\n        plt.tight_layout()\n        plt.savefig("forecast_plot.png", dpi=300, bbox_inches="tight")\n        mlflow.log_artifact("forecast_plot.png")\n        plt.close()\n\n        # Residual analysis\n        # Get historical predictions\n        historical_forecast = forecast[forecast["ds"] <= df["ds"].max()]\n        residuals = (\n            df.set_index("ds")["y"] - historical_forecast.set_index("ds")["yhat"]\n        )\n\n        # Plot residuals\n        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n        # Residuals over time\n        axes[0, 0].plot(residuals.index, residuals.values)\n        axes[0, 0].set_title("Residuals Over Time")\n        axes[0, 0].set_xlabel("Date")\n        axes[0, 0].set_ylabel("Residual")\n\n        # Residual distribution\n        axes[0, 1].hist(residuals.values, bins=30, alpha=0.7)\n        axes[0, 1].set_title("Residual Distribution")\n        axes[0, 1].set_xlabel("Residual")\n        axes[0, 1].set_ylabel("Frequency")\n\n        # Q-Q plot\n        from scipy import stats\n\n        stats.probplot(residuals.values, dist="norm", plot=axes[1, 0])\n        axes[1, 0].set_title("Q-Q Plot")\n\n        # Residuals vs fitted\n        axes[1, 1].scatter(historical_forecast["yhat"], residuals.values, alpha=0.6)\n        axes[1, 1].set_title("Residuals vs Fitted")\n        axes[1, 1].set_xlabel("Fitted Values")\n        axes[1, 1].set_ylabel("Residuals")\n\n        plt.tight_layout()\n        plt.savefig("residual_analysis.png", dpi=300, bbox_inches="tight")\n        mlflow.log_artifact("residual_analysis.png")\n        plt.close()\n\n        # Calculate residual statistics\n        residual_stats = {\n            "residual_mean": residuals.mean(),\n            "residual_std": residuals.std(),\n            "residual_skewness": stats.skew(residuals.values),\n            "residual_kurtosis": stats.kurtosis(residuals.values),\n            "ljung_box_pvalue": stats.diagnostic.acorr_ljungbox(\n                residuals.values, lags=10, return_df=True\n            )["lb_pvalue"].iloc[-1],\n        }\n\n        mlflow.log_metrics(residual_stats)\n\n        return forecast, residual_stats\n\n\n# Usage\nforecast_analysis, residual_stats = analyze_forecast_quality(model, df)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"hyperparameter-optimization",children:"Hyperparameter Optimization"}),"\n",(0,r.jsx)(n.h3,{id:"systematic-parameter-tuning",children:"Systematic Parameter Tuning"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import itertools\nfrom sklearn.metrics import mean_absolute_percentage_error\n\n\ndef optimize_prophet_hyperparameters(df, param_grid=None):\n    """Systematic hyperparameter optimization for Prophet."""\n\n    if param_grid is None:\n        param_grid = {\n            "changepoint_prior_scale": [0.001, 0.01, 0.1, 0.5],\n            "seasonality_prior_scale": [0.01, 0.1, 1.0, 10.0],\n            "holidays_prior_scale": [0.01, 0.1, 1.0, 10.0],\n            "seasonality_mode": ["additive", "multiplicative"],\n        }\n\n    # Generate all parameter combinations\n    param_names = list(param_grid.keys())\n    param_values = list(param_grid.values())\n    param_combinations = list(itertools.product(*param_values))\n\n    results = []\n\n    with mlflow.start_run(run_name="Prophet Hyperparameter Optimization"):\n        mlflow.log_param("total_combinations", len(param_combinations))\n\n        for i, param_combo in enumerate(param_combinations):\n            param_dict = dict(zip(param_names, param_combo))\n\n            with mlflow.start_run(run_name=f"Config_{i+1}", nested=True):\n                try:\n                    # Create model with current parameters\n                    model = Prophet(**param_dict)\n\n                    # Time series split for validation\n                    train_size = int(len(df) * 0.8)\n                    train_df = df.iloc[:train_size]\n                    test_df = df.iloc[train_size:]\n\n                    # Fit model\n                    model.fit(train_df)\n\n                    # Predict on test set\n                    future = model.make_future_dataframe(periods=len(test_df))\n                    if model.growth == "logistic":\n                        future["cap"] = df["cap"].iloc[-1]\n\n                    forecast = model.predict(future)\n                    test_forecast = forecast.iloc[-len(test_df) :]\n\n                    # Calculate metrics\n                    mape = mean_absolute_percentage_error(\n                        test_df["y"], test_forecast["yhat"]\n                    )\n                    mae = np.mean(np.abs(test_df["y"] - test_forecast["yhat"]))\n                    rmse = np.sqrt(np.mean((test_df["y"] - test_forecast["yhat"]) ** 2))\n\n                    # Log parameters and metrics\n                    mlflow.log_params(param_dict)\n                    mlflow.log_metrics(\n                        {"test_mape": mape, "test_mae": mae, "test_rmse": rmse}\n                    )\n\n                    # Store results\n                    result = {**param_dict, "mape": mape, "mae": mae, "rmse": rmse}\n                    results.append(result)\n\n                    print(f"Config {i+1}/{len(param_combinations)}: MAPE = {mape:.4f}")\n\n                except Exception as e:\n                    print(f"Error in configuration {i+1}: {e}")\n                    mlflow.log_param("error", str(e))\n\n        # Find best configuration\n        best_result = min(results, key=lambda x: x["mape"])\n\n        # Log best configuration\n        mlflow.log_params({f"best_{k}": v for k, v in best_result.items()})\n\n        # Train final model with best parameters\n        best_params = {\n            k: v for k, v in best_result.items() if k not in ["mape", "mae", "rmse"]\n        }\n        final_model = Prophet(**best_params)\n        final_model.fit(df)\n\n        # Log final model\n        mlflow.prophet.log_model(\n            pr_model=final_model,\n            name="best_model",\n            input_example=df[["ds"]].head(),\n        )\n\n        return final_model, best_result, results\n\n\n# Usage\nbest_model, best_config, all_results = optimize_prophet_hyperparameters(df)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"advanced-optimization-with-optuna",children:"Advanced Optimization with Optuna"}),"\n",(0,r.jsxs)(a,{children:[(0,r.jsx)("summary",{children:"Bayesian Hyperparameter Optimization"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import optuna\n\n\ndef objective(trial, df):\n    """Optuna objective function for Prophet optimization."""\n\n    # Define hyperparameter search space\n    params = {\n        "changepoint_prior_scale": trial.suggest_float(\n            "changepoint_prior_scale", 0.001, 1.0, log=True\n        ),\n        "seasonality_prior_scale": trial.suggest_float(\n            "seasonality_prior_scale", 0.01, 50.0, log=True\n        ),\n        "holidays_prior_scale": trial.suggest_float(\n            "holidays_prior_scale", 0.01, 50.0, log=True\n        ),\n        "seasonality_mode": trial.suggest_categorical(\n            "seasonality_mode", ["additive", "multiplicative"]\n        ),\n        "yearly_seasonality": trial.suggest_categorical(\n            "yearly_seasonality", [True, False, "auto"]\n        ),\n        "weekly_seasonality": trial.suggest_categorical(\n            "weekly_seasonality", [True, False, "auto"]\n        ),\n        "daily_seasonality": trial.suggest_categorical(\n            "daily_seasonality", [True, False, "auto"]\n        ),\n    }\n\n    with mlflow.start_run(nested=True):\n        try:\n            # Create and train model\n            model = Prophet(**params)\n\n            # Time series cross-validation\n            cv_results = cross_validation(\n                model.fit(df),\n                initial="730 days",\n                period="180 days",\n                horizon="90 days",\n                parallel="threads",\n            )\n\n            # Calculate performance metric\n            metrics = performance_metrics(cv_results)\n            mape = metrics["mape"].mean()\n\n            # Log trial results\n            mlflow.log_params(params)\n            mlflow.log_metric("cv_mape", mape)\n\n            return mape\n\n        except Exception as e:\n            print(f"Trial failed: {e}")\n            return float("inf")\n\n\ndef optuna_prophet_optimization(df, n_trials=100):\n    """Run Optuna optimization for Prophet."""\n\n    with mlflow.start_run(run_name="Optuna Prophet Optimization"):\n        # Create study\n        study = optuna.create_study(\n            direction="minimize", sampler=optuna.samplers.TPESampler(seed=42)\n        )\n\n        # Optimize\n        study.optimize(\n            lambda trial: objective(trial, df),\n            n_trials=n_trials,\n            show_progress_bar=True,\n        )\n\n        # Log best results\n        best_params = study.best_params\n        best_value = study.best_value\n\n        mlflow.log_params({f"best_{k}": v for k, v in best_params.items()})\n        mlflow.log_metric("best_mape", best_value)\n\n        # Train final model\n        final_model = Prophet(**best_params)\n        final_model.fit(df)\n\n        mlflow.prophet.log_model(pr_model=final_model, name="optuna_best_model")\n\n        return final_model, study\n\n\n# Usage\n# optimized_model, study = optuna_prophet_optimization(df, n_trials=50)\n'})})]}),"\n",(0,r.jsx)(n.h2,{id:"model-deployment-and-serving",children:"Model Deployment and Serving"}),"\n",(0,r.jsx)(n.h3,{id:"model-loading-and-prediction",children:"Model Loading and Prediction"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def load_and_predict_prophet_model(model_uri, future_periods=30):\n    """Load Prophet model and generate predictions."""\n\n    # Load model\n    loaded_model = mlflow.prophet.load_model(model_uri)\n\n    # Generate future dataframe\n    future = loaded_model.make_future_dataframe(periods=future_periods)\n\n    # Add any required regressors or caps\n    if hasattr(loaded_model, "extra_regressors") and loaded_model.extra_regressors:\n        # You would need to provide values for external regressors\n        # This is a simplified example\n        for regressor in loaded_model.extra_regressors:\n            future[regressor] = np.random.normal(1000, 100, len(future))\n\n    if loaded_model.growth == "logistic":\n        future["cap"] = 10000  # Set appropriate capacity\n\n    # Generate predictions\n    forecast = loaded_model.predict(future)\n\n    return forecast\n\n\n# Usage\n# run_id = "your_run_id_here"\n# model_uri = f"runs:/{run_id}/prophet_model"\n# predictions = load_and_predict_prophet_model(model_uri, future_periods=365)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"production-deployment-patterns",children:"Production Deployment Patterns"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'class ProphetForecaster:\n    """Production-ready Prophet forecaster class."""\n\n    def __init__(self, model_uri):\n        self.model_uri = model_uri\n        self.model = None\n        self.last_training_date = None\n\n    def load_model(self):\n        """Load the Prophet model."""\n        self.model = mlflow.prophet.load_model(self.model_uri)\n        if hasattr(self.model, "history"):\n            self.last_training_date = self.model.history["ds"].max()\n\n    def predict(self, periods=30, frequency="D", include_history=False):\n        """Generate predictions."""\n        if self.model is None:\n            self.load_model()\n\n        # Generate future dataframe\n        future = self.model.make_future_dataframe(\n            periods=periods, freq=frequency, include_history=include_history\n        )\n\n        # Handle logistic growth\n        if self.model.growth == "logistic":\n            future["cap"] = future.get("cap", 10000)  # Default capacity\n\n        # Generate forecast\n        forecast = self.model.predict(future)\n\n        # Return relevant columns\n        columns = ["ds", "yhat", "yhat_lower", "yhat_upper"]\n        if not include_history:\n            # Return only future predictions\n            forecast = forecast.tail(periods)\n\n        return forecast[columns]\n\n    def get_components(self, periods=30):\n        """Get forecast components."""\n        if self.model is None:\n            self.load_model()\n\n        future = self.model.make_future_dataframe(periods=periods)\n        if self.model.growth == "logistic":\n            future["cap"] = future.get("cap", 10000)\n\n        forecast = self.model.predict(future)\n\n        # Extract components\n        components = {}\n        for component in ["trend", "yearly", "weekly"]:\n            if component in forecast.columns:\n                components[component] = forecast[["ds", component]].tail(periods)\n\n        return components\n\n    def check_model_freshness(self, current_date=None):\n        """Check if model needs retraining."""\n        if current_date is None:\n            current_date = pd.Timestamp.now()\n\n        if self.last_training_date is None:\n            return False, "No training date available"\n\n        days_since_training = (current_date - self.last_training_date).days\n\n        # Define freshness threshold (e.g., 30 days)\n        freshness_threshold = 30\n\n        is_fresh = days_since_training < freshness_threshold\n        message = f"Model is {days_since_training} days old"\n\n        return is_fresh, message\n\n\n# Usage\nforecaster = ProphetForecaster("models:/ProphetForecastModel/Production")\npredictions = forecaster.predict(periods=90)\ncomponents = forecaster.get_components(periods=90)\nis_fresh, message = forecaster.check_model_freshness()\n'})}),"\n",(0,r.jsxs)(a,{children:[(0,r.jsx)("summary",{children:"Batch Prediction Pipeline"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def batch_prophet_predictions(model_registry_name, stage="Production"):\n    """Run batch predictions for multiple time series."""\n\n    with mlflow.start_run(run_name="Batch Prophet Predictions"):\n        # Load production model\n        model_uri = f"models:/{model_registry_name}/{stage}"\n        model = mlflow.prophet.load_model(model_uri)\n\n        # Generate predictions for different horizons\n        horizons = [30, 90, 365]  # Days\n        predictions = {}\n\n        for horizon in horizons:\n            future = model.make_future_dataframe(periods=horizon)\n            if model.growth == "logistic":\n                future["cap"] = 10000  # Set capacity\n\n            forecast = model.predict(future)\n\n            # Store predictions\n            predictions[f"{horizon}_days"] = forecast[\n                ["ds", "yhat", "yhat_lower", "yhat_upper"]\n            ].tail(horizon)\n\n            # Log prediction summary\n            pred_summary = {\n                f"{horizon}d_mean_forecast": forecast["yhat"].tail(horizon).mean(),\n                f"{horizon}d_forecast_range": forecast["yhat"].tail(horizon).max()\n                - forecast["yhat"].tail(horizon).min(),\n            }\n            mlflow.log_metrics(pred_summary)\n\n        # Save predictions as artifacts\n        for horizon, pred_df in predictions.items():\n            filename = f"predictions_{horizon}.csv"\n            pred_df.to_csv(filename, index=False)\n            mlflow.log_artifact(filename)\n\n        # Log batch prediction metadata\n        mlflow.log_params(\n            {\n                "model_uri": model_uri,\n                "prediction_date": pd.Timestamp.now().isoformat(),\n                "horizons": horizons,\n            }\n        )\n\n        return predictions\n'})})]}),"\n",(0,r.jsx)(n.h2,{id:"model-monitoring-and-maintenance",children:"Model Monitoring and Maintenance"}),"\n",(0,r.jsx)(n.h3,{id:"forecast-accuracy-monitoring",children:"Forecast Accuracy Monitoring"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def monitor_forecast_accuracy(model_uri, actuals_df, prediction_horizon_days=30):\n    """Monitor Prophet model accuracy against actual values."""\n\n    with mlflow.start_run(run_name="Forecast Accuracy Monitoring"):\n        # Load model\n        model = mlflow.prophet.load_model(model_uri)\n\n        # Generate historical predictions for comparison\n        cutoff_date = actuals_df["ds"].max() - pd.Timedelta(\n            days=prediction_horizon_days\n        )\n        historical_data = actuals_df[actuals_df["ds"] <= cutoff_date]\n\n        # Refit model on historical data\n        temp_model = Prophet()\n        temp_model.fit(historical_data)\n\n        # Generate predictions for the monitoring period\n        future = temp_model.make_future_dataframe(periods=prediction_horizon_days)\n        if temp_model.growth == "logistic":\n            future["cap"] = (\n                historical_data["cap"].iloc[-1]\n                if "cap" in historical_data.columns\n                else 10000\n            )\n\n        forecast = temp_model.predict(future)\n\n        # Get actual values for the prediction period\n        actual_values = actuals_df[actuals_df["ds"] > cutoff_date]\n        forecast_values = forecast[forecast["ds"] > cutoff_date]\n\n        # Align dates\n        merged = actual_values.merge(\n            forecast_values[["ds", "yhat", "yhat_lower", "yhat_upper"]], on="ds"\n        )\n\n        if len(merged) > 0:\n            # Calculate accuracy metrics\n            mae = np.mean(np.abs(merged["y"] - merged["yhat"]))\n            mape = np.mean(np.abs((merged["y"] - merged["yhat"]) / merged["y"])) * 100\n            rmse = np.sqrt(np.mean((merged["y"] - merged["yhat"]) ** 2))\n\n            # Coverage (percentage of actuals within prediction intervals)\n            coverage = (\n                np.mean(\n                    (merged["y"] >= merged["yhat_lower"])\n                    & (merged["y"] <= merged["yhat_upper"])\n                )\n                * 100\n            )\n\n            # Log metrics\n            accuracy_metrics = {\n                "monitoring_mae": mae,\n                "monitoring_mape": mape,\n                "monitoring_rmse": rmse,\n                "prediction_coverage": coverage,\n            }\n            mlflow.log_metrics(accuracy_metrics)\n\n            # Create accuracy visualization\n            plt.figure(figsize=(12, 6))\n            plt.plot(merged["ds"], merged["y"], label="Actual", marker="o")\n            plt.plot(merged["ds"], merged["yhat"], label="Predicted", marker="s")\n            plt.fill_between(\n                merged["ds"],\n                merged["yhat_lower"],\n                merged["yhat_upper"],\n                alpha=0.3,\n                label="Prediction Interval",\n            )\n            plt.title(f"Forecast Accuracy Monitoring (MAPE: {mape:.2f}%)")\n            plt.xlabel("Date")\n            plt.ylabel("Value")\n            plt.legend()\n            plt.xticks(rotation=45)\n            plt.tight_layout()\n            plt.savefig("accuracy_monitoring.png", dpi=300, bbox_inches="tight")\n            mlflow.log_artifact("accuracy_monitoring.png")\n            plt.close()\n\n            return accuracy_metrics\n        else:\n            print("No overlapping dates found for accuracy assessment")\n            return None\n\n\n# Usage\n# accuracy_metrics = monitor_forecast_accuracy(model_uri, new_actuals_df, prediction_horizon_days=30)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"automated-model-retraining",children:"Automated Model Retraining"}),"\n",(0,r.jsxs)(a,{children:[(0,r.jsx)("summary",{children:"Production Model Update Pipeline"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def automated_prophet_retraining(\n    current_model_name, new_data, performance_threshold_mape=10.0, min_data_points=100\n):\n    """Automated Prophet model retraining pipeline."""\n\n    with mlflow.start_run(run_name="Automated Prophet Retraining"):\n        # Load current production model\n        current_model_uri = f"models:/{current_model_name}/Production"\n\n        try:\n            current_model = mlflow.prophet.load_model(current_model_uri)\n            mlflow.log_param("current_model_loaded", True)\n        except Exception as e:\n            print(f"Could not load current model: {e}")\n            current_model = None\n            mlflow.log_param("current_model_loaded", False)\n\n        # Data quality checks\n        data_quality_passed = True\n        quality_issues = []\n\n        # Check data quantity\n        if len(new_data) < min_data_points:\n            data_quality_passed = False\n            quality_issues.append(\n                f"Insufficient data: {len(new_data)} < {min_data_points}"\n            )\n\n        # Check for missing values\n        missing_values = new_data[["ds", "y"]].isnull().sum().sum()\n        if missing_values > 0:\n            quality_issues.append(f"Missing values found: {missing_values}")\n\n        # Check date continuity\n        new_data = new_data.sort_values("ds")\n        date_gaps = pd.to_datetime(new_data["ds"]).diff().dt.days\n        large_gaps = (date_gaps > 7).sum()  # Gaps larger than 7 days\n        if large_gaps > 0:\n            quality_issues.append(f"Large date gaps found: {large_gaps}")\n\n        mlflow.log_params(\n            {\n                "data_quality_passed": data_quality_passed,\n                "data_points": len(new_data),\n                "quality_issues": "; ".join(quality_issues),\n            }\n        )\n\n        if not data_quality_passed:\n            print("Data quality checks failed. Skipping retraining.")\n            return None\n\n        # Train new model\n        new_model = Prophet(\n            yearly_seasonality=True,\n            weekly_seasonality=True,\n            daily_seasonality=False,\n            changepoint_prior_scale=0.05,\n        )\n\n        new_model.fit(new_data)\n\n        # Evaluate new model performance\n        cv_results = cross_validation(\n            new_model,\n            initial="365 days",\n            period="90 days",\n            horizon="30 days",\n            parallel="threads",\n        )\n\n        metrics = performance_metrics(cv_results)\n        new_mape = metrics["mape"].mean()\n\n        mlflow.log_metric("new_model_mape", new_mape)\n\n        # Compare with current model if available\n        should_deploy = True\n        if current_model is not None:\n            try:\n                # Test current model on new data\n                current_cv = cross_validation(\n                    current_model,\n                    initial="365 days",\n                    period="90 days",\n                    horizon="30 days",\n                )\n                current_metrics = performance_metrics(current_cv)\n                current_mape = current_metrics["mape"].mean()\n\n                mlflow.log_metric("current_model_mape", current_mape)\n\n                # Deploy if new model is significantly better\n                improvement = (current_mape - new_mape) / current_mape * 100\n                mlflow.log_metric("performance_improvement_percent", improvement)\n\n                should_deploy = improvement > 5.0  # Deploy if >5% improvement\n\n            except Exception as e:\n                print(f"Could not evaluate current model: {e}")\n                should_deploy = new_mape < performance_threshold_mape\n        else:\n            should_deploy = new_mape < performance_threshold_mape\n\n        mlflow.log_params(\n            {\n                "should_deploy": should_deploy,\n                "performance_threshold": performance_threshold_mape,\n            }\n        )\n\n        # Log and potentially deploy new model\n        model_info = mlflow.prophet.log_model(\n            pr_model=new_model,\n            name="retrained_model",\n            registered_model_name=current_model_name if should_deploy else None,\n        )\n\n        if should_deploy:\n            # Transition to production\n            client = mlflow.MlflowClient()\n            latest_version = client.get_latest_versions(\n                current_model_name, stages=["None"]\n            )[0]\n\n            client.transition_model_version_stage(\n                name=current_model_name,\n                version=latest_version.version,\n                stage="Production",\n            )\n\n            print(f"New model deployed to production with MAPE: {new_mape:.2f}%")\n        else:\n            print(\n                f"New model not deployed. MAPE: {new_mape:.2f}% did not meet criteria."\n            )\n\n        return new_model, should_deploy\n'})})]}),"\n",(0,r.jsx)(n.h2,{id:"best-practices-and-tips",children:"Best Practices and Tips"}),"\n",(0,r.jsx)(n.h3,{id:"data-preparation-best-practices",children:"Data Preparation Best Practices"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def prophet_data_best_practices():\n    """Demonstrate Prophet data preparation best practices."""\n\n    best_practices = {\n        "data_frequency": "Use consistent frequency (daily, weekly, monthly)",\n        "missing_values": "Prophet handles missing values, but document them",\n        "outliers": "Consider outlier detection and handling",\n        "data_volume": "Minimum 2-3 seasonal cycles (2-3 years for yearly seasonality)",\n        "column_names": "Always use \'ds\' for dates and \'y\' for values",\n        "date_format": "Ensure dates are properly parsed as datetime",\n        "timezone_handling": "Be consistent with timezone handling",\n    }\n\n    print("Prophet Data Preparation Best Practices:")\n    for practice, description in best_practices.items():\n        print(f"- {practice}: {description}")\n\n    return best_practices\n\n\n# Data validation function\ndef validate_prophet_data(df):\n    """Validate data for Prophet modeling."""\n\n    issues = []\n    recommendations = []\n\n    # Check required columns\n    if not all(col in df.columns for col in ["ds", "y"]):\n        issues.append("Missing required columns \'ds\' and/or \'y\'")\n\n    # Check data types\n    if "ds" in df.columns and not pd.api.types.is_datetime64_any_dtype(df["ds"]):\n        issues.append("Column \'ds\' is not datetime type")\n        recommendations.append(\n            "Convert \'ds\' to datetime: df[\'ds\'] = pd.to_datetime(df[\'ds\'])"\n        )\n\n    # Check for sufficient data\n    if len(df) < 100:\n        issues.append(f"Insufficient data points: {len(df)} (recommend >100)")\n\n    # Check for missing values\n    missing_y = df["y"].isnull().sum()\n    if missing_y > 0:\n        recommendations.append(f"Consider handling {missing_y} missing values in \'y\'")\n\n    # Check for duplicate dates\n    if "ds" in df.columns:\n        duplicates = df["ds"].duplicated().sum()\n        if duplicates > 0:\n            issues.append(f"Found {duplicates} duplicate dates")\n\n    # Check data range\n    if "ds" in df.columns and len(df) > 0:\n        date_range = (df["ds"].max() - df["ds"].min()).days\n        if date_range < 365:\n            recommendations.append(\n                "Less than 1 year of data may limit seasonality detection"\n            )\n\n    return {\n        "issues": issues,\n        "recommendations": recommendations,\n        "data_points": len(df),\n        "date_range_days": date_range if "ds" in df.columns and len(df) > 0 else 0,\n    }\n\n\n# Usage\nvalidation_results = validate_prophet_data(df)\nprint("Validation Results:", validation_results)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,r.jsxs)(a,{children:[(0,r.jsx)("summary",{children:"Prophet Performance Tips"}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def optimize_prophet_performance():\n    """Tips for optimizing Prophet performance."""\n\n    optimization_tips = {\n        "parallel_processing": {\n            "cross_validation": "Use parallel=\'threads\' or \'processes\' in cross_validation()",\n            "multiple_models": "Use joblib.Parallel for training multiple models",\n        },\n        "model_configuration": {\n            "mcmc_samples": "Set mcmc_samples=0 for faster MAP estimation",\n            "uncertainty_samples": "Reduce uncertainty_samples for faster predictions",\n            "stan_backend": "Use \'CMDSTANPY\' backend for better performance",\n        },\n        "data_preprocessing": {\n            "frequency": "Aggregate to appropriate frequency (daily vs hourly)",\n            "outliers": "Remove extreme outliers before training",\n            "data_size": "Consider sampling for very large datasets",\n        },\n    }\n\n    return optimization_tips\n\n\n# Example of parallel cross-validation\ndef parallel_prophet_evaluation(models_dict, df):\n    """Evaluate multiple Prophet models in parallel."""\n\n    from joblib import Parallel, delayed\n\n    def evaluate_single_model(name, model):\n        try:\n            cv_results = cross_validation(\n                model.fit(df),\n                initial="365 days",\n                period="90 days",\n                horizon="30 days",\n                parallel="threads",\n            )\n            metrics = performance_metrics(cv_results)\n            return name, metrics["mape"].mean()\n        except Exception as e:\n            return name, float("inf")\n\n    # Parallel evaluation\n    results = Parallel(n_jobs=-1)(\n        delayed(evaluate_single_model)(name, model)\n        for name, model in models_dict.items()\n    )\n\n    return dict(results)\n'})})]}),"\n",(0,r.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,r.jsx)(n.p,{children:"MLflow's Prophet integration provides a comprehensive solution for time series forecasting, experiment tracking, and model deployment. Whether you're forecasting business metrics, planning resources, or predicting future trends, the combination of Prophet's intuitive forecasting capabilities and MLflow's robust experiment management creates a powerful platform for professional time series analysis."}),"\n",(0,r.jsx)(n.p,{children:"Key benefits of using MLflow with Prophet include:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Simplified Forecasting Workflow"}),": Easy model logging and experiment tracking for time series projects"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Comprehensive Validation"}),": Built-in cross-validation and performance assessment tools"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Business-Ready Features"}),": Holiday modeling, custom seasonalities, and interpretable components"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Production Deployment"}),": Model registry integration with automated retraining capabilities"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Collaborative Development"}),": Team-friendly experiment sharing and model governance"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"The patterns and examples in this guide provide a solid foundation for building scalable, reliable time series forecasting systems. Start with basic Prophet models for immediate insights, then gradually adopt advanced features like custom seasonalities, automated hyperparameter tuning, and production monitoring as your forecasting needs evolve."}),"\n",(0,r.jsx)(n.p,{children:"Prophet's philosophy of making forecasting accessible to business users, combined with MLflow's enterprise-grade experiment management, creates an ideal platform for data-driven decision making through accurate, interpretable time series predictions."})]})}function p(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(m,{...e})}):m(e)}},28453:(e,n,a)=>{a.d(n,{R:()=>i,x:()=>s});var t=a(96540);const r={},o=t.createContext(r);function i(e){const n=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),t.createElement(o.Provider,{value:n},e.children)}},49374:(e,n,a)=>{a.d(n,{B:()=>l});a(96540);const t=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var r=a(86025),o=a(28774),i=a(74848);const s=e=>{const n=e.split(".");for(let a=n.length;a>0;a--){const e=n.slice(0,a).join(".");if(t[e])return e}return null};function l({fn:e,children:n}){const a=s(e);if(!a)return(0,i.jsx)(i.Fragment,{children:n});const l=(0,r.Ay)(`/${t[a]}#${e}`);return(0,i.jsx)(o.A,{to:l,target:"_blank",children:n??(0,i.jsxs)("code",{children:[e,"()"]})})}}}]);