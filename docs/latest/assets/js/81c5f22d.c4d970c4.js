"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7148],{28453:(e,l,o)=>{o.d(l,{R:()=>a,x:()=>i});var n=o(96540);const r={},t=n.createContext(r);function a(e){const l=n.useContext(t);return n.useMemo((function(){return"function"==typeof e?e(l):{...l,...e}}),[l,e])}function i(e){let l;return l=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),n.createElement(t.Provider,{value:l},e.children)}},67756:(e,l,o)=>{o.d(l,{B:()=>m});o(96540);const n=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var r=o(29030),t=o(56289),a=o(74848);const i=e=>{const l=e.split(".");for(let o=l.length;o>0;o--){const e=l.slice(0,o).join(".");if(n[e])return e}return null};function m(e){let{fn:l,children:o}=e;const m=i(l);if(!m)return(0,a.jsx)(a.Fragment,{children:o});const s=(0,r.Ay)(`/${n[m]}#${l}`);return(0,a.jsx)(t.A,{to:s,target:"_blank",children:o??(0,a.jsxs)("code",{children:[l,"()"]})})}},98489:(e,l,o)=>{o.r(l),o.d(l,{assets:()=>s,contentTitle:()=>m,default:()=>h,frontMatter:()=>i,metadata:()=>n,toc:()=>d});const n=JSON.parse('{"id":"getting-started/registering-first-model/step3-load-model/index","title":"Load a Registered Model","description":"To perform inference on a registered model version, we need to load it into memory. There are many","source":"@site/docs/getting-started/registering-first-model/step3-load-model/index.mdx","sourceDirName":"getting-started/registering-first-model/step3-load-model","slug":"/getting-started/registering-first-model/step3-load-model/","permalink":"/docs/latest/getting-started/registering-first-model/step3-load-model/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Explore the Registered Model","permalink":"/docs/latest/getting-started/registering-first-model/step2-explore-registered-model/"},"next":{"title":"5 Minute Tracking Server Overview","permalink":"/docs/latest/getting-started/tracking-server-overview/"}}');var r=o(74848),t=o(28453),a=o(67756);const i={},m="Load a Registered Model",s={},d=[{value:"Example 0: Load via Tracking Server",id:"example-0-load-via-tracking-server",level:2},{value:"Example 1: Load via Name and Version",id:"example-1-load-via-name-and-version",level:2},{value:"Example 2: Load via Model Version Alias",id:"example-2-load-via-model-version-alias",level:2}];function p(e){const l={code:"code",em:"em",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(l.header,{children:(0,r.jsx)(l.h1,{id:"load-a-registered-model",children:"Load a Registered Model"})}),"\n",(0,r.jsx)(l.p,{children:"To perform inference on a registered model version, we need to load it into memory. There are many\nways to find our model version, but the best method differs depending on the information you have\navailable. However, in the spirit of a quickstart, the below code snippet shows the simplest way to\nload a model from the model registry via a specific model URI and perform inference."}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-python",children:'import mlflow.sklearn\nfrom sklearn.datasets import make_regression\n\nmodel_name = "sk-learn-random-forest-reg-model"\nmodel_version = "latest"\n\n# Load the model from the Model Registry\nmodel_uri = f"models:/{model_name}/{model_version}"\nmodel = mlflow.sklearn.load_model(model_uri)\n\n# Generate a new dataset for prediction and predict\nX_new, _ = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)\ny_pred_new = model.predict(X_new)\n\nprint(y_pred_new)\n'})}),"\n",(0,r.jsxs)(l.p,{children:["Note that if you're not using sklearn, if your model flavor is supported, you should use the\nspecific model flavor load method e.g. ",(0,r.jsx)(l.code,{children:"mlflow.<flavor>.load_model()"}),". If the model flavor is\nnot supported, you should leverage ",(0,r.jsx)(a.B,{fn:"mlflow.pyfunc.load_model"}),". Throughout this tutorial\nwe leverage sklearn for demonstration purposes."]}),"\n",(0,r.jsx)(l.h2,{id:"example-0-load-via-tracking-server",children:"Example 0: Load via Tracking Server"}),"\n",(0,r.jsx)(l.p,{children:"A model URI is a unique identifier for a serialized model. Given the model artifact is stored with\nexperiments in the tracking server, you can use the below model URIs to bypass the model registry\nand load the artifact into memory."}),"\n",(0,r.jsxs)(l.ol,{children:["\n",(0,r.jsxs)(l.li,{children:[(0,r.jsx)(l.strong,{children:"Absolute local path"}),": ",(0,r.jsx)(l.code,{children:'mlflow.sklearn.load_model("/Users/me/path/to/local/model")'})]}),"\n",(0,r.jsxs)(l.li,{children:[(0,r.jsx)(l.strong,{children:"Relative local path"}),": ",(0,r.jsx)(l.code,{children:'mlflow.sklearn.load_model("relative/path/to/local/model")'})]}),"\n",(0,r.jsxs)(l.li,{children:[(0,r.jsx)(l.strong,{children:"Run id"}),": ",(0,r.jsx)(l.code,{children:'mlflow.sklearn.load_model(f"runs:/{mlflow_run_id}/{run_relative_path_to_model}")'})]}),"\n"]}),"\n",(0,r.jsx)(l.p,{children:"However, unless you're in the same environment that you logged the model, you typically won't have\nthe above information. Instead, you should load the model by leveraging the model's name and\nversion."}),"\n",(0,r.jsx)(l.h2,{id:"example-1-load-via-name-and-version",children:"Example 1: Load via Name and Version"}),"\n",(0,r.jsxs)(l.p,{children:["To load a model into memory via the ",(0,r.jsx)(l.code,{children:"model_name"})," and monotonically increasing ",(0,r.jsx)(l.code,{children:"model_version"}),",\nuse the below method:"]}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-python",children:'model = mlflow.sklearn.load_model(f"models:/{model_name}/{model_version}")\n'})}),"\n",(0,r.jsx)(l.p,{children:"While this method is quick and easy, the monotonically increasing model version lacks flexibility.\nOften, it's more efficient to leverage a model version alias."}),"\n",(0,r.jsx)(l.h2,{id:"example-2-load-via-model-version-alias",children:"Example 2: Load via Model Version Alias"}),"\n",(0,r.jsx)(l.p,{children:"Model version aliases are user-defined identifiers for a model version. Given they're mutable after\nmodel registration, they decouple model versions from the code that uses them."}),"\n",(0,r.jsxs)(l.p,{children:["For instance, let's say we have a model version alias called ",(0,r.jsx)(l.code,{children:"production_model"}),", corresponding to\na production model. When our team builds a better model that is ready for deployment, we don't have\nto change our serving workload code. Instead, in MLflow we reassign the ",(0,r.jsx)(l.code,{children:"production_model"})," alias\nfrom the old model version to the new one. This can be done simply in the UI. In the API, we run\n",(0,r.jsx)(l.em,{children:"client.set_registered_model_alias"})," with the same model name, alias name, and ",(0,r.jsx)(l.strong,{children:"new"})," model version\nID. It's that easy!"]}),"\n",(0,r.jsx)(l.p,{children:"In the prior page, we added a model version alias to our model, but here's a programmatic example."}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-python",children:'import mlflow.sklearn\nfrom mlflow import MlflowClient\n\nclient = MlflowClient()\n\n# Set model version alias\nmodel_name = "sk-learn-random-forest-reg-model"\nmodel_version_alias = "the_best_model_ever"\nclient.set_registered_model_alias(\n    model_name, model_version_alias, "1"\n)  # Duplicate of step in UI\n\n# Get information about the model\nmodel_info = client.get_model_version_by_alias(model_name, model_version_alias)\nmodel_tags = model_info.tags\nprint(model_tags)\n\n# Get the model version using a model URI\nmodel_uri = f"models:/{model_name}@{model_version_alias}"\nmodel = mlflow.sklearn.load_model(model_uri)\n\nprint(model)\n'})}),"\n",(0,r.jsx)(l.pre,{children:(0,r.jsx)(l.code,{className:"language-_",metastring:'title="Output"',children:"{'problem_type': 'regression'}\nRandomForestRegressor(max_depth=2, random_state=42)\n"})}),"\n",(0,r.jsxs)(l.p,{children:["Model version alias is highly dynamic and can correspond to anything that is meaningful for your\nteam. The most common example is a deployment state. For instance, let's say we have a ",(0,r.jsx)(l.code,{children:"champion"}),"\nmodel in production but are developing ",(0,r.jsx)(l.code,{children:"challenger"})," model that will hopefully out-perform our\nproduction model. You can use ",(0,r.jsx)(l.code,{children:"champion"})," and ",(0,r.jsx)(l.code,{children:"challenger"})," model version aliases to uniquely\nidentify these model versions for easy access."]}),"\n",(0,r.jsx)(l.p,{children:"That's it! You should now be comfortable..."}),"\n",(0,r.jsxs)(l.ol,{children:["\n",(0,r.jsx)(l.li,{children:"Registering a model"}),"\n",(0,r.jsx)(l.li,{children:"Finding a model and modifying the tags and model version alias via the MLflow UI"}),"\n",(0,r.jsx)(l.li,{children:"Loading the registered model for inference"}),"\n"]})]})}function h(e={}){const{wrapper:l}={...(0,t.R)(),...e.components};return l?(0,r.jsx)(l,{...e,children:(0,r.jsx)(p,{...e})}):p(e)}}}]);