/*! For license information please see 0a4ce45c.92e9e0dd.js.LICENSE.txt */
"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[3230],{3160:(e,t,i)=>{i.d(t,{A:()=>n});const n=(0,i(84722).A)("eye",[["path",{d:"M2.062 12.348a1 1 0 0 1 0-.696 10.75 10.75 0 0 1 19.876 0 1 1 0 0 1 0 .696 10.75 10.75 0 0 1-19.876 0",key:"1nclc0"}],["circle",{cx:"12",cy:"12",r:"3",key:"1v7zrd"}]])},6789:(e,t,i)=>{i.d(t,{A:()=>c});i(96540);var n=i(28774),o=i(34164);const a={tileCard:"tileCard_NHsj",tileIcon:"tileIcon_pyoR",tileLink:"tileLink_iUbu",tileImage:"tileImage_O4So"};var r=i(86025),s=i(21122),l=i(74848);function c({icon:e,image:t,imageDark:i,imageWidth:c,imageHeight:p,iconSize:d=32,containerHeight:m,title:h,description:u,href:g,linkText:f="Learn more \u2192",className:y}){if(!e&&!t)throw new Error("TileCard requires either an icon or image prop");const v=m?{height:`${m}px`}:{},x={};return c&&(x.width=`${c}px`),p&&(x.height=`${p}px`),(0,l.jsxs)(n.A,{href:g,className:(0,o.A)(a.tileCard,y),children:[(0,l.jsx)("div",{className:a.tileIcon,style:v,children:e?(0,l.jsx)(e,{size:d}):i?(0,l.jsx)(s.A,{sources:{light:(0,r.Ay)(t),dark:(0,r.Ay)(i)},alt:h,className:a.tileImage,style:x}):(0,l.jsx)("img",{src:(0,r.Ay)(t),alt:h,className:a.tileImage,style:x})}),(0,l.jsx)("h3",{children:h}),(0,l.jsx)("p",{children:u}),(0,l.jsx)("div",{className:a.tileLink,children:f})]})}},22492:(e,t,i)=>{i.d(t,{A:()=>n});const n=(0,i(84722).A)("shield",[["path",{d:"M20 13c0 5-3.5 7.5-7.66 8.95a1 1 0 0 1-.67-.01C7.5 20.5 4 18 4 13V6a1 1 0 0 1 1-1c2 0 4.5-1.2 6.24-2.72a1.17 1.17 0 0 1 1.52 0C14.51 3.81 17 5 19 5a1 1 0 0 1 1 1z",key:"oel41y"}]])},28453:(e,t,i)=>{i.d(t,{R:()=>r,x:()=>s});var n=i(96540);const o={},a=n.createContext(o);function r(e){const t=n.useContext(a);return n.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),n.createElement(a.Provider,{value:t},e.children)}},46858:(e,t,i)=>{i.d(t,{A:()=>n});const n=(0,i(84722).A)("zap",[["path",{d:"M4 14a1 1 0 0 1-.78-1.63l9.9-10.2a.5.5 0 0 1 .86.46l-1.92 6.02A1 1 0 0 0 13 10h7a1 1 0 0 1 .78 1.63l-9.9 10.2a.5.5 0 0 1-.86-.46l1.92-6.02A1 1 0 0 0 11 14z",key:"1xq2db"}]])},47792:(e,t,i)=>{i.d(t,{A:()=>n});const n=(0,i(84722).A)("target",[["circle",{cx:"12",cy:"12",r:"10",key:"1mglay"}],["circle",{cx:"12",cy:"12",r:"6",key:"1vlfrh"}],["circle",{cx:"12",cy:"12",r:"2",key:"1c9p78"}]])},51004:(e,t,i)=>{i.d(t,{A:()=>n});const n=(0,i(84722).A)("database",[["ellipse",{cx:"12",cy:"5",rx:"9",ry:"3",key:"msslwz"}],["path",{d:"M3 5V19A9 3 0 0 0 21 19V5",key:"1wlel7"}],["path",{d:"M3 12A9 3 0 0 0 21 12",key:"mv7ke4"}]])},56808:(e,t,i)=>{i.d(t,{A:()=>n});const n=(0,i(84722).A)("circle-play",[["circle",{cx:"12",cy:"12",r:"10",key:"1mglay"}],["polygon",{points:"10 8 16 12 10 16 10 8",key:"1cimsy"}]])},57073:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>j,contentTitle:()=>A,default:()=>L,frontMatter:()=>w,metadata:()=>n,toc:()=>b});const n=JSON.parse('{"id":"getting-started/index","title":"Getting Started with MLflow for GenAI","description":"Build, evaluate, and deploy production-ready GenAI applications with MLflow\'s comprehensive LLMOps platform","source":"@site/docs/genai/getting-started/index.mdx","sourceDirName":"getting-started","slug":"/getting-started/","permalink":"/mlflow-website/docs/latest/genai/getting-started/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"description":"Build, evaluate, and deploy production-ready GenAI applications with MLflow\'s comprehensive LLMOps platform","sidebar_position":1},"sidebar":"genAISidebar","previous":{"title":"FAQs","permalink":"/mlflow-website/docs/latest/genai/mlflow-3/faqs"},"next":{"title":"Try Managed MLflow","permalink":"/mlflow-website/docs/latest/genai/getting-started/databricks-trial/"}}');var o=i(74848),a=i(28453),r=i(82238),s=i(79206),l=i(65592),c=i(6789),p=i(86025),d=i(93672),m=i(98236),h=i(99653),u=i(3160),g=i(51004),f=i(22492),y=i(46858),v=i(56808),x=i(47792);const w={description:"Build, evaluate, and deploy production-ready GenAI applications with MLflow's comprehensive LLMOps platform",sidebar_position:1},A="Getting Started with MLflow for GenAI",j={},b=[{value:"The Complete Open Source LLMOps Platform for Production GenAI",id:"the-complete-open-source-llmops-platform-for-production-genai",level:2},{value:"The GenAI Development Lifecycle",id:"the-genai-development-lifecycle",level:2},{value:"Why Open Source MLflow for GenAI?",id:"why-open-source-mlflow-for-genai",level:2},{value:"Start Building Production GenAI Applications",id:"start-building-production-genai-applications",level:2},{value:"Add Complete Observability in One Line",id:"add-complete-observability-in-one-line",level:3},{value:"Manage and Optimize Prompts Systematically",id:"manage-and-optimize-prompts-systematically",level:3},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Essential Learning Path",id:"essential-learning-path",level:2},{value:"Advanced GenAI Capabilities",id:"advanced-genai-capabilities",level:2},{value:"Framework-Specific Integration Guides",id:"framework-specific-integration-guides",level:2},{value:"Start Your GenAI Journey with MLflow",id:"start-your-genai-journey-with-mlflow",level:2}];function k(e){const t={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.header,{children:(0,o.jsx)(t.h1,{id:"getting-started-with-mlflow-for-genai",children:"Getting Started with MLflow for GenAI"})}),"\n",(0,o.jsx)(t.h2,{id:"the-complete-open-source-llmops-platform-for-production-genai",children:"The Complete Open Source LLMOps Platform for Production GenAI"}),"\n",(0,o.jsx)(t.p,{children:"MLflow transforms how software engineers build, evaluate, and deploy GenAI applications. Get complete observability, systematic evaluation, and deployment confidence\u2014all while maintaining the flexibility to use any framework or model provider."}),"\n",(0,o.jsx)("div",{style:{margin:"2rem 0",textAlign:"center"},children:(0,o.jsx)("img",{src:(0,p.Ay)("/images/llms/tracing/tracing-top.gif"),alt:"MLflow Tracing UI showing detailed GenAI observability",style:{maxWidth:"100%",borderRadius:"8px",boxShadow:"0 4px 12px rgba(0, 0, 0, 0.15)"}})}),"\n",(0,o.jsx)(t.h2,{id:"the-genai-development-lifecycle",children:"The GenAI Development Lifecycle"}),"\n",(0,o.jsx)(t.p,{children:"MLflow provides a complete platform that supports every stage of GenAI application development. From initial prototyping to production monitoring, these integrated capabilities ensure you can build, test, and deploy with confidence."}),"\n",(0,o.jsx)(s.A,{concepts:[{icon:d.A,title:"Develop & Debug",description:"Trace every LLM call, prompt interaction, and tool invocation. Debug complex AI workflows with complete visibility into execution paths, token usage, and decision points."},{icon:m.A,title:"Evaluate & Improve",description:"Systematically test with LLM judges, human feedback, and custom metrics. Compare versions objectively and catch regressions before they reach production."},{icon:h.A,title:"Deploy & Monitor",description:"Serve models with confidence using built-in deployment targets. Monitor production performance and iterate based on real-world usage patterns."}]}),"\n",(0,o.jsx)(t.h2,{id:"why-open-source-mlflow-for-genai",children:"Why Open Source MLflow for GenAI?"}),"\n",(0,o.jsx)(t.p,{children:"As the original open source ML platform, MLflow brings battle-tested reliability and community-driven innovation to GenAI development. No vendor lock-in, no proprietary formats\u2014just powerful tools that work with your stack."}),"\n",(0,o.jsx)(r.A,{features:[{icon:u.A,title:"Production-Grade Observability",description:"Automatically instrument 15+ frameworks including OpenAI, LangChain, and LlamaIndex. Get detailed traces showing token usage, latency, and execution paths for every request\u2014no black boxes."},{icon:g.A,title:"Intelligent Prompt Management",description:"Version, compare, and deploy prompts with MLflow's prompt registry. Track performance across prompt variations and maintain audit trails for production systems."},{icon:f.A,title:"Automated Quality Assurance",description:"Build confidence with LLM judges and automated evaluation. Run systematic tests on every change and track quality metrics over time to prevent regressions."},{icon:y.A,title:"Framework-Agnostic Integration",description:"Use any LLM framework or provider without vendor lock-in. MLflow works with your existing tools while providing unified tracking, evaluation, and deployment."}]}),"\n",(0,o.jsx)(t.h2,{id:"start-building-production-genai-applications",children:"Start Building Production GenAI Applications"}),"\n",(0,o.jsx)(t.p,{children:"MLflow transforms GenAI development from complex instrumentation to simple, one-line integrations. See how easy it is to add comprehensive observability, evaluation, and deployment to your AI applications."}),"\n",(0,o.jsx)(t.h3,{id:"add-complete-observability-in-one-line",children:"Add Complete Observability in One Line"}),"\n",(0,o.jsx)(t.p,{children:"Transform any GenAI application into a fully observable system:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'import mlflow\n\n# Enable automatic tracing for your framework\nmlflow.openai.autolog()  # For OpenAI\nmlflow.langchain.autolog()  # For LangChain\nmlflow.llama_index.autolog()  # For LlamaIndex\nmlflow.dspy.autolog()  # For DSPy\n\n# Your existing code now generates detailed traces\nfrom openai import OpenAI\n\nclient = OpenAI()\nresponse = client.chat.completions.create(\n    model="gpt-4o-mini",\n    messages=[{"role": "user", "content": "Explain quantum computing"}],\n)\n# \u2705 Automatically traced: tokens, latency, cost, full request/response\n'})}),"\n",(0,o.jsx)(t.p,{children:"No code changes required. Every LLM call, tool interaction, and prompt execution is automatically captured with detailed metrics."}),"\n",(0,o.jsx)(t.h3,{id:"manage-and-optimize-prompts-systematically",children:"Manage and Optimize Prompts Systematically"}),"\n",(0,o.jsx)(t.p,{children:"Register prompts and automatically optimize them with data-driven techniques:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'import mlflow\nfrom mlflow.genai.optimize import OptimizerConfig, LLMParams\nfrom mlflow.genai.scorers import scorer\n\n# Register an initial prompt\ninitial_prompt = mlflow.genai.register_prompt(\n    name="math_tutor",\n    template="Answer this math question: {{question}}. Provide a clear explanation.",\n)\n\n# Prepare training data for optimization\ntrain_data = [\n    {\n        "inputs": {"question": "What is 15 + 27?"},\n        "expectations": {"expected_response": "42"},\n    },\n    {\n        "inputs": {"question": "Calculate 8 \xd7 9"},\n        "expectations": {"expected_response": "72"},\n    },\n    # ... more examples\n]\n\n\n@scorer\ndef exact_match(outputs: dict, expectations: dict) -> bool:\n    return outputs == expectations["expected_response"]\n\n\n# Automatically optimize the prompt using MLflow + DSPy\nresult = mlflow.genai.optimize_prompt(\n    target_llm_params=LLMParams(model_name="openai/gpt-4o-mini"),\n    prompt=initial_prompt,\n    train_data=train_data,\n    eval_data=train_data[:5],  # Hold-out evaluation set\n    scorers=[exact_match],\n    optimizer_config=OptimizerConfig(\n        num_instruction_candidates=5,  # Try 5 different prompt variations\n        max_few_shot_examples=3,  # Include up to 3 examples\n    ),\n)\n\n# The optimized prompt is automatically registered as a new version of the original prompt\noptimized_prompt = result.optimized_prompt\nprint(\n    f"Optimization improved accuracy from {result.baseline_score:.2f} to {result.optimized_score:.2f}"\n)\nprint(\n    f"Optimized prompt registered as version {optimized_prompt.version} of \'{optimized_prompt.name}\'"\n)\n\n# Deploy the best-performing version\nwith mlflow.start_run():\n    # Use the optimized prompt in your application\n    model_info = mlflow.openai.log_model(\n        model="gpt-4o-mini",\n        task="llm/v1/completions",\n        name="math_tutor_optimized",\n        prompts=[optimized_prompt],  # Link optimized prompt to model\n    )\n# \u2705 Data-driven prompt optimization + automatic versioning + deployment\n'})}),"\n",(0,o.jsx)(t.p,{children:"Transform manual prompt engineering into systematic, data-driven optimization with automatic performance tracking."}),"\n",(0,o.jsx)(t.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsx)(t.p,{children:"Ready to get started? You'll need:"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:"Python 3.10+ installed"}),"\n",(0,o.jsxs)(t.li,{children:["MLflow 3.0+ (",(0,o.jsx)(t.code,{children:"pip install --upgrade mlflow"}),")"]}),"\n",(0,o.jsxs)(t.li,{children:["For prompt optimization: DSPy (",(0,o.jsx)(t.code,{children:"pip install dspy"}),")"]}),"\n",(0,o.jsx)(t.li,{children:"API access to an LLM provider (OpenAI, Anthropic, etc.)"}),"\n"]}),"\n",(0,o.jsx)(t.hr,{}),"\n",(0,o.jsx)(t.h2,{id:"essential-learning-path",children:"Essential Learning Path"}),"\n",(0,o.jsx)(t.p,{children:"Master these core capabilities to build robust GenAI applications with MLflow. Start with observability, then add systematic evaluation and deployment."}),"\n",(0,o.jsxs)(l.A,{children:[(0,o.jsx)(c.A,{icon:v.A,iconSize:48,title:"Environment Setup",description:"Configure MLflow tracking, connect to registries, and set up your development environment for GenAI workflows",href:"/genai/getting-started/connect-environment",linkText:"Start setup \u2192",containerHeight:64}),(0,o.jsx)(c.A,{icon:u.A,iconSize:48,title:"Observability with Tracing",description:"Auto-instrument your GenAI application to capture every LLM call, prompt, and tool interaction for complete visibility",href:"/genai/tracing/quickstart",linkText:"Learn tracing \u2192",containerHeight:64}),(0,o.jsx)(c.A,{icon:m.A,iconSize:48,title:"Systematic Evaluation",description:"Build confidence with LLM judges and automated testing to catch quality issues before production",href:"/genai/eval-monitor",linkText:"Start evaluating \u2192",containerHeight:64})]}),"\n",(0,o.jsx)(t.p,{children:"These three foundations will give you the observability and quality confidence needed for production GenAI development. Each tutorial includes real code examples and best practices from production deployments."}),"\n",(0,o.jsx)(t.hr,{}),"\n",(0,o.jsx)(t.h2,{id:"advanced-genai-capabilities",children:"Advanced GenAI Capabilities"}),"\n",(0,o.jsx)(t.p,{children:"Once you've mastered the essentials, explore these advanced features to build sophisticated GenAI applications with enterprise-grade reliability."}),"\n",(0,o.jsxs)(l.A,{children:[(0,o.jsx)(c.A,{icon:g.A,iconSize:48,title:"Prompt Registry & Management",description:"Version prompts, A/B test variations, and maintain audit trails for production prompt management",href:"/genai/prompt-registry/prompt-engineering",linkText:"Manage prompts \u2192",containerHeight:64}),(0,o.jsx)(c.A,{icon:x.A,iconSize:48,title:"Automated Prompt Optimization",description:"Automatically improve prompts using DSPy's MIPROv2 algorithm with data-driven optimization and performance tracking",href:"/genai/prompt-registry/optimize-prompts",linkText:"Optimize prompts \u2192",containerHeight:64}),(0,o.jsx)(c.A,{icon:h.A,iconSize:48,title:"Model Deployment",description:"Deploy GenAI models to production with built-in serving, scaling, and monitoring capabilities",href:"/genai/serving",linkText:"Deploy models \u2192",containerHeight:64})]}),"\n",(0,o.jsx)(t.p,{children:"These capabilities enable you to build production-ready GenAI applications with systematic quality management and robust deployment infrastructure."}),"\n",(0,o.jsx)(t.hr,{}),"\n",(0,o.jsx)(t.h2,{id:"framework-specific-integration-guides",children:"Framework-Specific Integration Guides"}),"\n",(0,o.jsx)(t.p,{children:"MLflow provides deep integrations with popular GenAI frameworks. Choose your framework to get started with optimized instrumentation and best practices."}),"\n",(0,o.jsxs)(l.A,{children:[(0,o.jsx)(c.A,{image:"/images/logos/langchain-logo.png",iconSize:48,title:"LangChain Integration",description:"Auto-trace chains, agents, and tools with comprehensive LangChain instrumentation",href:"/genai/flavors/langchain",linkText:"Use LangChain \u2192",containerHeight:64}),(0,o.jsx)(c.A,{image:"/images/logos/llamaindex-logo.svg",iconSize:48,title:"LlamaIndex Integration",description:"Instrument RAG pipelines and document processing workflows with LlamaIndex support",href:"/genai/flavors/llama-index",linkText:"Use LlamaIndex \u2192",containerHeight:64}),(0,o.jsx)(c.A,{image:"/images/logos/openai-logo.svg",iconSize:48,title:"OpenAI Integration",description:"Track completions, embeddings, and function calls with native OpenAI instrumentation",href:"/genai/flavors/openai",linkText:"Use OpenAI \u2192",containerHeight:64}),(0,o.jsx)(c.A,{icon:d.A,iconSize:48,title:"DSPy Integration",description:"Build systematic prompt optimization workflows with DSPy modules and MLflow prompt registry",href:"/genai/flavors/dspy",linkText:"Use DSPy \u2192",containerHeight:64}),(0,o.jsx)(c.A,{icon:d.A,iconSize:48,title:"Custom Framework Support",description:"Instrument any LLM framework or build custom integrations with MLflow's flexible APIs",href:"/genai/flavors/chat-model-intro",linkText:"Build custom \u2192",containerHeight:64})]}),"\n",(0,o.jsx)(t.p,{children:"Each integration guide includes framework-specific examples, best practices, and optimization techniques for production deployments."}),"\n",(0,o.jsx)(t.hr,{}),"\n",(0,o.jsx)(t.h2,{id:"start-your-genai-journey-with-mlflow",children:"Start Your GenAI Journey with MLflow"}),"\n",(0,o.jsx)(t.p,{children:"Ready to build production-ready GenAI applications? Start with the Environment Setup guide above, then explore tracing for complete observability into your AI systems. Join thousands of engineers who trust MLflow's open source platform for their GenAI development."})]})}function L(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(k,{...e})}):k(e)}},65592:(e,t,i)=>{i.d(t,{A:()=>r});i(96540);var n=i(34164);const o={tilesGrid:"tilesGrid_hB9N"};var a=i(74848);function r({children:e,className:t}){return(0,a.jsx)("div",{className:(0,n.A)(o.tilesGrid,t),children:e})}},79206:(e,t,i)=>{i.d(t,{A:()=>a});i(96540);const n={conceptOverview:"conceptOverview_x8T_",overviewTitle:"overviewTitle_HyAI",conceptGrid:"conceptGrid_uJNV",conceptCard:"conceptCard_oday",conceptHeader:"conceptHeader_HCk5",conceptIcon:"conceptIcon_gejw",conceptTitle:"conceptTitle_TGMM",conceptDescription:"conceptDescription_ZyDn"};var o=i(74848);function a({concepts:e,title:t}){return(0,o.jsxs)("div",{className:n.conceptOverview,children:[t&&(0,o.jsx)("h3",{className:n.overviewTitle,children:t}),(0,o.jsx)("div",{className:n.conceptGrid,children:e.map((e,t)=>(0,o.jsxs)("div",{className:n.conceptCard,children:[(0,o.jsxs)("div",{className:n.conceptHeader,children:[e.icon&&(0,o.jsx)("div",{className:n.conceptIcon,children:(0,o.jsx)(e.icon,{size:20})}),(0,o.jsx)("h4",{className:n.conceptTitle,children:e.title})]}),(0,o.jsx)("p",{className:n.conceptDescription,children:e.description})]},t))})]})}},82238:(e,t,i)=>{i.d(t,{A:()=>a});i(96540);const n={featureHighlights:"featureHighlights_Ardf",highlightItem:"highlightItem_XPnN",highlightIcon:"highlightIcon_SUR8",highlightContent:"highlightContent_d0XP"};var o=i(74848);function a({features:e}){return(0,o.jsx)("div",{className:n.featureHighlights,children:e.map((e,t)=>(0,o.jsxs)("div",{className:n.highlightItem,children:[e.icon&&(0,o.jsx)("div",{className:n.highlightIcon,children:(0,o.jsx)(e.icon,{size:24})}),(0,o.jsxs)("div",{className:n.highlightContent,children:[(0,o.jsx)("h4",{children:e.title}),(0,o.jsx)("p",{children:e.description})]})]},t))})}},84722:(e,t,i)=>{i.d(t,{A:()=>c});var n=i(96540);const o=e=>{const t=(e=>e.replace(/^([A-Z])|[\s-_]+(\w)/g,(e,t,i)=>i?i.toUpperCase():t.toLowerCase()))(e);return t.charAt(0).toUpperCase()+t.slice(1)},a=(...e)=>e.filter((e,t,i)=>Boolean(e)&&""!==e.trim()&&i.indexOf(e)===t).join(" ").trim(),r=e=>{for(const t in e)if(t.startsWith("aria-")||"role"===t||"title"===t)return!0};var s={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};const l=(0,n.forwardRef)(({color:e="currentColor",size:t=24,strokeWidth:i=2,absoluteStrokeWidth:o,className:l="",children:c,iconNode:p,...d},m)=>(0,n.createElement)("svg",{ref:m,...s,width:t,height:t,stroke:e,strokeWidth:o?24*Number(i)/Number(t):i,className:a("lucide",l),...!c&&!r(d)&&{"aria-hidden":"true"},...d},[...p.map(([e,t])=>(0,n.createElement)(e,t)),...Array.isArray(c)?c:[c]])),c=(e,t)=>{const i=(0,n.forwardRef)(({className:i,...r},s)=>{return(0,n.createElement)(l,{ref:s,iconNode:t,className:a(`lucide-${c=o(e),c.replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()}`,`lucide-${e}`,i),...r});var c});return i.displayName=o(e),i}},93672:(e,t,i)=>{i.d(t,{A:()=>n});const n=(0,i(84722).A)("code-xml",[["path",{d:"m18 16 4-4-4-4",key:"1inbqp"}],["path",{d:"m6 8-4 4 4 4",key:"15zrgr"}],["path",{d:"m14.5 4-5 16",key:"e7oirm"}]])},98236:(e,t,i)=>{i.d(t,{A:()=>n});const n=(0,i(84722).A)("test-tube",[["path",{d:"M14.5 2v17.5c0 1.4-1.1 2.5-2.5 2.5c-1.4 0-2.5-1.1-2.5-2.5V2",key:"125lnx"}],["path",{d:"M8.5 2h7",key:"csnxdl"}],["path",{d:"M14.5 16h-5",key:"1ox875"}]])},99653:(e,t,i)=>{i.d(t,{A:()=>n});const n=(0,i(84722).A)("rocket",[["path",{d:"M4.5 16.5c-1.5 1.26-2 5-2 5s3.74-.5 5-2c.71-.84.7-2.13-.09-2.91a2.18 2.18 0 0 0-2.91-.09z",key:"m3kijz"}],["path",{d:"m12 15-3-3a22 22 0 0 1 2-3.95A12.88 12.88 0 0 1 22 2c0 2.72-.78 7.5-6 11a22.35 22.35 0 0 1-4 2z",key:"1fmvmk"}],["path",{d:"M9 12H4s.55-3.03 2-4c1.62-1.08 5 0 5 0",key:"1f8sc4"}],["path",{d:"M12 15v5s3.03-.55 4-2c1.08-1.62 0-5 0-5",key:"qeys4"}]])}}]);