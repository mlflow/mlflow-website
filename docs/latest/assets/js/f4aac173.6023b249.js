"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["5302"],{32422(e,r,l){l.r(r),l.d(r,{metadata:()=>n,default:()=>v,frontMatter:()=>j,contentTitle:()=>x,toc:()=>w,assets:()=>g});var n=JSON.parse('{"id":"eval-monitor/scorers/llm-judge/predefined","title":"Built-in LLM Judges","description":"MLflow provides several pre-configured LLM judges optimized for common evaluation scenarios.","source":"@site/docs/genai/eval-monitor/scorers/llm-judge/predefined.mdx","sourceDirName":"eval-monitor/scorers/llm-judge","slug":"/eval-monitor/scorers/llm-judge/predefined","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/predefined","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"genAISidebar","previous":{"title":"LLM Judges and Scorers","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/"},"next":{"title":"Guidelines","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/guidelines"}}'),t=l(74848),i=l(28453),s=l(54725),a=l(46077),o=l(78010),c=l(57250),d=l(95986),h=l(77541),u=l(10440),m=l(7043),p=l(42640),f=l(61878);let j={},x="Built-in LLM Judges",g={},w=[{value:"Example Usage",id:"example-usage",level:2},{value:"Available Judges",id:"available-judges",level:2},{value:"Response Quality",id:"response-quality",level:3},{value:"RAG",id:"rag",level:3},{value:"Tool Call",id:"tool-call",level:3},{value:"Multi-Turn",id:"multi-turn",level:3},{value:"Next Steps",id:"next-steps",level:2}];function y(e){let r={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(r.header,{children:(0,t.jsx)(r.h1,{id:"built-in-llm-judges",children:"Built-in LLM Judges"})}),"\n",(0,t.jsx)(r.p,{children:"MLflow provides several pre-configured LLM judges optimized for common evaluation scenarios."}),"\n",(0,t.jsx)(r.h2,{id:"example-usage",children:"Example Usage"}),"\n",(0,t.jsx)(d.A,{children:(0,t.jsxs)(o.A,{groupId:"creation-method",children:[(0,t.jsxs)(c.A,{value:"ui",label:"UI",default:!0,children:[(0,t.jsx)(r.admonition,{title:"Version Requirements",type:"note",children:(0,t.jsxs)(r.p,{children:["The Judge Builder UI requires ",(0,t.jsx)(r.strong,{children:"MLflow >= 3.9.0"}),"."]})}),(0,t.jsx)(r.p,{children:"The MLflow UI provides a visual Judge Builder that lets you create custom LLM judges without writing code."}),(0,t.jsxs)(r.ol,{children:["\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsxs)(r.p,{children:["Navigate to your experiment and select the ",(0,t.jsx)(r.strong,{children:"Judges"})," tab, then click ",(0,t.jsx)(r.strong,{children:"New LLM judge"})]}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:["\n",(0,t.jsxs)(r.p,{children:[(0,t.jsx)(r.strong,{children:"LLM judge"}),": Select a built-in judge. We're using the ",(0,t.jsx)(r.code,{children:"RelevanceToQuery"})," and ",(0,t.jsx)(r.code,{children:"Correctness"})," judges in this example."]}),"\n"]}),"\n"]}),(0,t.jsx)(a.A,{src:"/images/mlflow-3/eval-monitor/scorers/relevance-create-judge-ui.png",alt:"RelevanceToQuery Judge UI"}),(0,t.jsxs)(r.ol,{start:"3",children:["\n",(0,t.jsxs)(r.li,{children:["Click ",(0,t.jsx)(r.strong,{children:"Create judge"})," to save your new LLM judge"]}),"\n"]})]}),(0,t.jsxs)(c.A,{value:"sdk",label:"SDK",children:[(0,t.jsxs)(r.p,{children:["To use the built-in LLM judges, select the judge class from the ",(0,t.jsx)(r.a,{href:"#available-judges",children:"available judges"})," and pass it to the ",(0,t.jsx)(r.code,{children:"scorers"})," argument of the ",(0,t.jsx)(s.B,{fn:"mlflow.genai.evaluate",children:"evaluate"})," function."]}),(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-python",children:'import mlflow\nfrom mlflow.genai.scorers import Correctness, RelevanceToQuery, Guidelines\n\neval_dataset = [\n    {\n        "inputs": {"query": "What is the most common aggregate function in SQL?"},\n        "outputs": "The most common aggregate function in SQL is SUM().",\n        # Correctness judge requires an "expected_facts" field.\n        "expectations": {\n            "expected_facts": ["Most common aggregate function in SQL is COUNT()."],\n        },\n    },\n    {\n        "inputs": {"query": "How do I use MLflow?"},\n        # verbose answer\n        "outputs": "Hi, I\'m a chatbot that answers questions about MLflow. Thank you for asking a great question! I know MLflow well and I\'m glad to help you with that. You will love it! MLflow is a Python-based platform that provides a comprehensive set of tools for logging, tracking, and visualizing machine learning models and experiments throughout their entire lifecycle. It consists of four main components: MLflow Tracking for experiment management, MLflow Projects for reproducible runs, MLflow Models for standardized model packaging, and MLflow Model Registry for centralized model lifecycle management. To get started, simply install it with \'pip install mlflow\' and then use mlflow.start_run() to begin tracking your experiments with automatic logging of parameters, metrics, and artifacts. The platform creates a beautiful web UI where you can compare different runs, visualize metrics over time, and manage your entire ML workflow efficiently. MLflow integrates seamlessly with popular ML libraries like scikit-learn, TensorFlow, PyTorch, and many others, making it incredibly easy to incorporate into your existing projects!",\n        "expectations": {\n            "expected_facts": [\n                "MLflow is a tool for managing and tracking machine learning experiments."\n            ],\n        },\n    },\n]\n\nresults = mlflow.genai.evaluate(\n    data=eval_dataset,\n    scorers=[\n        Correctness(),\n        RelevanceToQuery(),\n    ],\n)\n'})})]})]})}),"\n",(0,t.jsx)(a.A,{src:"/images/mlflow-3/eval-monitor/scorers/builtin-judges-results.png",alt:"Built-in judges result"}),"\n",(0,t.jsx)(r.h2,{id:"available-judges",children:"Available Judges"}),"\n",(0,t.jsx)(r.h3,{id:"response-quality",children:"Response Quality"}),"\n",(0,t.jsxs)(r.table,{children:[(0,t.jsx)(r.thead,{children:(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.th,{children:"Judge"}),(0,t.jsx)(r.th,{children:"What does it evaluate?"}),(0,t.jsx)(r.th,{children:"Requires ground-truth?"}),(0,t.jsx)(r.th,{children:"Requires traces?"})]})}),(0,t.jsxs)(r.tbody,{children:[(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:(0,t.jsx)(r.a,{href:"/genai/eval-monitor/scorers/llm-judge/rag/relevance/#relevancetoquery-judge",children:"RelevanceToQuery"})}),(0,t.jsx)(r.td,{children:"Does the app's response directly address the user's input?"}),(0,t.jsx)(r.td,{children:"No"}),(0,t.jsx)(r.td,{children:"No"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:(0,t.jsx)(r.a,{href:"/genai/eval-monitor/scorers/llm-judge/response-quality/correctness",children:"Correctness"})}),(0,t.jsx)(r.td,{children:"Are the expected facts supported by the app's response?"}),(0,t.jsx)(r.td,{children:"Yes*"}),(0,t.jsx)(r.td,{children:"No"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsxs)(r.td,{children:[(0,t.jsx)(s.B,{fn:"mlflow.genai.scorers.Completeness",children:"Completeness"}),"**"]}),(0,t.jsx)(r.td,{children:"Does the agent address all questions in a single user prompt?"}),(0,t.jsx)(r.td,{children:"No"}),(0,t.jsx)(r.td,{children:"No"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:(0,t.jsx)(s.B,{fn:"mlflow.genai.scorers.Fluency",children:"Fluency"})}),(0,t.jsx)(r.td,{children:"Is the response grammatically correct and naturally flowing?"}),(0,t.jsx)(r.td,{children:"No"}),(0,t.jsx)(r.td,{children:"No"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:(0,t.jsx)(r.a,{href:"/genai/eval-monitor/scorers/llm-judge/response-quality/safety",children:"Safety"})}),(0,t.jsx)(r.td,{children:"Does the app's response avoid harmful or toxic content?"}),(0,t.jsx)(r.td,{children:"No"}),(0,t.jsx)(r.td,{children:"No"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:(0,t.jsx)(s.B,{fn:"mlflow.genai.scorers.Equivalence",children:"Equivalence"})}),(0,t.jsx)(r.td,{children:"Is the app's response equivalent to the expected output?"}),(0,t.jsx)(r.td,{children:"Yes"}),(0,t.jsx)(r.td,{children:"No"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:(0,t.jsx)(r.a,{href:"/genai/eval-monitor/scorers/llm-judge/guidelines/#1-built-in-guidelines-judge-global-guidelines",children:"Guidelines"})}),(0,t.jsx)(r.td,{children:"Does the response adhere to provided guidelines?"}),(0,t.jsx)(r.td,{children:"Yes*"}),(0,t.jsx)(r.td,{children:"No"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:(0,t.jsx)(r.a,{href:"/genai/eval-monitor/scorers/llm-judge/guidelines/#2-built-in-expectationsguidelines-judge-per-row-guidelines",children:"ExpectationsGuidelines"})}),(0,t.jsx)(r.td,{children:"Does the response meet specific expectations and guidelines?"}),(0,t.jsx)(r.td,{children:"Yes*"}),(0,t.jsx)(r.td,{children:"No"})]})]})]}),"\n",(0,t.jsx)(r.h3,{id:"rag",children:"RAG"}),"\n",(0,t.jsxs)(r.table,{children:[(0,t.jsx)(r.thead,{children:(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.th,{children:"Judge"}),(0,t.jsx)(r.th,{children:"What does it evaluate?"}),(0,t.jsx)(r.th,{children:"Requires ground-truth?"}),(0,t.jsx)(r.th,{children:"Requires traces?"})]})}),(0,t.jsxs)(r.tbody,{children:[(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:(0,t.jsx)(r.a,{href:"/genai/eval-monitor/scorers/llm-judge/rag/relevance/#retrievalrelevance-judge",children:"RetrievalRelevance"})}),(0,t.jsx)(r.td,{children:"Are retrieved documents relevant to the user's request?"}),(0,t.jsx)(r.td,{children:"No"}),(0,t.jsxs)(r.td,{children:["\u26A0\uFE0F ",(0,t.jsx)(r.strong,{children:"Trace Required"})]})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:(0,t.jsx)(r.a,{href:"/genai/eval-monitor/scorers/llm-judge/rag/groundedness",children:"RetrievalGroundedness"})}),(0,t.jsx)(r.td,{children:"Is the app's response grounded in retrieved information?"}),(0,t.jsx)(r.td,{children:"No"}),(0,t.jsxs)(r.td,{children:["\u26A0\uFE0F ",(0,t.jsx)(r.strong,{children:"Trace Required"})]})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:(0,t.jsx)(r.a,{href:"/genai/eval-monitor/scorers/llm-judge/rag/context-sufficiency",children:"RetrievalSufficiency"})}),(0,t.jsx)(r.td,{children:"Do retrieved documents contain all necessary information?"}),(0,t.jsx)(r.td,{children:"Yes"}),(0,t.jsxs)(r.td,{children:["\u26A0\uFE0F ",(0,t.jsx)(r.strong,{children:"Trace Required"})]})]})]})]}),"\n",(0,t.jsx)(r.h3,{id:"tool-call",children:"Tool Call"}),"\n",(0,t.jsxs)(r.table,{children:[(0,t.jsx)(r.thead,{children:(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.th,{children:"Judge"}),(0,t.jsx)(r.th,{children:"What does it evaluate?"}),(0,t.jsx)(r.th,{children:"Requires ground-truth?"}),(0,t.jsx)(r.th,{children:"Requires traces?"})]})}),(0,t.jsxs)(r.tbody,{children:[(0,t.jsxs)(r.tr,{children:[(0,t.jsxs)(r.td,{children:[(0,t.jsx)(r.a,{href:"/genai/eval-monitor/scorers/llm-judge/tool-call/correctness",children:"ToolCallCorrectness"}),"**"]}),(0,t.jsx)(r.td,{children:"Are the tool calls and arguments correct for the user query?"}),(0,t.jsx)(r.td,{children:"No"}),(0,t.jsxs)(r.td,{children:["\u26A0\uFE0F ",(0,t.jsx)(r.strong,{children:"Trace Required"})]})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsxs)(r.td,{children:[(0,t.jsx)(r.a,{href:"/genai/eval-monitor/scorers/llm-judge/tool-call/efficiency",children:"ToolCallEfficiency"}),"**"]}),(0,t.jsx)(r.td,{children:"Are the tool calls efficient without redundancy?"}),(0,t.jsx)(r.td,{children:"No"}),(0,t.jsxs)(r.td,{children:["\u26A0\uFE0F ",(0,t.jsx)(r.strong,{children:"Trace Required"})]})]})]})]}),"\n",(0,t.jsx)(r.p,{children:"*Can extract expectations from trace assessments if available."}),"\n",(0,t.jsx)(r.p,{children:"**Indicates experimental features that may change in future releases."}),"\n",(0,t.jsx)(r.h3,{id:"multi-turn",children:"Multi-Turn"}),"\n",(0,t.jsxs)(r.p,{children:["Multi-turn judges evaluate entire conversation sessions rather than individual turns. They require traces with session IDs and are experimental in MLflow 3.7.0. See ",(0,t.jsx)(r.a,{href:"/genai/tracing/track-users-sessions/",children:"Track Users and Sessions"})]}),"\n",(0,t.jsxs)(r.admonition,{title:"Multi-Turn Evaluation Requirements",type:"info",children:[(0,t.jsx)(r.p,{children:"Multi-turn judges require:"}),(0,t.jsxs)(r.ol,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Session IDs"}),": Traces must have ",(0,t.jsx)(r.code,{children:"mlflow.trace.session"})," metadata"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"List or DataFrame input"}),": Currently only supports pre-collected traces (no ",(0,t.jsx)(r.code,{children:"predict_fn"})," support yet)"]}),"\n"]})]}),"\n",(0,t.jsxs)(r.table,{children:[(0,t.jsx)(r.thead,{children:(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.th,{children:"Judge"}),(0,t.jsx)(r.th,{children:"What does it evaluate?"}),(0,t.jsx)(r.th,{children:"Requires Session?"})]})}),(0,t.jsxs)(r.tbody,{children:[(0,t.jsxs)(r.tr,{children:[(0,t.jsxs)(r.td,{children:[(0,t.jsx)(s.B,{fn:"mlflow.genai.scorers.ConversationCompleteness",children:"ConversationCompleteness"}),"**"]}),(0,t.jsx)(r.td,{children:"Does the agent address all user questions throughout the conversation?"}),(0,t.jsx)(r.td,{children:"Yes"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsxs)(r.td,{children:[(0,t.jsx)(s.B,{fn:"mlflow.genai.scorers.ConversationalGuidelines",children:"ConversationalGuidelines"}),"**"]}),(0,t.jsx)(r.td,{children:"Do the assistant's responses comply with provided guidelines?"}),(0,t.jsx)(r.td,{children:"Yes"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsxs)(r.td,{children:[(0,t.jsx)(s.B,{fn:"mlflow.genai.scorers.ConversationalRoleAdherence",children:"ConversationalRoleAdherence"}),"**"]}),(0,t.jsx)(r.td,{children:"Does the assistant maintain its assigned role throughout the conversation?"}),(0,t.jsx)(r.td,{children:"Yes"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsxs)(r.td,{children:[(0,t.jsx)(s.B,{fn:"mlflow.genai.scorers.ConversationalSafety",children:"ConversationalSafety"}),"**"]}),(0,t.jsx)(r.td,{children:"Are the assistant's responses safe and free of harmful content?"}),(0,t.jsx)(r.td,{children:"Yes"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsxs)(r.td,{children:[(0,t.jsx)(s.B,{fn:"mlflow.genai.scorers.ConversationalToolCallEfficiency",children:"ConversationalToolCallEfficiency"}),"**"]}),(0,t.jsx)(r.td,{children:"Was tool usage across the conversation efficient and appropriate?"}),(0,t.jsx)(r.td,{children:"Yes"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsxs)(r.td,{children:[(0,t.jsx)(s.B,{fn:"mlflow.genai.scorers.KnowledgeRetention",children:"KnowledgeRetention"}),"**"]}),(0,t.jsx)(r.td,{children:"Does the assistant correctly retain information from earlier user inputs?"}),(0,t.jsx)(r.td,{children:"Yes"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsxs)(r.td,{children:[(0,t.jsx)(s.B,{fn:"mlflow.genai.scorers.UserFrustration",children:"UserFrustration"}),"**"]}),(0,t.jsx)(r.td,{children:"Is the user frustrated? Was the frustration resolved?"}),(0,t.jsx)(r.td,{children:"Yes"})]})]})]}),"\n",(0,t.jsx)(r.admonition,{title:"Availability",type:"note",children:(0,t.jsxs)(r.p,{children:["Safety and RetrievalRelevance judges are currently only available in ",(0,t.jsx)(r.a,{href:"https://docs.databricks.com/mlflow3/genai/eval-monitor/",children:"Databricks managed MLflow"})," and will be open-sourced soon."]})}),"\n",(0,t.jsxs)(r.admonition,{type:"tip",children:[(0,t.jsx)(r.p,{children:"Typically, you can get started with evaluation using built-in judges. However, every AI application is unique and has domain-specific quality criteria. At some point, you'll need to create your own custom LLM judges."}),(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsx)(r.li,{children:"Your application has complex inputs/outputs that built-in judges can't parse"}),"\n",(0,t.jsx)(r.li,{children:"You need to evaluate specific business logic or domain-specific criteria"}),"\n",(0,t.jsx)(r.li,{children:"You want to combine multiple evaluation aspects into a single judge"}),"\n"]}),(0,t.jsxs)(r.p,{children:["See ",(0,t.jsx)("ins",{children:(0,t.jsx)(r.a,{href:"/genai/eval-monitor/scorers/llm-judge/guidelines",children:"custom LLM judges"})})," guide for detailed examples."]})]}),"\n",(0,t.jsx)(r.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsxs)(u.A,{children:[(0,t.jsx)(h.A,{icon:m.A,title:"Guidelines Judge",description:"Learn how to use the Guidelines judge to evaluate responses against custom criteria",href:"/genai/eval-monitor/scorers/llm-judge/guidelines"}),(0,t.jsx)(h.A,{icon:p.A,title:"Evaluate Agents",description:"Learn how to evaluate AI agents with specialized techniques and judges",href:"/genai/eval-monitor/running-evaluation/agents"}),(0,t.jsx)(h.A,{icon:f.A,title:"Evaluate Traces",description:"Evaluate production traces to understand and improve your AI application's behavior",href:"/genai/eval-monitor/running-evaluation/traces"})]})]})}function v(e={}){let{wrapper:r}={...(0,i.R)(),...e.components};return r?(0,t.jsx)(r,{...e,children:(0,t.jsx)(y,{...e})}):y(e)}},75689(e,r,l){l.d(r,{A:()=>o});var n=l(96540);let t=e=>{let r=e.replace(/^([A-Z])|[\s-_]+(\w)/g,(e,r,l)=>l?l.toUpperCase():r.toLowerCase());return r.charAt(0).toUpperCase()+r.slice(1)},i=(...e)=>e.filter((e,r,l)=>!!e&&""!==e.trim()&&l.indexOf(e)===r).join(" ").trim();var s={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};let a=(0,n.forwardRef)(({color:e="currentColor",size:r=24,strokeWidth:l=2,absoluteStrokeWidth:t,className:a="",children:o,iconNode:c,...d},h)=>(0,n.createElement)("svg",{ref:h,...s,width:r,height:r,stroke:e,strokeWidth:t?24*Number(l)/Number(r):l,className:i("lucide",a),...!o&&!(e=>{for(let r in e)if(r.startsWith("aria-")||"role"===r||"title"===r)return!0})(d)&&{"aria-hidden":"true"},...d},[...c.map(([e,r])=>(0,n.createElement)(e,r)),...Array.isArray(o)?o:[o]])),o=(e,r)=>{let l=(0,n.forwardRef)(({className:l,...s},o)=>(0,n.createElement)(a,{ref:o,iconNode:r,className:i(`lucide-${t(e).replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()}`,`lucide-${e}`,l),...s}));return l.displayName=t(e),l}},42640(e,r,l){l.d(r,{A:()=>n});let n=(0,l(75689).A)("bot",[["path",{d:"M12 8V4H8",key:"hb8ula"}],["rect",{width:"16",height:"12",x:"4",y:"8",rx:"2",key:"enze0r"}],["path",{d:"M2 14h2",key:"vft8re"}],["path",{d:"M20 14h2",key:"4cs60a"}],["path",{d:"M15 13v2",key:"1xurst"}],["path",{d:"M9 13v2",key:"rq6x2g"}]])},61878(e,r,l){l.d(r,{A:()=>n});let n=(0,l(75689).A)("git-branch",[["line",{x1:"6",x2:"6",y1:"3",y2:"15",key:"17qcm7"}],["circle",{cx:"18",cy:"6",r:"3",key:"1h7g24"}],["circle",{cx:"6",cy:"18",r:"3",key:"fqmcym"}],["path",{d:"M18 9a9 9 0 0 1-9 9",key:"n2h4wq"}]])},7043(e,r,l){l.d(r,{A:()=>n});let n=(0,l(75689).A)("hammer",[["path",{d:"m15 12-8.373 8.373a1 1 0 1 1-3-3L12 9",key:"eefl8a"}],["path",{d:"m18 15 4-4",key:"16gjal"}],["path",{d:"m21.5 11.5-1.914-1.914A2 2 0 0 1 19 8.172V7l-2.26-2.26a6 6 0 0 0-4.202-1.756L9 2.96l.92.82A6.18 6.18 0 0 1 12 8.4V10l2 2h1.172a2 2 0 0 1 1.414.586L18.5 14.5",key:"b7pghm"}]])},57250(e,r,l){l.d(r,{A:()=>i});var n=l(74848);l(96540);var t=l(34164);function i({children:e,hidden:r,className:l}){return(0,n.jsx)("div",{role:"tabpanel",className:(0,t.A)("tabItem_Ymn6",l),hidden:r,children:e})}},78010(e,r,l){l.d(r,{A:()=>w});var n=l(74848),t=l(96540),i=l(34164),s=l(88287),a=l(28584),o=l(56347),c=l(99989),d=l(96629),h=l(80618),u=l(41367);function m(e){return t.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,t.isValidElement)(e)&&function(e){let{props:r}=e;return!!r&&"object"==typeof r&&"value"in r}(e))return e;throw Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function p({value:e,tabValues:r}){return r.some(r=>r.value===e)}var f=l(19863);function j({className:e,block:r,selectedValue:l,selectValue:t,tabValues:s}){let o=[],{blockElementScrollPositionUntilNextRender:c}=(0,a.a_)(),d=e=>{let r=e.currentTarget,n=s[o.indexOf(r)].value;n!==l&&(c(r),t(n))},h=e=>{let r=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{let l=o.indexOf(e.currentTarget)+1;r=o[l]??o[0];break}case"ArrowLeft":{let l=o.indexOf(e.currentTarget)-1;r=o[l]??o[o.length-1]}}r?.focus()};return(0,n.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":r},e),children:s.map(({value:e,label:r,attributes:t})=>(0,n.jsx)("li",{role:"tab",tabIndex:l===e?0:-1,"aria-selected":l===e,ref:e=>{o.push(e)},onKeyDown:h,onClick:d,...t,className:(0,i.A)("tabs__item","tabItem_LNqP",t?.className,{"tabs__item--active":l===e}),children:r??e},e))})}function x({lazy:e,children:r,selectedValue:l}){let s=(Array.isArray(r)?r:[r]).filter(Boolean);if(e){let e=s.find(e=>e.props.value===l);return e?(0,t.cloneElement)(e,{className:(0,i.A)("margin-top--md",e.props.className)}):null}return(0,n.jsx)("div",{className:"margin-top--md",children:s.map((e,r)=>(0,t.cloneElement)(e,{key:r,hidden:e.props.value!==l}))})}function g(e){let r=function(e){let r,{defaultValue:l,queryString:n=!1,groupId:i}=e,s=function(e){let{values:r,children:l}=e;return(0,t.useMemo)(()=>{let e=r??m(l).map(({props:{value:e,label:r,attributes:l,default:n}})=>({value:e,label:r,attributes:l,default:n})),n=(0,h.XI)(e,(e,r)=>e.value===r.value);if(n.length>0)throw Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`);return e},[r,l])}(e),[a,f]=(0,t.useState)(()=>(function({defaultValue:e,tabValues:r}){if(0===r.length)throw Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!p({value:e,tabValues:r}))throw Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${r.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}let l=r.find(e=>e.default)??r[0];if(!l)throw Error("Unexpected error: 0 tabValues");return l.value})({defaultValue:l,tabValues:s})),[j,x]=function({queryString:e=!1,groupId:r}){let l=(0,o.W6)(),n=function({queryString:e=!1,groupId:r}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!r)throw Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return r??null}({queryString:e,groupId:r});return[(0,d.aZ)(n),(0,t.useCallback)(e=>{if(!n)return;let r=new URLSearchParams(l.location.search);r.set(n,e),l.replace({...l.location,search:r.toString()})},[n,l])]}({queryString:n,groupId:i}),[g,w]=function({groupId:e}){let r=e?`docusaurus.tab.${e}`:null,[l,n]=(0,u.Dv)(r);return[l,(0,t.useCallback)(e=>{r&&n.set(e)},[r,n])]}({groupId:i}),y=p({value:r=j??g,tabValues:s})?r:null;return(0,c.A)(()=>{y&&f(y)},[y]),{selectedValue:a,selectValue:(0,t.useCallback)(e=>{if(!p({value:e,tabValues:s}))throw Error(`Can't select invalid tab value=${e}`);f(e),x(e),w(e)},[x,w,s]),tabValues:s}}(e);return(0,n.jsxs)("div",{className:(0,i.A)(s.G.tabs.container,"tabs-container","tabList__CuJ"),children:[(0,n.jsx)(j,{...r,...e}),(0,n.jsx)(x,{...r,...e})]})}function w(e){let r=(0,f.A)();return(0,n.jsx)(g,{...e,children:m(e.children)},String(r))}},54725(e,r,l){l.d(r,{B:()=>s});var n=l(74848);l(96540);var t=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}'),i=l(66497);function s({fn:e,children:r,hash:l}){let s=(e=>{let r=e.split(".");for(let e=r.length;e>0;e--){let l=r.slice(0,e).join(".");if(t[l])return l}return null})(e);if(!s)return(0,n.jsx)(n.Fragment,{children:r});let a=(0,i.default)(`/${t[s]}#${l??e}`);return(0,n.jsx)("a",{href:a,target:"_blank",children:r??(0,n.jsxs)("code",{children:[e,"()"]})})}},46077(e,r,l){l.d(r,{A:()=>i});var n=l(74848);l(96540);var t=l(66497);function i({src:e,alt:r,width:l,caption:i,className:s}){return(0,n.jsxs)("div",{className:`container_JwLF ${s||""}`,children:[(0,n.jsx)("div",{className:"imageWrapper_RfGN",style:l?{width:l}:{},children:(0,n.jsx)("img",{src:(0,t.default)(e),alt:r,className:"image_bwOA"})}),i&&(0,n.jsx)("p",{className:"caption_jo2G",children:i})]})}},95986(e,r,l){l.d(r,{A:()=>t});var n=l(74848);l(96540);function t({children:e}){return(0,n.jsx)("div",{className:"wrapper_sf5q",children:e})}},77541(e,r,l){l.d(r,{A:()=>c});var n=l(74848);l(96540);var t=l(95310),i=l(34164);let s="tileImage_O4So";var a=l(66497),o=l(92802);function c({icon:e,image:r,imageDark:l,imageWidth:c,imageHeight:d,iconSize:h=32,containerHeight:u,title:m,description:p,href:f,linkText:j="Learn more \u2192",className:x}){if(!e&&!r)throw Error("TileCard requires either an icon or image prop");let g=u?{height:`${u}px`}:{},w={};return c&&(w.width=`${c}px`),d&&(w.height=`${d}px`),(0,n.jsxs)(t.A,{href:f,className:(0,i.A)("tileCard_NHsj",x),children:[(0,n.jsx)("div",{className:"tileIcon_pyoR",style:g,children:e?(0,n.jsx)(e,{size:h}):l?(0,n.jsx)(o.A,{sources:{light:(0,a.default)(r),dark:(0,a.default)(l)},alt:m,className:s,style:w}):(0,n.jsx)("img",{src:(0,a.default)(r),alt:m,className:s,style:w})}),(0,n.jsx)("h3",{children:m}),(0,n.jsx)("p",{children:p}),(0,n.jsx)("div",{className:"tileLink_iUbu",children:j})]})}},10440(e,r,l){l.d(r,{A:()=>i});var n=l(74848);l(96540);var t=l(34164);function i({children:e,className:r}){return(0,n.jsx)("div",{className:(0,t.A)("tilesGrid_hB9N",r),children:e})}},28453(e,r,l){l.d(r,{R:()=>s,x:()=>a});var n=l(96540);let t={},i=n.createContext(t);function s(e){let r=n.useContext(i);return n.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function a(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),n.createElement(i.Provider,{value:r},e.children)}}}]);