"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8808],{19883:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/logged_models_tab-b9598f8561caa18ca28111a5cb4c2766.png"},22060:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/chatbot_prompt-c4adcf11a8289f59b736beb7aa483d87.png"},24097:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/logged_model_autolog_traces-b7d819cc102de467745069cc054c4abc.png"},26029:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>o,default:()=>m,frontMatter:()=>l,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"prompt-version-mgmt/version-tracking/quickstart","title":"GenAI Agent Quickstart","description":"Build and evaluate a LangChain-based chatbot with MLflow\'s comprehensive tracking and evaluation capabilities. This quickstart demonstrates prompt engineering, trace generation, and performance assessment using MLflow 3\'s GenAI features.","source":"@site/docs/genai/prompt-version-mgmt/version-tracking/quickstart.mdx","sourceDirName":"prompt-version-mgmt/version-tracking","slug":"/prompt-version-mgmt/version-tracking/quickstart","permalink":"/docs/latest/genai/prompt-version-mgmt/version-tracking/quickstart","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"genAISidebar","previous":{"title":"Version Tracking for GenAI Applications","permalink":"/docs/latest/genai/prompt-version-mgmt/version-tracking/"},"next":{"title":"Track Application Versions with MLflow","permalink":"/docs/latest/genai/prompt-version-mgmt/version-tracking/track-application-versions-with-mlflow"}}');var i=t(74848),r=t(28453);t(49374);const l={sidebar_position:2},o="GenAI Agent Quickstart",s={},c=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Install Required Packages",id:"install-required-packages",level:3},{value:"Set OpenAI API Key",id:"set-openai-api-key",level:3},{value:"Overview",id:"overview",level:2},{value:"Step 1: Register a Prompt Template",id:"step-1-register-a-prompt-template",level:2},{value:"View Your Prompt in MLflow UI",id:"view-your-prompt-in-mlflow-ui",level:3},{value:"Step 2: Build a LangChain Conversational Chain",id:"step-2-build-a-langchain-conversational-chain",level:2},{value:"Step 3: Enable Trace Observability",id:"step-3-enable-trace-observability",level:2},{value:"Configure Active Model and Autologging",id:"configure-active-model-and-autologging",level:3},{value:"Generate Test Traces",id:"generate-test-traces",level:3},{value:"Explore Traces in the UI",id:"explore-traces-in-the-ui",level:3},{value:"Step 4: Evaluate Model Performance",id:"step-4-evaluate-model-performance",level:2},{value:"Run Evaluation with Custom Metrics",id:"run-evaluation-with-custom-metrics",level:3},{value:"Analyze Evaluation Results",id:"analyze-evaluation-results",level:3},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"Additional Resources",id:"additional-resources",level:2}];function p(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"genai-agent-quickstart",children:"GenAI Agent Quickstart"})}),"\n",(0,i.jsx)(n.p,{children:"Build and evaluate a LangChain-based chatbot with MLflow's comprehensive tracking and evaluation capabilities. This quickstart demonstrates prompt engineering, trace generation, and performance assessment using MLflow 3's GenAI features."}),"\n",(0,i.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsx)(n.h3,{id:"install-required-packages",children:"Install Required Packages"}),"\n",(0,i.jsx)(n.admonition,{title:"MLflow 3 Required",type:"note",children:(0,i.jsx)(n.p,{children:"This quickstart requires MLflow version 3.0 or higher for full GenAI functionality."})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pip install --upgrade mlflow\npip install langchain-openai\n"})}),"\n",(0,i.jsx)(n.h3,{id:"set-openai-api-key",children:"Set OpenAI API Key"}),"\n",(0,i.jsx)(n.p,{children:"Configure your OpenAI API key to authenticate with OpenAI services:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"export OPENAI_API_KEY=your_api_key_here\n"})}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"In this quickstart, you'll learn how to:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Register and version control prompt templates"}),"\n",(0,i.jsx)(n.li,{children:"Create a LangChain-based conversational agent"}),"\n",(0,i.jsx)(n.li,{children:"Enable automatic trace logging for debugging"}),"\n",(0,i.jsx)(n.li,{children:"Evaluate model performance with custom metrics"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Let's build a simple IT support chatbot and track its development lifecycle with MLflow."}),"\n",(0,i.jsx)(n.h2,{id:"step-1-register-a-prompt-template",children:"Step 1: Register a Prompt Template"}),"\n",(0,i.jsx)(n.p,{children:"Start by creating a versioned prompt template. This enables you to track prompt evolution and ensure reproducibility across experiments."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import mlflow\n\nsystem_prompt = mlflow.genai.register_prompt(\n    name="chatbot_prompt",\n    template="You are a chatbot that can answer questions about IT. Answer this question: {{question}}",\n    commit_message="Initial version of chatbot",\n)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"view-your-prompt-in-mlflow-ui",children:"View Your Prompt in MLflow UI"}),"\n",(0,i.jsxs)(n.p,{children:["Navigate to the ",(0,i.jsx)(n.strong,{children:"Prompts"})," tab to see your registered prompt:"]}),"\n",(0,i.jsx)("div",{className:"center-div",style:{width:"100%"},children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"The MLflow UI showing a prompt\nversion",src:t(22060).A+"",width:"3448",height:"828"})})}),"\n",(0,i.jsx)(n.h2,{id:"step-2-build-a-langchain-conversational-chain",children:"Step 2: Build a LangChain Conversational Chain"}),"\n",(0,i.jsx)(n.p,{children:"Create a simple chain that combines your prompt template with OpenAI's chat model:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from langchain.schema.output_parser import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\n\n# Convert MLflow prompt to LangChain format\nprompt = ChatPromptTemplate.from_template(system_prompt.to_single_brace_format())\n\n# Build the chain: prompt \u2192 LLM \u2192 output parser\nchain = prompt | ChatOpenAI(temperature=0.7) | StrOutputParser()\n\n# Test the chain\nquestion = "What is MLflow?"\nprint(chain.invoke({"question": question}))\n# MLflow is an open-source platform for managing the end-to-end machine learning lifecycle...\n'})}),"\n",(0,i.jsx)(n.h2,{id:"step-3-enable-trace-observability",children:"Step 3: Enable Trace Observability"}),"\n",(0,i.jsx)(n.p,{children:"Set up automatic trace logging to monitor your model's behavior during development. This creates a linked history of all model interactions."}),"\n",(0,i.jsx)(n.h3,{id:"configure-active-model-and-autologging",children:"Configure Active Model and Autologging"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Set the active model for linking traces\nmlflow.set_active_model(name="langchain_model")\n\n# Enable autologging - all traces will be automatically linked to the active model\nmlflow.langchain.autolog()\n'})}),"\n",(0,i.jsx)(n.h3,{id:"generate-test-traces",children:"Generate Test Traces"}),"\n",(0,i.jsx)(n.p,{children:"Run multiple queries to generate traces for analysis:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'questions = [\n    {"question": "What is MLflow Tracking and how does it work?"},\n    {"question": "What is Unity Catalog?"},\n    {"question": "What are user-defined functions (UDFs)?"},\n]\noutputs = []\n\nfor question in questions:\n    outputs.append(chain.invoke(question))\n\n# Verify traces are linked to the active model\nactive_model_id = mlflow.get_active_model_id()\nmlflow.search_traces(model_id=active_model_id)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"explore-traces-in-the-ui",children:"Explore Traces in the UI"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"View the Logged Model"}),": Check the ",(0,i.jsx)(n.strong,{children:"Models"})," tab in your experiment:"]}),"\n"]}),"\n",(0,i.jsx)("div",{className:"center-div",style:{width:"100%"},children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"The MLflow UI showing the logged models in an\nexperiment",src:t(19883).A+"",width:"3448",height:"680"})})}),"\n",(0,i.jsxs)(n.ol,{start:"2",children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Access Model Details"}),": Click on your model to view its unique ",(0,i.jsx)(n.code,{children:"model_id"}),":"]}),"\n"]}),"\n",(0,i.jsx)("div",{className:"center-div",style:{width:"100%"},children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"The MLflow UI showing the logged model details\npage",src:t(89530).A+"",width:"3436",height:"986"})})}),"\n",(0,i.jsxs)(n.ol,{start:"3",children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Analyze Generated Traces"}),": Navigate to the ",(0,i.jsx)(n.strong,{children:"Traces"})," tab to examine individual interactions:"]}),"\n"]}),"\n",(0,i.jsx)("div",{className:"center-div",style:{width:"100%"},children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"The MLflow UI showing the logged model autolog traces\nlineage",src:t(24097).A+"",width:"3436",height:"1296"})})}),"\n",(0,i.jsx)(n.h2,{id:"step-4-evaluate-model-performance",children:"Step 4: Evaluate Model Performance"}),"\n",(0,i.jsx)(n.p,{children:"Use MLflow's evaluation framework to assess your chatbot's accuracy and relevance against expected responses."}),"\n",(0,i.jsx)(n.h3,{id:"run-evaluation-with-custom-metrics",children:"Run Evaluation with Custom Metrics"}),"\n",(0,i.jsx)(n.p,{children:"Evaluate your model using GenAI-specific metrics:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'eval_df = pd.DataFrame(\n    {\n        "inputs": questions,\n        "expected_response": [\n            """MLflow Tracking is a key component of the MLflow platform designed to record and manage machine learning experiments. It enables data scientists and engineers to log parameters, code versions, metrics, and artifacts in a systematic way, facilitating experiment tracking and reproducibility.\n\nHow It Works:\n\nAt the heart of MLflow Tracking is the concept of a run, which is an execution of a machine learning code. Each run can log the following:\n\nParameters: Input variables or hyperparameters used in the model (e.g., learning rate, number of trees). Metrics: Quantitative measures to evaluate the model\'s performance (e.g., accuracy, loss). Artifacts: Output files like models, datasets, or images generated during the run. Source Code: The version of the code or Git commit hash used. These logs are stored in a tracking server, which can be set up locally or on a remote server. The tracking server uses a backend storage (like a database or file system) to keep a record of all runs and their associated data.\n\nUsers interact with MLflow Tracking through its APIs available in multiple languages (Python, R, Java, etc.). By invoking these APIs in the code, you can start and end runs, and log data as the experiment progresses. Additionally, MLflow offers autologging capabilities for popular machine learning libraries, automatically capturing relevant parameters and metrics without manual code changes.\n\nThe logged data can be visualized using the MLflow UI, a web-based interface that displays all experiments and runs. This UI allows you to compare runs side-by-side, filter results, and analyze performance metrics over time. It aids in identifying the best models and understanding the impact of different parameters.\n\nBy providing a structured way to record experiments, MLflow Tracking enhances collaboration among team members, ensures transparency, and makes it easier to reproduce results. It integrates seamlessly with other MLflow components like Projects and Model Registry, offering a comprehensive solution for managing the machine learning lifecycle.""",\n            """Unity Catalog is a feature in Databricks that allows you to create a centralized inventory of your data assets, such as tables, views, and functions, and share them across different teams and projects. It enables easy discovery, collaboration, and reuse of data assets within your organization.\n\nWith Unity Catalog, you can:\n\n1. Create a single source of truth for your data assets: Unity Catalog acts as a central repository of all your data assets, making it easier to find and access the data you need.\n2. Improve collaboration: By providing a shared inventory of data assets, Unity Catalog enables data scientists, engineers, and other stakeholders to collaborate more effectively.\n3. Foster reuse of data assets: Unity Catalog encourages the reuse of existing data assets, reducing the need to create new assets from scratch and improving overall efficiency.\n4. Enhance data governance: Unity Catalog provides a clear view of data assets, enabling better data governance and compliance.\n\nUnity Catalog is particularly useful in large organizations where data is scattered across different teams, projects, and environments. It helps create a unified view of data assets, making it easier to work with data across different teams and projects.""",\n            """User-defined functions (UDFs) in the context of Databricks and Apache Spark are custom functions that you can create to perform specific tasks on your data. These functions are written in a programming language such as Python, Java, Scala, or SQL, and can be used to extend the built-in functionality of Spark.\n\nUDFs can be used to perform complex data transformations, data cleaning, or to apply custom business logic to your data. Once defined, UDFs can be invoked in SQL queries or in DataFrame transformations, allowing you to reuse your custom logic across multiple queries and applications.\n\nTo use UDFs in Databricks, you first need to define them in a supported programming language, and then register them with the SparkSession. Once registered, UDFs can be used in SQL queries or DataFrame transformations like any other built-in function.""",\n        ],\n        "outputs": outputs,\n    }\n)\n\nfrom mlflow.genai.scorers import Correctness, RelevanceToQuery, Guidelines\n\n# Run evaluation with GenAI metrics\nresult = mlflow.genai.evaluate(\n    data=eval_df,\n    scorers=[\n        Correctness(),\n        RelevanceToQuery(),\n    ],\n)\n\n# View evaluation results\nresult.tables["eval_results"]\n'})}),"\n",(0,i.jsx)(n.h3,{id:"analyze-evaluation-results",children:"Analyze Evaluation Results"}),"\n",(0,i.jsx)(n.p,{children:"The evaluation generates detailed metrics with justifications:"}),"\n",(0,i.jsx)("div",{className:"center-div",style:{width:"100%"},children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"The MLflow UI showing the evaluate run\nmetrics",src:t(34225).A+"",width:"3448",height:"1736"})})}),"\n",(0,i.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(n.p,{children:"You've successfully:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\u2705 Created a versioned prompt template for reproducibility"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Built a LangChain conversational agent with OpenAI"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Enabled automatic trace logging for complete observability"}),"\n",(0,i.jsx)(n.li,{children:"\u2705 Evaluated model performance with GenAI-specific metrics"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Experiment with Prompts"}),": Try different prompt templates and compare their performance"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Add Custom Metrics"}),": Create domain-specific evaluation metrics for your use case"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Deploy Your Model"}),": Use MLflow's deployment capabilities to serve your chatbot"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Scale Evaluations"}),": Run evaluations on larger datasets to ensure robustness"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"additional-resources",children:"Additional Resources"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/genai/prompt-version-mgmt/prompt-registry",children:"MLflow Prompt Registry Guide"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/genai/eval-monitor",children:"Model Evaluation Guide"})}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(p,{...e})}):p(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>l,x:()=>o});var a=t(96540);const i={},r=a.createContext(i);function l(e){const n=a.useContext(r);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),a.createElement(r.Provider,{value:n},e.children)}},34225:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/evaluate_metrics-81c775cb071619221be4aa6e5512a3e5.png"},49374:(e,n,t)=>{t.d(n,{B:()=>s});t(96540);const a=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var i=t(86025),r=t(28774),l=t(74848);const o=e=>{const n=e.split(".");for(let t=n.length;t>0;t--){const e=n.slice(0,t).join(".");if(a[e])return e}return null};function s({fn:e,children:n}){const t=o(e);if(!t)return(0,l.jsx)(l.Fragment,{children:n});const s=(0,i.Ay)(`/${a[t]}#${e}`);return(0,l.jsx)(r.A,{to:s,target:"_blank",children:n??(0,l.jsxs)("code",{children:[e,"()"]})})}},89530:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/logged_model_page-ead92fc3d0979e51c906ccbd612a6a61.png"}}]);