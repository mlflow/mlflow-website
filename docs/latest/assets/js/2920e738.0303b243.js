/*! For license information please see 2920e738.0303b243.js.LICENSE.txt */
"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4331],{3160:(e,n,t)=>{t.d(n,{A:()=>i});const i=(0,t(84722).A)("eye",[["path",{d:"M2.062 12.348a1 1 0 0 1 0-.696 10.75 10.75 0 0 1 19.876 0 1 1 0 0 1 0 .696 10.75 10.75 0 0 1-19.876 0",key:"1nclc0"}],["circle",{cx:"12",cy:"12",r:"3",key:"1v7zrd"}]])},6789:(e,n,t)=>{t.d(n,{A:()=>c});t(96540);var i=t(28774),a=t(34164);const r={tileCard:"tileCard_NHsj",tileIcon:"tileIcon_pyoR",tileLink:"tileLink_iUbu",tileImage:"tileImage_O4So"};var l=t(86025),o=t(21122),s=t(74848);function c({icon:e,image:n,imageDark:t,imageWidth:c,imageHeight:p,iconSize:m=32,containerHeight:h,title:d,description:f,href:u,linkText:g="Learn more \u2192",className:w}){if(!e&&!n)throw new Error("TileCard requires either an icon or image prop");const v=h?{height:`${h}px`}:{},y={};return c&&(y.width=`${c}px`),p&&(y.height=`${p}px`),(0,s.jsxs)(i.A,{href:u,className:(0,a.A)(r.tileCard,w),children:[(0,s.jsx)("div",{className:r.tileIcon,style:v,children:e?(0,s.jsx)(e,{size:m}):t?(0,s.jsx)(o.A,{sources:{light:(0,l.Ay)(n),dark:(0,l.Ay)(t)},alt:d,className:r.tileImage,style:y}):(0,s.jsx)("img",{src:(0,l.Ay)(n),alt:d,className:r.tileImage,style:y})}),(0,s.jsx)("h3",{children:d}),(0,s.jsx)("p",{children:f}),(0,s.jsx)("div",{className:r.tileLink,children:g})]})}},22864:(e,n,t)=>{t.d(n,{A:()=>i});const i=(0,t(84722).A)("chart-column",[["path",{d:"M3 3v16a2 2 0 0 0 2 2h16",key:"c24i48"}],["path",{d:"M18 17V9",key:"2bz60n"}],["path",{d:"M13 17V5",key:"1frdt8"}],["path",{d:"M8 17v-3",key:"17ska0"}]])},28453:(e,n,t)=>{t.d(n,{R:()=>l,x:()=>o});var i=t(96540);const a={},r=i.createContext(a);function l(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:l(e.components),i.createElement(r.Provider,{value:n},e.children)}},47792:(e,n,t)=>{t.d(n,{A:()=>i});const i=(0,t(84722).A)("target",[["circle",{cx:"12",cy:"12",r:"10",key:"1mglay"}],["circle",{cx:"12",cy:"12",r:"6",key:"1vlfrh"}],["circle",{cx:"12",cy:"12",r:"2",key:"1c9p78"}]])},49374:(e,n,t)=>{t.d(n,{B:()=>o});t(96540);const i=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}');var a=t(86025),r=t(74848);const l=e=>{const n=e.split(".");for(let t=n.length;t>0;t--){const e=n.slice(0,t).join(".");if(i[e])return e}return null};function o({fn:e,children:n,hash:t}){const o=l(e);if(!o)return(0,r.jsx)(r.Fragment,{children:n});const s=(0,a.Ay)(`/${i[o]}#${t??e}`);return(0,r.jsx)("a",{href:s,target:"_blank",children:n??(0,r.jsxs)("code",{children:[e,"()"]})})}},60665:(e,n,t)=>{t.d(n,{A:()=>i});const i=(0,t(84722).A)("book-open",[["path",{d:"M12 7v14",key:"1akyts"}],["path",{d:"M3 18a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h5a4 4 0 0 1 4 4 4 4 0 0 1 4-4h5a1 1 0 0 1 1 1v13a1 1 0 0 1-1 1h-6a3 3 0 0 0-3 3 3 3 0 0 0-3-3z",key:"ruj8y"}]])},61878:(e,n,t)=>{t.d(n,{A:()=>i});const i=(0,t(84722).A)("git-branch",[["line",{x1:"6",x2:"6",y1:"3",y2:"15",key:"17qcm7"}],["circle",{cx:"18",cy:"6",r:"3",key:"1h7g24"}],["circle",{cx:"6",cy:"18",r:"3",key:"fqmcym"}],["path",{d:"M18 9a9 9 0 0 1-9 9",key:"n2h4wq"}]])},65592:(e,n,t)=>{t.d(n,{A:()=>l});t(96540);var i=t(34164);const a={tilesGrid:"tilesGrid_hB9N"};var r=t(74848);function l({children:e,className:n}){return(0,r.jsx)("div",{className:(0,i.A)(a.tilesGrid,n),children:e})}},66927:(e,n,t)=>{t.d(n,{A:()=>l});t(96540);const i={container:"container_JwLF",imageWrapper:"imageWrapper_RfGN",image:"image_bwOA",caption:"caption_jo2G"};var a=t(86025),r=t(74848);function l({src:e,alt:n,width:t,caption:l,className:o}){return(0,r.jsxs)("div",{className:`${i.container} ${o||""}`,children:[(0,r.jsx)("div",{className:i.imageWrapper,style:t?{width:t}:{},children:(0,r.jsx)("img",{src:(0,a.Ay)(e),alt:n,className:i.image})}),l&&(0,r.jsx)("p",{className:i.caption,children:l})]})}},79206:(e,n,t)=>{t.d(n,{A:()=>r});t(96540);const i={conceptOverview:"conceptOverview_x8T_",overviewTitle:"overviewTitle_HyAI",conceptGrid:"conceptGrid_uJNV",conceptCard:"conceptCard_oday",conceptHeader:"conceptHeader_HCk5",conceptIcon:"conceptIcon_gejw",conceptTitle:"conceptTitle_TGMM",conceptDescription:"conceptDescription_ZyDn"};var a=t(74848);function r({concepts:e,title:n}){return(0,a.jsxs)("div",{className:i.conceptOverview,children:[n&&(0,a.jsx)("h3",{className:i.overviewTitle,children:n}),(0,a.jsx)("div",{className:i.conceptGrid,children:e.map((e,n)=>(0,a.jsxs)("div",{className:i.conceptCard,children:[(0,a.jsxs)("div",{className:i.conceptHeader,children:[e.icon&&(0,a.jsx)("div",{className:i.conceptIcon,children:(0,a.jsx)(e.icon,{size:20})}),(0,a.jsx)("h4",{className:i.conceptTitle,children:e.title})]}),(0,a.jsx)("p",{className:i.conceptDescription,children:e.description})]},n))})]})}},80964:(e,n,t)=>{t.d(n,{A:()=>i});const i=(0,t(84722).A)("settings",[["path",{d:"M12.22 2h-.44a2 2 0 0 0-2 2v.18a2 2 0 0 1-1 1.73l-.43.25a2 2 0 0 1-2 0l-.15-.08a2 2 0 0 0-2.73.73l-.22.38a2 2 0 0 0 .73 2.73l.15.1a2 2 0 0 1 1 1.72v.51a2 2 0 0 1-1 1.74l-.15.09a2 2 0 0 0-.73 2.73l.22.38a2 2 0 0 0 2.73.73l.15-.08a2 2 0 0 1 2 0l.43.25a2 2 0 0 1 1 1.73V20a2 2 0 0 0 2 2h.44a2 2 0 0 0 2-2v-.18a2 2 0 0 1 1-1.73l.43-.25a2 2 0 0 1 2 0l.15.08a2 2 0 0 0 2.73-.73l.22-.39a2 2 0 0 0-.73-2.73l-.15-.08a2 2 0 0 1-1-1.74v-.5a2 2 0 0 1 1-1.74l.15-.09a2 2 0 0 0 .73-2.73l-.22-.38a2 2 0 0 0-2.73-.73l-.15.08a2 2 0 0 1-2 0l-.43-.25a2 2 0 0 1-1-1.73V4a2 2 0 0 0-2-2z",key:"1qme2f"}],["circle",{cx:"12",cy:"12",r:"3",key:"1v7zrd"}]])},84722:(e,n,t)=>{t.d(n,{A:()=>c});var i=t(96540);const a=e=>{const n=(e=>e.replace(/^([A-Z])|[\s-_]+(\w)/g,(e,n,t)=>t?t.toUpperCase():n.toLowerCase()))(e);return n.charAt(0).toUpperCase()+n.slice(1)},r=(...e)=>e.filter((e,n,t)=>Boolean(e)&&""!==e.trim()&&t.indexOf(e)===n).join(" ").trim(),l=e=>{for(const n in e)if(n.startsWith("aria-")||"role"===n||"title"===n)return!0};var o={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};const s=(0,i.forwardRef)(({color:e="currentColor",size:n=24,strokeWidth:t=2,absoluteStrokeWidth:a,className:s="",children:c,iconNode:p,...m},h)=>(0,i.createElement)("svg",{ref:h,...o,width:n,height:n,stroke:e,strokeWidth:a?24*Number(t)/Number(n):t,className:r("lucide",s),...!c&&!l(m)&&{"aria-hidden":"true"},...m},[...p.map(([e,n])=>(0,i.createElement)(e,n)),...Array.isArray(c)?c:[c]])),c=(e,n)=>{const t=(0,i.forwardRef)(({className:t,...l},o)=>{return(0,i.createElement)(s,{ref:o,iconNode:n,className:r(`lucide-${c=a(e),c.replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()}`,`lucide-${e}`,t),...l});var c});return t.displayName=a(e),t}},93672:(e,n,t)=>{t.d(n,{A:()=>i});const i=(0,t(84722).A)("code-xml",[["path",{d:"m18 16 4-4-4-4",key:"1inbqp"}],["path",{d:"m6 8-4 4 4 4",key:"15zrgr"}],["path",{d:"m14.5 4-5 16",key:"e7oirm"}]])},99653:(e,n,t)=>{t.d(n,{A:()=>i});const i=(0,t(84722).A)("rocket",[["path",{d:"M4.5 16.5c-1.5 1.26-2 5-2 5s3.74-.5 5-2c.71-.84.7-2.13-.09-2.91a2.18 2.18 0 0 0-2.91-.09z",key:"m3kijz"}],["path",{d:"m12 15-3-3a22 22 0 0 1 2-3.95A12.88 12.88 0 0 1 22 2c0 2.72-.78 7.5-6 11a22.35 22.35 0 0 1-4 2z",key:"1fmvmk"}],["path",{d:"M9 12H4s.55-3.03 2-4c1.62-1.08 5 0 5 0",key:"1f8sc4"}],["path",{d:"M12 15v5s3.03-.55 4-2c1.08-1.62 0-5 0-5",key:"qeys4"}]])},99943:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>_,contentTitle:()=>y,default:()=>j,frontMatter:()=>v,metadata:()=>i,toc:()=>x});const i=JSON.parse('{"id":"version-tracking/quickstart","title":"Version Tracking Quickstart","description":"Build and track a LangChain-based chatbot with MLflow\'s version management capabilities. This quickstart demonstrates prompt versioning, application tracking, trace generation, and performance evaluation using MLflow\'s GenAI features.","source":"@site/docs/genai/version-tracking/quickstart.mdx","sourceDirName":"version-tracking","slug":"/version-tracking/quickstart","permalink":"/mlflow-website/docs/latest/genai/version-tracking/quickstart","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"genAISidebar","previous":{"title":"Version Tracking for GenAI Applications","permalink":"/mlflow-website/docs/latest/genai/version-tracking/"},"next":{"title":"Track versions of Git-based applications with MLflow","permalink":"/mlflow-website/docs/latest/genai/version-tracking/track-application-versions-with-mlflow"}}');var a=t(74848),r=t(28453),l=(t(49374),t(79206)),o=t(65592),s=t(6789),c=t(66927),p=t(61878),m=t(80964),h=t(3160),d=t(47792),f=t(93672),u=t(22864),g=t(60665),w=t(99653);const v={sidebar_position:2},y="Version Tracking Quickstart",_={},x=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Install Required Packages",id:"install-required-packages",level:3},{value:"Set OpenAI API Key",id:"set-openai-api-key",level:3},{value:"What You&#39;ll Learn",id:"what-youll-learn",level:2},{value:"Step 1: Register a Prompt Template",id:"step-1-register-a-prompt-template",level:2},{value:"View Your Prompt in MLflow UI",id:"view-your-prompt-in-mlflow-ui",level:3},{value:"Step 2: Build a LangChain Conversational Chain",id:"step-2-build-a-langchain-conversational-chain",level:2},{value:"Step 3: Enable Trace Observability",id:"step-3-enable-trace-observability",level:2},{value:"Configure Active Model and Autologging",id:"configure-active-model-and-autologging",level:3},{value:"Generate Test Traces",id:"generate-test-traces",level:3},{value:"Explore Traces in the UI",id:"explore-traces-in-the-ui",level:3},{value:"Step 4: Evaluate Model Performance",id:"step-4-evaluate-model-performance",level:2},{value:"Analyze Outputs Manually",id:"analyze-outputs-manually",level:3},{value:"View Results in MLflow UI",id:"view-results-in-mlflow-ui",level:3},{value:"What You&#39;ve Built",id:"what-youve-built",level:2},{value:"Next Steps",id:"next-steps",level:2}];function k(e){const n={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"version-tracking-quickstart",children:"Version Tracking Quickstart"})}),"\n",(0,a.jsx)(n.p,{children:"Build and track a LangChain-based chatbot with MLflow's version management capabilities. This quickstart demonstrates prompt versioning, application tracking, trace generation, and performance evaluation using MLflow's GenAI features."}),"\n",(0,a.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,a.jsx)(n.h3,{id:"install-required-packages",children:"Install Required Packages"}),"\n",(0,a.jsx)(n.admonition,{title:"MLflow 3 Required",type:"note",children:(0,a.jsx)(n.p,{children:"This quickstart requires MLflow version 3.0 or higher for full GenAI functionality."})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"pip install --upgrade mlflow\npip install langchain-openai\n"})}),"\n",(0,a.jsx)(n.h3,{id:"set-openai-api-key",children:"Set OpenAI API Key"}),"\n",(0,a.jsx)(n.p,{children:"Configure your OpenAI API key to authenticate with OpenAI services:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"export OPENAI_API_KEY=your_api_key_here\n"})}),"\n",(0,a.jsx)(n.h2,{id:"what-youll-learn",children:"What You'll Learn"}),"\n",(0,a.jsx)(n.p,{children:"This quickstart covers the essential concepts for building trackable GenAI applications with MLflow's version management system."}),"\n",(0,a.jsx)(l.A,{concepts:[{icon:p.A,title:"Version Control Prompts",description:"Register and track prompt templates with full version history for reproducible experiments"},{icon:m.A,title:"Build LangChain Agents",description:"Create conversational agents with automatic MLflow integration and observability"},{icon:h.A,title:"Trace Everything",description:"Enable comprehensive trace logging to monitor and debug your model's behavior"},{icon:d.A,title:"Evaluate Performance",description:"Assess model quality with built-in metrics and custom evaluation frameworks"}]}),"\n",(0,a.jsx)(n.p,{children:"Let's build a simple IT support chatbot and track its development lifecycle with MLflow."}),"\n",(0,a.jsx)(n.h2,{id:"step-1-register-a-prompt-template",children:"Step 1: Register a Prompt Template"}),"\n",(0,a.jsx)(n.p,{children:"Start by creating a versioned prompt template. This enables you to track prompt evolution and ensure reproducibility across experiments."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\n\nsystem_prompt = mlflow.genai.register_prompt(\n    name="chatbot_prompt",\n    template="You are a chatbot that can answer questions about IT. Answer this question: {{question}}",\n    commit_message="Initial version of chatbot",\n)\n'})}),"\n",(0,a.jsx)(n.h3,{id:"view-your-prompt-in-mlflow-ui",children:"View Your Prompt in MLflow UI"}),"\n",(0,a.jsxs)(n.p,{children:["Navigate to the ",(0,a.jsx)(n.strong,{children:"Prompts"})," tab to see your registered prompt:"]}),"\n",(0,a.jsx)(c.A,{src:"/images/mlflow-3/genai/chatbot_prompt.png",alt:"The MLflow UI showing a prompt version",width:"90%"}),"\n",(0,a.jsx)(n.h2,{id:"step-2-build-a-langchain-conversational-chain",children:"Step 2: Build a LangChain Conversational Chain"}),"\n",(0,a.jsx)(n.p,{children:"Create a simple chain that combines your prompt template with OpenAI's chat model:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from langchain.schema.output_parser import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\n\n# Convert MLflow prompt to LangChain format\nprompt = ChatPromptTemplate.from_template(system_prompt.to_single_brace_format())\n\n# Build the chain: prompt \u2192 LLM \u2192 output parser\nchain = prompt | ChatOpenAI(temperature=0.7) | StrOutputParser()\n\n# Test the chain\nquestion = "What is MLflow?"\nprint(chain.invoke({"question": question}))\n# MLflow is an open-source platform for managing the end-to-end machine learning lifecycle...\n'})}),"\n",(0,a.jsx)(n.h2,{id:"step-3-enable-trace-observability",children:"Step 3: Enable Trace Observability"}),"\n",(0,a.jsx)(n.p,{children:"Set up automatic trace logging to monitor your model's behavior during development. This creates a linked history of all model interactions."}),"\n",(0,a.jsx)(n.h3,{id:"configure-active-model-and-autologging",children:"Configure Active Model and Autologging"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Set the active model for linking traces\nmlflow.set_active_model(name="langchain_model")\n\n# Enable autologging - all traces will be automatically linked to the active model\nmlflow.langchain.autolog()\n'})}),"\n",(0,a.jsx)(n.h3,{id:"generate-test-traces",children:"Generate Test Traces"}),"\n",(0,a.jsx)(n.p,{children:"Run multiple queries to generate traces for analysis:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'questions = [\n    {"question": "What is MLflow Tracking and how does it work?"},\n    {"question": "What is Unity Catalog?"},\n    {"question": "What are user-defined functions (UDFs)?"},\n]\noutputs = []\n\nfor question in questions:\n    outputs.append(chain.invoke(question))\n\n# Verify traces are linked to the active model\nactive_model_id = mlflow.get_active_model_id()\nmlflow.search_traces(model_id=active_model_id)\n'})}),"\n",(0,a.jsx)(n.h3,{id:"explore-traces-in-the-ui",children:"Explore Traces in the UI"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"View the Logged Model"}),": Check the ",(0,a.jsx)(n.strong,{children:"Models"})," tab in your experiment:"]}),"\n"]}),"\n",(0,a.jsx)(c.A,{src:"/images/mlflow-3/genai/logged_models_tab.png",alt:"The MLflow UI showing the logged models in an experiment",width:"90%"}),"\n",(0,a.jsxs)(n.ol,{start:"2",children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Access Model Details"}),": Click on your model to view its unique ",(0,a.jsx)(n.code,{children:"model_id"}),":"]}),"\n"]}),"\n",(0,a.jsx)(c.A,{src:"/images/mlflow-3/genai/logged_model_page.png",alt:"The MLflow UI showing the logged model details page",width:"90%"}),"\n",(0,a.jsxs)(n.ol,{start:"3",children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Analyze Generated Traces"}),": Navigate to the ",(0,a.jsx)(n.strong,{children:"Traces"})," tab to examine individual interactions:"]}),"\n"]}),"\n",(0,a.jsx)(c.A,{src:"/images/mlflow-3/genai/logged_model_autolog_traces.png",alt:"The MLflow UI showing the logged model autolog traces lineage",width:"90%"}),"\n",(0,a.jsx)(n.h2,{id:"step-4-evaluate-model-performance",children:"Step 4: Evaluate Model Performance"}),"\n",(0,a.jsx)(n.p,{children:"Evaluation is crucial for understanding how well your chatbot performs and ensuring quality improvements over time. MLflow provides the foundation for systematic evaluation tracking."}),"\n",(0,a.jsx)(n.p,{children:"Key evaluation capabilities:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Quality Assessment"}),": Systematically evaluate response quality using keyword coverage and content analysis to ensure your chatbot meets expectations"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Performance Metrics"}),": Track quantitative measures like response length and keyword matching to monitor improvement over time"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Continuous Monitoring"}),": Log evaluation results to MLflow for ongoing performance tracking and comparison across model iterations"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"Use MLflow's tracking capabilities to assess your chatbot's accuracy and relevance against expected responses."}),"\n",(0,a.jsx)(n.h3,{id:"analyze-outputs-manually",children:"Analyze Outputs Manually"}),"\n",(0,a.jsx)(n.p,{children:"Evaluate your model outputs by comparing them to expected responses:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import pandas as pd\n\n# Create evaluation dataset\neval_data = [\n    {\n        "question": "What is MLflow Tracking and how does it work?",\n        "expected_keywords": [\n            "experiment tracking",\n            "parameters",\n            "metrics",\n            "artifacts",\n            "UI",\n        ],\n    },\n    {\n        "question": "What is Unity Catalog?",\n        "expected_keywords": [\n            "data assets",\n            "centralized",\n            "collaboration",\n            "governance",\n        ],\n    },\n    {\n        "question": "What are user-defined functions (UDFs)?",\n        "expected_keywords": [\n            "custom functions",\n            "data transformations",\n            "Spark",\n            "SQL",\n        ],\n    },\n]\n\n\n# Simple evaluation metrics\ndef evaluate_response(response, expected_keywords):\n    """Simple keyword-based evaluation."""\n    response_lower = response.lower()\n    keyword_matches = sum(\n        1 for keyword in expected_keywords if keyword.lower() in response_lower\n    )\n    coverage_score = keyword_matches / len(expected_keywords)\n    response_length = len(response.split())\n\n    return {\n        "keyword_coverage": coverage_score,\n        "response_length": response_length,\n        "keyword_matches": keyword_matches,\n    }\n\n\n# Evaluate each response\nevaluation_results = []\nfor i, (output, eval_item) in enumerate(zip(outputs, eval_data)):\n    metrics = evaluate_response(output, eval_item["expected_keywords"])\n    evaluation_results.append(\n        {\n            "question": eval_item["question"],\n            "response": output,\n            "keyword_coverage": metrics["keyword_coverage"],\n            "response_length": metrics["response_length"],\n            "keyword_matches": metrics["keyword_matches"],\n        }\n    )\n\n    print(\n        f"Question {i+1}: {metrics[\'keyword_matches\']}/{len(eval_item[\'expected_keywords\'])} keywords found"\n    )\n    print(f"Coverage: {metrics[\'keyword_coverage\']:.1%}")\n    print(f"Response length: {metrics[\'response_length\']} words\\n")\n\n# Log evaluation metrics\nwith mlflow.start_run():\n    avg_coverage = sum(r["keyword_coverage"] for r in evaluation_results) / len(\n        evaluation_results\n    )\n    avg_length = sum(r["response_length"] for r in evaluation_results) / len(\n        evaluation_results\n    )\n\n    mlflow.log_metric("avg_keyword_coverage", avg_coverage)\n    mlflow.log_metric("avg_response_length", avg_length)\n\n    print(f"\ud83d\udcca Average keyword coverage: {avg_coverage:.1%}")\n    print(f"\ud83d\udcca Average response length: {avg_length:.0f} words")\n'})}),"\n",(0,a.jsx)(n.h3,{id:"view-results-in-mlflow-ui",children:"View Results in MLflow UI"}),"\n",(0,a.jsxs)(n.p,{children:["The evaluation metrics are logged to MLflow for tracking and comparison. Navigate to the ",(0,a.jsx)(n.strong,{children:"Experiments"})," tab to view your evaluation run and compare results across different iterations."]}),"\n",(0,a.jsx)(n.h2,{id:"what-youve-built",children:"What You've Built"}),"\n",(0,a.jsx)(n.p,{children:"You now have a complete version-tracked GenAI application with comprehensive observability and evaluation capabilities."}),"\n",(0,a.jsx)(n.p,{children:"What you've accomplished:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Versioned Prompt Templates"}),": Your prompts are now registered in MLflow with full version history, enabling reproducible experiments and systematic improvements"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Integrated LangChain Agent"}),": Built a conversational agent with automatic MLflow integration that captures every interaction for analysis and debugging"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Complete Trace Observability"}),": Enabled comprehensive trace logging that links all model interactions to your versioned application for full visibility"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Systematic Evaluation"}),": Implemented performance tracking with keyword-based metrics that log results to MLflow for ongoing quality monitoring"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,a.jsxs)(o.A,{children:[(0,a.jsx)(s.A,{href:"/genai/version-tracking/track-application-versions-with-mlflow",title:"Track Application Versions",description:"Learn advanced version tracking patterns for production GenAI applications",icon:f.A}),(0,a.jsx)(s.A,{href:"/genai/version-tracking/compare-app-versions",title:"Compare App Versions",description:"Analyze performance differences between versions using trace-based comparison",icon:u.A}),(0,a.jsx)(s.A,{href:"/genai/prompt-registry",title:"Prompt Registry",description:"Manage prompts at scale with MLflow's centralized prompt registry",icon:g.A}),(0,a.jsx)(s.A,{href:"/genai/eval-monitor",title:"Evaluation & Monitoring",description:"Build comprehensive evaluation pipelines for production GenAI applications",icon:w.A})]})]})}function j(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(k,{...e})}):k(e)}}}]);