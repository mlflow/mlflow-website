"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[3718],{11470:(e,n,a)=>{a.d(n,{A:()=>v});var r=a(96540),l=a(34164),t=a(23104),o=a(56347),i=a(205),s=a(57485),p=a(31682),m=a(70679);function c(e){return r.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function d(e){const{values:n,children:a}=e;return(0,r.useMemo)((()=>{const e=n??function(e){return c(e).map((({props:{value:e,label:n,attributes:a,default:r}})=>({value:e,label:n,attributes:a,default:r})))}(a);return function(e){const n=(0,p.XI)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,a])}function u({value:e,tabValues:n}){return n.some((n=>n.value===e))}function f({queryString:e=!1,groupId:n}){const a=(0,o.W6)(),l=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,s.aZ)(l),(0,r.useCallback)((e=>{if(!l)return;const n=new URLSearchParams(a.location.search);n.set(l,e),a.replace({...a.location,search:n.toString()})}),[l,a])]}function h(e){const{defaultValue:n,queryString:a=!1,groupId:l}=e,t=d(e),[o,s]=(0,r.useState)((()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!u({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const a=n.find((e=>e.default))??n[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:n,tabValues:t}))),[p,c]=f({queryString:a,groupId:l}),[h,g]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[a,l]=(0,m.Dv)(n);return[a,(0,r.useCallback)((e=>{n&&l.set(e)}),[n,l])]}({groupId:l}),_=(()=>{const e=p??h;return u({value:e,tabValues:t})?e:null})();(0,i.A)((()=>{_&&s(_)}),[_]);return{selectedValue:o,selectValue:(0,r.useCallback)((e=>{if(!u({value:e,tabValues:t}))throw new Error(`Can't select invalid tab value=${e}`);s(e),c(e),g(e)}),[c,g,t]),tabValues:t}}var g=a(92303);const _={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var w=a(74848);function y({className:e,block:n,selectedValue:a,selectValue:r,tabValues:o}){const i=[],{blockElementScrollPositionUntilNextRender:s}=(0,t.a_)(),p=e=>{const n=e.currentTarget,l=i.indexOf(n),t=o[l].value;t!==a&&(s(n),r(t))},m=e=>{let n=null;switch(e.key){case"Enter":p(e);break;case"ArrowRight":{const a=i.indexOf(e.currentTarget)+1;n=i[a]??i[0];break}case"ArrowLeft":{const a=i.indexOf(e.currentTarget)-1;n=i[a]??i[i.length-1];break}}n?.focus()};return(0,w.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,l.A)("tabs",{"tabs--block":n},e),children:o.map((({value:e,label:n,attributes:r})=>(0,w.jsx)("li",{role:"tab",tabIndex:a===e?0:-1,"aria-selected":a===e,ref:e=>{i.push(e)},onKeyDown:m,onClick:p,...r,className:(0,l.A)("tabs__item",_.tabItem,r?.className,{"tabs__item--active":a===e}),children:n??e},e)))})}function x({lazy:e,children:n,selectedValue:a}){const t=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=t.find((e=>e.props.value===a));return e?(0,r.cloneElement)(e,{className:(0,l.A)("margin-top--md",e.props.className)}):null}return(0,w.jsx)("div",{className:"margin-top--md",children:t.map(((e,n)=>(0,r.cloneElement)(e,{key:n,hidden:e.props.value!==a})))})}function k(e){const n=h(e);return(0,w.jsxs)("div",{className:(0,l.A)("tabs-container",_.tabList),children:[(0,w.jsx)(y,{...n,...e}),(0,w.jsx)(x,{...n,...e})]})}function v(e){const n=(0,g.A)();return(0,w.jsx)(k,{...e,children:c(e.children)},String(n))}},19365:(e,n,a)=>{a.d(n,{A:()=>o});a(96540);var r=a(34164);const l={tabItem:"tabItem_Ymn6"};var t=a(74848);function o({children:e,hidden:n,className:a}){return(0,t.jsx)("div",{role:"tabpanel",className:(0,r.A)(l.tabItem,a),hidden:n,children:e})}},28453:(e,n,a)=>{a.d(n,{R:()=>o,x:()=>i});var r=a(96540);const l={},t=r.createContext(l);function o(e){const n=r.useContext(t);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:o(e.components),r.createElement(t.Provider,{value:n},e.children)}},49374:(e,n,a)=>{a.d(n,{B:()=>s});a(96540);const r=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var l=a(86025),t=a(28774),o=a(74848);const i=e=>{const n=e.split(".");for(let a=n.length;a>0;a--){const e=n.slice(0,a).join(".");if(r[e])return e}return null};function s({fn:e,children:n}){const a=i(e);if(!a)return(0,o.jsx)(o.Fragment,{children:n});const s=(0,l.Ay)(`/${r[a]}#${e}`);return(0,o.jsx)(t.A,{to:s,target:"_blank",children:n??(0,o.jsxs)("code",{children:[e,"()"]})})}},62829:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>m,contentTitle:()=>p,default:()=>u,frontMatter:()=>s,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"traditional-ml/sparkml/guide/index","title":"Spark MLlib with MLflow","description":"In this comprehensive guide, we\'ll walk you through how to use Spark MLlib with MLflow for experiment tracking, model management, and production deployment. We\'ll cover basic model logging, pipeline tracking, and deployment patterns that will get you productive quickly with distributed machine learning.","source":"@site/docs/classic-ml/traditional-ml/sparkml/guide/index.mdx","sourceDirName":"traditional-ml/sparkml/guide","slug":"/traditional-ml/sparkml/guide/","permalink":"/docs/latest/ml/traditional-ml/sparkml/guide/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"classicMLSidebar","previous":{"title":"MLflow Spark MLlib Integration","permalink":"/docs/latest/ml/traditional-ml/sparkml/"},"next":{"title":"MLflow Prophet Integration","permalink":"/docs/latest/ml/traditional-ml/prophet/"}}');var l=a(74848),t=a(28453),o=(a(49374),a(11470)),i=a(19365);const s={},p="Spark MLlib with MLflow",m={},c=[{value:"Quick Start with Basic Model Logging",id:"quick-start-with-basic-model-logging",level:2},{value:"Model Formats and Loading",id:"model-formats-and-loading",level:2},{value:"Pipeline Tracking and Management",id:"pipeline-tracking-and-management",level:2},{value:"Spark Datasource Autologging",id:"spark-datasource-autologging",level:2},{value:"Model Signatures and Schema Management",id:"model-signatures-and-schema-management",level:2},{value:"Cross-Platform Deployment",id:"cross-platform-deployment",level:2},{value:"Production Deployment",id:"production-deployment",level:2},{value:"Error Handling and Best Practices",id:"error-handling-and-best-practices",level:2},{value:"Conclusion",id:"conclusion",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.header,{children:(0,l.jsx)(n.h1,{id:"spark-mllib-with-mlflow",children:"Spark MLlib with MLflow"})}),"\n",(0,l.jsx)(n.p,{children:"In this comprehensive guide, we'll walk you through how to use Spark MLlib with MLflow for experiment tracking, model management, and production deployment. We'll cover basic model logging, pipeline tracking, and deployment patterns that will get you productive quickly with distributed machine learning."}),"\n",(0,l.jsx)(n.h2,{id:"quick-start-with-basic-model-logging",children:"Quick Start with Basic Model Logging"}),"\n",(0,l.jsx)(n.p,{children:"The simplest way to get started is by logging your Spark MLlib models directly to MLflow:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport mlflow.spark\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import Tokenizer, HashingTF\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql import SparkSession\n\n# Initialize Spark session\nspark = SparkSession.builder.appName("MLflowSparkExample").getOrCreate()\n\n# Prepare training data\ntraining = spark.createDataFrame(\n    [\n        (0, "a b c d e spark", 1.0),\n        (1, "b d", 0.0),\n        (2, "spark f g h", 1.0),\n        (3, "hadoop mapreduce", 0.0),\n    ],\n    ["id", "text", "label"],\n)\n\n# Create ML Pipeline\ntokenizer = Tokenizer(inputCol="text", outputCol="words")\nhashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol="features")\nlr = LogisticRegression(maxIter=10, regParam=0.001)\npipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n\n# Train and log the model\nwith mlflow.start_run():\n    model = pipeline.fit(training)\n\n    # Log the entire pipeline\n    model_info = mlflow.spark.log_model(spark_model=model, name="spark-pipeline")\n\n    # Log parameters manually\n    mlflow.log_params(\n        {\n            "max_iter": lr.getMaxIter(),\n            "reg_param": lr.getRegParam(),\n            "num_features": hashingTF.getNumFeatures(),\n        }\n    )\n\nprint(f"Model logged with URI: {model_info.model_uri}")\n'})}),"\n",(0,l.jsx)(n.p,{children:"This simple example automatically logs:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"The complete Spark ML pipeline with all stages"}),"\n",(0,l.jsx)(n.li,{children:"Model parameters from each pipeline stage"}),"\n",(0,l.jsx)(n.li,{children:"The trained model in both Spark native and PyFunc formats"}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"model-formats-and-loading",children:"Model Formats and Loading"}),"\n",(0,l.jsxs)(o.A,{children:[(0,l.jsxs)(i.A,{value:"native",label:"Native Spark Format",children:[(0,l.jsx)(n.p,{children:"The native Spark format preserves the full functionality of your Spark ML pipeline:"}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'# Load as native Spark model (requires Spark session)\nspark_model = mlflow.spark.load_model(model_info.model_uri)\n\n# Use for distributed batch scoring\ntest_data = spark.createDataFrame(\n    [(4, "spark i j k"), (5, "l m n"), (6, "spark hadoop spark"), (7, "apache hadoop")],\n    ["id", "text"],\n)\n\npredictions = spark_model.transform(test_data)\npredictions.show()\n'})}),(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Best for:"})," Large-scale batch processing, existing Spark infrastructure"]})]}),(0,l.jsxs)(i.A,{value:"pyfunc",label:"PyFunc Format",children:[(0,l.jsx)(n.p,{children:"The PyFunc format enables deployment outside of Spark environments:"}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'import pandas as pd\n\n# Load as PyFunc model (no Spark session required)\npyfunc_model = mlflow.pyfunc.load_model(model_info.model_uri)\n\n# Use with pandas DataFrame\ntest_data = pd.DataFrame(\n    {"text": ["spark machine learning", "hadoop distributed computing"]}\n)\n\n# Predictions work seamlessly\npredictions = pyfunc_model.predict(test_data)\nprint(predictions)\n'})}),(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Best for:"})," REST API deployment, edge computing, non-Spark environments"]})]}),(0,l.jsxs)(i.A,{value:"conversion",label:"Format Conversion",children:[(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Automatic Conversion Process:"})}),(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Input Handling"}),": PyFunc automatically converts pandas DataFrames to Spark DataFrames"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Spark Context"}),": Creates a local Spark session if none exists"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Output Processing"}),": Converts Spark ML vector outputs to arrays for pandas compatibility"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Performance Trade-offs"}),": Initialization overhead vs deployment flexibility"]}),"\n"]}),(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"When to Use Each Format:"})}),(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Native Spark"}),": Large-scale batch processing, existing Spark infrastructure"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"PyFunc"}),": REST API deployment, edge computing, non-Spark environments"]}),"\n"]})]})]}),"\n",(0,l.jsx)(n.h2,{id:"pipeline-tracking-and-management",children:"Pipeline Tracking and Management"}),"\n",(0,l.jsxs)(o.A,{children:[(0,l.jsx)(i.A,{value:"basic",label:"Basic Pipeline",children:(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'from pyspark.ml.feature import VectorAssembler, StandardScaler\nfrom pyspark.ml.classification import RandomForestClassifier\n\n# Load your dataset\ndata = spark.read.csv("path/to/dataset.csv", header=True, inferSchema=True)\n\nwith mlflow.start_run(run_name="Feature Pipeline"):\n    # Create feature engineering pipeline\n    feature_cols = ["age", "income", "credit_score"]\n    assembler = VectorAssembler(inputCols=feature_cols, outputCol="raw_features")\n    scaler = StandardScaler(inputCol="raw_features", outputCol="features")\n    rf = RandomForestClassifier(featuresCol="features", labelCol="label", numTrees=100)\n\n    # Create complete pipeline\n    pipeline = Pipeline(stages=[assembler, scaler, rf])\n\n    # Train pipeline\n    model = pipeline.fit(data)\n\n    # Log pipeline parameters\n    mlflow.log_params(\n        {\n            "num_features": len(feature_cols),\n            "num_trees": rf.getNumTrees(),\n            "max_depth": rf.getMaxDepth(),\n        }\n    )\n\n    # Log the complete pipeline\n    mlflow.spark.log_model(spark_model=model, name="feature_pipeline")\n'})})}),(0,l.jsx)(i.A,{value:"tuning",label:"Hyperparameter Tuning",children:(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nwith mlflow.start_run(run_name="Hyperparameter Tuning"):\n    # Create base pipeline\n    lr = LogisticRegression(featuresCol="features", labelCol="label")\n    pipeline = Pipeline(stages=[assembler, scaler, lr])\n\n    # Create parameter grid\n    param_grid = (\n        ParamGridBuilder()\n        .addGrid(lr.regParam, [0.01, 0.1, 1.0])\n        .addGrid(lr.maxIter, [50, 100])\n        .build()\n    )\n\n    # Create cross-validator\n    evaluator = BinaryClassificationEvaluator(labelCol="label")\n    cv = CrossValidator(\n        estimator=pipeline,\n        estimatorParamMaps=param_grid,\n        evaluator=evaluator,\n        numFolds=3,\n    )\n\n    # Fit cross-validator\n    cv_model = cv.fit(train_data)\n\n    # Log best parameters\n    best_model = cv_model.bestModel\n    best_lr_stage = best_model.stages[-1]\n\n    mlflow.log_params(\n        {\n            "best_regParam": best_lr_stage.getRegParam(),\n            "best_maxIter": best_lr_stage.getMaxIter(),\n        }\n    )\n\n    # Evaluate on test set\n    test_predictions = cv_model.transform(test_data)\n    test_auc = evaluator.evaluate(test_predictions)\n    mlflow.log_metric("test_auc", test_auc)\n\n    # Log the best model\n    mlflow.spark.log_model(spark_model=cv_model.bestModel, name="best_cv_model")\n'})})})]}),"\n",(0,l.jsx)(n.h2,{id:"spark-datasource-autologging",children:"Spark Datasource Autologging"}),"\n",(0,l.jsxs)(o.A,{children:[(0,l.jsxs)(i.A,{value:"enable",label:"Enable Autologging",children:[(0,l.jsx)(n.p,{children:"MLflow provides automatic logging of Spark datasource information:"}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'import mlflow.spark\n\n# Enable Spark datasource autologging\nmlflow.spark.autolog()\n\n# Now all datasource reads are automatically logged\nwith mlflow.start_run():\n    # These datasource operations are automatically tracked\n    raw_data = spark.read.parquet("s3://my-bucket/training-data/")\n    processed_data = spark.read.csv(\n        "hdfs://cluster/processed/features.csv", header=True\n    )\n\n    # Train your model - datasource info is logged automatically\n    model = pipeline.fit(processed_data)\n\n    # Model training and datasource information both captured\n    mlflow.spark.log_model(model, name="model_with_datasource_tracking")\n'})})]}),(0,l.jsxs)(i.A,{value:"setup",label:"Setup Requirements",children:[(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Requirements:"})}),(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Spark Version"}),": Requires Spark 3.0 or above"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"MLflow-Spark JAR"}),": Must be included in Spark session configuration"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Environment"}),": Not supported on Databricks shared/serverless clusters"]}),"\n"]}),(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"JAR Configuration:"})}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'from pyspark.sql import SparkSession\n\n# Configure Spark session with MLflow JAR\nspark = (\n    SparkSession.builder.appName("MLflowAutologgingApp")\n    .config("spark.jars.packages", "org.mlflow:mlflow-spark_2.12:2.16.2")\n    .getOrCreate()\n)\n'})}),(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"What Gets Logged:"})}),(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Path Information"}),": Complete paths to data sources"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Format Details"}),": File formats (parquet, delta, csv, etc.)"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Version Information"}),": For versioned sources like Delta Lake"]}),"\n"]})]})]}),"\n",(0,l.jsx)(n.h2,{id:"model-signatures-and-schema-management",children:"Model Signatures and Schema Management"}),"\n",(0,l.jsxs)(o.A,{children:[(0,l.jsx)(i.A,{value:"vectors",label:"Spark ML Vectors",children:(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'from mlflow.models import infer_signature\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.functions import array_to_vector\n\n# Create data with vector features\nvector_data = spark.createDataFrame(\n    [([3.0, 4.0], 0), ([5.0, 6.0], 1)], ["features_array", "label"]\n).select(array_to_vector("features_array").alias("features"), "label")\n\n# Train model\nlr = LogisticRegression(featuresCol="features", labelCol="label")\nmodel = lr.fit(vector_data)\n\n# Get predictions for signature\npredictions = model.transform(vector_data)\n\n# Infer signature automatically\nsignature = infer_signature(vector_data, predictions.select("prediction"))\n\nwith mlflow.start_run():\n    mlflow.spark.log_model(\n        spark_model=model,\n        name="vector_model",\n        signature=signature,\n        input_example=vector_data.limit(2).toPandas(),\n    )\n'})})}),(0,l.jsx)(i.A,{value:"manual",label:"Manual Signatures",children:(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'from mlflow.types import DataType, Schema, ColSpec\nfrom mlflow.types.schema import SparkMLVector\nfrom mlflow.models.signature import ModelSignature\n\n# Create detailed model signature\ninput_schema = Schema(\n    [\n        ColSpec(DataType.string, "text"),\n        ColSpec(DataType.double, "numeric_feature"),\n        ColSpec(SparkMLVector(), "vector_feature"),\n    ]\n)\n\noutput_schema = Schema([ColSpec(DataType.double, "prediction")])\n\nsignature = ModelSignature(inputs=input_schema, outputs=output_schema)\n\n# Log model with explicit signature\nwith mlflow.start_run():\n    mlflow.spark.log_model(\n        spark_model=model, name="production_model", signature=signature\n    )\n'})})})]}),"\n",(0,l.jsx)(n.h2,{id:"cross-platform-deployment",children:"Cross-Platform Deployment"}),"\n",(0,l.jsxs)(o.A,{children:[(0,l.jsxs)(i.A,{value:"onnx",label:"ONNX Conversion",children:[(0,l.jsx)(n.p,{children:"Convert Spark MLlib models to ONNX format for cross-platform deployment:"}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'# Note: This requires onnxmltools (Spark ML support is experimental)\n# pip install onnxmltools\n\nimport onnxmltools\n\nwith mlflow.start_run(run_name="ONNX Conversion"):\n    # Train your Spark ML model\n    model = pipeline.fit(training_data)\n\n    # Log original Spark model\n    spark_model_info = mlflow.spark.log_model(spark_model=model, name="spark_model")\n\n    try:\n        # Convert to ONNX using onnxmltools\n        # Note: Spark ML conversion is experimental and may have limitations\n        onnx_model = onnxmltools.convert_sparkml(\n            model, name="SparkMLPipeline", target_opset=None  # Use default opset\n        )\n\n        # Save ONNX model as artifact\n        onnx_model_path = "model.onnx"\n        onnxmltools.utils.save_model(onnx_model, onnx_model_path)\n\n        mlflow.log_artifact(onnx_model_path)\n        mlflow.log_param("onnx_conversion_successful", True)\n\n        # Log ONNX model info\n        opset_version = onnx_model.opset_import[0].version\n        mlflow.log_param("onnx_opset_version", opset_version)\n\n    except Exception as e:\n        mlflow.log_param("onnx_conversion_error", str(e))\n        mlflow.log_param("onnx_conversion_successful", False)\n\n        # ONNX conversion for Spark ML is experimental and may not work\n        # for all model types. Consider using PyFunc format instead.\n'})}),(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Note:"})," Spark ML to ONNX conversion is experimental in onnxmltools and may not support all Spark ML operators. For production deployments, consider using MLflow's PyFunc format for broader compatibility."]})]}),(0,l.jsx)(i.A,{value:"registry",label:"Model Registry",children:(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'from mlflow import MlflowClient\n\nclient = MlflowClient()\n\n# Register model with production metadata\nwith mlflow.start_run():\n    # Train and evaluate model\n    model = pipeline.fit(train_data)\n\n    # Log model with registration\n    model_info = mlflow.spark.log_model(\n        spark_model=model,\n        name="production_candidate",\n        registered_model_name="CustomerSegmentationModel",\n    )\n\n    # Add production readiness tags\n    mlflow.set_tags(\n        {\n            "validation_passed": "true",\n            "deployment_target": "batch_scoring",\n            "model_type": "classification",\n        }\n    )\n\n# Promote model through stages\nmodel_version = client.get_latest_versions(\n    "CustomerSegmentationModel", stages=["None"]\n)[0]\n\n# Transition to Staging\nclient.transition_model_version_stage(\n    name="CustomerSegmentationModel", version=model_version.version, stage="Staging"\n)\n'})})})]}),"\n",(0,l.jsx)(n.h2,{id:"production-deployment",children:"Production Deployment"}),"\n",(0,l.jsxs)(o.A,{children:[(0,l.jsx)(i.A,{value:"batch",label:"Batch Inference",children:(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'def production_batch_scoring(model_uri, input_path, output_path):\n    """Simple production batch scoring pipeline."""\n\n    with mlflow.start_run(run_name="Batch_Scoring"):\n        # Load production model\n        model = mlflow.spark.load_model(model_uri)\n\n        # Load input data\n        input_data = spark.read.parquet(input_path)\n\n        # Generate predictions\n        predictions = model.transform(input_data)\n\n        # Add metadata\n        predictions_with_metadata = predictions.withColumn(\n            "prediction_timestamp", F.current_timestamp()\n        )\n\n        # Write predictions\n        (predictions_with_metadata.write.mode("overwrite").parquet(output_path))\n\n        # Log job metrics\n        record_count = predictions.count()\n        mlflow.log_metrics({"records_processed": record_count, "job_success": 1})\n\n        return output_path\n\n\n# Usage\nproduction_batch_scoring(\n    model_uri="models:/CustomerSegmentationModel/Production",\n    input_path="s3://data-lake/daily-customers/",\n    output_path="s3://predictions/customer-segments/",\n)\n'})})}),(0,l.jsx)(i.A,{value:"evaluation",label:"Model Evaluation",children:(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'def evaluate_spark_model(model, test_data, model_name):\n    """Evaluate Spark ML model with comprehensive metrics."""\n\n    with mlflow.start_run(run_name=f"Evaluation_{model_name}"):\n        # Generate predictions\n        predictions = model.transform(test_data)\n\n        # Calculate metrics based on problem type\n        from pyspark.ml.evaluation import (\n            BinaryClassificationEvaluator,\n            MulticlassClassificationEvaluator,\n        )\n\n        # Binary classification metrics\n        binary_evaluator = BinaryClassificationEvaluator(labelCol="label")\n        auc = binary_evaluator.evaluate(predictions)\n\n        # Multiclass metrics\n        mc_evaluator = MulticlassClassificationEvaluator(labelCol="label")\n        accuracy = mc_evaluator.evaluate(\n            predictions, {mc_evaluator.metricName: "accuracy"}\n        )\n        f1 = mc_evaluator.evaluate(predictions, {mc_evaluator.metricName: "f1"})\n\n        # Log evaluation metrics\n        mlflow.log_metrics({"auc": auc, "accuracy": accuracy, "f1_score": f1})\n\n        # Feature importance (if available)\n        if hasattr(model.stages[-1], "featureImportances"):\n            feature_importance = model.stages[-1].featureImportances.toArray()\n\n            # Log top 5 feature importances\n            for i, importance in enumerate(feature_importance[:5]):\n                mlflow.log_metric(f"feature_importance_{i}", importance)\n\n        return {"auc": auc, "accuracy": accuracy, "f1_score": f1}\n\n\n# Usage\nevaluation_results = evaluate_spark_model(model, test_data, "RandomForest")\n'})})})]}),"\n",(0,l.jsx)(n.h2,{id:"error-handling-and-best-practices",children:"Error Handling and Best Practices"}),"\n",(0,l.jsxs)(o.A,{children:[(0,l.jsx)(i.A,{value:"robust",label:"Robust Training",children:(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'def train_spark_model_with_error_handling(data_path, model_config):\n    """Production-ready model training with error handling."""\n\n    with mlflow.start_run(run_name="Robust_Training"):\n        try:\n            # Load and validate data\n            data = spark.read.parquet(data_path)\n            record_count = data.count()\n\n            if record_count == 0:\n                raise ValueError("Input dataset is empty")\n\n            mlflow.log_metric("input_record_count", record_count)\n\n            # Create and train pipeline\n            pipeline = create_pipeline(model_config)\n            model = pipeline.fit(data)\n\n            # Validate model can make predictions\n            test_sample = data.limit(10)\n            predictions = model.transform(test_sample)\n            prediction_count = predictions.count()\n\n            if prediction_count != 10:\n                raise ValueError("Model validation failed")\n\n            # Log successful model\n            model_info = mlflow.spark.log_model(spark_model=model, name="robust_model")\n\n            mlflow.log_param("training_status", "success")\n            return model_info\n\n        except Exception as e:\n            # Log error information\n            mlflow.log_param("training_status", "failed")\n            mlflow.log_param("error_message", str(e))\n            raise\n\n\ndef create_pipeline(config):\n    """Create ML pipeline from configuration."""\n\n    # Simple pipeline creation logic\n    feature_cols = config.get("feature_columns", [])\n    assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")\n\n    algorithm = config.get("algorithm", "logistic_regression")\n    if algorithm == "logistic_regression":\n        classifier = LogisticRegression(featuresCol="features", labelCol="label")\n    elif algorithm == "random_forest":\n        classifier = RandomForestClassifier(featuresCol="features", labelCol="label")\n    else:\n        raise ValueError(f"Unsupported algorithm: {algorithm}")\n\n    return Pipeline(stages=[assembler, classifier])\n'})})}),(0,l.jsxs)(i.A,{value:"troubleshooting",label:"Troubleshooting",children:[(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Common Issues and Solutions:"})}),(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Serialization Issues:"})}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'# Test model serialization\ndef test_model_serialization(model):\n    try:\n        with tempfile.TemporaryDirectory() as temp_dir:\n            mlflow.spark.save_model(model, temp_dir)\n            loaded_model = mlflow.spark.load_model(temp_dir)\n            return True\n    except Exception as e:\n        print(f"Serialization failed: {e}")\n        return False\n'})}),(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Memory Issues:"})}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'# Configure Spark for large models\nspark.conf.set("spark.sql.adaptive.enabled", "true")\nspark.conf.set("spark.sql.adaptive.coalescePartitions.enabled", "true")\n\n# Cache strategically\nlarge_dataset.cache()  # Only when reused multiple times\n'})}),(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"PyFunc Loading Issues:"})}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'# Ensure Spark session exists for PyFunc\nfrom mlflow.utils._spark_utils import _get_active_spark_session\n\nif _get_active_spark_session() is None:\n    spark = SparkSession.builder.appName("MLflowPyFunc").getOrCreate()\n'})})]}),(0,l.jsxs)(i.A,{value:"optimization",label:"Performance Tips",children:[(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Efficient Logging:"})}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'def efficient_spark_ml_logging():\n    """Configure efficient logging for Spark ML."""\n\n    with mlflow.start_run():\n        # Log parameters early (lightweight)\n        mlflow.log_params({"algorithm": "random_forest", "num_trees": 100})\n\n        # Train model\n        model = pipeline.fit(large_dataset)\n\n        # Log metrics before model (in case model logging fails)\n        metrics = {"accuracy": 0.95}\n        mlflow.log_metrics(metrics)\n\n        # Log model with minimal examples for large datasets\n        mlflow.spark.log_model(\n            spark_model=model,\n            name="efficient_model",\n            input_example=sample_data.limit(3).toPandas(),  # Small sample only\n        )\n'})}),(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Spark Configuration:"})}),(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'# Optimize Spark for MLflow operations\ndef configure_spark_for_mlflow():\n    """Configure Spark session for optimal MLflow performance."""\n\n    spark_config = {\n        "spark.sql.adaptive.enabled": "true",\n        "spark.sql.adaptive.coalescePartitions.enabled": "true",\n        "spark.serializer": "org.apache.spark.serializer.KryoSerializer",\n    }\n\n    for key, value in spark_config.items():\n        spark.conf.set(key, value)\n'})})]})]}),"\n",(0,l.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,l.jsx)(n.p,{children:"MLflow's Spark MLlib integration provides a comprehensive solution for tracking and managing distributed machine learning workflows. Whether you're building simple classification models or complex multi-stage pipelines, MLflow helps you maintain reproducibility and deploy models efficiently."}),"\n",(0,l.jsx)(n.p,{children:"Key benefits of using MLflow with Spark MLlib include:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Complete Pipeline Tracking"}),": Automatic logging of multi-stage ML pipelines with all parameters and artifacts"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Flexible Deployment"}),": Deploy as native Spark models for batch processing or PyFunc wrappers for universal compatibility"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Data Lineage"}),": Automatic tracking of data sources through Spark datasource autologging"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Cross-Platform Support"}),": ONNX conversion enables deployment across different environments"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Production Ready"}),": Model registry integration and robust error handling for enterprise deployments"]}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:"The patterns shown in this guide provide a solid foundation for building scalable, reproducible distributed machine learning systems. Start with basic model logging for immediate experiment tracking benefits, then adopt advanced features like datasource autologging and model registry integration as your needs grow."})]})}function u(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(d,{...e})}):d(e)}}}]);