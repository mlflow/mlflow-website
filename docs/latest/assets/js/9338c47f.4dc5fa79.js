"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[2076],{16581:(t,e,n)=>{n.d(e,{p:()=>s});var r=n(74848);const s=({children:t,isStderr:e})=>(0,r.jsx)("pre",{style:{margin:0,borderRadius:0,background:"none",fontSize:"0.85rem",flexGrow:1,padding:"var(--padding-sm)"},children:t})},24279:(t,e,n)=>{n.r(e),n.d(e,{assets:()=>m,contentTitle:()=>h,default:()=>p,frontMatter:()=>c,metadata:()=>r,toc:()=>g});const r=JSON.parse('{"id":"traditional-ml/xgboost/quickstart/quickstart-xgboost-ipynb","title":"Get Started with MLflow + XGBoost","description":"Download this notebook","source":"@site/docs/classic-ml/traditional-ml/xgboost/quickstart/quickstart-xgboost-ipynb.mdx","sourceDirName":"traditional-ml/xgboost/quickstart","slug":"/traditional-ml/xgboost/quickstart/quickstart-xgboost","permalink":"/docs/latest/ml/traditional-ml/xgboost/quickstart/quickstart-xgboost","draft":false,"unlisted":false,"editUrl":"https://github.com/mlflow/mlflow/edit/master/docs/docs/classic-ml/traditional-ml/xgboost/quickstart/quickstart-xgboost.ipynb","tags":[],"version":"current","frontMatter":{"custom_edit_url":"https://github.com/mlflow/mlflow/edit/master/docs/docs/classic-ml/traditional-ml/xgboost/quickstart/quickstart-xgboost.ipynb","slug":"quickstart-xgboost"},"sidebar":"classicMLSidebar","previous":{"title":"MLflow XGBoost Integration","permalink":"/docs/latest/ml/traditional-ml/xgboost/"},"next":{"title":"XGBoost within MLflow","permalink":"/docs/latest/ml/traditional-ml/xgboost/guide/"}}');var s=n(74848),o=n(28453),a=n(75983),i=n(16581),l=n(81226),d=n(27594);const c={custom_edit_url:"https://github.com/mlflow/mlflow/edit/master/docs/docs/classic-ml/traditional-ml/xgboost/quickstart/quickstart-xgboost.ipynb",slug:"quickstart-xgboost"},h="Get Started with MLflow + XGBoost",m={},g=[{value:"Install dependencies",id:"install-dependencies",level:2},{value:"Load and prepare the dataset",id:"load-and-prepare-the-dataset",level:2},{value:"Connect to MLflow Tracking Server",id:"connect-to-mlflow-tracking-server",level:2},{value:"Logging with MLflow",id:"logging-with-mlflow",level:2},{value:"View results",id:"view-results",level:2}];function u(t){const e={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...t.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"get-started-with-mlflow--xgboost",children:"Get Started with MLflow + XGBoost"})}),"\n",(0,s.jsx)(d.O,{href:"https://raw.githubusercontent.com/mlflow/mlflow/master/docs/docs/classic-ml/traditional-ml/xgboost/quickstart/quickstart-xgboost.ipynb",children:"Download this notebook"}),"\n",(0,s.jsx)(e.p,{children:"In this guide, we will show you how to train a model with XGBoost and log your training using MLflow."}),"\n",(0,s.jsxs)(e.p,{children:["We will be using the ",(0,s.jsx)(e.a,{href:"https://mlflow.org/docs/latest/ml/getting-started/databricks-trial.html",children:"Databricks Free Trial"}),", which has built-in support for MLflow. The Databricks Free Trial provides an opportunity to use Databricks platform for free. If you haven't already, please register for an account via ",(0,s.jsx)(e.a,{href:"https://signup.databricks.com/?destination_url=/ml/experiments-signup?source=TRY_MLFLOW&dbx_source=TRY_MLFLOW&signup_experience_step=EXPRESS&provider=MLFLOW",children:"this link"}),"."]}),"\n",(0,s.jsx)(e.p,{children:"You can run code in this guide from cloud-based notebooks like Databricks notebook or Google Colab, or run it on your local machine."}),"\n",(0,s.jsx)(e.h2,{id:"install-dependencies",children:"Install dependencies"}),"\n",(0,s.jsxs)(e.p,{children:["Let's install the ",(0,s.jsx)(e.code,{children:"mlflow"})," package."]}),"\n",(0,s.jsx)(a.d,{executionCount:0,children:"%pip install mlflow"}),"\n",(0,s.jsx)(e.p,{children:"Then let's import the packages"}),"\n",(0,s.jsx)(a.d,{executionCount:" ",children:"import numpy as np\nimport xgboost as xgb\nfrom sklearn.datasets import load_iris\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.model_selection import train_test_split\n\nimport mlflow\nfrom mlflow.models import infer_signature"}),"\n",(0,s.jsx)(e.h2,{id:"load-and-prepare-the-dataset",children:"Load and prepare the dataset"}),"\n",(0,s.jsxs)(e.p,{children:["We will train a simple multi-class classification model for Iris flowers using the ",(0,s.jsx)(e.a,{href:"https://en.wikipedia.org/wiki/Iris_flower_data_set",children:"iris dataset"}),"."]}),"\n",(0,s.jsxs)(e.p,{children:["Let's load the dataset using ",(0,s.jsx)(e.code,{children:"load_iris()"})," into a pandas Dataframe and take a look at the data."]}),"\n",(0,s.jsx)(a.d,{executionCount:2,children:"iris_df = load_iris(as_frame=True).frame\niris_df"}),"\n",(0,s.jsx)(l.Q,{children:(0,s.jsx)("div",{dangerouslySetInnerHTML:{__html:'<div>\n<style scoped>\n  .dataframe tbody tr th:only-of-type {\n      vertical-align: middle;\n  }\n\n  .dataframe tbody tr th {\n      vertical-align: top;\n  }\n\n  .dataframe thead th {\n      text-align: right;\n  }\n</style>\n<table border="1" class="dataframe">\n<thead>\n  <tr style="text-align: right;">\n    <th></th>\n    <th>sepal length (cm)</th>\n    <th>sepal width (cm)</th>\n    <th>petal length (cm)</th>\n    <th>petal width (cm)</th>\n    <th>target</th>\n  </tr>\n</thead>\n<tbody>\n  <tr>\n    <th>0</th>\n    <td>5.1</td>\n    <td>3.5</td>\n    <td>1.4</td>\n    <td>0.2</td>\n    <td>0</td>\n  </tr>\n  <tr>\n    <th>1</th>\n    <td>4.9</td>\n    <td>3.0</td>\n    <td>1.4</td>\n    <td>0.2</td>\n    <td>0</td>\n  </tr>\n  <tr>\n    <th>2</th>\n    <td>4.7</td>\n    <td>3.2</td>\n    <td>1.3</td>\n    <td>0.2</td>\n    <td>0</td>\n  </tr>\n  <tr>\n    <th>3</th>\n    <td>4.6</td>\n    <td>3.1</td>\n    <td>1.5</td>\n    <td>0.2</td>\n    <td>0</td>\n  </tr>\n  <tr>\n    <th>4</th>\n    <td>5.0</td>\n    <td>3.6</td>\n    <td>1.4</td>\n    <td>0.2</td>\n    <td>0</td>\n  </tr>\n  <tr>\n    <th>...</th>\n    <td>...</td>\n    <td>...</td>\n    <td>...</td>\n    <td>...</td>\n    <td>...</td>\n  </tr>\n  <tr>\n    <th>145</th>\n    <td>6.7</td>\n    <td>3.0</td>\n    <td>5.2</td>\n    <td>2.3</td>\n    <td>2</td>\n  </tr>\n  <tr>\n    <th>146</th>\n    <td>6.3</td>\n    <td>2.5</td>\n    <td>5.0</td>\n    <td>1.9</td>\n    <td>2</td>\n  </tr>\n  <tr>\n    <th>147</th>\n    <td>6.5</td>\n    <td>3.0</td>\n    <td>5.2</td>\n    <td>2.0</td>\n    <td>2</td>\n  </tr>\n  <tr>\n    <th>148</th>\n    <td>6.2</td>\n    <td>3.4</td>\n    <td>5.4</td>\n    <td>2.3</td>\n    <td>2</td>\n  </tr>\n  <tr>\n    <th>149</th>\n    <td>5.9</td>\n    <td>3.0</td>\n    <td>5.1</td>\n    <td>1.8</td>\n    <td>2</td>\n  </tr>\n</tbody>\n</table>\n<p>150 rows \xd7 5 columns</p>\n</div>'}})}),"\n",(0,s.jsx)(e.p,{children:"Now we'll split our dataset into training and testing sets"}),"\n",(0,s.jsx)(a.d,{executionCount:3,children:"# Split into 80% training and 20% testing\ntrain_df, test_df = train_test_split(iris_df, test_size=0.2, random_state=42)\ntrain_df.shape, test_df.shape"}),"\n",(0,s.jsx)(i.p,{children:"((120, 5), (30, 5))"}),"\n",(0,s.jsx)(a.d,{executionCount:" ",children:'# Separate the target column for the training set\ntrain_dataset = mlflow.data.from_pandas(train_df, name="train")\nX_train = train_dataset.df.drop(["target"], axis=1)\ny_train = train_dataset.df[["target"]]\n\ndtrain = xgb.DMatrix(X_train, label=y_train)'}),"\n",(0,s.jsx)(a.d,{executionCount:0,children:'# Separate the target column for the testing set\ntest_dataset = mlflow.data.from_pandas(test_df, name="test")\nX_test = test_dataset.df.drop(["target"], axis=1)\ny_test = test_dataset.df[["target"]]\n\ndtest = xgb.DMatrix(X_test, label=y_test)'}),"\n",(0,s.jsx)(e.h2,{id:"connect-to-mlflow-tracking-server",children:"Connect to MLflow Tracking Server"}),"\n",(0,s.jsxs)(e.p,{children:["Before training, we need to configure the MLflow tracking server because we will log data into MLflow. In this tutorial, we will use Databricks Free Trial for MLflow tracking server. For other options such as using your local MLflow server, please read the ",(0,s.jsx)(e.a,{href:"https://mlflow.org/docs/latest/ml/getting-started/tracking-server-overview/",children:"Tracking Server Overview"}),"."]}),"\n",(0,s.jsxs)(e.p,{children:["If you have not, please set up your account and access token of the Databricks Free Trial by following ",(0,s.jsx)(e.a,{href:"https://mlflow.org/docs/latest/ml/getting-started/tracking-server-overview/",children:"this guide"}),". It should take no longer than 5 mins to register. For this guide, we need the ML experiment dashboard for us to track our training progress."]}),"\n",(0,s.jsx)(e.p,{children:"After successfully registering an account on the Databricks Free Trial, let's connnect MLflow to the Databricks Workspace. You will need to enter following information:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Databricks Host"}),": https://<your workspace host>.cloud.databricks.com"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Token"}),": You Personal Access Token"]}),"\n"]}),"\n",(0,s.jsx)(a.d,{executionCount:0,children:"mlflow.login()"}),"\n",(0,s.jsx)(e.p,{children:"Now this notebook is connected to the hosted tracking server. Let's configure some MLflow metadata. Two things to set up:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"mlflow.set_tracking_uri"}),': always use "databricks".']}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"mlflow.set_experiment"}),": pick up a name you like, start with ",(0,s.jsx)(e.code,{children:"/Users/<your email>/"}),"."]}),"\n"]}),"\n",(0,s.jsx)(a.d,{executionCount:0,children:'mlflow.set_tracking_uri("databricks")\nmlflow.set_experiment("/Users/<your email>/mlflow-xgboost-quickstart")'}),"\n",(0,s.jsx)(e.h2,{id:"logging-with-mlflow",children:"Logging with MLflow"}),"\n",(0,s.jsx)(e.p,{children:"MLflow has powerful tracking APIs that let's us log runs and models along with their associated metadata such as parameters and metrics. Let's train and evaluate our model."}),"\n",(0,s.jsx)(a.d,{executionCount:0,children:'# Start a training run\nwith mlflow.start_run() as run:\n  # Define and log the parameters for our model\n  params = {\n      "objective": "multi:softprob",\n      "num_class": len(set(train_df["target"])),\n      "max_depth": 8,\n      "learning_rate": 0.05,\n      "subsample": 0.9,\n      "colsample_bytree": 0.9,\n      "min_child_weight": 1,\n      "gamma": 0,\n      "reg_alpha": 0,\n      "reg_lambda": 1,\n      "random_state": 42,\n  }\n  training_config = {\n      "num_boost_round": 200,\n      "early_stopping_rounds": 20,\n  }\n  mlflow.log_params(params)\n  mlflow.log_params(training_config)\n\n  # Custom evaluation tracking\n  eval_results = {}\n  # Train model with custom callback\n  model = xgb.train(\n      params=params,\n      dtrain=dtrain,\n      num_boost_round=training_config["num_boost_round"],\n      evals=[(dtrain, "train"), (dtest, "test")],\n      early_stopping_rounds=training_config["early_stopping_rounds"],\n      evals_result=eval_results,\n      verbose_eval=False,\n  )\n\n  # Log training history to the run\n  for epoch, (train_metrics, test_metrics) in enumerate(\n      zip(eval_results["train"]["mlogloss"], eval_results["test"]["mlogloss"])\n  ):\n      mlflow.log_metrics(\n          {"train_logloss": train_metrics, "test_logloss": test_metrics}, step=epoch\n      )\n\n  # Final evaluation\n  y_pred_proba = model.predict(dtest)\n  y_pred = np.argmax(y_pred_proba, axis=1)\n  final_metrics = {\n      "accuracy": accuracy_score(y_test, y_pred),\n      "roc_auc": roc_auc_score(y_test, y_pred_proba, multi_class="ovr"),\n  }\n  mlflow.log_metrics(final_metrics, step=model.best_iteration)\n\n  # Log the model at the best iteration, linked with all params and metrics\n  model_info = mlflow.xgboost.log_model(\n      xgb_model=model,\n      name="xgboost_model",\n      signature=infer_signature(X_train, y_pred_proba),\n      input_example=X_train[:5],\n      step=model.best_iteration,\n  )'}),"\n",(0,s.jsx)(e.h2,{id:"view-results",children:"View results"}),"\n",(0,s.jsxs)(e.p,{children:["Let's look at our training and testing results. Log in to your Databricks Workspace, and click on the ",(0,s.jsx)(e.code,{children:"Experiments"})," tab from the left menu. The initial page displays a list of runs, where we can see our run."]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.img,{src:"https://imgur.com/2D2X5kK.png",alt:"runs page"})}),"\n",(0,s.jsx)(e.p,{children:"Now let's head to the models tab, where we can see the model that we logged"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.img,{src:"https://imgur.com/7si9VP8.png",alt:"models page"})}),"\n",(0,s.jsx)(e.p,{children:"Clicking on the model name will take you to the model details page, with information on its parameters, metrics, and other metadata."}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.img,{src:"https://imgur.com/mJhwhSr.png",alt:"model details page"})}),"\n",(0,s.jsx)(e.p,{children:"We can also inspect our model using the API"}),"\n",(0,s.jsx)(a.d,{executionCount:0,children:"logged_model = mlflow.get_logged_model(model_info.model_id)\n\nlogged_model, logged_model.metrics, logged_model.params"})]})}function p(t={}){const{wrapper:e}={...(0,o.R)(),...t.components};return e?(0,s.jsx)(e,{...t,children:(0,s.jsx)(u,{...t})}):u(t)}},27594:(t,e,n)=>{n.d(e,{O:()=>o});var r=n(96540),s=n(74848);function o({children:t,href:e}){const n=(0,r.useCallback)((async t=>{if(t.preventDefault(),window.gtag)try{window.gtag("event","notebook-download",{href:e})}catch{}const n=await fetch(e),r=await n.blob(),s=window.URL.createObjectURL(r),o=document.createElement("a");o.style.display="none",o.href=s;const a=e.split("/").pop();o.download=a,document.body.appendChild(o),o.click(),window.URL.revokeObjectURL(s),document.body.removeChild(o)}),[e]);return(0,s.jsx)("a",{className:"button button--primary",style:{marginBottom:"1rem",display:"block",width:"min-content"},href:e,download:!0,onClick:n,children:t})}},75983:(t,e,n)=>{n.d(e,{d:()=>a});var r=n(21028);const s="codeBlock_oJcR";var o=n(74848);const a=({children:t,executionCount:e})=>(0,o.jsx)("div",{style:{flexGrow:1,minWidth:0,marginTop:"var(--padding-md)",width:"100%"},children:(0,o.jsx)(r.A,{className:s,language:"python",children:t})})},81226:(t,e,n)=>{n.d(e,{Q:()=>s});var r=n(74848);const s=({children:t})=>(0,r.jsx)("div",{style:{flexGrow:1,minWidth:0,fontSize:"0.8rem",width:"100%"},children:t})}}]);