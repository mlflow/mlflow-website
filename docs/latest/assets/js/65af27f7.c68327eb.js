"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5529],{3227:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/training-annotation-f77b70a4465ce45e8827db3e1d6d7153.png"},11195:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/cleanup-experiments-9584c36dc7dfadb05a1610962dd63fb9.gif"},28453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>o});var i=n(96540);const r={},s=i.createContext(r);function a(e){const t=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),i.createElement(s.Provider,{value:t},e.children)}},30086:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/dogfood-9b65feb01f70c0ef6482252664f1d102.gif"},42292:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"getting-started/logging-first-model/step6-logging-a-run/index","title":"Logging our first runs with MLflow","description":"In our previous segments, we worked through setting up our first MLflow Experiment and equipped it","source":"@site/docs/getting-started/logging-first-model/step6-logging-a-run/index.mdx","sourceDirName":"getting-started/logging-first-model/step6-logging-a-run","slug":"/getting-started/logging-first-model/step6-logging-a-run/","permalink":"/docs/latest/getting-started/logging-first-model/step6-logging-a-run/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6}}');var r=n(74848),s=n(28453);const a={sidebar_position:6},o="Logging our first runs with MLflow",l={},d=[{value:"Crafting the Apple Sales Dataset",id:"crafting-the-apple-sales-dataset",level:2},{value:"Using Experiments in early-stage project development",id:"using-experiments-in-early-stage-project-development",level:3},{value:"Using MLflow Tracking to keep track of training",id:"using-mlflow-tracking-to-keep-track-of-training",level:2},{value:"Putting it all together",id:"putting-it-all-together",level:2}];function c(e){const t={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"logging-our-first-runs-with-mlflow",children:"Logging our first runs with MLflow"})}),"\n",(0,r.jsx)(t.p,{children:"In our previous segments, we worked through setting up our first MLflow Experiment and equipped it\nwith custom tags. These tags, as we'll soon discover, are instrumental in seamlessly retrieving\nrelated experiments that belong to a broader project."}),"\n",(0,r.jsx)(t.p,{children:"In the last section, we created a dataset that we'll be using to train a series of models."}),"\n",(0,r.jsx)(t.p,{children:"As we advance in this section, we'll delve deeper into the core features of MLflow Tracking:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:["Making use of the ",(0,r.jsx)(t.code,{children:"start_run"})," context for creating and efficiently managing runs."]}),"\n",(0,r.jsx)(t.li,{children:"An introduction to logging, covering tags, parameters, and metrics."}),"\n",(0,r.jsx)(t.li,{children:"Understanding the role and formation of a model signature."}),"\n",(0,r.jsx)(t.li,{children:"Logging a trained model, solidifying its presence in our MLflow run."}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:"But first, a foundational step awaits us. For our upcoming tasks, we need a dataset, specifically\nfocused on apple sales. While it's tempting to scour the internet for one, crafting our own dataset\nwill ensure it aligns perfectly with our objectives."}),"\n",(0,r.jsx)(t.h2,{id:"crafting-the-apple-sales-dataset",children:"Crafting the Apple Sales Dataset"}),"\n",(0,r.jsx)(t.p,{children:"Let's roll up our sleeves and construct this dataset."}),"\n",(0,r.jsx)(t.p,{children:"We need a data set that defines the dynamics of apple sales influenced by various factors like\nweekends, promotions, and fluctuating prices. This dataset will serve as the bedrock upon which\nour predictive models will be built and tested."}),"\n",(0,r.jsx)(t.p,{children:"Before we get to that, though, let's take a look at what we've learned so far and how these principles\nwere used when crafting this data set for the purposes of this tutorial."}),"\n",(0,r.jsx)(t.h3,{id:"using-experiments-in-early-stage-project-development",children:"Using Experiments in early-stage project development"}),"\n",(0,r.jsx)(t.p,{children:"As the diagram below shows, I tried taking a series of shortcuts. In order to record what I was trying,\nI created a new MLflow Experiment to record the state of what I tried. Since I was using different data\nsets and models, each subsequent modification that I was trying necessitated a new Experiment."}),"\n",(0,r.jsx)("figure",{className:"center-div",style:{width:1024,maxWidth:"100%",textAlign:"center"},children:(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.img,{alt:"Using MLflow Tracking for building this demo",src:n(83322).A+"",width:"1154",height:"779"}),"\n",(0,r.jsx)("figcaption",{children:"Using Experiments in MLflow Tracking to keep track of building this tutorial"})]})}),"\n",(0,r.jsx)(t.p,{children:"After finding a workable approach for the dataset generator, the results can be seen in the MLflow\nUI."}),"\n",(0,r.jsx)("figure",{className:"center-div",style:{width:1024,maxWidth:"100%",textAlign:"center"},children:(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.img,{alt:"Checking the results of the test",src:n(30086).A+"",width:"2048",height:"1855"}),"\n",(0,r.jsx)("figcaption",{children:"Validating the results of a training run in the MLflow UI"})]})}),"\n",(0,r.jsx)(t.p,{children:"Once I found something that actually worked, I cleaned everything up (deleted them)."}),"\n",(0,r.jsx)("figure",{className:"center-div",style:{width:1024,maxWidth:"100%",textAlign:"center"},children:(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.img,{alt:"Tidying up",src:n(11195).A+"",width:"2048",height:"1855"}),"\n",(0,r.jsx)("figcaption",{children:"Removing experiments that were filled with failed attempts"})]})}),"\n",(0,r.jsx)(t.admonition,{type:"note",children:(0,r.jsxs)(t.p,{children:["If you're precisely following along to this tutorial and you delete your ",(0,r.jsx)(t.code,{children:"Apple_Models"}),"\nExperiment, recreate it before proceeding to the next step in the tutorial."]})}),"\n",(0,r.jsx)(t.h2,{id:"using-mlflow-tracking-to-keep-track-of-training",children:"Using MLflow Tracking to keep track of training"}),"\n",(0,r.jsx)(t.p,{children:"Now that we have our data set and have seen a little bit of how runs are recorded, let's dive in to\nusing MLflow to tracking a training iteration."}),"\n",(0,r.jsx)(t.p,{children:"To start with, we will need to import our required modules."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:"import mlflow\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"})}),"\n",(0,r.jsxs)(t.p,{children:["Notice that here we aren't importing the ",(0,r.jsx)(t.code,{children:"MlflowClient"})," directly. For this portion, we're going to\nbe using the ",(0,r.jsx)(t.code,{children:"fluent"})," API. The fluent APIs use a globally referenced state of the MLflow tracking\nserver's uri. This global instance allows for us to use these 'higher-level' (simpler) APIs to perform\nevery action that we can otherwise do with the ",(0,r.jsx)(t.code,{children:"MlflowClient"}),", with the addition of some other useful\nsyntax (such as context handlers that we'll be using very shortly) to make integrating MLflow to\nML workloads as simple as possible."]}),"\n",(0,r.jsxs)(t.p,{children:["In order to use the ",(0,r.jsx)(t.code,{children:"fluent"})," API, we'll need to set the global reference to the Tracking server's\naddress. We do this via the following command:"]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'mlflow.set_tracking_uri("http://127.0.0.1:8080")\n'})}),"\n",(0,r.jsx)(t.p,{children:"Once this is set, we can define a few more constants that we're going to be using when logging our\ntraining events to MLflow in the form of runs. We'll start by defining an Experiment that will be used\nto log runs to. The parent-child relationship of Experiments to Runs and its utility will become very\nclear once we start iterating over some ideas and need to compare the results of our tests."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'# Sets the current active experiment to the "Apple_Models" experiment and\n# returns the Experiment metadata\napple_experiment = mlflow.set_experiment("Apple_Models")\n\n# Define a run name for this iteration of training.\n# If this is not set, a unique name will be auto-generated for your run.\nrun_name = "apples_rf_test"\n\n# Define an artifact path that the model will be saved to.\nartifact_path = "rf_apples"\n'})}),"\n",(0,r.jsx)(t.p,{children:"With these variables defined, we can commence with actually training a model."}),"\n",(0,r.jsx)(t.p,{children:"Firstly, let's look at what we're going to be running. Following the code display, we'll look at\nan annotated version of the code."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'# Split the data into features and target and drop irrelevant date field and target field\nX = data.drop(columns=["date", "demand"])\ny = data["demand"]\n\n# Split the data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\nparams = {\n    "n_estimators": 100,\n    "max_depth": 6,\n    "min_samples_split": 10,\n    "min_samples_leaf": 4,\n    "bootstrap": True,\n    "oob_score": False,\n    "random_state": 888,\n}\n\n# Train the RandomForestRegressor\nrf = RandomForestRegressor(**params)\n\n# Fit the model on the training data\nrf.fit(X_train, y_train)\n\n# Predict on the validation set\ny_pred = rf.predict(X_val)\n\n# Calculate error metrics\nmae = mean_absolute_error(y_val, y_pred)\nmse = mean_squared_error(y_val, y_pred)\nrmse = np.sqrt(mse)\nr2 = r2_score(y_val, y_pred)\n\n# Assemble the metrics we\'re going to write into a collection\nmetrics = {"mae": mae, "mse": mse, "rmse": rmse, "r2": r2}\n\n# Initiate the MLflow run context\nwith mlflow.start_run(run_name=run_name) as run:\n    # Log the parameters used for the model fit\n    mlflow.log_params(params)\n\n    # Log the error metrics that were calculated during validation\n    mlflow.log_metrics(metrics)\n\n    # Log an instance of the trained model for later use\n    mlflow.sklearn.log_model(sk_model=rf, input_example=X_val, name=artifact_path)\n'})}),"\n",(0,r.jsx)(t.p,{children:"To aid in visualizing how MLflow tracking API calls add in to an ML training code base, see the figure below."}),"\n",(0,r.jsx)("div",{className:"center-div",style:{width:1024,maxWidth:"100%"},children:(0,r.jsx)(t.p,{children:(0,r.jsx)(t.img,{alt:"Explanation of MLflow integration into ML training code",src:n(3227).A+"",width:"1309",height:"1123"})})}),"\n",(0,r.jsx)(t.h2,{id:"putting-it-all-together",children:"Putting it all together"}),"\n",(0,r.jsx)(t.p,{children:"Let's see what this looks like when we run our model training code and navigate to the MLflow UI."}),"\n",(0,r.jsx)("div",{className:"center-div",style:{width:1024,maxWidth:"100%"},children:(0,r.jsx)(t.p,{children:(0,r.jsx)(t.img,{alt:"Log the model to MLflow",src:n(77118).A+"",width:"2048",height:"1855"})})})]})}function h(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},77118:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/logging-first-model-8ce987f9bc12f37fa817db47808211c1.gif"},83322:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/dogfood-diagram-35db042c5169d0eb70ca33ff2a30ce67.svg"}}]);