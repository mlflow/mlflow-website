"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5924],{25508:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/quickstart_tracking_overview-2fc1efa4bce294fc4114ce35fa34fe04.png"},28453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>a});var i=t(96540);const r={},l=i.createContext(r);function s(e){const n=i.useContext(l);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),i.createElement(l.Provider,{value:n},e.children)}},73484:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>p,frontMatter:()=>s,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"getting-started/hyperparameter-tuning/index","title":"Hyperparameter Tuning & Deployment Quickstart","description":"Master the complete MLOps workflow with MLflow\'s hyperparameter optimization capabilities. In this hands-on quickstart, you\'ll learn how to systematically find the best model parameters, track experiments, and deploy production-ready models.","source":"@site/docs/classic-ml/getting-started/hyperparameter-tuning/index.mdx","sourceDirName":"getting-started/hyperparameter-tuning","slug":"/getting-started/hyperparameter-tuning/","permalink":"/docs/latest/ml/getting-started/hyperparameter-tuning/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"classicMLSidebar","previous":{"title":"Logging First Model","permalink":"/docs/latest/ml/getting-started/logging-first-model/notebooks/logging-first-model"},"next":{"title":"Deep Learning Quickstart","permalink":"/docs/latest/ml/getting-started/deep-learning"}}');var r=t(74848),l=t(28453);const s={},a="Hyperparameter Tuning & Deployment Quickstart",o={},d=[{value:"What You&#39;ll Learn",id:"what-youll-learn",level:2},{value:"Prerequisites &amp; Setup",id:"prerequisites--setup",level:2},{value:"Quick Setup",id:"quick-setup",level:3},{value:"Install Dependencies",id:"install-dependencies",level:3},{value:"Set Environment Variable",id:"set-environment-variable",level:3},{value:"The Challenge: Wine Quality Prediction",id:"the-challenge-wine-quality-prediction",level:2},{value:"Step 1: Prepare Your Data",id:"step-1-prepare-your-data",level:2},{value:"Step 2: Define Your Model Architecture",id:"step-2-define-your-model-architecture",level:2},{value:"Step 3: Set Up Hyperparameter Optimization",id:"step-3-set-up-hyperparameter-optimization",level:2},{value:"Step 4: Run the Hyperparameter Optimization",id:"step-4-run-the-hyperparameter-optimization",level:2},{value:"Step 5: Analyze Results in MLflow UI",id:"step-5-analyze-results-in-mlflow-ui",level:2},{value:"Table View Analysis",id:"table-view-analysis",level:3},{value:"Visual Analysis",id:"visual-analysis",level:3},{value:"Key Insights to Look For",id:"key-insights-to-look-for",level:3},{value:"Step 6: Register Your Best Model",id:"step-6-register-your-best-model",level:2},{value:"Step 7: Deploy Your Model Locally",id:"step-7-deploy-your-model-locally",level:2},{value:"Test Your Deployment",id:"test-your-deployment",level:3},{value:"Test with Python",id:"test-with-python",level:3},{value:"Step 8: Build Production Container",id:"step-8-build-production-container",level:2},{value:"Test Your Container",id:"test-your-container",level:3},{value:"Step 9: Deploy to Cloud (Optional)",id:"step-9-deploy-to-cloud-optional",level:2},{value:"Popular Cloud Options",id:"popular-cloud-options",level:3},{value:"What You&#39;ve Accomplished",id:"what-youve-accomplished",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"Enhance Your MLOps Skills",id:"enhance-your-mlops-skills",level:3},{value:"Scale Your Infrastructure with a Tracking Server",id:"scale-your-infrastructure-with-a-tracking-server",level:3}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"hyperparameter-tuning--deployment-quickstart",children:"Hyperparameter Tuning & Deployment Quickstart"})}),"\n",(0,r.jsx)(n.p,{children:"Master the complete MLOps workflow with MLflow's hyperparameter optimization capabilities. In this hands-on quickstart, you'll learn how to systematically find the best model parameters, track experiments, and deploy production-ready models."}),"\n",(0,r.jsx)(n.h2,{id:"what-youll-learn",children:"What You'll Learn"}),"\n",(0,r.jsx)(n.p,{children:"By the end of this tutorial, you'll know how to:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\ud83d\udd0d ",(0,r.jsx)(n.strong,{children:"Run intelligent hyperparameter optimization"})," with Hyperopt and MLflow tracking"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udcca ",(0,r.jsx)(n.strong,{children:"Compare experiment results"})," using MLflow's powerful visualization tools"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83c\udfc6 ",(0,r.jsx)(n.strong,{children:"Identify and register your best model"})," for production use"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\ude80 ",(0,r.jsx)(n.strong,{children:"Deploy models to REST APIs"})," for real-time inference"]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udce6 ",(0,r.jsx)(n.strong,{children:"Build production containers"})," ready for cloud deployment"]}),"\n"]}),"\n",(0,r.jsx)("div",{className:"center-div",style:{width:800,maxWidth:"100%"},children:(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Diagram showing Data Science and MLOps workflow with MLflow",src:t(25508).A+"",width:"2342",height:"660"})})}),"\n",(0,r.jsx)(n.h2,{id:"prerequisites--setup",children:"Prerequisites & Setup"}),"\n",(0,r.jsx)(n.h3,{id:"quick-setup",children:"Quick Setup"}),"\n",(0,r.jsx)(n.p,{children:"For this quickstart, we'll use a local MLflow tracking server. Start it with:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"mlflow ui --port 5000\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Keep this running in a separate terminal. Your MLflow UI will be available at ",(0,r.jsx)(n.a,{href:"http://localhost:5000",children:"http://localhost:5000"}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"install-dependencies",children:"Install Dependencies"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"pip install mlflow[extras] hyperopt tensorflow scikit-learn pandas numpy\n"})}),"\n",(0,r.jsx)(n.h3,{id:"set-environment-variable",children:"Set Environment Variable"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"export MLFLOW_TRACKING_URI=http://localhost:5000\n"})}),"\n",(0,r.jsx)(n.admonition,{title:"Team Collaboration and Managed Setup",type:"tip",children:(0,r.jsxs)(n.p,{children:["For production environments or team collaboration, consider using ",(0,r.jsx)(n.a,{href:"/ml/getting-started/running-notebooks/",children:"MLflow Tracking Server configurations"}),". For a fully-managed solution, get started with Databricks Free Trial by visiting the ",(0,r.jsx)(n.a,{href:"https://signup.databricks.com/?destination_url=/ml/experiments-signup?source=OSS_DOCS&dbx_source=TRY_MLFLOW&signup_experience_step=EXPRESS&provider=MLFLOW",children:"Databricks Trial Signup Page"})," and follow the instructions outlined there. It takes about 5 minutes to set up, after which you'll have access to a nearly fully-functional Databricks Workspace for logging your tutorial experiments, traces, models, and artifacts."]})}),"\n",(0,r.jsx)(n.h2,{id:"the-challenge-wine-quality-prediction",children:"The Challenge: Wine Quality Prediction"}),"\n",(0,r.jsxs)(n.p,{children:["We'll optimize a neural network that predicts wine quality from chemical properties. Our goal is to minimize ",(0,r.jsx)(n.strong,{children:"Root Mean Square Error (RMSE)"})," by finding the optimal combination of:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Learning Rate"}),": How aggressively the model learns"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Momentum"}),": How much the optimizer considers previous updates"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"step-1-prepare-your-data",children:"Step 1: Prepare Your Data"}),"\n",(0,r.jsx)(n.p,{children:"First, let's load and explore our dataset:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport tensorflow as tf\nfrom tensorflow import keras\nimport mlflow\nfrom mlflow.models import infer_signature\nfrom hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n\n# Load the wine quality dataset\ndata = pd.read_csv(\n    "https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv",\n    sep=";",\n)\n\n# Create train/validation/test splits\ntrain, test = train_test_split(data, test_size=0.25, random_state=42)\ntrain_x = train.drop(["quality"], axis=1).values\ntrain_y = train[["quality"]].values.ravel()\ntest_x = test.drop(["quality"], axis=1).values\ntest_y = test[["quality"]].values.ravel()\n\n# Further split training data for validation\ntrain_x, valid_x, train_y, valid_y = train_test_split(\n    train_x, train_y, test_size=0.2, random_state=42\n)\n\n# Create model signature for deployment\nsignature = infer_signature(train_x, train_y)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"step-2-define-your-model-architecture",children:"Step 2: Define Your Model Architecture"}),"\n",(0,r.jsx)(n.p,{children:"Create a reusable function to build and train models:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def create_and_train_model(learning_rate, momentum, epochs=10):\n    """\n    Create and train a neural network with specified hyperparameters.\n\n    Returns:\n        dict: Training results including model and metrics\n    """\n    # Normalize input features for better training stability\n    mean = np.mean(train_x, axis=0)\n    var = np.var(train_x, axis=0)\n\n    # Define model architecture\n    model = keras.Sequential(\n        [\n            keras.Input([train_x.shape[1]]),\n            keras.layers.Normalization(mean=mean, variance=var),\n            keras.layers.Dense(64, activation="relu"),\n            keras.layers.Dropout(0.2),  # Add regularization\n            keras.layers.Dense(32, activation="relu"),\n            keras.layers.Dense(1),\n        ]\n    )\n\n    # Compile with specified hyperparameters\n    model.compile(\n        optimizer=keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum),\n        loss="mean_squared_error",\n        metrics=[keras.metrics.RootMeanSquaredError()],\n    )\n\n    # Train with early stopping for efficiency\n    early_stopping = keras.callbacks.EarlyStopping(\n        patience=3, restore_best_weights=True\n    )\n\n    # Train the model\n    history = model.fit(\n        train_x,\n        train_y,\n        validation_data=(valid_x, valid_y),\n        epochs=epochs,\n        batch_size=64,\n        callbacks=[early_stopping],\n        verbose=0,  # Reduce output for cleaner logs\n    )\n\n    # Evaluate on validation set\n    val_loss, val_rmse = model.evaluate(valid_x, valid_y, verbose=0)\n\n    return {\n        "model": model,\n        "val_rmse": val_rmse,\n        "val_loss": val_loss,\n        "history": history,\n        "epochs_trained": len(history.history["loss"]),\n    }\n'})}),"\n",(0,r.jsx)(n.h2,{id:"step-3-set-up-hyperparameter-optimization",children:"Step 3: Set Up Hyperparameter Optimization"}),"\n",(0,r.jsx)(n.p,{children:"Now let's create the optimization framework:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def objective(params):\n    """\n    Objective function for hyperparameter optimization.\n    This function will be called by Hyperopt for each trial.\n    """\n    with mlflow.start_run(nested=True):\n        # Log hyperparameters being tested\n        mlflow.log_params(\n            {\n                "learning_rate": params["learning_rate"],\n                "momentum": params["momentum"],\n                "optimizer": "SGD",\n                "architecture": "64-32-1",\n            }\n        )\n\n        # Train model with current hyperparameters\n        result = create_and_train_model(\n            learning_rate=params["learning_rate"],\n            momentum=params["momentum"],\n            epochs=15,\n        )\n\n        # Log training results\n        mlflow.log_metrics(\n            {\n                "val_rmse": result["val_rmse"],\n                "val_loss": result["val_loss"],\n                "epochs_trained": result["epochs_trained"],\n            }\n        )\n\n        # Log the trained model\n        mlflow.tensorflow.log_model(result["model"], name="model", signature=signature)\n\n        # Log training curves as artifacts\n        import matplotlib.pyplot as plt\n\n        plt.figure(figsize=(12, 4))\n\n        plt.subplot(1, 2, 1)\n        plt.plot(result["history"].history["loss"], label="Training Loss")\n        plt.plot(result["history"].history["val_loss"], label="Validation Loss")\n        plt.title("Model Loss")\n        plt.xlabel("Epoch")\n        plt.ylabel("Loss")\n        plt.legend()\n\n        plt.subplot(1, 2, 2)\n        plt.plot(\n            result["history"].history["root_mean_squared_error"], label="Training RMSE"\n        )\n        plt.plot(\n            result["history"].history["val_root_mean_squared_error"],\n            label="Validation RMSE",\n        )\n        plt.title("Model RMSE")\n        plt.xlabel("Epoch")\n        plt.ylabel("RMSE")\n        plt.legend()\n\n        plt.tight_layout()\n        plt.savefig("training_curves.png")\n        mlflow.log_artifact("training_curves.png")\n        plt.close()\n\n        # Return loss for Hyperopt (it minimizes)\n        return {"loss": result["val_rmse"], "status": STATUS_OK}\n\n\n# Define search space for hyperparameters\nsearch_space = {\n    "learning_rate": hp.loguniform("learning_rate", np.log(1e-5), np.log(1e-1)),\n    "momentum": hp.uniform("momentum", 0.0, 0.9),\n}\n\nprint("Search space defined:")\nprint("- Learning rate: 1e-5 to 1e-1 (log-uniform)")\nprint("- Momentum: 0.0 to 0.9 (uniform)")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"step-4-run-the-hyperparameter-optimization",children:"Step 4: Run the Hyperparameter Optimization"}),"\n",(0,r.jsx)(n.p,{children:"Execute the optimization experiment:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Create or set experiment\nexperiment_name = "wine-quality-optimization"\nmlflow.set_experiment(experiment_name)\n\nprint(f"Starting hyperparameter optimization experiment: {experiment_name}")\nprint("This will run 15 trials to find optimal hyperparameters...")\n\nwith mlflow.start_run(run_name="hyperparameter-sweep"):\n    # Log experiment metadata\n    mlflow.log_params(\n        {\n            "optimization_method": "Tree-structured Parzen Estimator (TPE)",\n            "max_evaluations": 15,\n            "objective_metric": "validation_rmse",\n            "dataset": "wine-quality",\n            "model_type": "neural_network",\n        }\n    )\n\n    # Run optimization\n    trials = Trials()\n    best_params = fmin(\n        fn=objective,\n        space=search_space,\n        algo=tpe.suggest,\n        max_evals=15,\n        trials=trials,\n        verbose=True,\n    )\n\n    # Find and log best results\n    best_trial = min(trials.results, key=lambda x: x["loss"])\n    best_rmse = best_trial["loss"]\n\n    # Log optimization results\n    mlflow.log_params(\n        {\n            "best_learning_rate": best_params["learning_rate"],\n            "best_momentum": best_params["momentum"],\n        }\n    )\n    mlflow.log_metrics(\n        {\n            "best_val_rmse": best_rmse,\n            "total_trials": len(trials.trials),\n            "optimization_completed": 1,\n        }\n    )\n'})}),"\n",(0,r.jsx)(n.h2,{id:"step-5-analyze-results-in-mlflow-ui",children:"Step 5: Analyze Results in MLflow UI"}),"\n",(0,r.jsxs)(n.p,{children:["Open ",(0,r.jsx)(n.a,{href:"http://localhost:5000",children:"http://localhost:5000"})," in your browser to explore your results:"]}),"\n",(0,r.jsx)(n.h3,{id:"table-view-analysis",children:"Table View Analysis"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Navigate to your experiment"}),': Click on "wine-quality-optimization"']}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Add key columns"}),': Click "Columns" and add:',"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"Metrics | val_rmse"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"Parameters | learning_rate"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.code,{children:"Parameters | momentum"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sort by performance"}),": Click the ",(0,r.jsx)(n.code,{children:"val_rmse"})," column header to sort by best performance"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"visual-analysis",children:"Visual Analysis"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Switch to Chart view"}),': Click the "Chart" tab']}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Create parallel coordinates plot"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:'Select "Parallel coordinates"'}),"\n",(0,r.jsxs)(n.li,{children:["Add ",(0,r.jsx)(n.code,{children:"learning_rate"})," and ",(0,r.jsx)(n.code,{children:"momentum"})," as coordinates"]}),"\n",(0,r.jsxs)(n.li,{children:["Set ",(0,r.jsx)(n.code,{children:"val_rmse"})," as the metric"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Interpret the visualization"}),":","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Blue lines = better performing runs"}),"\n",(0,r.jsx)(n.li,{children:"Red lines = worse performing runs"}),"\n",(0,r.jsx)(n.li,{children:"Look for patterns in successful parameter combinations"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"key-insights-to-look-for",children:"Key Insights to Look For"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Learning rate patterns"}),": Too high causes instability, too low causes slow convergence"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Momentum effects"}),": Moderate momentum (0.3-0.7) often works best"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Training curves"}),": Check artifacts to see if models converged properly"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"step-6-register-your-best-model",children:"Step 6: Register Your Best Model"}),"\n",(0,r.jsx)(n.p,{children:"Time to promote your best model to production:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Find the best run"}),": In the Table view, click on the run with the lowest ",(0,r.jsx)(n.code,{children:"val_rmse"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Navigate to model artifacts"}),': Scroll to the "Artifacts" section']}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Register the model"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:'Click "Register Model" next to the model folder'}),"\n",(0,r.jsxs)(n.li,{children:["Enter model name: ",(0,r.jsx)(n.code,{children:"wine-quality-predictor"})]}),"\n",(0,r.jsx)(n.li,{children:'Add description: "Optimized neural network for wine quality prediction"'}),"\n",(0,r.jsx)(n.li,{children:'Click "Register"'}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Manage model lifecycle"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:'Go to "Models" tab in MLflow UI'}),"\n",(0,r.jsx)(n.li,{children:"Click on your registered model"}),"\n",(0,r.jsx)(n.li,{children:'Transition to "Staging" stage for testing'}),"\n",(0,r.jsx)(n.li,{children:"Add tags and descriptions as needed"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"step-7-deploy-your-model-locally",children:"Step 7: Deploy Your Model Locally"}),"\n",(0,r.jsx)(n.p,{children:"Test your model with a REST API deployment:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Serve the model (choose the version number you registered)\nmlflow models serve -m "models:/wine-quality-predictor/1" --port 5002\n'})}),"\n",(0,r.jsx)(n.admonition,{title:"Port Configuration",type:"note",children:(0,r.jsx)(n.p,{children:"We use port 5002 to avoid conflicts with the MLflow UI running on port 5000. In production, you'd typically use port 80 or 443."})}),"\n",(0,r.jsx)(n.h3,{id:"test-your-deployment",children:"Test Your Deployment"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Test with a sample wine\ncurl -X POST http://localhost:5002/invocations \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "dataframe_split": {\n      "columns": [\n        "fixed acidity", "volatile acidity", "citric acid", "residual sugar",\n        "chlorides", "free sulfur dioxide", "total sulfur dioxide", "density",\n        "pH", "sulphates", "alcohol"\n      ],\n      "data": [[7.0, 0.27, 0.36, 20.7, 0.045, 45, 170, 1.001, 3.0, 0.45, 8.8]]\n    }\n  }\'\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Expected Response:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "predictions": [5.31]\n}\n'})}),"\n",(0,r.jsx)(n.p,{children:"This predicts a wine quality score of approximately 5.31 on the 3-8 scale."}),"\n",(0,r.jsx)(n.h3,{id:"test-with-python",children:"Test with Python"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import requests\nimport json\n\n# Prepare test data\ntest_wine = {\n    "dataframe_split": {\n        "columns": [\n            "fixed acidity",\n            "volatile acidity",\n            "citric acid",\n            "residual sugar",\n            "chlorides",\n            "free sulfur dioxide",\n            "total sulfur dioxide",\n            "density",\n            "pH",\n            "sulphates",\n            "alcohol",\n        ],\n        "data": [[7.0, 0.27, 0.36, 20.7, 0.045, 45, 170, 1.001, 3.0, 0.45, 8.8]],\n    }\n}\n\n# Make prediction request\nresponse = requests.post(\n    "http://localhost:5002/invocations",\n    headers={"Content-Type": "application/json"},\n    data=json.dumps(test_wine),\n)\n\nprediction = response.json()\nprint(f"Predicted wine quality: {prediction[\'predictions\'][0]:.2f}")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"step-8-build-production-container",children:"Step 8: Build Production Container"}),"\n",(0,r.jsx)(n.p,{children:"Create a Docker container for cloud deployment:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Build Docker image\nmlflow models build-docker \\\n  --model-uri "models:/wine-quality-predictor/1" \\\n  --name "wine-quality-api"\n'})}),"\n",(0,r.jsx)(n.admonition,{title:"Build Time",type:"info",children:(0,r.jsx)(n.p,{children:"The Docker build process typically takes 3-5 minutes as it installs all dependencies and configures the runtime environment."})}),"\n",(0,r.jsx)(n.h3,{id:"test-your-container",children:"Test Your Container"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Run the container\ndocker run -p 5003:8080 wine-quality-api\n\n# Test in another terminal\ncurl -X POST http://localhost:5003/invocations \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "dataframe_split": {\n      "columns": ["fixed acidity","volatile acidity","citric acid","residual sugar","chlorides","free sulfur dioxide","total sulfur dioxide","density","pH","sulphates","alcohol"],\n      "data": [[7.0, 0.27, 0.36, 20.7, 0.045, 45, 170, 1.001, 3.0, 0.45, 8.8]]\n    }\n  }\'\n'})}),"\n",(0,r.jsx)(n.h2,{id:"step-9-deploy-to-cloud-optional",children:"Step 9: Deploy to Cloud (Optional)"}),"\n",(0,r.jsx)(n.p,{children:"Your Docker container is now ready for cloud deployment:"}),"\n",(0,r.jsx)(n.h3,{id:"popular-cloud-options",children:"Popular Cloud Options"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"AWS"}),": Deploy to ECS, EKS, or SageMaker"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Example: Push to ECR and deploy to ECS\naws ecr create-repository --repository-name wine-quality-api\ndocker tag wine-quality-api:latest <your-account>.dkr.ecr.us-east-1.amazonaws.com/wine-quality-api:latest\ndocker push <your-account>.dkr.ecr.us-east-1.amazonaws.com/wine-quality-api:latest\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Azure"}),": Deploy to Container Instances or AKS"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Example: Deploy to Azure Container Instances\naz container create \\\n  --resource-group myResourceGroup \\\n  --name wine-quality-api \\\n  --image wine-quality-api:latest \\\n  --ports 8080\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Google Cloud"}),": Deploy to Cloud Run or GKE"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Example: Deploy to Cloud Run\ngcloud run deploy wine-quality-api \\\n  --image gcr.io/your-project/wine-quality-api \\\n  --platform managed \\\n  --port 8080\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Databricks"}),": Deploy with Mosaic AI Model Serving"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# First, register your model in Unity Catalog\nimport mlflow\n\nmlflow.set_registry_uri("databricks-uc")\n\nwith mlflow.start_run():\n    # Log your model to Unity Catalog\n    mlflow.tensorflow.log_model(\n        model,\n        name="wine-quality-model",\n        registered_model_name="main.default.wine_quality_predictor",\n    )\n\n# Then create a serving endpoint using the Databricks UI:\n# 1. Navigate to "Serving" in the Databricks workspace\n# 2. Click "Create serving endpoint"\n# 3. Select your registered model from Unity Catalog\n# 4. Configure compute and traffic settings\n# 5. Deploy and test your endpoint\n'})}),"\n",(0,r.jsx)(n.p,{children:"Or use the Databricks deployment client programmatically:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from mlflow.deployments import get_deploy_client\n\n# Create deployment client\nclient = get_deploy_client("databricks")\n\n# Create serving endpoint\nendpoint = client.create_endpoint(\n    config={\n        "name": "wine-quality-endpoint",\n        "config": {\n            "served_entities": [\n                {\n                    "entity_name": "main.default.wine_quality_predictor",\n                    "entity_version": "1",\n                    "workload_size": "Small",\n                    "scale_to_zero_enabled": True,\n                }\n            ]\n        },\n    }\n)\n\n# Query the endpoint\nresponse = client.predict(\n    endpoint="wine-quality-endpoint",\n    inputs={\n        "dataframe_split": {\n            "columns": [\n                "fixed acidity",\n                "volatile acidity",\n                "citric acid",\n                "residual sugar",\n                "chlorides",\n                "free sulfur dioxide",\n                "total sulfur dioxide",\n                "density",\n                "pH",\n                "sulphates",\n                "alcohol",\n            ],\n            "data": [[7.0, 0.27, 0.36, 20.7, 0.045, 45, 170, 1.001, 3.0, 0.45, 8.8]],\n        }\n    },\n)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"what-youve-accomplished",children:"What You've Accomplished"}),"\n",(0,r.jsxs)(n.p,{children:["\ud83c\udf89 ",(0,r.jsx)(n.strong,{children:"Congratulations!"})," You've completed a full MLOps workflow:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Optimized hyperparameters"})," using systematic search instead of guesswork"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Tracked 15+ experiments"})," with complete reproducibility"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Visualized results"})," to understand parameter relationships"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Registered your best model"})," with proper versioning"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Deployed to REST API"})," for real-time predictions"]}),"\n",(0,r.jsxs)(n.li,{children:["\u2705 ",(0,r.jsx)(n.strong,{children:"Containerized for production"})," deployment"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsx)(n.h3,{id:"enhance-your-mlops-skills",children:"Enhance Your MLOps Skills"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Advanced Optimization"}),": Try ",(0,r.jsx)(n.a,{href:"https://optuna.org/",children:"Optuna"})," or ",(0,r.jsx)(n.a,{href:"https://docs.ray.io/en/latest/tune/index.html",children:"Ray Tune"})," for more sophisticated hyperparameter optimization. Both work seamlessly with MLflow."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Model Monitoring"}),": Implement drift detection and performance monitoring in production"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"A/B Testing"}),": Compare model versions in production using MLflow's model registry"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"CI/CD Integration"}),": Automate model training and deployment with GitHub Actions or similar"]}),"\n"]}),"\n",(0,r.jsxs)(n.h3,{id:"scale-your-infrastructure-with-a-tracking-server",children:["Scale Your Infrastructure with a ",(0,r.jsx)(n.a,{href:"/ml/getting-started/tracking-server-overview",children:"Tracking Server"})]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"MLflow on Kubernetes"}),": Deploy MLflow tracking server on K8s for team collaboration"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Database Backend"}),": Use PostgreSQL or MySQL instead of file-based storage"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Artifact Storage"}),": Configure S3, Azure Blob, or GCS for model artifacts"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Authentication"}),": Add user management and access controls with built-in ",(0,r.jsx)(n.a,{href:"/ml/auth",children:"Authentication"})]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"The foundation you've built here scales to any machine learning problem. The key principles\u2014systematic experimentation, comprehensive tracking, and automated deployment\u2014remain constant across domains and complexity levels."})]})}function p(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}}}]);