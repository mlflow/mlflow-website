"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[9729],{10493:(e,n,r)=>{r.d(n,{Zp:()=>l,AC:()=>s,WO:()=>d,_C:()=>c,$3:()=>p,jK:()=>m});var t=r(34164);const i={CardGroup:"CardGroup_P84T",NoGap:"NoGap_O9Dj",MaxThreeColumns:"MaxThreeColumns_FO1r",AutofillColumns:"AutofillColumns_fKhQ",Card:"Card_aSCR",CardBordered:"CardBordered_glGF",CardBody:"CardBody_BhRs",TextColor:"TextColor_a8Tp",BoxRoot:"BoxRoot_Etgr",FlexWrapNowrap:"FlexWrapNowrap_f60k",FlexJustifyContentFlexStart:"FlexJustifyContentFlexStart_ZYv5",FlexDirectionRow:"FlexDirectionRow_T2qL",FlexAlignItemsCenter:"FlexAlignItemsCenter_EHVM",FlexFlex:"FlexFlex__JTE",Link:"Link_fVkl",MarginLeft4:"MarginLeft4_YQSJ",MarginTop4:"MarginTop4_jXKN",PaddingBottom4:"PaddingBottom4_O9gt",LogoCardContent:"LogoCardContent_kCQm",LogoCardImage:"LogoCardImage_JdcX",SmallLogoCardContent:"SmallLogoCardContent_LxhV",SmallLogoCardRounded:"SmallLogoCardRounded_X50_",SmallLogoCardImage:"SmallLogoCardImage_tPZl",NewFeatureCardContent:"NewFeatureCardContent_Rq3d",NewFeatureCardHeading:"NewFeatureCardHeading_f6q3",NewFeatureCardHeadingSeparator:"NewFeatureCardHeadingSeparator_pSx8",NewFeatureCardTags:"NewFeatureCardTags_IFHO",NewFeatureCardWrapper:"NewFeatureCardWrapper_NQ0k",TitleCardContent:"TitleCardContent_l9MQ",TitleCardHeader:"TitleCardHeader_fUQy",TitleCardHeaderRight:"TitleCardHeaderRight_iBLX",TitleCardTitle:"TitleCardTitle__K8J",TitleCardSeparator:"TitleCardSeparator_IN2E",Cols1:"Cols1_Gr2U",Cols2:"Cols2_sRvc",Cols3:"Cols3_KjUS",Cols4:"Cols4_dKOj",Cols5:"Cols5_jDmj",Cols6:"Cols6_Q0OR"};var o=r(28774),a=r(74848);const s=({children:e,isSmall:n,cols:r,noGap:o})=>(0,a.jsx)("div",{className:(0,t.A)(i.CardGroup,n?i.AutofillColumns:r?i[`Cols${r}`]:i.MaxThreeColumns,o&&i.NoGap),children:e}),l=({children:e,link:n=""})=>n?(0,a.jsx)(o.A,{className:(0,t.A)(i.Link,i.Card,i.CardBordered),to:n,children:e}):(0,a.jsx)("div",{className:(0,t.A)(i.Card,i.CardBordered),children:e}),c=({headerText:e,link:n,text:r})=>(0,a.jsx)(l,{link:n,children:(0,a.jsxs)("span",{children:[(0,a.jsx)("div",{className:(0,t.A)(i.CardTitle,i.BoxRoot,i.PaddingBottom4),style:{pointerEvents:"none"},children:(0,a.jsx)("div",{className:(0,t.A)(i.BoxRoot,i.FlexFlex,i.FlexAlignItemsCenter,i.FlexDirectionRow,i.FlexJustifyContentFlexStart,i.FlexWrapNowrap),style:{marginLeft:"-4px",marginTop:"-4px"},children:(0,a.jsx)("div",{className:(0,t.A)(i.BoxRoot,i.BoxHideIfEmpty,i.MarginTop4,i.MarginLeft4),style:{pointerEvents:"auto"},children:(0,a.jsx)("span",{className:"",children:e})})})}),(0,a.jsx)("span",{className:(0,t.A)(i.TextColor,i.CardBody),children:(0,a.jsx)("p",{children:r})})]})}),d=({description:e,children:n,link:r})=>(0,a.jsx)(l,{link:r,children:(0,a.jsxs)("div",{className:i.LogoCardContent,children:[(0,a.jsx)("div",{className:i.LogoCardImage,children:n}),(0,a.jsx)("p",{className:i.TextColor,children:e})]})}),p=({children:e,link:n})=>(0,a.jsx)("div",{className:(0,t.A)(i.Card,i.CardBordered,i.SmallLogoCardRounded),children:n?(0,a.jsx)(o.A,{className:(0,t.A)(i.Link),to:n,children:(0,a.jsx)("div",{className:i.SmallLogoCardContent,children:(0,a.jsx)("div",{className:(0,t.A)("max-height-img-container",i.SmallLogoCardImage),children:e})})}):(0,a.jsx)("div",{className:i.SmallLogoCardContent,children:(0,a.jsx)("div",{className:(0,t.A)("max-height-img-container",i.SmallLogoCardImage),children:e})})}),m=({title:e,description:n,link:r="",headerRight:o,children:s})=>(0,a.jsx)(l,{link:r,children:(0,a.jsxs)("div",{className:i.TitleCardContent,children:[(0,a.jsxs)("div",{className:(0,t.A)(i.TitleCardHeader),children:[(0,a.jsx)("div",{className:(0,t.A)(i.TitleCardTitle),style:{textAlign:"left",fontWeight:"bold"},children:e}),(0,a.jsx)("div",{className:i.TitleCardHeaderRight,children:o})]}),(0,a.jsx)("hr",{className:(0,t.A)(i.TitleCardSeparator),style:{margin:"12px 0"}}),s?(0,a.jsx)("div",{className:(0,t.A)(i.TextColor),children:s}):(0,a.jsx)("p",{className:(0,t.A)(i.TextColor),dangerouslySetInnerHTML:{__html:n}})]})})},11470:(e,n,r)=>{r.d(n,{A:()=>b});var t=r(96540),i=r(34164),o=r(17559),a=r(23104),s=r(56347),l=r(205),c=r(57485),d=r(31682),p=r(70679);function m(e){return t.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,t.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function h(e){const{values:n,children:r}=e;return(0,t.useMemo)(()=>{const e=n??function(e){return m(e).map(({props:{value:e,label:n,attributes:r,default:t}})=>({value:e,label:n,attributes:r,default:t}))}(r);return function(e){const n=(0,d.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,r])}function u({value:e,tabValues:n}){return n.some(n=>n.value===e)}function f({queryString:e=!1,groupId:n}){const r=(0,s.W6)(),i=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,c.aZ)(i),(0,t.useCallback)(e=>{if(!i)return;const n=new URLSearchParams(r.location.search);n.set(i,e),r.replace({...r.location,search:n.toString()})},[i,r])]}function g(e){const{defaultValue:n,queryString:r=!1,groupId:i}=e,o=h(e),[a,s]=(0,t.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!u({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const r=n.find(e=>e.default)??n[0];if(!r)throw new Error("Unexpected error: 0 tabValues");return r.value}({defaultValue:n,tabValues:o})),[c,d]=f({queryString:r,groupId:i}),[m,g]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[r,i]=(0,p.Dv)(n);return[r,(0,t.useCallback)(e=>{n&&i.set(e)},[n,i])]}({groupId:i}),x=(()=>{const e=c??m;return u({value:e,tabValues:o})?e:null})();(0,l.A)(()=>{x&&s(x)},[x]);return{selectedValue:a,selectValue:(0,t.useCallback)(e=>{if(!u({value:e,tabValues:o}))throw new Error(`Can't select invalid tab value=${e}`);s(e),d(e),g(e)},[d,g,o]),tabValues:o}}var x=r(92303);const _={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var y=r(74848);function w({className:e,block:n,selectedValue:r,selectValue:t,tabValues:o}){const s=[],{blockElementScrollPositionUntilNextRender:l}=(0,a.a_)(),c=e=>{const n=e.currentTarget,i=s.indexOf(n),a=o[i].value;a!==r&&(l(n),t(a))},d=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const r=s.indexOf(e.currentTarget)+1;n=s[r]??s[0];break}case"ArrowLeft":{const r=s.indexOf(e.currentTarget)-1;n=s[r]??s[s.length-1];break}}n?.focus()};return(0,y.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":n},e),children:o.map(({value:e,label:n,attributes:t})=>(0,y.jsx)("li",{role:"tab",tabIndex:r===e?0:-1,"aria-selected":r===e,ref:e=>{s.push(e)},onKeyDown:d,onClick:c,...t,className:(0,i.A)("tabs__item",_.tabItem,t?.className,{"tabs__item--active":r===e}),children:n??e},e))})}function v({lazy:e,children:n,selectedValue:r}){const o=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=o.find(e=>e.props.value===r);return e?(0,t.cloneElement)(e,{className:(0,i.A)("margin-top--md",e.props.className)}):null}return(0,y.jsx)("div",{className:"margin-top--md",children:o.map((e,n)=>(0,t.cloneElement)(e,{key:n,hidden:e.props.value!==r}))})}function j(e){const n=g(e);return(0,y.jsxs)("div",{className:(0,i.A)(o.G.tabs.container,"tabs-container",_.tabList),children:[(0,y.jsx)(w,{...n,...e}),(0,y.jsx)(v,{...n,...e})]})}function b(e){const n=(0,x.A)();return(0,y.jsx)(j,{...e,children:m(e.children)},String(n))}},19365:(e,n,r)=>{r.d(n,{A:()=>a});r(96540);var t=r(34164);const i={tabItem:"tabItem_Ymn6"};var o=r(74848);function a({children:e,hidden:n,className:r}){return(0,o.jsx)("div",{role:"tabpanel",className:(0,t.A)(i.tabItem,r),hidden:n,children:e})}},28453:(e,n,r)=>{r.d(n,{R:()=>a,x:()=>s});var t=r(96540);const i={},o=t.createContext(i);function a(e){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),t.createElement(o.Provider,{value:n},e.children)}},49374:(e,n,r)=>{r.d(n,{B:()=>s});r(96540);const t=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}');var i=r(86025),o=r(74848);const a=e=>{const n=e.split(".");for(let r=n.length;r>0;r--){const e=n.slice(0,r).join(".");if(t[e])return e}return null};function s({fn:e,children:n,hash:r}){const s=a(e);if(!s)return(0,o.jsx)(o.Fragment,{children:n});const l=(0,i.Ay)(`/${t[s]}#${r??e}`);return(0,o.jsx)("a",{href:l,target:"_blank",children:n??(0,o.jsxs)("code",{children:[e,"()"]})})}},63575:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>p,contentTitle:()=>d,default:()=>u,frontMatter:()=>c,metadata:()=>t,toc:()=>m});const t=JSON.parse('{"id":"tracing/prod-tracing","title":"Production Monitoring for GenAI Applications","description":"Machine learning projects don\'t conclude with their initial launch. Ongoing monitoring and incremental enhancements are critical for long-term success. MLflow Tracing offers comprehensive observability for your production applications, supporting the iterative process of continuous improvement while ensuring quality delivery to users.","source":"@site/docs/genai/tracing/prod-tracing.mdx","sourceDirName":"tracing","slug":"/tracing/prod-tracing","permalink":"/mlflow-website/docs/latest/genai/tracing/prod-tracing","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"genAISidebar","previous":{"title":"Export MLflow Traces/Metrics via OTLP","permalink":"/mlflow-website/docs/latest/genai/tracing/opentelemetry/export"},"next":{"title":"Tracing FAQ","permalink":"/mlflow-website/docs/latest/genai/tracing/faq"}}');var i=r(74848),o=r(28453),a=(r(49374),r(11470)),s=r(19365),l=r(10493);const c={},d="Production Monitoring for GenAI Applications",p={},m=[{value:"Key Monitoring Areas",id:"key-monitoring-areas",level:2},{value:"Setting Up Tracing for Production Endpoints",id:"setting-up-tracing-for-production-endpoints",level:2},{value:"Pro Tip: Using the Lightweight Tracing SDK",id:"pro-tip-using-the-lightweight-tracing-sdk",level:4},{value:"Environment Variable Configuration",id:"environment-variable-configuration",level:3},{value:"Self-Hosted Tracking Server",id:"self-hosted-tracking-server",level:2},{value:"Performance Considerations",id:"performance-considerations",level:3},{value:"Docker Deployment Example",id:"docker-deployment-example",level:3},{value:"Kubernetes Deployment Example",id:"kubernetes-deployment-example",level:3},{value:"OpenTelemetry Backends",id:"opentelemetry-backends",level:2},{value:"Managed Monitoring with Databricks",id:"managed-monitoring-with-databricks",level:2},{value:"Production Monitoring Configurations",id:"production-monitoring-configurations",level:2},{value:"Asynchronous Trace Logging",id:"asynchronous-trace-logging",level:3},{value:"Sampling Traces",id:"sampling-traces",level:3},{value:"Adding Context to Production Traces",id:"adding-context-to-production-traces",level:2},{value:"Tracking Request, Session, and User Context",id:"tracking-request-session-and-user-context",level:3},{value:"Feedback Collection",id:"feedback-collection",level:3},{value:"Querying Traces with Context",id:"querying-traces-with-context",level:3},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2}];function h(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"production-monitoring-for-genai-applications",children:"Production Monitoring for GenAI Applications"})}),"\n",(0,i.jsx)(n.p,{children:"Machine learning projects don't conclude with their initial launch. Ongoing monitoring and incremental enhancements are critical for long-term success. MLflow Tracing offers comprehensive observability for your production applications, supporting the iterative process of continuous improvement while ensuring quality delivery to users."}),"\n",(0,i.jsx)(n.p,{children:"GenAI applications face unique challenges that make production monitoring essential. Quality drift can occur over time due to model updates, data distribution shifts, or new user interaction patterns. The operational complexity of multi-step workflows involving LLMs, vector databases, and retrieval systems creates multiple potential failure points that need continuous oversight. Cost management becomes critical as token usage and API costs can vary significantly based on user behavior and model performance."}),"\n",(0,i.jsx)(n.h2,{id:"key-monitoring-areas",children:"Key Monitoring Areas"}),"\n",(0,i.jsx)(n.p,{children:"Understanding what to monitor helps you focus on metrics that actually impact user experience and business outcomes. Rather than trying to monitor everything, focus on areas that provide actionable insights for your specific application and user base."}),"\n",(0,i.jsxs)(a.A,{children:[(0,i.jsxs)(s.A,{value:"operational",label:"Operational Metrics",default:!0,children:[(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Performance and Reliability"}),": Monitor end-to-end response times from user request to final response, including LLM inference latency, retrieval system performance, and component-level bottlenecks. Track overall error rates, LLM API failures, timeout occurrences, and dependency failures to maintain system reliability."]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Resource Utilization"}),": Monitor token consumption patterns, API cost tracking, request throughput, and system resource usage to optimize performance and control costs."]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Business Metrics"}),": Track user engagement rates, session completion rates, feature adoption, and user satisfaction scores to understand the business impact of your application."]})]}),(0,i.jsxs)(s.A,{value:"quality",label:"Quality Metrics",children:[(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Response Quality"}),": Assess response relevance to user queries, factual accuracy, completeness of responses, and consistency across similar queries to ensure your application meets user needs."]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Safety and Compliance"}),": Monitor for harmful content detection, bias monitoring, privacy compliance, and regulatory adherence, which is especially important for applications in regulated industries."]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"User Experience Quality"}),": Track response helpfulness, clarity and readability, appropriate tone and style, and multi-turn conversation quality to optimize user satisfaction."]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Domain-Specific Quality"}),": Implement metrics that vary by application type, such as technical accuracy for specialized domains, citation quality for RAG applications, code quality for programming assistants, or creative quality for content generation."]})]}),(0,i.jsxs)(s.A,{value:"business",label:"Business Impact",children:[(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"User Behavior"}),": Monitor session duration and depth, feature usage patterns, user retention rates, and conversion metrics to understand how users engage with your application."]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Operational Efficiency"}),": Track support ticket reduction, process automation success, time savings for users, and task completion rates to measure operational improvements."]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Cost-Benefit Analysis"}),": Compare infrastructure costs versus value delivered, ROI on GenAI investment, productivity improvements, and customer satisfaction impact to justify and optimize your GenAI initiatives."]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"setting-up-tracing-for-production-endpoints",children:"Setting Up Tracing for Production Endpoints"}),"\n",(0,i.jsx)(n.p,{children:"When deploying your GenAI application to production, you need to configure MLflow Tracing to send traces to your MLflow tracking server. This configuration forms the foundation for all production observability capabilities."}),"\n",(0,i.jsx)(l.Zp,{children:(0,i.jsx)("div",{className:"flex-column",children:(0,i.jsx)("div",{className:"flex-row",children:(0,i.jsxs)("div",{className:"flex-item",children:[(0,i.jsx)(n.h4,{id:"pro-tip-using-the-lightweight-tracing-sdk",children:"Pro Tip: Using the Lightweight Tracing SDK"}),(0,i.jsxs)(n.p,{children:["The ",(0,i.jsxs)(n.a,{href:"/genai/tracing/lightweight-sdk",children:["MLflow Tracing SDK ",(0,i.jsx)(n.code,{children:"mlflow-tracing"})]})," is a lightweight package that only includes the minimum set of dependencies to instrument your code/models/agents with MLflow Tracing."]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"\u26a1\ufe0f Faster Deployment"}),": Significantly smaller package size and fewer dependencies enable quicker deployments in containers and serverless environments"]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"\ud83d\udd27 Simple Dependency Management"}),": Reduced dependencies mean less maintenance overhead and fewer potential conflicts"]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"\ud83d\udce6 Enhanced Portability"}),": Easily deploy across different platforms with minimal compatibility concerns"]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"\ud83d\udd12 Improved Security"}),": Smaller attack surface with fewer dependencies reduces security risks"]}),(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"\ud83d\ude80 Performance Optimizations"}),": Optimized for high-volume tracing in production environments"]})]})})})}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsx)(n.admonition,{title:"Compatibility Warning",type:"warning",children:(0,i.jsxs)(n.p,{children:["When installing the MLflow Tracing SDK, make sure the environment ",(0,i.jsx)(n.strong,{children:"does not have"})," the full MLflow package installed. Having both packages in the same environment might cause conflicts and unexpected behaviors."]})}),"\n",(0,i.jsx)(n.h3,{id:"environment-variable-configuration",children:"Environment Variable Configuration"}),"\n",(0,i.jsxs)(n.p,{children:["Configure the following environment variables in your production environment. See ",(0,i.jsx)(n.a,{href:"#production-monitoring-configurations",children:"Production Monitoring Configurations"})," below for more details about these configurations."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Required: Set MLflow Tracking URI\nexport MLFLOW_TRACKING_URI="http://your-mlflow-server:5000"\n\n# Optional: Configure the experiment name for organizing traces\nexport MLFLOW_EXPERIMENT_NAME="production-genai-app"\n\n# Optional: Configure async logging (recommended for production)\nexport MLFLOW_ENABLE_ASYNC_TRACE_LOGGING=true\nexport MLFLOW_ASYNC_TRACE_LOGGING_MAX_WORKERS=10\nexport MLFLOW_ASYNC_TRACE_LOGGING_MAX_QUEUE_SIZE=1000\n\n# Optional: Configure trace sampling ratio (default is 1.0)\nexport MLFLOW_TRACE_SAMPLING_RATIO=0.1\n'})}),"\n",(0,i.jsx)(n.h2,{id:"self-hosted-tracking-server",children:"Self-Hosted Tracking Server"}),"\n",(0,i.jsx)(n.p,{children:"You can use the MLflow tracking server to store production traces. However, the tracking server is optimized for offline experience and generally not suitable for handling hyper-scale traffic. For high-volume production workloads, consider using OpenTelemetry integration with dedicated observability platforms."}),"\n",(0,i.jsxs)(n.p,{children:["If you choose to use the tracking server in production, we ",(0,i.jsx)(n.strong,{children:"strongly recommend"}),":"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Use SQL-based tracking server"})," on top of a scalable database and artifact storage"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Configure proper indexing"})," on trace tables for better query performance"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Set up periodic deletion"})," for trace data management"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Monitor server performance"})," and scale appropriately"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Refer to the ",(0,i.jsx)(n.a,{href:"/ml/tracking#tracking-setup",children:"tracking server setup guide"})," for more details."]}),"\n",(0,i.jsx)(n.h3,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Database"}),": Use PostgreSQL or MySQL for better concurrent write performance rather than SQLite for production deployments."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Storage"}),": Use cloud storage (S3, Azure Blob, GCS) for artifact storage to ensure scalability and reliability."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Indexing"}),": Ensure proper indexes on ",(0,i.jsx)(n.code,{children:"timestamp_ms"}),", ",(0,i.jsx)(n.code,{children:"status"}),", and frequently queried tag columns to maintain query performance as trace volume grows."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Retention"}),": Implement data retention policies to manage storage costs and maintain system performance over time."]}),"\n",(0,i.jsx)(n.h3,{id:"docker-deployment-example",children:"Docker Deployment Example"}),"\n",(0,i.jsx)(n.p,{children:"When deploying with Docker, pass environment variables through your container configuration:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-dockerfile",children:'# Dockerfile\nFROM python:3.9-slim\n\n# Install dependencies\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\n# Copy application code\nCOPY . /app\nWORKDIR /app\n\n# Set default environment variables (can be overridden at runtime)\nENV MLFLOW_TRACKING_URI=""\nENV MLFLOW_EXPERIMENT_NAME="production-genai-app"\nENV MLFLOW_ENABLE_ASYNC_TRACE_LOGGING=true\n\nCMD ["python", "app.py"]\n'})}),"\n",(0,i.jsx)(n.p,{children:"Run the container with environment variables:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'docker run -d \\\n  -e MLFLOW_TRACKING_URI="http://your-mlflow-server:5000" \\\n  -e MLFLOW_EXPERIMENT_NAME="production-genai-app" \\\n  -e MLFLOW_ENABLE_ASYNC_TRACE_LOGGING=true \\\n  -e APP_VERSION="1.0.0" \\\n  your-app:latest\n'})}),"\n",(0,i.jsx)(n.h3,{id:"kubernetes-deployment-example",children:"Kubernetes Deployment Example"}),"\n",(0,i.jsx)(n.p,{children:"For Kubernetes deployments, use ConfigMaps and Secrets:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"# configmap.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: mlflow-config\ndata:\n  MLFLOW_TRACKING_URI: 'http://mlflow-server:5000'\n  MLFLOW_EXPERIMENT_NAME: 'production-genai-app'\n  MLFLOW_ENABLE_ASYNC_TRACE_LOGGING: 'true'\n\n---\n# deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: genai-app\nspec:\n  template:\n    spec:\n      containers:\n        - name: app\n          image: your-app:latest\n          envFrom:\n            - configMapRef:\n                name: mlflow-config\n          env:\n            - name: APP_VERSION\n              value: '1.0.0'\n"})}),"\n",(0,i.jsx)(n.h2,{id:"opentelemetry-backends",children:"OpenTelemetry Backends"}),"\n",(0,i.jsxs)(n.p,{children:["MLflow Traces can be exported to any OpenTelemetry-compatible backend. See the ",(0,i.jsx)(n.a,{href:"/genai/tracing/opentelemetry/export",children:"OpenTelemetry Integration"})," documentation for more details."]}),"\n",(0,i.jsx)(n.h2,{id:"managed-monitoring-with-databricks",children:"Managed Monitoring with Databricks"}),"\n",(0,i.jsxs)(n.p,{children:["Databricks also offers a ",(0,i.jsx)(n.a,{href:"https://docs.databricks.com/aws/en/generative-ai/agent-evaluation/monitoring",children:"managed solution"})," for monitoring your GenAI applications that integrates with MLflow Tracing."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:"https://assets.docs.databricks.com/_static/images/generative-ai/monitoring/monitoring-hero.gif",alt:"Monitoring Hero"})}),"\n",(0,i.jsx)(n.p,{children:"Capabilities include:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Track ",(0,i.jsx)(n.strong,{children:"operational metrics"})," like request volume, latency, errors, and cost."]}),"\n",(0,i.jsxs)(n.li,{children:["Monitor ",(0,i.jsx)(n.strong,{children:"quality metrics"})," such as correctness, safety, context sufficiency, and more using managed evaluation."]}),"\n",(0,i.jsxs)(n.li,{children:["Configure ",(0,i.jsx)(n.strong,{children:"custom metrics"})," with Python function."]}),"\n",(0,i.jsxs)(n.li,{children:["Root cause analysis by looking at the recorded ",(0,i.jsx)(n.strong,{children:"traces"})," from MLflow Tracing."]}),"\n",(0,i.jsx)(n.li,{children:"Support for applications hosted outside of Databricks"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"production-monitoring-configurations",children:"Production Monitoring Configurations"}),"\n",(0,i.jsx)(n.h3,{id:"asynchronous-trace-logging",children:"Asynchronous Trace Logging"}),"\n",(0,i.jsx)(n.p,{children:"For production applications, MLflow logs traces asynchronously by default to prevent blocking your application:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Environment Variable"}),(0,i.jsx)(n.th,{children:"Description"}),(0,i.jsx)(n.th,{children:"Default Value"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"MLFLOW_ENABLE_ASYNC_TRACE_LOGGING"})}),(0,i.jsxs)(n.td,{children:["Whether to log traces asynchronously. When set to ",(0,i.jsx)(n.code,{children:"False"}),", traces will be logged in a blocking manner."]}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"True"})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"MLFLOW_ASYNC_TRACE_LOGGING_MAX_WORKERS"})}),(0,i.jsx)(n.td,{children:"The maximum number of worker threads to use for async trace logging per process. Increasing this allows higher throughput of trace logging, but also increases CPU usage and memory consumption."}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"10"})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"MLFLOW_ASYNC_TRACE_LOGGING_MAX_QUEUE_SIZE"})}),(0,i.jsx)(n.td,{children:"The maximum number of traces that can be queued before being logged to backend by the worker threads. When the queue is full, new traces will be discarded. Increasing this allows higher durability of trace logging, but also increases memory consumption."}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"1000"})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"MLFLOW_ASYNC_TRACE_LOGGING_RETRY_TIMEOUT"})}),(0,i.jsx)(n.td,{children:"The timeout in seconds for retrying failed trace logging. When a trace logging fails, it will be retried up to this timeout with backoff, after which it will be discarded."}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"500"})})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"Example configuration for high-volume applications:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"export MLFLOW_ENABLE_ASYNC_TRACE_LOGGING=true\nexport MLFLOW_ASYNC_TRACE_LOGGING_MAX_WORKERS=20\nexport MLFLOW_ASYNC_TRACE_LOGGING_MAX_QUEUE_SIZE=2000\nexport MLFLOW_ASYNC_TRACE_LOGGING_RETRY_TIMEOUT=600\n"})}),"\n",(0,i.jsx)(n.h3,{id:"sampling-traces",children:"Sampling Traces"}),"\n",(0,i.jsx)(n.p,{children:"For a high-volume application, you may want to reduce the number of traces exported to the backend. You can configure the sampling ratio to control the number of traces exported."}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Environment Variable"}),(0,i.jsx)(n.th,{children:"Description"}),(0,i.jsx)(n.th,{children:"Default Value"})]})}),(0,i.jsx)(n.tbody,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"MLFLOW_TRACE_SAMPLING_RATIO"})}),(0,i.jsxs)(n.td,{children:["The sampling ratio for traces. When set to ",(0,i.jsx)(n.code,{children:"0.0"}),", no traces will be exported. When set to ",(0,i.jsx)(n.code,{children:"1.0"}),", all traces will be exported."]}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"1.0"})})]})})]}),"\n",(0,i.jsxs)(n.p,{children:["The default value is ",(0,i.jsx)(n.code,{children:"1.0"}),", which means all traces will be exported. When set to less than ",(0,i.jsx)(n.code,{children:"1.0"}),", say ",(0,i.jsx)(n.code,{children:"0.1"}),", only 10% of the traces will be exported. The sampling is done at the trace level, meaning that all spans in some traces will be exported or discarded together."]}),"\n",(0,i.jsx)(n.h2,{id:"adding-context-to-production-traces",children:"Adding Context to Production Traces"}),"\n",(0,i.jsx)(n.p,{children:"In production environments, enriching traces with contextual information is crucial for understanding user behavior, debugging issues, and improving your GenAI application. This context enables you to analyze user interactions, track quality across different segments, and identify patterns that lead to better or worse outcomes."}),"\n",(0,i.jsx)(n.h3,{id:"tracking-request-session-and-user-context",children:"Tracking Request, Session, and User Context"}),"\n",(0,i.jsx)(n.p,{children:"Production applications need to track multiple pieces of context simultaneously. Here's a comprehensive example showing how to track all of these in a FastAPI application:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport os\nfrom fastapi import FastAPI, Request, HTTPException\nfrom pydantic import BaseModel\n\n# Initialize FastAPI app\napp = FastAPI()\n\n\nclass ChatRequest(BaseModel):\n    message: str\n\n\n@app.post("/chat")  # FastAPI decorator should be outermost\n@mlflow.trace  # Ensure @mlflow.trace is the inner decorator\ndef handle_chat(request: Request, chat_request: ChatRequest):\n    # Retrieve all context from request headers\n    client_request_id = request.headers.get("X-Request-ID")\n    session_id = request.headers.get("X-Session-ID")\n    user_id = request.headers.get("X-User-ID")\n\n    # Update the current trace with all context and environment metadata\n    mlflow.update_current_trace(\n        client_request_id=client_request_id,\n        tags={\n            # Session context - groups traces from multi-turn conversations\n            "mlflow.trace.session": session_id,\n            # User context - associates traces with specific users\n            "mlflow.trace.user": user_id,\n            # Environment metadata - tracks deployment context\n            "environment": "production",\n            "app_version": os.getenv("APP_VERSION", "1.0.0"),\n            "deployment_id": os.getenv("DEPLOYMENT_ID", "unknown"),\n            "region": os.getenv("REGION", "us-east-1"),\n        },\n    )\n\n    # Your application logic for processing the chat message\n    response_text = f"Processed message: \'{chat_request.message}\'"\n\n    return {"response": response_text}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"feedback-collection",children:"Feedback Collection"}),"\n",(0,i.jsx)(n.p,{children:"Capturing user feedback on specific interactions is essential for understanding quality and improving your GenAI application:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom mlflow.client import MlflowClient\nfrom fastapi import FastAPI, Query, Request\nfrom pydantic import BaseModel\nfrom typing import Optional\nfrom mlflow.entities import AssessmentSource\n\napp = FastAPI()\n\n\nclass FeedbackRequest(BaseModel):\n    is_correct: bool  # True for correct, False for incorrect\n    comment: Optional[str] = None\n\n\n@app.post("/chat_feedback")\ndef handle_chat_feedback(\n    request: Request,\n    client_request_id: str = Query(\n        ..., description="The client request ID from the original chat request"\n    ),\n    feedback: FeedbackRequest = ...,\n):\n    """\n    Collect user feedback for a specific chat interaction identified by client_request_id.\n    """\n    # Search for the trace with the matching client_request_id\n    client = MlflowClient()\n    experiment = client.get_experiment_by_name("production-genai-app")\n    traces = client.search_traces(experiment_ids=[experiment.experiment_id])\n    traces = [\n        trace for trace in traces if trace.info.client_request_id == client_request_id\n    ][:1]\n\n    if not traces:\n        return {\n            "status": "error",\n            "message": f"Unable to find data for client request ID: {client_request_id}",\n        }, 500\n\n    # Log feedback using MLflow\'s log_feedback API\n    mlflow.log_feedback(\n        trace_id=traces[0].info.trace_id,\n        name="response_is_correct",\n        value=feedback.is_correct,\n        source=AssessmentSource(\n            source_type="HUMAN", source_id=request.headers.get("X-User-ID")\n        ),\n        rationale=feedback.comment,\n    )\n\n    return {\n        "status": "success",\n        "message": "Feedback recorded successfully",\n        "trace_id": traces[0].info.trace_id,\n    }\n'})}),"\n",(0,i.jsx)(n.h3,{id:"querying-traces-with-context",children:"Querying Traces with Context"}),"\n",(0,i.jsx)(n.p,{children:"Use the contextual information to analyze production behavior:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import mlflow\n\n# Query traces by user\nuser_traces = mlflow.search_traces(\n    experiment_ids=[experiment.experiment_id],\n    filter_string=\"tags.`mlflow.trace.user` = 'user-jane-doe-12345'\",\n    max_results=100,\n)\n\n# Query traces by session\nsession_traces = mlflow.search_traces(\n    experiment_ids=[experiment.experiment_id],\n    filter_string=\"tags.`mlflow.trace.session` = 'session-def-456'\",\n    max_results=100,\n)\n\n# Query traces by environment\nproduction_traces = mlflow.search_traces(\n    experiment_ids=[experiment.experiment_id],\n    filter_string=\"tags.environment = 'production'\",\n    max_results=100,\n)\n"})}),"\n",(0,i.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(n.p,{children:"Production monitoring with MLflow Tracing provides comprehensive observability for your GenAI applications. Understanding how users actually interact with your application, monitoring quality and performance in real-world conditions, and tracking the business impact of your GenAI initiatives are all essential for long-term success."}),"\n",(0,i.jsxs)(n.p,{children:["Key recommendations for successful production deployments include using ",(0,i.jsx)(n.code,{children:"mlflow-tracing"})," for production deployments to minimize dependencies and optimize performance, configuring async logging for high-volume applications to prevent blocking, adding rich context with tags and metadata for effective debugging and analysis, implementing feedback collection for quality monitoring and continuous improvement, considering OpenTelemetry integration for enterprise observability platforms, and monitoring performance while implementing proper error handling."]}),"\n",(0,i.jsx)(n.p,{children:"Whether you're using self-hosted MLflow, integrating with enterprise observability platforms through OpenTelemetry, or leveraging Databricks Mosaic AI's advanced capabilities, MLflow Tracing provides the foundation for understanding and improving your production GenAI applications."}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/genai/tracing/observe-with-traces",children:"Debug & Observe Your App with Tracing"})}),": Learn foundational observability concepts and techniques"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/genai/tracing/observe-with-traces/query-via-sdk",children:"Query Traces via SDK"})}),": Understand how to programmatically access trace data for analysis"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/genai/tracing/track-users-sessions",children:"Track Users & Sessions"})}),": Implement user and session context tracking for better monitoring insights"]})]})}function u(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}}}]);