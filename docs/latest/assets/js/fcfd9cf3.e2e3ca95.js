"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["438"],{36289(e,n,t){t.r(n),t.d(n,{metadata:()=>r,default:()=>w,frontMatter:()=>f,contentTitle:()=>g,toc:()=>j,assets:()=>x});var r=JSON.parse('{"id":"eval-monitor/automatic-evaluations/index","title":"Automatic Evaluation","description":"Automatically evaluate traces and multi-turn conversations as they\'re logged - no code required","source":"@site/docs/genai/eval-monitor/automatic-evaluations/index.mdx","sourceDirName":"eval-monitor/automatic-evaluations","slug":"/eval-monitor/automatic-evaluations/","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/automatic-evaluations/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"genAISidebar","previous":{"title":"Evaluate Conversations","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/running-evaluation/multi-turn"},"next":{"title":"LLM Judges and Scorers","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/scorers/"}}'),i=t(74848),a=t(28453),l=t(78010),s=t(57250),o=t(95986),c=t(10440),d=t(77541),h=t(43975),u=t(47504),m=t(54725),p=t(66497);let f={},g="Automatic Evaluation",x={},j=[{value:"Automatic vs Offline Evaluation",id:"automatic-vs-offline-evaluation",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Setting Up Automatic Evaluation",id:"setting-up-automatic-evaluation",level:2},{value:"Viewing Results",id:"viewing-results",level:2},{value:"Configuration Options",id:"configuration-options",level:2},{value:"Sampling Rate",id:"sampling-rate",level:3},{value:"Filtering Traces",id:"filtering-traces",level:3},{value:"Session-Level Evaluation",id:"session-level-evaluation",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"How It Works",id:"how-it-works",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Next Steps",id:"next-steps",level:2}];function v(e){let n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"automatic-evaluation",children:"Automatic Evaluation"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.em,{children:"Automatically evaluate traces and multi-turn conversations as they're logged - no code required"})}),"\n",(0,i.jsx)(n.p,{children:"Automatic evaluation runs your LLM judges automatically on traces and multi-turn conversations as they're logged to MLflow, without requiring manual execution of code. This enables two key use cases:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Streamlined Quality Iteration"}),": Seamlessly measure quality as you iterate on your agent or LLM application in development, getting immediate feedback and quality insights without extra evaluation steps"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Production Monitoring"}),": Continuously monitor for issues like hallucinations, PII leakage, or user frustration on live traffic (often referred to as online evaluation)"]}),"\n"]}),"\n",(0,i.jsx)("video",{src:(0,p.default)("/images/llms/tracing/automatic-evaluation-ui-setup.mp4"),controls:!0,loop:!0,autoPlay:!0,muted:!0,"aria-label":"Automatic Evaluation Setup"}),"\n",(0,i.jsx)(n.h2,{id:"automatic-vs-offline-evaluation",children:"Automatic vs Offline Evaluation"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{}),(0,i.jsx)(n.th,{children:"Automatic Evaluation"}),(0,i.jsx)(n.th,{children:"Offline Evaluation"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"When it runs"})}),(0,i.jsx)(n.td,{children:"Automatically, as traces and conversations are logged"}),(0,i.jsxs)(n.td,{children:["Manually, when you call ",(0,i.jsx)(n.a,{href:"/genai/eval-monitor/running-evaluation/traces",children:(0,i.jsx)(n.code,{children:"mlflow.genai.evaluate()"})})]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Use case"})}),(0,i.jsx)(n.td,{children:"Production quality tracking, continuous monitoring, internal QA, interactive testing"}),(0,i.jsx)(n.td,{children:"Regression testing, bug fix verification, pre-deployment testing, comparing agent versions"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Data source"})}),(0,i.jsx)(n.td,{children:"Live traces and conversations from your application"}),(0,i.jsx)(n.td,{children:"Curated datasets or historical traces"})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsx)(n.p,{children:"Before setting up automatic evaluation, ensure that:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/genai/getting-started/connect-environment",children:"The MLflow Server is running"})})}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/genai/tracing/quickstart",children:"MLflow Tracing is enabled"})})," in your agent or LLM application","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsxs)(n.strong,{children:["For ",(0,i.jsx)(n.a,{href:"#session-level-evaluation",children:"multi-turn conversation evaluation"})]}),", traces must include ",(0,i.jsx)(n.a,{href:"/genai/tracing/track-users-sessions",children:"session IDs"})]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/genai/governance/ai-gateway/endpoints/create-and-manage",children:"An AI Gateway endpoint is configured"})})," for LLM judge execution","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["LLM judges require an LLM to perform evaluations, and ",(0,i.jsx)(n.a,{href:"/genai/governance/ai-gateway/endpoints/create-and-manage",children:"AI Gateway endpoints"})," provide secure, managed access to LLMs"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"setting-up-automatic-evaluation",children:"Setting Up Automatic Evaluation"}),"\n",(0,i.jsxs)(n.p,{children:["These examples show how to set up LLM judges that automatically evaluate traces and multi-turn conversations as they're logged to an ",(0,i.jsx)(n.a,{href:"/genai/tracing/quickstart#create-a-mlflow-experiment",children:"MLflow Experiment"}),", and how to update or disable existing judges. For more details on creating LLM judges, see ",(0,i.jsx)(n.a,{href:"/genai/eval-monitor/scorers/#llms-as-judges",children:"LLM-as-a-Judge"}),"."]}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Automatic evaluation only supports ",(0,i.jsx)(n.a,{href:"/genai/eval-monitor/scorers/#llms-as-judges",children:"LLM judges"}),". Code-based scorers (using the ",(0,i.jsxs)(n.a,{href:"/genai/eval-monitor/scorers/custom",children:[(0,i.jsx)(n.code,{children:"@scorer"})," decorator"]}),") are not supported. Use ",(0,i.jsx)(n.a,{href:"/genai/eval-monitor/scorers/llm-judge/predefined",children:"built-in judges"})," or create custom judges with ",(0,i.jsx)(n.a,{href:"/genai/eval-monitor/scorers/llm-judge/custom-judges/create-custom-judge",children:(0,i.jsx)(n.code,{children:"make_judge()"})}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["When a judge is created or enabled, it evaluates traces and sessions that are ",(0,i.jsx)(n.strong,{children:"at most one hour old"}),". Updating a judge's configuration does not trigger re-evaluation of previously assessed traces."]}),"\n"]})}),"\n",(0,i.jsx)(o.A,{children:(0,i.jsxs)(l.A,{children:[(0,i.jsx)(s.A,{value:"ui",label:"UI",default:!0,children:(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Navigate to your experiment and select the ",(0,i.jsx)(n.strong,{children:"Judges"})," tab"]}),"\n",(0,i.jsx)("img",{src:t(2358).A,alt:"Judges tab",width:"108",style:{borderRadius:"8px",border:"1px solid #ddd",boxShadow:"0 1px 4px rgba(0,0,0,0.05)"}}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Click ",(0,i.jsx)(n.strong,{children:"+ New LLM judge"})]}),"\n",(0,i.jsx)("img",{src:t(87927).A,alt:"New LLM judge button",width:"180",style:{borderRadius:"8px",border:"1px solid #ddd",boxShadow:"0 1px 4px rgba(0,0,0,0.05)"}}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Select scope"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Traces"}),": Evaluate individual traces"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Sessions"}),": Evaluate entire multi-turn conversations"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Configure the judge"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"LLM judge"}),": Select a built-in judge or create a custom one"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Name"}),": A unique name for the judge"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Instructions"}),": Define evaluation criteria for the judge"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Output type"}),": Select the type of value the judge will return"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Model"}),": Select an ",(0,i.jsx)(n.a,{href:"/genai/governance/ai-gateway/endpoints/create-and-manage",children:"AI Gateway"})," endpoint (LLM) to run the judge"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Evaluation settings"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Check ",(0,i.jsx)(n.strong,{children:'"Automatically evaluate future traces using this judge"'})]}),"\n",(0,i.jsxs)(n.li,{children:["Set the ",(0,i.jsx)(n.strong,{children:"Sample rate"})," (percentage of traces or sessions to evaluate)"]}),"\n",(0,i.jsxs)(n.li,{children:["Optionally add a ",(0,i.jsx)(n.strong,{children:"Filter string"})," to target specific traces or sessions"]}),"\n"]}),"\n",(0,i.jsx)("img",{src:t(60738).A,alt:"Evaluation settings",width:"400",style:{borderRadius:"8px",border:"1px solid #ddd",boxShadow:"0 1px 4px rgba(0,0,0,0.05)"}}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["Click ",(0,i.jsx)(n.strong,{children:"Save"})]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["To edit or disable an existing judge, select it in the ",(0,i.jsx)(n.strong,{children:"Judges"})," tab."]}),"\n",(0,i.jsx)("img",{src:t(7919).A,alt:"Edit LLM judge button",width:"270",style:{borderRadius:"8px",border:"1px solid #ddd",boxShadow:"0 1px 4px rgba(0,0,0,0.05)"}}),"\n"]}),"\n"]})}),(0,i.jsxs)(s.A,{value:"sdk",label:"SDK",children:[(0,i.jsxs)(n.p,{children:["For more details about the APIs used in this example, see ",(0,i.jsx)(m.B,{fn:"mlflow.genai.scorers.Scorer.start"}),", ",(0,i.jsx)(m.B,{fn:"mlflow.genai.scorers.Scorer.update"}),", and ",(0,i.jsx)(m.B,{fn:"mlflow.genai.scorers.Scorer.stop"}),"."]}),(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"1. Specify the experiment for automatic evaluation"})}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import mlflow\n\nmlflow.set_experiment("my-experiment")\n'})}),(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"2. Start automatic evaluation for a trace-level judge"})}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from mlflow.genai.scorers import ToolCallCorrectness, ScorerSamplingConfig\n\ntool_judge = ToolCallCorrectness(model="gateway:/my-llm-endpoint")\nregistered_tool_judge = tool_judge.register(name="tool_call_correctness")\nregistered_tool_judge.start(\n    sampling_config=ScorerSamplingConfig(sample_rate=0.5),  # Evaluate 50% of traces\n)\n'})}),(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"3. Start automatic evaluation for a multi-turn (session-level) judge"})}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from mlflow.genai.scorers import ConversationalGuidelines, ScorerSamplingConfig\n\nfrustration_judge = ConversationalGuidelines(\n    name="user_frustration",\n    guidelines="The user should not express frustration, confusion, or dissatisfaction during the conversation.",\n    model="gateway:/my-llm-endpoint",\n)\nregistered_frustration_judge = frustration_judge.register(name="user_frustration")\nregistered_frustration_judge.start(\n    sampling_config=ScorerSamplingConfig(sample_rate=1.0),  # Evaluate all conversations\n)\n'})}),(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"4. Update or disable automatic evaluation for an existing judge"})}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from mlflow.genai.scorers import get_scorer, ScorerSamplingConfig\n\njudge = get_scorer(name="tool_call_correctness")\njudge.update(\n    sampling_config=ScorerSamplingConfig(sample_rate=0.3)\n)  # Change sample rate\njudge.stop()  # Or, disable the judge\n'})})]})]})}),"\n",(0,i.jsx)(n.h2,{id:"viewing-results",children:"Viewing Results"}),"\n",(0,i.jsxs)(n.p,{children:["Assessments from automatic evaluation appear directly in the MLflow UI. For traces, assessments typically appear within a minute or two of logging. Multi-turn sessions are evaluated after 5 minutes of inactivity (no new traces have been added to the session) by default\u2014this is ",(0,i.jsx)(m.B,{fn:"mlflow.environment_variables.MLFLOW_ONLINE_SCORING_DEFAULT_SESSION_COMPLETION_BUFFER_SECONDS",children:"configurable"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"Navigate to your experiment in the MLflow UI to see results."}),"\n",(0,i.jsxs)("div",{style:{marginBottom:"16px"},children:[(0,i.jsx)("img",{src:t(51874).A,alt:"Online evaluation charts showing assessment trends",style:{width:"80%",borderRadius:"8px",border:"1px solid #ddd",boxShadow:"0 1px 4px rgba(0,0,0,0.05)"}}),(0,i.jsx)("div",{style:{width:"80%",textAlign:"left",marginTop:"8px",color:"#666",fontSize:"0.9em"},children:(0,i.jsx)(n.p,{children:"Charts in the Overview tab display quality and performance trends over time"})})]}),"\n",(0,i.jsxs)("div",{style:{display:"flex",flexDirection:"column",alignItems:"flex-end"},children:[(0,i.jsx)("img",{src:t(9703).A,alt:"Online evaluation results showing assessment scores for traces",style:{width:"80%",borderRadius:"8px",border:"1px solid #ddd",boxShadow:"0 1px 4px rgba(0,0,0,0.05)"}}),(0,i.jsx)("div",{style:{width:"80%",textAlign:"right",marginTop:"8px",color:"#666",fontSize:"0.9em"},children:(0,i.jsx)(n.p,{children:"Assessments from automatic evaluation appear as columns in the Traces tab"})})]}),"\n",(0,i.jsx)(n.h2,{id:"configuration-options",children:"Configuration Options"}),"\n",(0,i.jsx)(n.h3,{id:"sampling-rate",children:"Sampling Rate"}),"\n",(0,i.jsx)(n.p,{children:"Control what percentage of traces are evaluated (0-100%). Balance cost and coverage based on your needs:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Development"}),": Use a high sampling rate to detect as many issues as possible before production deployment"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Production"}),": Consider using lower rates if necessary to control costs"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"filtering-traces",children:"Filtering Traces"}),"\n",(0,i.jsxs)(n.p,{children:["Use ",(0,i.jsx)(n.a,{href:"/genai/tracing/search-traces",children:"trace search syntax"})," to target specific traces. Examples:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Only evaluate successful traces\nfilter_string = \"trace.status = 'OK'\"\n\n# Only evaluate traces from production environment\nfilter_string = \"metadata.environment = 'production'\"\n"})}),"\n",(0,i.jsx)(n.admonition,{type:"note",children:(0,i.jsxs)(n.p,{children:["For session-level evaluation, filters apply to the ",(0,i.jsx)(n.strong,{children:"first trace"})," in the session."]})}),"\n",(0,i.jsx)(n.h3,{id:"session-level-evaluation",children:"Session-Level Evaluation"}),"\n",(0,i.jsx)(n.p,{children:"Automatic evaluation can assess entire multi-turn conversations (sessions), in addition to individual traces."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Session completion"}),": A session is considered complete (ready for automatic evaluation) after no new traces arrive for 5 minutes (",(0,i.jsx)(m.B,{fn:"mlflow.environment_variables.MLFLOW_ONLINE_SCORING_DEFAULT_SESSION_COMPLETION_BUFFER_SECONDS",children:"configurable"}),")"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Re-evaluation"}),": If new traces are added to the session after evaluation, the session is re-evaluated and previous automatic evaluation results are replaced"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["For more information about session evaluation, see ",(0,i.jsx)(n.a,{href:"/genai/eval-monitor/running-evaluation/multi-turn",children:"Evaluate Conversations"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Combine judges"}),": Use multiple judges for comprehensive quality coverage"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Start with a high sampling rate, then scale down as needed"}),": Use a high sampling rate during development to detect as many issues as possible before production deployment, then reduce for production if necessary to control costs"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Monitor costs"}),": LLM-based evaluation has associated costs\u2014adjust sampling accordingly"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Use filters strategically in production"}),": Focus evaluation on high-value or high-risk traces"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"how-it-works",children:"How It Works"}),"\n",(0,i.jsx)(n.p,{children:"LLM judges are periodically executed securely within the MLflow server as new traces and multi-turn conversations are received. Evaluation happens asynchronously and does not block trace logging, so your application's performance is unaffected."}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.a,{href:"/genai/getting-started/connect-environment",children:"MLflow Server"})," uses ",(0,i.jsx)(n.a,{href:"/genai/governance/ai-gateway/",children:"AI Gateway"})," endpoints to access LLMs for judge execution, ensuring secure and managed model access. Only the relevant trace or session data required by the judge (such as inputs, outputs, and context) is sent to the LLM."]}),"\n",(0,i.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Issue"}),(0,i.jsx)(n.th,{children:"Solution"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Missing assessments"})}),(0,i.jsx)(n.td,{children:"Verify that the judge is active, the filter matches your traces, the sampling rate is greater than zero, and the traces are less than one hour old"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Unexpected or unsatisfactory judge results"})}),(0,i.jsxs)(n.td,{children:["Edit the judge's instructions or use the ",(0,i.jsxs)(n.a,{href:"/genai/eval-monitor/scorers/llm-judge/alignment",children:[(0,i.jsx)(n.code,{children:"align()"})," method"]})," to optimize them automatically"]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Evaluation errors"})}),(0,i.jsx)(n.td,{children:"Check trace/session assessments in the UI or SDK, or server logs, for details. Failed evaluations are not retried automatically"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:["For further debugging, enable debug logging on the MLflow server by setting the ",(0,i.jsx)(m.B,{fn:"mlflow.environment_variables.MLFLOW_LOGGING_LEVEL",children:(0,i.jsx)("code",{children:"MLFLOW_LOGGING_LEVEL=DEBUG"})})," environment variable and checking the MLflow server logs."]}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsxs)(c.A,{children:[(0,i.jsx)(d.A,{icon:h.A,iconSize:48,title:"LLM-as-a-Judge",description:"Learn more about creating and customizing LLM judges for your specific quality criteria.",href:"/genai/eval-monitor/scorers/#llms-as-judges",linkText:"Learn more \u2192",containerHeight:64}),(0,i.jsx)(d.A,{icon:u.A,iconSize:48,title:"Evaluate Conversations",description:"Learn more about evaluating multi-turn conversations.",href:"/genai/eval-monitor/running-evaluation/multi-turn",linkText:"Learn more \u2192",containerHeight:64})]})]})}function w(e={}){let{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(v,{...e})}):v(e)}},75689(e,n,t){t.d(n,{A:()=>o});var r=t(96540);let i=e=>{let n=e.replace(/^([A-Z])|[\s-_]+(\w)/g,(e,n,t)=>t?t.toUpperCase():n.toLowerCase());return n.charAt(0).toUpperCase()+n.slice(1)},a=(...e)=>e.filter((e,n,t)=>!!e&&""!==e.trim()&&t.indexOf(e)===n).join(" ").trim();var l={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};let s=(0,r.forwardRef)(({color:e="currentColor",size:n=24,strokeWidth:t=2,absoluteStrokeWidth:i,className:s="",children:o,iconNode:c,...d},h)=>(0,r.createElement)("svg",{ref:h,...l,width:n,height:n,stroke:e,strokeWidth:i?24*Number(t)/Number(n):t,className:a("lucide",s),...!o&&!(e=>{for(let n in e)if(n.startsWith("aria-")||"role"===n||"title"===n)return!0})(d)&&{"aria-hidden":"true"},...d},[...c.map(([e,n])=>(0,r.createElement)(e,n)),...Array.isArray(o)?o:[o]])),o=(e,n)=>{let t=(0,r.forwardRef)(({className:t,...l},o)=>(0,r.createElement)(s,{ref:o,iconNode:n,className:a(`lucide-${i(e).replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()}`,`lucide-${e}`,t),...l}));return t.displayName=i(e),t}},47504(e,n,t){t.d(n,{A:()=>r});let r=(0,t(75689).A)("message-square",[["path",{d:"M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z",key:"1lielz"}]])},43975(e,n,t){t.d(n,{A:()=>r});let r=(0,t(75689).A)("scale",[["path",{d:"m16 16 3-8 3 8c-.87.65-1.92 1-3 1s-2.13-.35-3-1Z",key:"7g6ntu"}],["path",{d:"m2 16 3-8 3 8c-.87.65-1.92 1-3 1s-2.13-.35-3-1Z",key:"ijws7r"}],["path",{d:"M7 21h10",key:"1b0cd5"}],["path",{d:"M12 3v18",key:"108xh3"}],["path",{d:"M3 7h2c2 0 5-1 7-2 2 1 5 2 7 2h2",key:"3gwbw2"}]])},7919(e,n,t){t.d(n,{A:()=>r});let r=t.p+"assets/images/edit-llm-judge-button-20eae3b628d868a4c3f014c5e478701f.png"},60738(e,n,t){t.d(n,{A:()=>r});let r=t.p+"assets/images/evaluation-settings-015320f1e469372c39ed925295791f40.png"},2358(e,n,t){t.d(n,{A:()=>r});let r=t.p+"assets/images/judges-tab-c1dea9a24e9809d6c7f8dbb4e2891767.png"},87927(e,n,t){t.d(n,{A:()=>r});let r=t.p+"assets/images/new-llm-judge-button-ee8d6028b0f3b278dbf49cd81759de7f.png"},51874(e,n,t){t.d(n,{A:()=>r});let r=t.p+"assets/images/online-evaluation-charts-c92ee3860b1b862ab09f32df26f2bd5d.png"},9703(e,n,t){t.d(n,{A:()=>r});let r=t.p+"assets/images/online-evaluation-results-ed55cb9aec590cdc084af7f3221e8db5.png"},57250(e,n,t){t.d(n,{A:()=>a});var r=t(74848);t(96540);var i=t(34164);function a({children:e,hidden:n,className:t}){return(0,r.jsx)("div",{role:"tabpanel",className:(0,i.A)("tabItem_Ymn6",t),hidden:n,children:e})}},78010(e,n,t){t.d(n,{A:()=>v});var r=t(74848),i=t(96540),a=t(34164),l=t(88287),s=t(28584),o=t(56347),c=t(99989),d=t(96629),h=t(80618),u=t(41367);function m(e){return i.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,i.isValidElement)(e)&&function(e){let{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function p({value:e,tabValues:n}){return n.some(n=>n.value===e)}var f=t(19863);function g({className:e,block:n,selectedValue:t,selectValue:i,tabValues:l}){let o=[],{blockElementScrollPositionUntilNextRender:c}=(0,s.a_)(),d=e=>{let n=e.currentTarget,r=l[o.indexOf(n)].value;r!==t&&(c(n),i(r))},h=e=>{let n=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{let t=o.indexOf(e.currentTarget)+1;n=o[t]??o[0];break}case"ArrowLeft":{let t=o.indexOf(e.currentTarget)-1;n=o[t]??o[o.length-1]}}n?.focus()};return(0,r.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,a.A)("tabs",{"tabs--block":n},e),children:l.map(({value:e,label:n,attributes:i})=>(0,r.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{o.push(e)},onKeyDown:h,onClick:d,...i,className:(0,a.A)("tabs__item","tabItem_LNqP",i?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function x({lazy:e,children:n,selectedValue:t}){let l=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){let e=l.find(e=>e.props.value===t);return e?(0,i.cloneElement)(e,{className:(0,a.A)("margin-top--md",e.props.className)}):null}return(0,r.jsx)("div",{className:"margin-top--md",children:l.map((e,n)=>(0,i.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function j(e){let n=function(e){let n,{defaultValue:t,queryString:r=!1,groupId:a}=e,l=function(e){let{values:n,children:t}=e;return(0,i.useMemo)(()=>{let e=n??m(t).map(({props:{value:e,label:n,attributes:t,default:r}})=>({value:e,label:n,attributes:t,default:r})),r=(0,h.XI)(e,(e,n)=>e.value===n.value);if(r.length>0)throw Error(`Docusaurus error: Duplicate values "${r.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`);return e},[n,t])}(e),[s,f]=(0,i.useState)(()=>(function({defaultValue:e,tabValues:n}){if(0===n.length)throw Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!p({value:e,tabValues:n}))throw Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}let t=n.find(e=>e.default)??n[0];if(!t)throw Error("Unexpected error: 0 tabValues");return t.value})({defaultValue:t,tabValues:l})),[g,x]=function({queryString:e=!1,groupId:n}){let t=(0,o.W6)(),r=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,d.aZ)(r),(0,i.useCallback)(e=>{if(!r)return;let n=new URLSearchParams(t.location.search);n.set(r,e),t.replace({...t.location,search:n.toString()})},[r,t])]}({queryString:r,groupId:a}),[j,v]=function({groupId:e}){let n=e?`docusaurus.tab.${e}`:null,[t,r]=(0,u.Dv)(n);return[t,(0,i.useCallback)(e=>{n&&r.set(e)},[n,r])]}({groupId:a}),w=p({value:n=g??j,tabValues:l})?n:null;return(0,c.A)(()=>{w&&f(w)},[w]),{selectedValue:s,selectValue:(0,i.useCallback)(e=>{if(!p({value:e,tabValues:l}))throw Error(`Can't select invalid tab value=${e}`);f(e),x(e),v(e)},[x,v,l]),tabValues:l}}(e);return(0,r.jsxs)("div",{className:(0,a.A)(l.G.tabs.container,"tabs-container","tabList__CuJ"),children:[(0,r.jsx)(g,{...n,...e}),(0,r.jsx)(x,{...n,...e})]})}function v(e){let n=(0,f.A)();return(0,r.jsx)(j,{...e,children:m(e.children)},String(n))}},54725(e,n,t){t.d(n,{B:()=>l});var r=t(74848);t(96540);var i=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}'),a=t(66497);function l({fn:e,children:n,hash:t}){let l=(e=>{let n=e.split(".");for(let e=n.length;e>0;e--){let t=n.slice(0,e).join(".");if(i[t])return t}return null})(e);if(!l)return(0,r.jsx)(r.Fragment,{children:n});let s=(0,a.default)(`/${i[l]}#${t??e}`);return(0,r.jsx)("a",{href:s,target:"_blank",children:n??(0,r.jsxs)("code",{children:[e,"()"]})})}},95986(e,n,t){t.d(n,{A:()=>i});var r=t(74848);t(96540);function i({children:e}){return(0,r.jsx)("div",{className:"wrapper_sf5q",children:e})}},77541(e,n,t){t.d(n,{A:()=>c});var r=t(74848);t(96540);var i=t(95310),a=t(34164);let l="tileImage_O4So";var s=t(66497),o=t(92802);function c({icon:e,image:n,imageDark:t,imageWidth:c,imageHeight:d,iconSize:h=32,containerHeight:u,title:m,description:p,href:f,linkText:g="Learn more \u2192",className:x}){if(!e&&!n)throw Error("TileCard requires either an icon or image prop");let j=u?{height:`${u}px`}:{},v={};return c&&(v.width=`${c}px`),d&&(v.height=`${d}px`),(0,r.jsxs)(i.A,{href:f,className:(0,a.A)("tileCard_NHsj",x),children:[(0,r.jsx)("div",{className:"tileIcon_pyoR",style:j,children:e?(0,r.jsx)(e,{size:h}):t?(0,r.jsx)(o.A,{sources:{light:(0,s.default)(n),dark:(0,s.default)(t)},alt:m,className:l,style:v}):(0,r.jsx)("img",{src:(0,s.default)(n),alt:m,className:l,style:v})}),(0,r.jsx)("h3",{children:m}),(0,r.jsx)("p",{children:p}),(0,r.jsx)("div",{className:"tileLink_iUbu",children:g})]})}},10440(e,n,t){t.d(n,{A:()=>a});var r=t(74848);t(96540);var i=t(34164);function a({children:e,className:n}){return(0,r.jsx)("div",{className:(0,i.A)("tilesGrid_hB9N",n),children:e})}},28453(e,n,t){t.d(n,{R:()=>l,x:()=>s});var r=t(96540);let i={},a=r.createContext(i);function l(e){let n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);