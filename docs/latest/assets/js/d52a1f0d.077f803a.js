"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8020],{28453:(e,n,o)=>{o.d(n,{R:()=>a,x:()=>s});var t=o(96540);const l={},r=t.createContext(l);function a(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:a(e.components),t.createElement(r.Provider,{value:n},e.children)}},67756:(e,n,o)=>{o.d(n,{B:()=>i});o(96540);const t=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var l=o(29030),r=o(56289),a=o(74848);const s=e=>{const n=e.split(".");for(let o=n.length;o>0;o--){const e=n.slice(0,o).join(".");if(t[e])return e}return null};function i(e){let{fn:n,children:o}=e;const i=s(n);if(!i)return(0,a.jsx)(a.Fragment,{children:o});const m=(0,l.Ay)(`/${t[i]}#${n}`);return(0,a.jsx)(r.A,{to:m,target:"_blank",children:o??(0,a.jsxs)("code",{children:[n,"()"]})})}},73041:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>c,contentTitle:()=>m,default:()=>p,frontMatter:()=>i,metadata:()=>t,toc:()=>f});const t=JSON.parse('{"id":"llms/sentence-transformers/guide/index","title":"Sentence Transformers within MLflow","description":"The sentence_transformers flavor is in active development and is marked as Experimental. Public APIs may change and new features are","source":"@site/docs/llms/sentence-transformers/guide/index.mdx","sourceDirName":"llms/sentence-transformers/guide","slug":"/llms/sentence-transformers/guide/","permalink":"/docs/latest/llms/sentence-transformers/guide/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"sidebar_label":"Detailed Guides"},"sidebar":"docsSidebar","previous":{"title":"Introduction to Advanced Semantic Similarity Analysis with Sentence Transformers and MLflow","permalink":"/docs/latest/llms/sentence-transformers/tutorials/semantic-similarity/semantic-similarity-sentence-transformers"},"next":{"title":"MLflow LLM Evaluation","permalink":"/docs/latest/llms/llm-evaluate/"}}');var l=o(74848),r=o(28453),a=o(56289),s=o(67756);const i={sidebar_position:2,sidebar_label:"Detailed Guides"},m="Sentence Transformers within MLflow",c={},f=[{value:"Tutorials for Sentence Transformers",id:"tutorials-for-sentence-transformers",level:2},{value:"Input and Output Types for PyFunc",id:"input-and-output-types-for-pyfunc",level:2},{value:"Saving and Logging Sentence Transformers Models",id:"saving-and-logging-sentence-transformers-models",level:2},{value:"Saving Sentence Transformers Models with an OpenAI-Compatible Inference Interface",id:"saving-sentence-transformers-models-with-an-openai-compatible-inference-interface",level:2},{value:"Custom Python Function Implementation",id:"custom-python-function-implementation",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.header,{children:(0,l.jsx)(n.h1,{id:"sentence-transformers-within-mlflow",children:"Sentence Transformers within MLflow"})}),"\n",(0,l.jsx)(n.admonition,{title:"attention",type:"warning",children:(0,l.jsxs)(n.p,{children:["The ",(0,l.jsx)(n.code,{children:"sentence_transformers"})," flavor is in active development and is marked as Experimental. Public APIs may change and new features are\nsubject to be added as additional functionality is brought to the flavor."]})}),"\n",(0,l.jsxs)(n.p,{children:["The ",(0,l.jsx)(n.code,{children:"sentence_transformers"})," model flavor enables logging of\n",(0,l.jsx)(n.a,{href:"https://www.sbert.net",children:"sentence-transformers models"})," in MLflow format via\nthe ",(0,l.jsx)(s.B,{fn:"mlflow.sentence_transformers.save_model"})," and ",(0,l.jsx)(s.B,{fn:"mlflow.sentence_transformers.log_model"})," functions. Using these\nfunctions also adds the ",(0,l.jsx)(n.code,{children:"python_function"})," flavor to the MLflow Models, enabling the model to be\ninterpreted as a generic Python function for inference via ",(0,l.jsx)(s.B,{fn:"mlflow.pyfunc.load_model"}),".\nAdditionally, ",(0,l.jsx)(s.B,{fn:"mlflow.sentence_transformers.load_model"})," can be used to load a saved or logged MLflow\nModel with the ",(0,l.jsx)(n.code,{children:"sentence_transformers"})," flavor in the native sentence-transformers format."]}),"\n",(0,l.jsx)(n.h2,{id:"tutorials-for-sentence-transformers",children:"Tutorials for Sentence Transformers"}),"\n",(0,l.jsx)(n.p,{children:"Looking to get right in to some usable examples and tutorials that show how to leverage this library with MLflow?"}),"\n",(0,l.jsx)(a.A,{className:"button button--primary",to:"/llms/sentence-transformers#getting-started-with-the-mlflow-sentence-transformers-flavor-tutorials-and-guides",children:(0,l.jsx)("span",{children:"See the Tutorials"})}),"\n",(0,l.jsx)(n.h2,{id:"input-and-output-types-for-pyfunc",children:"Input and Output Types for PyFunc"}),"\n",(0,l.jsxs)(n.p,{children:["The ",(0,l.jsx)(n.code,{children:"sentence_transformers"})," ",(0,l.jsx)(n.a,{href:"/model#pyfunc-model-flavor",children:"python_function (pyfunc) model flavor"})," standardizes\nthe process of embedding sentences and computing semantic similarity. This standardization allows for serving\nand batch inference by adapting the required data structures for ",(0,l.jsx)(n.code,{children:"sentence_transformers"})," into formats compatible with JSON serialization and casting to Pandas DataFrames."]}),"\n",(0,l.jsx)(n.admonition,{type:"note",children:(0,l.jsxs)(n.p,{children:["The ",(0,l.jsx)(n.code,{children:"sentence_transformers"})," flavor supports various models for tasks such as embedding generation, semantic similarity, and paraphrase mining. The specific input and output types will depend on the model and task being performed."]})}),"\n",(0,l.jsx)(n.h2,{id:"saving-and-logging-sentence-transformers-models",children:"Saving and Logging Sentence Transformers Models"}),"\n",(0,l.jsx)(n.p,{children:"You can save and log sentence-transformers models in MLflow. Here's an example of both saving and logging a model:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-Python",children:'import mlflow\nfrom sentence_transformers import SentenceTransformer\n\nmodel = SentenceTransformer("model_name")\n\n# Saving the model\nmlflow.sentence_transformers.save_model(model=model, path="path/to/save/directory")\n\n# Logging the model\nwith mlflow.start_run():\n    mlflow.sentence_transformers.log_model(\n        sentence_transformers_model=model, artifact_path="model_artifact_path"\n    )\n'})}),"\n",(0,l.jsx)(n.h2,{id:"saving-sentence-transformers-models-with-an-openai-compatible-inference-interface",children:"Saving Sentence Transformers Models with an OpenAI-Compatible Inference Interface"}),"\n",(0,l.jsx)(n.admonition,{type:"note",children:(0,l.jsx)(n.p,{children:"This feature is only available in MLflow 2.11.0 and above."})}),"\n",(0,l.jsxs)(n.p,{children:["MLflow's ",(0,l.jsx)(n.code,{children:"sentence_transformers"})," flavor allows you to pass in the ",(0,l.jsx)(n.code,{children:"task"})," param with the string value ",(0,l.jsx)(n.code,{children:'"llm/v1/embeddings"'}),"\nwhen saving a model with ",(0,l.jsx)(s.B,{fn:"mlflow.sentence_transformers.save_model"})," and ",(0,l.jsx)(s.B,{fn:"mlflow.sentence_transformers.log_model"}),"."]}),"\n",(0,l.jsx)(n.p,{children:"For example:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom sentence_transformers import SentenceTransformer\n\nmodel = SentenceTransformer("all-MiniLM-L6-v2")\n\nmlflow.sentence_transformers.save_model(\n    model=model, path="path/to/save/directory", task="llm/v1/embeddings"\n)\n'})}),"\n",(0,l.jsxs)(n.p,{children:["When ",(0,l.jsx)(n.code,{children:"task"})," is set as ",(0,l.jsx)(n.code,{children:'"llm/v1/embeddings"'}),", MLflow handles the following for you:"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Setting an embeddings compatible signature for the model"}),"\n",(0,l.jsxs)(n.li,{children:["Performing data pre- and post-processing to ensure the inputs and outputs conform to\nthe ",(0,l.jsx)(n.a,{href:"/llms/deployments/#embeddings",children:"Embeddings API spec"}),",\nwhich is compatible with OpenAI's API spec."]}),"\n"]}),"\n",(0,l.jsxs)(n.p,{children:["Note that these modifications only apply when the model is loaded with ",(0,l.jsx)(s.B,{fn:"mlflow.pyfunc.load_model"})," (e.g. when\nserving the model with the ",(0,l.jsx)(n.code,{children:"mlflow models serve"})," CLI tool). If you want to load just the base pipeline, you can\nalways do so via ",(0,l.jsx)(s.B,{fn:"mlflow.sentence_transformers.load_model"}),"."]}),"\n",(0,l.jsxs)(n.p,{children:["Aside from the ",(0,l.jsx)(n.code,{children:"sentence-transformers"})," flavor, the ",(0,l.jsx)(n.code,{children:"transformers"})," flavor also support OpenAI-compatible inference interface (",(0,l.jsx)(n.code,{children:'"llm/v1/chat"'})," and ",(0,l.jsx)(n.code,{children:'"llm/v1/completions"'}),"). Refer to\n",(0,l.jsx)(n.a,{href:"/llms/transformers/tutorials/conversational/pyfunc-chat-model",children:"the Transformers flavor guide"})," for more information."]}),"\n",(0,l.jsx)(n.h2,{id:"custom-python-function-implementation",children:"Custom Python Function Implementation"}),"\n",(0,l.jsxs)(n.p,{children:["In addition to using pre-built models, you can create custom Python functions with the ",(0,l.jsx)(n.em,{children:"sentence_transformers"})," flavor. Here's an example of a custom\nimplementation for comparing the similarity between text documents:"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom mlflow.pyfunc import PythonModel\nimport pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer, util\n\n\nclass DocumentSimilarityModel(PythonModel):\n    def load_context(self, context):\n        """Load the model context for inference."""\n        self.model = SentenceTransformer.load(context.artifacts["model_path"])\n\n    def predict(self, context, model_input):\n        """Predict method for comparing similarity between documents."""\n        if isinstance(model_input, pd.DataFrame) and model_input.shape[1] == 2:\n            documents = model_input.values\n        else:\n            raise ValueError("Input must be a DataFrame with exactly two columns.")\n\n        # Compute embeddings for each document separately\n        embeddings1 = self.model.encode(documents[:, 0], convert_to_tensor=True)\n        embeddings2 = self.model.encode(documents[:, 1], convert_to_tensor=True)\n\n        # Calculate cosine similarity\n        similarity_scores = util.cos_sim(embeddings1, embeddings2)\n\n        return pd.DataFrame(similarity_scores.numpy(), columns=["similarity_score"])\n\n\n# Example model saving and loading\nmodel = SentenceTransformer("all-MiniLM-L6-v2")\nmodel_path = "/tmp/sentence_transformers_model"\nmodel.save(model_path)\n\n# Example usage\nwith mlflow.start_run():\n    model_info = mlflow.pyfunc.log_model(\n        name="document_similarity_model",\n        python_model=DocumentSimilarityModel(),\n        artifacts={"model_path": model_path},\n    )\n\nloaded = mlflow.pyfunc.load_model(model_info.model_uri)\n\n# Test prediction\ndf = pd.DataFrame(\n    {\n        "doc1": ["Sentence Transformers is a wonderful package!"],\n        "doc2": ["MLflow is pretty great too!"],\n    }\n)\n\nresult = loaded.predict(df)\nprint(result)\n'})}),"\n",(0,l.jsx)(n.p,{children:"Which will generate the similarity score for the documents passed, as shown below:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"    similarity_score\n0          0.275423\n"})})]})}function p(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(d,{...e})}):d(e)}}}]);