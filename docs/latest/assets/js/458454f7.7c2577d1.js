"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4172],{878:(e,n,r)=>{r.d(n,{A:()=>t});const t=r.p+"assets/images/tracking-setup-local-server-cd51180e89bfd0a18c52f5b33e0f188d.png"},5729:(e,n,r)=>{r.d(n,{A:()=>t});const t=r.p+"assets/images/tracking-setup-artifacts-only-f9630e7e6dc87eab52eea8f85a706382.png"},10493:(e,n,r)=>{r.d(n,{Zp:()=>s,AC:()=>o,WO:()=>d,_C:()=>c,$3:()=>h,jK:()=>m});var t=r(34164);const a={CardGroup:"CardGroup_P84T",MaxThreeColumns:"MaxThreeColumns_FO1r",AutofillColumns:"AutofillColumns_fKhQ",Card:"Card_aSCR",CardBordered:"CardBordered_glGF",CardBody:"CardBody_BhRs",TextColor:"TextColor_a8Tp",BoxRoot:"BoxRoot_Etgr",FlexWrapNowrap:"FlexWrapNowrap_f60k",FlexJustifyContentFlexStart:"FlexJustifyContentFlexStart_ZYv5",FlexDirectionRow:"FlexDirectionRow_T2qL",FlexAlignItemsCenter:"FlexAlignItemsCenter_EHVM",FlexFlex:"FlexFlex__JTE",Link:"Link_fVkl",MarginLeft4:"MarginLeft4_YQSJ",MarginTop4:"MarginTop4_jXKN",PaddingBottom4:"PaddingBottom4_O9gt",LogoCardContent:"LogoCardContent_kCQm",LogoCardImage:"LogoCardImage_JdcX",SmallLogoCardContent:"SmallLogoCardContent_LxhV",SmallLogoCardImage:"SmallLogoCardImage_tPZl",NewFeatureCardContent:"NewFeatureCardContent_Rq3d",NewFeatureCardHeading:"NewFeatureCardHeading_f6q3",NewFeatureCardHeadingSeparator:"NewFeatureCardHeadingSeparator_pSx8",NewFeatureCardTags:"NewFeatureCardTags_IFHO",NewFeatureCardWrapper:"NewFeatureCardWrapper_NQ0k",TitleCardContent:"TitleCardContent_l9MQ",TitleCardTitle:"TitleCardTitle__K8J",TitleCardSeparator:"TitleCardSeparator_IN2E",Cols1:"Cols1_Gr2U",Cols2:"Cols2_sRvc",Cols3:"Cols3_KjUS",Cols4:"Cols4_dKOj",Cols5:"Cols5_jDmj",Cols6:"Cols6_Q0OR"};var l=r(28774),i=r(74848);const o=({children:e,isSmall:n,cols:r})=>(0,i.jsx)("div",{className:(0,t.A)(a.CardGroup,n?a.AutofillColumns:r?a[`Cols${r}`]:a.MaxThreeColumns),children:e}),s=({children:e,link:n=""})=>n?(0,i.jsx)(l.A,{className:(0,t.A)(a.Link,a.Card,a.CardBordered),to:n,children:e}):(0,i.jsx)("div",{className:(0,t.A)(a.Card,a.CardBordered),children:e}),c=({headerText:e,link:n,text:r})=>(0,i.jsx)(s,{link:n,children:(0,i.jsxs)("span",{children:[(0,i.jsx)("div",{className:(0,t.A)(a.CardTitle,a.BoxRoot,a.PaddingBottom4),style:{pointerEvents:"none"},children:(0,i.jsx)("div",{className:(0,t.A)(a.BoxRoot,a.FlexFlex,a.FlexAlignItemsCenter,a.FlexDirectionRow,a.FlexJustifyContentFlexStart,a.FlexWrapNowrap),style:{marginLeft:"-4px",marginTop:"-4px"},children:(0,i.jsx)("div",{className:(0,t.A)(a.BoxRoot,a.BoxHideIfEmpty,a.MarginTop4,a.MarginLeft4),style:{pointerEvents:"auto"},children:(0,i.jsx)("span",{className:"",children:e})})})}),(0,i.jsx)("span",{className:(0,t.A)(a.TextColor,a.CardBody),children:(0,i.jsx)("p",{children:r})})]})}),d=({description:e,children:n,link:r})=>(0,i.jsx)(s,{link:r,children:(0,i.jsxs)("div",{className:a.LogoCardContent,children:[(0,i.jsx)("div",{className:a.LogoCardImage,children:n}),(0,i.jsx)("p",{className:a.TextColor,children:e})]})}),h=({children:e,link:n})=>(0,i.jsx)(s,{link:n,children:(0,i.jsx)("div",{className:a.SmallLogoCardContent,children:(0,i.jsx)("div",{className:(0,t.A)("max-height-img-container",a.SmallLogoCardImage),children:e})})}),m=({title:e,description:n,link:r=""})=>(0,i.jsx)(s,{link:r,children:(0,i.jsxs)("div",{className:a.TitleCardContent,children:[(0,i.jsx)("div",{className:(0,t.A)(a.TitleCardTitle),style:{textAlign:"left",fontWeight:"bold"},children:e}),(0,i.jsx)("hr",{className:(0,t.A)(a.TitleCardSeparator),style:{margin:"12px 0"}}),(0,i.jsx)("p",{className:(0,t.A)(a.TextColor),children:n})]})})},11470:(e,n,r)=>{r.d(n,{A:()=>v});var t=r(96540),a=r(34164),l=r(23104),i=r(56347),o=r(205),s=r(57485),c=r(31682),d=r(70679);function h(e){return t.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,t.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function m(e){const{values:n,children:r}=e;return(0,t.useMemo)((()=>{const e=n??function(e){return h(e).map((({props:{value:e,label:n,attributes:r,default:t}})=>({value:e,label:n,attributes:r,default:t})))}(r);return function(e){const n=(0,c.XI)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,r])}function f({value:e,tabValues:n}){return n.some((n=>n.value===e))}function u({queryString:e=!1,groupId:n}){const r=(0,i.W6)(),a=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,s.aZ)(a),(0,t.useCallback)((e=>{if(!a)return;const n=new URLSearchParams(r.location.search);n.set(a,e),r.replace({...r.location,search:n.toString()})}),[a,r])]}function p(e){const{defaultValue:n,queryString:r=!1,groupId:a}=e,l=m(e),[i,s]=(0,t.useState)((()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!f({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const r=n.find((e=>e.default))??n[0];if(!r)throw new Error("Unexpected error: 0 tabValues");return r.value}({defaultValue:n,tabValues:l}))),[c,h]=u({queryString:r,groupId:a}),[p,g]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[r,a]=(0,d.Dv)(n);return[r,(0,t.useCallback)((e=>{n&&a.set(e)}),[n,a])]}({groupId:a}),x=(()=>{const e=c??p;return f({value:e,tabValues:l})?e:null})();(0,o.A)((()=>{x&&s(x)}),[x]);return{selectedValue:i,selectValue:(0,t.useCallback)((e=>{if(!f({value:e,tabValues:l}))throw new Error(`Can't select invalid tab value=${e}`);s(e),h(e),g(e)}),[h,g,l]),tabValues:l}}var g=r(92303);const x={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var w=r(74848);function y({className:e,block:n,selectedValue:r,selectValue:t,tabValues:i}){const o=[],{blockElementScrollPositionUntilNextRender:s}=(0,l.a_)(),c=e=>{const n=e.currentTarget,a=o.indexOf(n),l=i[a].value;l!==r&&(s(n),t(l))},d=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const r=o.indexOf(e.currentTarget)+1;n=o[r]??o[0];break}case"ArrowLeft":{const r=o.indexOf(e.currentTarget)-1;n=o[r]??o[o.length-1];break}}n?.focus()};return(0,w.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,a.A)("tabs",{"tabs--block":n},e),children:i.map((({value:e,label:n,attributes:t})=>(0,w.jsx)("li",{role:"tab",tabIndex:r===e?0:-1,"aria-selected":r===e,ref:e=>{o.push(e)},onKeyDown:d,onClick:c,...t,className:(0,a.A)("tabs__item",x.tabItem,t?.className,{"tabs__item--active":r===e}),children:n??e},e)))})}function k({lazy:e,children:n,selectedValue:r}){const l=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=l.find((e=>e.props.value===r));return e?(0,t.cloneElement)(e,{className:(0,a.A)("margin-top--md",e.props.className)}):null}return(0,w.jsx)("div",{className:"margin-top--md",children:l.map(((e,n)=>(0,t.cloneElement)(e,{key:n,hidden:e.props.value!==r})))})}function j(e){const n=p(e);return(0,w.jsxs)("div",{className:(0,a.A)("tabs-container",x.tabList),children:[(0,w.jsx)(y,{...n,...e}),(0,w.jsx)(k,{...n,...e})]})}function v(e){const n=(0,g.A)();return(0,w.jsx)(j,{...e,children:h(e.children)},String(n))}},19365:(e,n,r)=>{r.d(n,{A:()=>i});r(96540);var t=r(34164);const a={tabItem:"tabItem_Ymn6"};var l=r(74848);function i({children:e,hidden:n,className:r}){return(0,l.jsx)("div",{role:"tabpanel",className:(0,t.A)(a.tabItem,r),hidden:n,children:e})}},22044:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>u,contentTitle:()=>f,default:()=>x,frontMatter:()=>m,metadata:()=>t,toc:()=>p});const t=JSON.parse('{"id":"tracking/index","title":"MLflow Tracking","description":"The MLflow Tracking is an API and UI for logging parameters, code versions, metrics, and output files","source":"@site/docs/classic-ml/tracking/index.mdx","sourceDirName":"tracking","slug":"/tracking/","permalink":"/docs/latest/ml/tracking/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"sidebar_label":"Overview","sidebar_position":0},"sidebar":"classicMLSidebar","previous":{"title":"spaCy within MLflow","permalink":"/docs/latest/ml/deep-learning/spacy/guide/"},"next":{"title":"MLflow Tracking Quickstart","permalink":"/docs/latest/ml/tracking/quickstart/"}}');var a=r(74848),l=r(28453),i=r(28774),o=r(10493),s=r(49374),c=r(11470),d=r(19365),h=r(72839);const m={sidebar_label:"Overview",sidebar_position:0},f="MLflow Tracking",u={},p=[{value:"Quickstart",id:"quickstart",level:2},{value:"Concepts",id:"concepts",level:2},{value:"Runs",id:"runs",level:3},{value:"Models",id:"models",level:3},{value:"Experiments",id:"experiments",level:3},{value:"Tracking Runs",id:"start-logging",level:2},{value:"Searching Logged Models Programmatically",id:"search_logged_models",level:3},{value:"Querying Runs Programmatically",id:"tracking_query_api",level:3},{value:"Tracking Models",id:"tracking-models",level:2},{value:"Logging Model Checkpoints",id:"logging-model-checkpoints",level:3},{value:"Linking Metrics to Models and Datasets",id:"linking-metrics-to-models-and-datasets",level:3},{value:"Searching and Ranking Model Checkpoints",id:"searching-and-ranking-model-checkpoints",level:3},{value:"Model URIs in MLflow 3",id:"model-uris-in-mlflow-3",level:3},{value:"Tracking Datasets",id:"tracking-datasets",level:2},{value:"Explore Runs, Models, and Results",id:"explore-runs-models-and-results",level:2},{value:"Tracking UI",id:"tracking_ui",level:3},{value:"Set up the MLflow Tracking Environment",id:"tracking-setup",level:2},{value:"Components",id:"components",level:3},{value:"MLflow Tracking APIs",id:"mlflow-tracking-apis",level:4},{value:"Backend Store",id:"backend-store",level:4},{value:"Artifact Store",id:"artifact-stores",level:4},{value:"MLflow Tracking Server (Optional)",id:"tracking_server",level:4},{value:"Common Setups",id:"tracking_setup",level:3},{value:"Other Configuration with MLflow Tracking Server",id:"other-tracking-setup",level:2},{value:"Using MLflow Tracking Server Locally",id:"using-mlflow-tracking-server-locally",level:4},{value:"Running MLflow Tracking Server in Artifacts-only Mode",id:"running-mlflow-tracking-server-in-artifacts-only-mode",level:4},{value:"Disable Artifact Proxying to Allow Direct Access to Artifacts",id:"disable-artifact-proxying-to-allow-direct-access-to-artifacts",level:4},{value:"FAQ",id:"faq",level:2},{value:"Can I launch multiple runs in parallel?",id:"can-i-launch-multiple-runs-in-parallel",level:3},{value:"How can I organize many MLflow Runs neatly?",id:"how-can-i-organize-many-mlflow-runs-neatly",level:3},{value:"Can I directly access remote storage without running the Tracking Server?",id:"can-i-directly-access-remote-storage-without-running-the-tracking-server",level:3},{value:"How to integrate MLflow Tracking with Model Registry?",id:"tracking-with-model-registry",level:4},{value:"How to include additional description texts about the run?",id:"how-to-include-additional-description-texts-about-the-run",level:4}];function g(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"mlflow-tracking",children:"MLflow Tracking"})}),"\n",(0,a.jsxs)(n.p,{children:["The MLflow Tracking is an API and UI for logging parameters, code versions, metrics, and output files\nwhen running your machine learning code and for later visualizing the results.\nMLflow Tracking provides ",(0,a.jsx)(i.A,{to:"/api_reference/python_api/index.html",target:"_blank",children:"Python"}),"\n, ",(0,a.jsx)(i.A,{to:"/api_reference/rest-api.html",target:"_blank",children:"REST"}),"\n, ",(0,a.jsx)(i.A,{to:"/api_reference/R-api.html",target:"_blank",children:"R"}),",\nand ",(0,a.jsx)(i.A,{to:"/api_reference/java_api/index.html",target:"_blank",children:"Java"})," APIs."]}),"\n",(0,a.jsx)("figure",{children:(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.img,{src:r(89180).A+"",width:"1537",height:"842"}),"\n",(0,a.jsx)("figcaption",{children:"A screenshot of the MLflow Tracking UI, showing a plot of validation loss metrics during model training."})]})}),"\n",(0,a.jsx)(n.h2,{id:"quickstart",children:"Quickstart"}),"\n",(0,a.jsx)(n.p,{children:"If you haven't used MLflow Tracking before, we strongly recommend going through the following quickstart tutorial."}),"\n",(0,a.jsx)(o.AC,{children:(0,a.jsx)(o._C,{headerText:"MLflow Tracking Quickstart",link:"/ml/tracking/quickstart",text:"A great place to start to learn the fundamentals of MLflow Tracking! Learn in 5 minutes how to log, register, and load a model for inference."})}),"\n",(0,a.jsx)(n.h2,{id:"concepts",children:"Concepts"}),"\n",(0,a.jsx)(n.h3,{id:"runs",children:"Runs"}),"\n",(0,a.jsxs)(n.p,{children:["MLflow Tracking is organized around the concept of ",(0,a.jsx)(n.strong,{children:"runs"}),", which are executions of some piece of\ndata science code, for example, a single ",(0,a.jsx)(n.code,{children:"python train.py"})," execution. Each run records metadata\n(various information about your run such as metrics, parameters, start and end times) and artifacts\n(output files from the run such as model weights, images, etc)."]}),"\n",(0,a.jsx)(n.h3,{id:"models",children:"Models"}),"\n",(0,a.jsx)(n.p,{children:"Models represent the trained machine learning artifacts that are produced during your runs. Logged Models contain their own metadata and artifacts similar to runs."}),"\n",(0,a.jsx)(n.h3,{id:"experiments",children:"Experiments"}),"\n",(0,a.jsxs)(n.p,{children:["An experiment groups together runs and models for a specific task. You can create an experiment using the CLI, API, or UI.\nThe MLflow API and UI also let you create and search for experiments. See ",(0,a.jsx)(n.a,{href:"/ml/tracking/tracking-api#experiment-organization",children:"Organizing Runs into Experiments"}),"\nfor more details on how to organize your runs into experiments."]}),"\n",(0,a.jsx)(n.h2,{id:"start-logging",children:"Tracking Runs"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"/ml/tracking/tracking-api",children:"MLflow Tracking APIs"})," provide a set of functions to track your runs. For example, you can call ",(0,a.jsx)(s.B,{fn:"mlflow.start_run"})," to start a new run,\nthen call ",(0,a.jsx)(n.a,{href:"/ml/tracking/tracking-api",children:"Logging Functions"})," such as ",(0,a.jsx)(s.B,{fn:"mlflow.log_param"})," and ",(0,a.jsx)(s.B,{fn:"mlflow.log_metric"})," to log parameters and metrics respectively.\nPlease visit the ",(0,a.jsx)(n.a,{href:"/ml/tracking/tracking-api",children:"Tracking API documentation"})," for more details about using these APIs."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\n\nwith mlflow.start_run():\n    mlflow.log_param("lr", 0.001)\n    # Your ml code\n    ...\n    mlflow.log_metric("val_loss", val_loss)\n'})}),"\n",(0,a.jsxs)(n.p,{children:["Alternatively, ",(0,a.jsx)(n.a,{href:"/ml/tracking/autolog",children:"Auto-logging"})," offers an ultra-quick setup for starting MLflow tracking.\nThis powerful feature allows you to log metrics, parameters, and models without the need for explicit log statements -\nall you need to do is call ",(0,a.jsx)(s.B,{fn:"mlflow.autolog"})," before your training code. Auto-logging supports popular\nlibraries such as ",(0,a.jsx)(n.a,{href:"/ml/tracking/autolog#autolog-sklearn",children:"Scikit-learn"}),", ",(0,a.jsx)(n.a,{href:"/ml/tracking/autolog#autolog-xgboost",children:"XGBoost"}),", ",(0,a.jsx)(n.a,{href:"/ml/tracking/autolog#autolog-pytorch",children:"PyTorch"}),",\n",(0,a.jsx)(n.a,{href:"/ml/tracking/autolog#autolog-keras",children:"Keras"}),", ",(0,a.jsx)(n.a,{href:"/ml/tracking/autolog#autolog-spark",children:"Spark"}),", and more. See ",(0,a.jsx)(n.a,{href:"/ml/tracking/autolog",children:"Automatic Logging Documentation"}),"\nfor supported libraries and how to use auto-logging APIs with each of them."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import mlflow\n\nmlflow.autolog()\n\n# Your training code...\n"})}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["By default, without any particular server/database configuration, MLflow Tracking logs data to the local ",(0,a.jsx)(n.code,{children:"mlruns"})," directory.\nIf you want to log your runs to a different location, such as a remote database and cloud storage, in order to share your results with\nyour team, follow the instructions in the ",(0,a.jsx)(n.a,{href:"#tracking-setup",children:"Set up MLflow Tracking Environment"})," section."]})}),"\n",(0,a.jsx)(n.h3,{id:"search_logged_models",children:"Searching Logged Models Programmatically"}),"\n",(0,a.jsxs)(n.p,{children:["MLflow 3 introduces powerful model search capabilities through ",(0,a.jsx)(s.B,{fn:"mlflow.search_logged_models"}),". This API allows you to find specific models across your experiments based on performance metrics, parameters, and model attributes using SQL-like syntax."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\n\n# Find high-performing models across experiments\ntop_models = mlflow.search_logged_models(\n    experiment_ids=["1", "2"],\n    filter_string="metrics.accuracy > 0.95 AND params.model_type = \'RandomForest\'",\n    order_by=[{"field_name": "metrics.f1_score", "ascending": False}],\n    max_results=5,\n)\n\n# Get the best model for deployment\nbest_model = mlflow.search_logged_models(\n    experiment_ids=["1"],\n    filter_string="metrics.accuracy > 0.9",\n    max_results=1,\n    order_by=[{"field_name": "metrics.accuracy", "ascending": False}],\n    output_format="list",\n)[0]\n\n# Load the best model directly\nloaded_model = mlflow.pyfunc.load_model(f"models:/{best_model.model_id}")\n'})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Key Features:"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"SQL-like filtering"}),": Use ",(0,a.jsx)(n.code,{children:"metrics."}),", ",(0,a.jsx)(n.code,{children:"params."}),", and attribute prefixes to build complex queries"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Dataset-aware search"}),": Filter metrics based on specific datasets for fair model comparison"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Flexible ordering"}),": Sort by multiple criteria to find the best models"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Direct model loading"}),": Use the new ",(0,a.jsx)(n.code,{children:"models:/<model_id>"})," URI format for immediate model access"]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["For comprehensive examples and advanced search patterns, see the ",(0,a.jsx)(n.a,{href:"/ml/search/search-models",children:"Search Logged Models Guide"}),"."]}),"\n",(0,a.jsx)(n.h3,{id:"tracking_query_api",children:"Querying Runs Programmatically"}),"\n",(0,a.jsxs)(n.p,{children:["You can also access all of the functions in the Tracking UI programmatically with ",(0,a.jsx)(s.B,{fn:"mlflow.client.MlflowClient",children:"MlflowClient"}),"."]}),"\n",(0,a.jsx)(n.p,{children:"For example, the following code snippet search for runs that has the best validation loss among all runs in the experiment."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"client = mlflow.tracking.MlflowClient()\nexperiment_id = \"0\"\nbest_run = client.search_runs(\n    experiment_id, order_by=[\"metrics.val_loss ASC\"], max_results=1\n)[0]\nprint(best_run.info)\n# {'run_id': '...', 'metrics': {'val_loss': 0.123}, ...}\n"})}),"\n",(0,a.jsx)(n.h2,{id:"tracking-models",children:"Tracking Models"}),"\n",(0,a.jsx)(n.p,{children:"MLflow 3 introduces enhanced model tracking capabilities that allow you to log multiple model checkpoints within a single run and track their performance against different datasets. This is particularly useful for deep learning workflows where you want to save and compare model checkpoints at different training stages."}),"\n",(0,a.jsx)(n.h3,{id:"logging-model-checkpoints",children:"Logging Model Checkpoints"}),"\n",(0,a.jsxs)(n.p,{children:["You can log model checkpoints at different steps during training using the ",(0,a.jsx)(n.code,{children:"step"})," parameter in model logging functions. Each logged model gets a unique model ID that you can use to reference it later."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport mlflow.pytorch\n\nwith mlflow.start_run() as run:\n    for epoch in range(100):\n        # Train your model\n        train_model(model, epoch)\n\n        # Log model checkpoint every 10 epochs\n        if epoch % 10 == 0:\n            model_info = mlflow.pytorch.log_model(\n                pytorch_model=model,\n                name=f"checkpoint-epoch-{epoch}",\n                step=epoch,\n                input_example=sample_input,\n            )\n\n            # Log metrics linked to this specific model checkpoint\n            accuracy = evaluate_model(model, validation_data)\n            mlflow.log_metric(\n                key="accuracy",\n                value=accuracy,\n                step=epoch,\n                model_id=model_info.model_id,  # Link metric to specific model\n                dataset=validation_dataset,\n            )\n'})}),"\n",(0,a.jsx)(n.h3,{id:"linking-metrics-to-models-and-datasets",children:"Linking Metrics to Models and Datasets"}),"\n",(0,a.jsx)(n.p,{children:"MLflow 3 allows you to link metrics to specific model checkpoints and datasets, providing better traceability of model performance:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Create a dataset reference\ntrain_dataset = mlflow.data.from_pandas(train_df, name="training_data")\n\n# Log metric with model and dataset links\nmlflow.log_metric(\n    key="f1_score",\n    value=0.95,\n    step=epoch,\n    model_id=model_info.model_id,  # Links to specific model checkpoint\n    dataset=train_dataset,  # Links to specific dataset\n)\n'})}),"\n",(0,a.jsx)(n.h3,{id:"searching-and-ranking-model-checkpoints",children:"Searching and Ranking Model Checkpoints"}),"\n",(0,a.jsxs)(n.p,{children:["Use ",(0,a.jsx)(s.B,{fn:"mlflow.search_logged_models"})," to search and rank model checkpoints based on their performance metrics:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Search for all models in a run, ordered by accuracy\nranked_models = mlflow.search_logged_models(\n    filter_string=f"source_run_id=\'{run.info.run_id}\'",\n    order_by=[{"field_name": "metrics.accuracy", "ascending": False}],\n    output_format="list",\n)\n\n# Get the best performing model\nbest_model = ranked_models[0]\nprint(f"Best model: {best_model.name}")\nprint(f"Accuracy: {best_model.metrics[0].value}")\n\n# Load the best model for inference\nloaded_model = mlflow.pyfunc.load_model(f"models:/{best_model.model_id}")\n'})}),"\n",(0,a.jsx)(n.h3,{id:"model-uris-in-mlflow-3",children:"Model URIs in MLflow 3"}),"\n",(0,a.jsx)(n.p,{children:"MLflow 3 introduces a new model URI format that uses model IDs instead of run IDs, providing more direct model referencing:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# New MLflow 3 model URI format\nmodel_uri = f"models:/{model_info.model_id}"\nloaded_model = mlflow.pyfunc.load_model(model_uri)\n\n# This replaces the older run-based URI format:\n# model_uri = f"runs:/{run_id}/model_path"\n'})}),"\n",(0,a.jsx)(n.p,{children:"This new approach provides several advantages:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Direct model reference"}),": No need to know the run ID and artifact path"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Better model lifecycle management"}),": Each model checkpoint has its own unique identifier"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Improved model comparison"}),": Easily compare different checkpoints within the same run"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Enhanced traceability"}),": Clear links between models, metrics, and datasets"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"tracking-datasets",children:"Tracking Datasets"}),"\n",(0,a.jsxs)(n.p,{children:["MLflow offers the ability to track datasets that are associated with model training events. These metadata associated with the Dataset can be stored through the use of the ",(0,a.jsx)(s.B,{fn:"mlflow.log_input"})," API.\nTo learn more, please visit the ",(0,a.jsx)(n.a,{href:"/ml/dataset/",children:"MLflow data documentation"})," to see the features available in this API."]}),"\n",(0,a.jsx)(n.h2,{id:"explore-runs-models-and-results",children:"Explore Runs, Models, and Results"}),"\n",(0,a.jsx)(n.h3,{id:"tracking_ui",children:"Tracking UI"}),"\n",(0,a.jsx)(n.p,{children:"The Tracking UI lets you visually explore your experiments, runs, and models, as shown on top of this page."}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Experiment-based run listing and comparison (including run comparison across multiple experiments)"}),"\n",(0,a.jsx)(n.li,{children:"Searching for runs by parameter or metric value"}),"\n",(0,a.jsx)(n.li,{children:"Visualizing run metrics"}),"\n",(0,a.jsx)(n.li,{children:"Downloading run results (artifacts and metadata)"}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"These features are available for models as well, as shown below."}),"\n",(0,a.jsx)("figure",{children:(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.img,{alt:"MLflow UI Experiment view page models tab",src:r(47780).A+"",width:"3834",height:"1926"}),"\n",(0,a.jsx)("figcaption",{children:"A screenshot of the MLflow Tracking UI on the models tab, showing a list of models under the experiment."})]})}),"\n",(0,a.jsxs)(n.p,{children:["If you log runs to a local ",(0,a.jsx)(n.code,{children:"mlruns"})," directory, run the following command in the directory above it,\nthen access ",(0,a.jsx)(n.a,{href:"http://127.0.0.1:5000",children:"http://127.0.0.1:5000"})," in your browser."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"mlflow ui --port 5000\n"})}),"\n",(0,a.jsxs)(n.p,{children:["Alternatively, the ",(0,a.jsx)(n.a,{href:"#tracking_server",children:"MLflow Tracking Server"})," serves the same UI and enables remote\nstorage of run artifacts. In that case, you can view the UI at ",(0,a.jsx)(n.code,{children:"http://<IP address of your MLflow tracking server>:5000"}),"\nfrom any machine that can connect to your tracking server."]}),"\n",(0,a.jsx)(n.h2,{id:"tracking-setup",children:"Set up the MLflow Tracking Environment"}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsx)(n.p,{children:"If you just want to log your experiment data and models to local files, you can skip this section."})}),"\n",(0,a.jsx)(n.p,{children:"MLflow Tracking supports many different scenarios for your development workflow. This section will guide you through how to set up the MLflow Tracking environment for your particular use case.\nFrom a bird's-eye view, the MLflow Tracking environment consists of the following components."}),"\n",(0,a.jsx)(n.h3,{id:"components",children:"Components"}),"\n",(0,a.jsx)(n.h4,{id:"mlflow-tracking-apis",children:(0,a.jsx)(n.a,{href:"/ml/tracking/tracking-api",children:"MLflow Tracking APIs"})}),"\n",(0,a.jsx)(n.p,{children:"You can call MLflow Tracking APIs in your ML code to log runs and communicate with the MLflow Tracking Server if necessary."}),"\n",(0,a.jsx)(n.h4,{id:"backend-store",children:(0,a.jsx)(n.a,{href:"/ml/tracking/backend-stores",children:"Backend Store"})}),"\n",(0,a.jsxs)(n.p,{children:["The backend store persists various metadata for each ",(0,a.jsx)(n.a,{href:"#runs",children:"Run"}),", such as run ID, start and end times, parameters, metrics, etc.\nMLflow supports two types of storage for the backend: ",(0,a.jsx)(n.strong,{children:"file-system-based"})," like local files and ",(0,a.jsx)(n.strong,{children:"database-based"})," like PostgreSQL."]}),"\n",(0,a.jsx)(n.p,{children:"Additionally, if you are interfacing with a managed service (such as Databricks or Azure Machine Learning), you will be interfacing with a\nREST-based backend store that is externally managed and not directly accessible."}),"\n",(0,a.jsx)(n.h4,{id:"artifact-stores",children:(0,a.jsx)(n.a,{href:"/ml/tracking/artifact-stores",children:"Artifact Store"})}),"\n",(0,a.jsxs)(n.p,{children:["Artifact store persists (typically large) artifacts for each run, such as model weights (e.g. a pickled scikit-learn model),\nimages (e.g. PNGs), model and data files (e.g. ",(0,a.jsx)(n.a,{href:"https://parquet.apache.org",children:"Parquet"})," file). MLflow stores artifacts ina a\nlocal file (",(0,a.jsx)(n.code,{children:"mlruns"}),") by default, but also supports different storage options such as Amazon S3 and Azure Blob Storage."]}),"\n",(0,a.jsxs)(n.p,{children:["For models which are logged as MLflow artifacts, you can refer the model through a model URI of format: ",(0,a.jsx)(n.code,{children:"models:/<model_id>"}),",\nwhere 'model_id' is the unique identifier assigned to the logged model. This replaces the older ",(0,a.jsx)(n.code,{children:"runs:/<run_id>/<artifact_path>"})," format\nand provides more direct model referencing."]}),"\n",(0,a.jsxs)(n.p,{children:["If the model is registered in the ",(0,a.jsx)(n.a,{href:"/ml/model-registry",children:"MLflow Model Registry"}),",\nyou can also refer the the model through a model URI of format: ",(0,a.jsx)(n.code,{children:"models:/<model-name>/<model-version>"}),",\nsee ",(0,a.jsx)(n.a,{href:"/ml/model-registry",children:"MLflow Model Registry"})," for details."]}),"\n",(0,a.jsxs)(n.h4,{id:"tracking_server",children:[(0,a.jsx)(n.a,{href:"/ml/tracking/server",children:"MLflow Tracking Server"})," (Optional)"]}),"\n",(0,a.jsxs)(n.p,{children:["MLflow Tracking Server is a stand-alone HTTP server that provides REST APIs for accessing backend and/or artifact store.\nTracking server also offers flexibility to configure what data to server, govern access control, versioning, and etc. Read\n",(0,a.jsx)(n.a,{href:"/ml/tracking/server",children:"MLflow Tracking Server documentation"})," for more details."]}),"\n",(0,a.jsx)(n.h3,{id:"tracking_setup",children:"Common Setups"}),"\n",(0,a.jsx)(n.p,{children:"By configuring these components properly, you can create an MLflow Tracking environment suitable for your team's development workflow.\nThe following diagram and table show a few common setups for the MLflow Tracking environment."}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:r(35312).A+"",width:"2393",height:"1454"})}),"\n",(0,a.jsxs)(h.X,{children:[(0,a.jsx)("thead",{children:(0,a.jsxs)("tr",{children:[(0,a.jsx)("th",{}),(0,a.jsx)("th",{children:"1. Localhost (default)"}),(0,a.jsx)("th",{children:"2. Local Tracking with Local Database"}),(0,a.jsxs)("th",{children:["3. Remote Tracking with ",(0,a.jsx)(n.a,{href:"#tracking_server",children:"MLflow Tracking Server"})]})]})}),(0,a.jsxs)("tbody",{children:[(0,a.jsxs)("tr",{children:[(0,a.jsx)("th",{children:"Scenario"}),(0,a.jsx)("td",{children:"Solo development"}),(0,a.jsx)("td",{children:"Solo development"}),(0,a.jsx)("td",{children:"Team development"})]}),(0,a.jsxs)("tr",{children:[(0,a.jsx)("th",{children:"Use Case"}),(0,a.jsxs)("td",{children:["By default, MLflow records metadata and artifacts for each run to a local directory, ",(0,a.jsx)(n.code,{children:"mlruns"}),". This is the simplest way to get started with MLflow Tracking, without setting up any external server, database, and storage."]}),(0,a.jsxs)("td",{children:["The MLflow client can interface with a SQLAlchemy-compatible database (e.g., SQLite, PostgreSQL, MySQL) for the ",(0,a.jsx)(n.a,{href:"/ml/tracking/backend-stores",children:"backend"}),". Saving metadata to a database allows you cleaner management of your experiment data while skipping the effort of setting up a server."]}),(0,a.jsx)("td",{children:"MLflow Tracking Server can be configured with an artifacts HTTP proxy, passing artifact requests through the tracking server to store and retrieve artifacts without having to interact with underlying object store services. This is particularly useful for team development scenarios where you want to store artifacts and experiment metadata in a shared location with proper access control."})]}),(0,a.jsxs)("tr",{children:[(0,a.jsx)("th",{children:"Tutorial"}),(0,a.jsx)("td",{children:(0,a.jsx)(n.a,{href:"/ml/tracking/quickstart",children:"QuickStart"})}),(0,a.jsx)("td",{children:(0,a.jsx)(n.a,{href:"/ml/tracking/tutorials/local-database",children:"Tracking Experiments using a Local Database"})}),(0,a.jsx)("td",{children:(0,a.jsx)(n.a,{href:"/ml/tracking/tutorials/remote-server",children:"Remote Experiment Tracking with MLflow Tracking Server"})})]})]})]}),"\n",(0,a.jsxs)(n.h2,{id:"other-tracking-setup",children:["Other Configuration with ",(0,a.jsx)(n.a,{href:"#tracking_server",children:"MLflow Tracking Server"})]}),"\n",(0,a.jsxs)(n.p,{children:["MLflow Tracking Server provides customizability for other special use cases. Please follow\n",(0,a.jsx)(n.a,{href:"/ml/tracking/tutorials/remote-server",children:"Remote Experiment Tracking with MLflow Tracking Server"})," for learning\nthe basic setup and continue to the following materials for advanced configurations to meet your needs."]}),"\n",(0,a.jsxs)(c.A,{children:[(0,a.jsxs)(d.A,{label:"Local Tracking Server",value:"local-tracking-server",default:!0,children:[(0,a.jsx)(n.h4,{id:"using-mlflow-tracking-server-locally",children:"Using MLflow Tracking Server Locally"}),(0,a.jsx)(n.p,{children:"You can of course run MLflow Tracking Server locally. While this doesn't provide much additional benefit over directly using\nthe local files or database, might useful for testing your team development workflow locally or running your machine learning\ncode on a container environment."}),(0,a.jsx)("div",{class:"center-div",style:{width:"50%"},children:(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:r(878).A+"",width:"911",height:"746"})})})]}),(0,a.jsxs)(d.A,{label:"Artifacts-only Mode",value:"artifacts-only-mode",children:[(0,a.jsx)(n.h4,{id:"running-mlflow-tracking-server-in-artifacts-only-mode",children:"Running MLflow Tracking Server in Artifacts-only Mode"}),(0,a.jsxs)(n.p,{children:["MLflow Tracking Server has an ",(0,a.jsx)(n.code,{children:"--artifacts-only"})," option which allows the server to handle (proxy) exclusively artifacts, without permitting\nthe processing of metadata. This is particularly useful when you are in a large organization or are training extremely large models. In these scenarios, you might have high artifact\ntransfer volumes and can benefit from splitting out the traffic for serving artifacts to not impact tracking functionality. Please read\n",(0,a.jsx)(n.a,{href:"/ml/tracking/server#tracking-server-artifacts-only",children:"Optionally using a Tracking Server instance exclusively for artifact handling"}),"\nfor more details on how to use this mode."]}),(0,a.jsx)("div",{class:"center-div",style:{width:"50%"},children:(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:r(5729).A+"",width:"972",height:"725"})})})]}),(0,a.jsxs)(d.A,{label:"Direct Access to Artifacts",value:"direct-access-to-artifacts",children:[(0,a.jsx)(n.h4,{id:"disable-artifact-proxying-to-allow-direct-access-to-artifacts",children:"Disable Artifact Proxying to Allow Direct Access to Artifacts"}),(0,a.jsxs)(n.p,{children:["MLflow Tracking Server, by default, serves both artifacts and only metadata. However, in some cases, you may want\nto allow direct access to the remote artifacts storage to avoid the overhead of a proxy while preserving the functionality\nof metadata tracking. This can be done by disabling artifact proxying by starting server with ",(0,a.jsx)(n.code,{children:"--no-serve-artifacts"})," option.\nRefer to ",(0,a.jsx)(n.a,{href:"/ml/tracking/server#tracking-server-no-proxy",children:"Use Tracking Server without Proxying Artifacts Access"}),"\nfor how to set this up."]}),(0,a.jsx)("div",{class:"center-div",style:{width:"50%"},children:(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{src:r(67716).A+"",width:"974",height:"1059"})})})]})]}),"\n",(0,a.jsx)(n.h2,{id:"faq",children:"FAQ"}),"\n",(0,a.jsx)(n.h3,{id:"can-i-launch-multiple-runs-in-parallel",children:"Can I launch multiple runs in parallel?"}),"\n",(0,a.jsxs)(n.p,{children:["Yes, MLflow supports launching multiple runs in parallel e.g. multi processing / threading.\nSee ",(0,a.jsx)(n.a,{href:"/ml/tracking/tracking-api#parallel-execution-strategies",children:"Launching Multiple Runs in One Program"})," for more details."]}),"\n",(0,a.jsx)(n.h3,{id:"how-can-i-organize-many-mlflow-runs-neatly",children:"How can I organize many MLflow Runs neatly?"}),"\n",(0,a.jsx)(n.p,{children:"MLflow provides a few ways to organize your runs:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"/ml/tracking/tracking-api#experiment-organization",children:"Organize runs into experiments"})," - Experiments are logical containers for your runs. You can create an experiment using the CLI, API, or UI."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"/ml/tracking/tracking-api#hierarchical-runs-with-parent-child-relationships",children:"Create child runs"})," - You can create child runs under a single parent run to group them together. For example, you can create a child run for each fold in a cross-validation experiment."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"/ml/tracking/tracking-api#smart-tagging-for-organization",children:"Add tags to runs"})," - You can associate arbitrary tags with each run, which allows you to filter and search runs based on tags."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"can-i-directly-access-remote-storage-without-running-the-tracking-server",children:"Can I directly access remote storage without running the Tracking Server?"}),"\n",(0,a.jsx)(n.p,{children:"Yes, while it is best practice to have the MLflow Tracking Server as a proxy for artifacts access for team development workflows, you may not need that\nif you are using it for personal projects or testing. You can achieve this by following the workaround below:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["Set up artifacts configuration such as credentials and endpoints, just like you would for the MLflow Tracking Server.\nSee ",(0,a.jsx)(n.a,{href:"/ml/tracking/artifact-stores#artifacts-store-supported-storages",children:"configure artifact storage"})," for more details."]}),"\n",(0,a.jsx)(n.li,{children:"Create an experiment with an explicit artifact location,"}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'experiment_name = "your_experiment_name"\nmlflow.create_experiment(experiment_name, artifact_location="s3://your-bucket")\nmlflow.set_experiment(experiment_name)\n'})}),"\n",(0,a.jsx)(n.p,{children:"Your runs under this experiment will log artifacts to the remote storage directly."}),"\n",(0,a.jsxs)(n.h4,{id:"tracking-with-model-registry",children:["How to integrate MLflow Tracking with ",(0,a.jsx)(n.a,{href:"/ml/model-registry",children:"Model Registry"}),"?"]}),"\n",(0,a.jsxs)(n.p,{children:["To use the Model Registry functionality with MLflow tracking, you ",(0,a.jsx)(n.strong,{children:"must use database backed store"})," such as PostgresQL and log a model using the ",(0,a.jsx)(n.code,{children:"log_model"})," methods of the corresponding model flavors.\nOnce a model has been logged, you can add, modify, update, or delete the model in the Model Registry through the UI or the API.\nSee ",(0,a.jsx)(n.a,{href:"/ml/tracking/backend-stores",children:"Backend Stores"})," and ",(0,a.jsx)(n.a,{href:"#tracking_setup",children:"Common Setups"})," for how to configures backend store properly for your workflow."]}),"\n",(0,a.jsx)(n.h4,{id:"how-to-include-additional-description-texts-about-the-run",children:"How to include additional description texts about the run?"}),"\n",(0,a.jsxs)(n.p,{children:["A system tag ",(0,a.jsx)(n.code,{children:"mlflow.note.content"})," can be used to add descriptive note about this run. While the other ",(0,a.jsx)(n.a,{href:"/ml/tracking/tracking-api#system-tags-reference",children:"system tags"})," are set automatically,\nthis tag is ",(0,a.jsx)(n.strong,{children:"not set by default"})," and users can override it to include additional information about the run. The content will be displayed on the run's page under\nthe Notes section."]})]})}function x(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(g,{...e})}):g(e)}},28453:(e,n,r)=>{r.d(n,{R:()=>i,x:()=>o});var t=r(96540);const a={},l=t.createContext(a);function i(e){const n=t.useContext(l);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),t.createElement(l.Provider,{value:n},e.children)}},35312:(e,n,r)=>{r.d(n,{A:()=>t});const t=r.p+"assets/images/tracking-setup-overview-3d8cfd511355d9379328d69573763331.png"},47780:(e,n,r)=>{r.d(n,{A:()=>t});const t=r.p+"assets/images/tracking-models-ui-0f88d40c517e103cdead462aab12781a.png"},49374:(e,n,r)=>{r.d(n,{B:()=>s});r(96540);const t=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var a=r(86025),l=r(28774),i=r(74848);const o=e=>{const n=e.split(".");for(let r=n.length;r>0;r--){const e=n.slice(0,r).join(".");if(t[e])return e}return null};function s({fn:e,children:n}){const r=o(e);if(!r)return(0,i.jsx)(i.Fragment,{children:n});const s=(0,a.Ay)(`/${t[r]}#${e}`);return(0,i.jsx)(l.A,{to:s,target:"_blank",children:n??(0,i.jsxs)("code",{children:[e,"()"]})})}},67716:(e,n,r)=>{r.d(n,{A:()=>t});const t=r.p+"assets/images/tracking-setup-no-serve-artifacts-9e21c03b857275a42dc667e4454fba37.png"},72839:(e,n,r)=>{r.d(n,{X:()=>a});var t=r(74848);function a({children:e}){return(0,t.jsx)("div",{className:"w-full overflow-x-auto",children:(0,t.jsx)("table",{children:e})})}},89180:(e,n,r)=>{r.d(n,{A:()=>t});const t=r.p+"assets/images/tracking-metrics-ui-temp-ffc0da57b388076730e20207dbd7f9c4.png"}}]);