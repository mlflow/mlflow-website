"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7167],{19418:(e,n,r)=>{r.d(n,{A:()=>t});const t=r.p+"assets/images/semantic-search-arch-97a3a588b74143ad9f7096dce599380b.png"},28453:(e,n,r)=>{r.d(n,{R:()=>a,x:()=>l});var t=r(96540);const s={},i=t.createContext(s);function a(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),t.createElement(i.Provider,{value:n},e.children)}},67756:(e,n,r)=>{r.d(n,{B:()=>o});r(96540);const t=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var s=r(29030),i=r(56289),a=r(74848);const l=e=>{const n=e.split(".");for(let r=n.length;r>0;r--){const e=n.slice(0,r).join(".");if(t[e])return e}return null};function o(e){let{fn:n,children:r}=e;const o=l(n);if(!o)return(0,a.jsx)(a.Fragment,{children:r});const c=(0,s.Ay)(`/${t[o]}#${n}`);return(0,a.jsx)(i.A,{to:c,target:"_blank",children:r??(0,a.jsxs)("code",{children:[n,"()"]})})}},83832:(e,n,r)=>{r.d(n,{A:()=>t});const t=r.p+"assets/images/sentence-transformers-architecture-b83485a83e698e3e1576f44024570e81.png"},86294:(e,n,r)=>{r.d(n,{Zp:()=>o,AC:()=>l,WO:()=>d,tf:()=>h,_C:()=>c,$3:()=>m,jK:()=>f});var t=r(34164);const s={CardGroup:"CardGroup_P84T",MaxThreeColumns:"MaxThreeColumns_FO1r",AutofillColumns:"AutofillColumns_fKhQ",Card:"Card_aSCR",CardBordered:"CardBordered_glGF",CardBody:"CardBody_BhRs",TextColor:"TextColor_a8Tp",BoxRoot:"BoxRoot_Etgr",FlexWrapNowrap:"FlexWrapNowrap_f60k",FlexJustifyContentFlexStart:"FlexJustifyContentFlexStart_ZYv5",FlexDirectionRow:"FlexDirectionRow_T2qL",FlexAlignItemsCenter:"FlexAlignItemsCenter_EHVM",FlexFlex:"FlexFlex__JTE",Link:"Link_fVkl",MarginLeft4:"MarginLeft4_YQSJ",MarginTop4:"MarginTop4_jXKN",PaddingBottom4:"PaddingBottom4_O9gt",LogoCardContent:"LogoCardContent_kCQm",LogoCardImage:"LogoCardImage_JdcX",SmallLogoCardContent:"SmallLogoCardContent_LxhV",SmallLogoCardImage:"SmallLogoCardImage_tPZl",NewFeatureCardContent:"NewFeatureCardContent_Rq3d",NewFeatureCardHeading:"NewFeatureCardHeading_f6q3",NewFeatureCardHeadingSeparator:"NewFeatureCardHeadingSeparator_pSx8",NewFeatureCardTags:"NewFeatureCardTags_IFHO",NewFeatureCardWrapper:"NewFeatureCardWrapper_NQ0k",TitleCardContent:"TitleCardContent_l9MQ",TitleCardTitle:"TitleCardTitle__K8J",TitleCardSeparator:"TitleCardSeparator_IN2E",Cols1:"Cols1_Gr2U",Cols2:"Cols2_sRvc",Cols3:"Cols3_KjUS",Cols4:"Cols4_dKOj",Cols5:"Cols5_jDmj",Cols6:"Cols6_Q0OR"};var i=r(56289),a=r(74848);const l=e=>{let{children:n,isSmall:r,cols:i}=e;return(0,a.jsx)("div",{className:(0,t.A)(s.CardGroup,r?s.AutofillColumns:i?s[`Cols${i}`]:s.MaxThreeColumns),children:n})},o=e=>{let{children:n,link:r=""}=e;return r?(0,a.jsx)(i.A,{className:(0,t.A)(s.Link,s.Card,s.CardBordered),to:r,children:n}):(0,a.jsx)("div",{className:(0,t.A)(s.Card,s.CardBordered),children:n})},c=e=>{let{headerText:n,link:r,text:i}=e;return(0,a.jsx)(o,{link:r,children:(0,a.jsxs)("span",{children:[(0,a.jsx)("div",{className:(0,t.A)(s.CardTitle,s.BoxRoot,s.PaddingBottom4),style:{pointerEvents:"none"},children:(0,a.jsx)("div",{className:(0,t.A)(s.BoxRoot,s.FlexFlex,s.FlexAlignItemsCenter,s.FlexDirectionRow,s.FlexJustifyContentFlexStart,s.FlexWrapNowrap),style:{marginLeft:"-4px",marginTop:"-4px"},children:(0,a.jsx)("div",{className:(0,t.A)(s.BoxRoot,s.BoxHideIfEmpty,s.MarginTop4,s.MarginLeft4),style:{pointerEvents:"auto"},children:(0,a.jsx)("span",{className:"",children:n})})})}),(0,a.jsx)("span",{className:(0,t.A)(s.TextColor,s.CardBody),children:(0,a.jsx)("p",{children:i})})]})})},d=e=>{let{description:n,children:r,link:t}=e;return(0,a.jsx)(o,{link:t,children:(0,a.jsxs)("div",{className:s.LogoCardContent,children:[(0,a.jsx)("div",{className:s.LogoCardImage,children:r}),(0,a.jsx)("p",{className:s.TextColor,children:n})]})})},m=e=>{let{children:n,link:r}=e;return(0,a.jsx)(o,{link:r,children:(0,a.jsx)("div",{className:s.SmallLogoCardContent,children:(0,a.jsx)("div",{className:(0,t.A)("max-height-img-container",s.SmallLogoCardImage),children:n})})})},h=e=>{let{children:n,description:r,name:t,releaseVersion:l,learnMoreLink:c=""}=e;return(0,a.jsx)(o,{children:(0,a.jsxs)("div",{className:s.NewFeatureCardWrapper,children:[(0,a.jsxs)("div",{className:s.NewFeatureCardContent,children:[(0,a.jsxs)("div",{className:s.NewFeatureCardHeading,children:[t,(0,a.jsx)("br",{}),(0,a.jsx)("hr",{className:s.NewFeatureCardHeadingSeparator})]}),(0,a.jsx)("div",{className:s.LogoCardImage,children:n}),(0,a.jsx)("br",{}),(0,a.jsx)("p",{children:r}),(0,a.jsx)("br",{})]}),(0,a.jsxs)("div",{className:s.NewFeatureCardTags,children:[(0,a.jsx)("div",{children:c&&(0,a.jsx)(i.A,{className:"button button--outline button--sm button--primary",to:c,children:"Learn more"})}),(0,a.jsxs)(i.A,{className:"button button--outline button--sm button--primary",to:`https://github.com/mlflow/mlflow/releases/tag/v${l}`,children:["released in ",l]})]})]})})},f=e=>{let{title:n,description:r,link:i=""}=e;return(0,a.jsx)(o,{link:i,children:(0,a.jsxs)("div",{className:s.TitleCardContent,children:[(0,a.jsx)("div",{className:(0,t.A)(s.TitleCardTitle),style:{textAlign:"left",fontWeight:"bold"},children:n}),(0,a.jsx)("hr",{className:(0,t.A)(s.TitleCardSeparator),style:{margin:"12px 0"}}),(0,a.jsx)("p",{className:(0,t.A)(s.TextColor),children:r})]})})}},95080:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>m,contentTitle:()=>d,default:()=>p,frontMatter:()=>c,metadata:()=>t,toc:()=>h});const t=JSON.parse('{"id":"llms/sentence-transformers/index","title":"MLflow Sentence-Transformers Flavor","description":"Introduction","source":"@site/docs/llms/sentence-transformers/index.mdx","sourceDirName":"llms/sentence-transformers","slug":"/llms/sentence-transformers/","permalink":"/docs/latest/llms/sentence-transformers/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"sidebar_position":0,"sidebar_label":"Overview"},"sidebar":"docsSidebar","previous":{"title":"Storage Optimization","permalink":"/docs/latest/llms/transformers/large-models/"},"next":{"title":"Overview","permalink":"/docs/latest/llms/sentence-transformers/"}}');var s=r(74848),i=r(28453),a=r(56289),l=r(86294),o=r(67756);const c={sidebar_position:0,sidebar_label:"Overview"},d="MLflow Sentence-Transformers Flavor",m={},h=[{value:"Introduction",id:"introduction",level:2},{value:"What makes this Library so Special?",id:"what-makes-this-library-so-special",level:2},{value:"Features",id:"features",level:2},{value:"What can you do with Sentence Transformers and MLflow?",id:"what-can-you-do-with-sentence-transformers-and-mlflow",level:3},{value:"Deployment Made Easy",id:"deployment-made-easy",level:3},{value:"Getting Started with the MLflow Sentence Transformers Flavor - Tutorials and Guides",id:"getting-started-with-the-mlflow-sentence-transformers-flavor-tutorials-and-guides",level:2},{value:"Detailed Documentation",id:"detailed-documentation",level:2},{value:"Learning More About Sentence Transformers",id:"learning-more-about-sentence-transformers",level:2},{value:"Official Documentation and Source code",id:"official-documentation-and-source-code",level:3},{value:"Official Guides and Tutorials for Sentence Transformers",id:"official-guides-and-tutorials-for-sentence-transformers",level:3},{value:"Library Resources",id:"library-resources",level:3}];function f(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"mlflow-sentence-transformers-flavor",children:"MLflow Sentence-Transformers Flavor"})}),"\n",(0,s.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Sentence-Transformers"})," is a groundbreaking Python library that specializes in producing high-quality, semantically rich embeddings\nfor sentences and paragraphs. Developed as an extension of the well-known ",(0,s.jsx)(n.a,{href:"https://huggingface.co/docs/transformers/index",children:"Transformers"})," library\nby \ud83e\udd17 Hugging Face, Sentence-Transformers is tailored for tasks requiring a deep understanding of sentence-level context. This library is\nessential for NLP applications such as semantic search, text clustering, and similarity assessment."]}),"\n",(0,s.jsx)(n.p,{children:"Leveraging pre-trained models like BERT, RoBERTa, and DistilBERT, which are fine-tuned for sentence embeddings, Sentence-Transformers simplifies the process\nof generating meaningful vector representations of text. The library stands out for its simplicity, efficiency, and the quality of embeddings it produces."}),"\n",(0,s.jsx)(n.p,{children:"The library features a number of powerful high-level utility functions for performing common follow-on tasks with sentence embeddings.\nThese include:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Semantic Textual Similarity"}),": Assessing the ",(0,s.jsx)(n.a,{href:"https://www.sbert.net/docs/usage/semantic_textual_similarity.html",children:"semantic similarity"})," between two sentences."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Semantic Search"}),": ",(0,s.jsx)(n.a,{href:"https://www.sbert.net/examples/applications/semantic-search/README.html",children:"Searching"})," for the most semantically similar sentences in a corpus for a given query."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Clustering"}),": Grouping ",(0,s.jsx)(n.a,{href:"https://www.sbert.net/examples/applications/clustering/README.html",children:"similar sentences"})," together."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Information Retrieval"}),": Finding the most relevant sentences for a given query via document ",(0,s.jsx)(n.a,{href:"https://www.sbert.net/examples/applications/retrieve_rerank/README.html",children:"retrieval and ranking"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Paraphrase Mining"}),": Finding text entries that have similar (or identical) ",(0,s.jsx)(n.a,{href:"https://www.sbert.net/examples/applications/paraphrase-mining/README.html",children:"meaning"})," in a large corpus of text."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"what-makes-this-library-so-special",children:"What makes this Library so Special?"}),"\n",(0,s.jsx)(n.p,{children:"Let's take a look at a very basic representation of how the Sentence-Transformers library works and what you can do with it!"}),"\n",(0,s.jsx)("figure",{className:"center-div",style:{width:"90%",textAlign:"center"},children:(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.img,{alt:"Sentence-Transformers Model Architecture",src:r(83832).A+"",width:"1380",height:"1282"}),"\n",(0,s.jsx)("figcaption",{children:"Sentence-Transformers Model Architecture Overview"})]})}),"\n",(0,s.jsx)(n.p,{children:"Integrating Sentence-Transformers with MLflow, a platform dedicated to streamlining the entire machine learning lifecycle, enhances the experiment tracking and deployment\ncapabilities for these specialized NLP models. MLflow's support for Sentence-Transformers enables practitioners to effectively manage experiments, track different model versions,\nand deploy models for various NLP tasks with ease."}),"\n",(0,s.jsx)(n.p,{children:"Sentence-Transformers offers:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"High-Quality Sentence Embeddings"}),": Efficient generation of sentence embeddings that capture the contextual and semantic nuances of language."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Pre-Trained Model Availability"}),": Access to a diverse range of pre-trained models fine-tuned for sentence embedding tasks, streamlining the process of embedding generation."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Ease of Use"}),": Simplified API, making it accessible for both NLP experts and newcomers."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Custom Training and Fine-Tuning"}),": Flexibility to fine-tune models on specific datasets or train new models from scratch for tailored NLP solutions."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"With MLflow's Sentence-Transformers flavor, users benefit from:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Streamlined Experiment Tracking"}),": Easily log parameters, metrics, and sentence embedding models during the training and fine-tuning process."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Hassle-Free Deployment"}),": Deploy sentence embedding models for various applications with straightforward API calls."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Broad Model Compatibility"}),": Support for a range of sentence embedding models from the Sentence-Transformers library, ensuring access to the latest in embedding technology."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Whether you're working on semantic text similarity, clustering, or information retrieval, MLflow's integration with Sentence-Transformers provides a robust and efficient\npathway for incorporating advanced sentence-level understanding into your applications."}),"\n",(0,s.jsx)(n.h2,{id:"features",children:"Features"}),"\n",(0,s.jsx)(n.p,{children:"With MLflow's Sentence-Transformers flavor, users can:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Save"})," and ",(0,s.jsx)(n.strong,{children:"log"})," Sentence-Transformer models within MLflow with the respective APIs: ",(0,s.jsx)(o.B,{fn:"mlflow.sentence_transformers.save_model"})," and ",(0,s.jsx)(o.B,{fn:"mlflow.sentence_transformers.log_model"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["Track detailed experiments, including ",(0,s.jsx)(n.strong,{children:"parameters"}),", ",(0,s.jsx)(n.strong,{children:"metrics"}),", and ",(0,s.jsx)(n.strong,{children:"artifacts"})," associated with fine tuning runs."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"/deployment",children:"Deploy"})," sentence embedding models for practical applications."]}),"\n",(0,s.jsxs)(n.li,{children:["Utilize the ",(0,s.jsx)(o.B,{fn:"mlflow.pyfunc.PythonModel",children:(0,s.jsx)(n.code,{children:"mlflow.pyfunc.PythonModel"})})," flavor for generic Python function inference, enabling complex and powerful custom ML solutions."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"what-can-you-do-with-sentence-transformers-and-mlflow",children:"What can you do with Sentence Transformers and MLflow?"}),"\n",(0,s.jsx)(n.p,{children:"One of the more powerful applications that can be built with these tools is a semantic search engine. By using readily available open source\ntooling, you can build a semantic search engine that can find the most semantically similar sentences in a corpus for a given query. This is\na significant improvement over traditional keyword-based search engines, which are limited in their ability to understand the context of a query."}),"\n",(0,s.jsx)(n.p,{children:"An example high-level architecture for such an application stack is shown below:"}),"\n",(0,s.jsx)("figure",{className:"center-div",style:{width:"90%",textAlign:"center"},children:(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.img,{alt:"Semantic Search Architecture",src:r(19418).A+"",width:"1376",height:"797"}),"\n",(0,s.jsx)("figcaption",{children:"A basic architecture for a semantic search engine built with Sentence Transformers and MLflow"})]})}),"\n",(0,s.jsx)(n.h3,{id:"deployment-made-easy",children:"Deployment Made Easy"}),"\n",(0,s.jsxs)(n.p,{children:["Once a model is trained, it needs to be deployed for inference. MLflow's integration with Sentence Transformers simplifies this by providing\nfunctions such as ",(0,s.jsx)(o.B,{fn:"mlflow.sentence_transformers.load_model"})," and ",(0,s.jsx)(o.B,{fn:"mlflow.pyfunc.load_model"}),", which allow for easy model serving.\nYou can read more about ",(0,s.jsx)(n.a,{href:"/deployment",children:"deploying models with MLflow"}),", find further information\non ",(0,s.jsx)(a.A,{to:"/api_reference/cli.html#mlflow-deployments",target:"_blank",children:"using the deployments API"}),", and ",(0,s.jsx)(a.A,{to:"/api_reference/cli.html#mlflow-models-serve",target:"_blank",children:"starting a local model serving endpoint"})," to get a\ndeeper understanding of the deployment options that MLflow has available."]}),"\n",(0,s.jsx)(n.h2,{id:"getting-started-with-the-mlflow-sentence-transformers-flavor-tutorials-and-guides",children:"Getting Started with the MLflow Sentence Transformers Flavor - Tutorials and Guides"}),"\n",(0,s.jsx)(l.AC,{children:(0,s.jsx)(l._C,{headerText:"MLflow Sentence Transformers Tutorials and Guides",link:"/llms/sentence-transformers/tutorials/",text:"Learn different ways that you can leverage the power of the sentence-transformers library, leveraging MLflow's APIs for tracking and inference capabilities."})}),"\n",(0,s.jsx)(n.h2,{id:"detailed-documentation",children:(0,s.jsx)(n.a,{href:"/llms/sentence-transformers/guide",children:"Detailed Documentation"})}),"\n",(0,s.jsx)(n.p,{children:"To learn more about the details of the MLflow flavor for sentence transformers, delve into the comprehensive guide below."}),"\n",(0,s.jsx)(a.A,{className:"button button--primary",to:"guide",children:(0,s.jsx)("span",{children:"View the Comprehensive Guide"})}),"\n",(0,s.jsx)(n.h2,{id:"learning-more-about-sentence-transformers",children:"Learning More About Sentence Transformers"}),"\n",(0,s.jsx)(n.p,{children:"Sentence Transformers is a versatile framework for computing dense vector representations of sentences, paragraphs, and images.\nBased on transformer networks like BERT, RoBERTa, and XLM-RoBERTa, it offers state-of-the-art performance across various tasks.\nThe framework is designed for easy use and customization, making it suitable for a wide range of applications in natural language processing\nand beyond."}),"\n",(0,s.jsx)(n.p,{children:"For those interested in delving deeper into Sentence Transformers, the following resources are invaluable:"}),"\n",(0,s.jsx)(n.h3,{id:"official-documentation-and-source-code",children:"Official Documentation and Source code"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Official Documentation"}),": For a comprehensive guide to getting started, advanced usage, and API references, visit the ",(0,s.jsx)(n.a,{href:"https://www.sbert.net",children:"Sentence Transformers Documentation"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"GitHub Repository"}),": The ",(0,s.jsx)(n.a,{href:"https://github.com/UKPLab/sentence-transformers",children:"Sentence Transformers GitHub repository"})," is the primary source for the latest code, examples, and updates. Here, you can also report issues, contribute to the project, or explore how the community is using and extending the framework."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"official-guides-and-tutorials-for-sentence-transformers",children:"Official Guides and Tutorials for Sentence Transformers"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Training Custom Models"}),": The framework supports ",(0,s.jsx)(n.a,{href:"https://www.sbert.net/docs/training/overview.html",children:"fine-tuning of custom embedding models"})," to achieve the best performance on specific tasks."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Publications and Research"}),": To understand the scientific foundations of Sentence Transformers, the ",(0,s.jsx)(n.a,{href:"https://www.sbert.net/docs/publications.html",children:"publications section"})," offers a collection of research papers that have been integrated into the framework."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Application Examples"}),": Explore a variety of ",(0,s.jsx)(n.a,{href:"https://github.com/UKPLab/sentence-transformers/tree/master/examples/applications",children:"application examples"})," demonstrating the practical use of Sentence Transformers in different scenarios."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"library-resources",children:"Library Resources"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"PyPI Package"}),": The ",(0,s.jsx)(n.a,{href:"https://pypi.org/project/sentence-transformers",children:"PyPI page for Sentence Transformers"})," provides information on installation, version history, and package dependencies."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Conda Forge Package"}),": For users preferring Conda as their package manager, the ",(0,s.jsx)(n.a,{href:"https://anaconda.org/conda-forge/sentence-transformers",children:"Conda Forge page for Sentence Transformers"})," is the go-to resource for installation and package details."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Pretrained Models"}),": Sentence Transformers offers an extensive range of ",(0,s.jsx)(n.a,{href:"https://www.sbert.net/docs/pretrained_models.html",children:"pretrained models"})," optimized for various languages and tasks. These models can be easily integrated into your projects."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Sentence Transformers is continually evolving, with regular updates and additions to its capabilities. Whether you're a researcher, developer, or enthusiast in the field of natural language processing, these resources will help you make the most of this powerful tool."})]})}function p(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(f,{...e})}):f(e)}}}]);