"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[6509],{28453:(e,n,l)=>{l.d(n,{R:()=>o,x:()=>r});var t=l(96540);const s={},i=t.createContext(s);function o(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(i.Provider,{value:n},e.children)}},49374:(e,n,l)=>{l.d(n,{B:()=>a});l(96540);const t=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var s=l(86025),i=l(28774),o=l(74848);const r=e=>{const n=e.split(".");for(let l=n.length;l>0;l--){const e=n.slice(0,l).join(".");if(t[e])return e}return null};function a({fn:e,children:n}){const l=r(e);if(!l)return(0,o.jsx)(o.Fragment,{children:n});const a=(0,s.Ay)(`/${t[l]}#${e}`);return(0,o.jsx)(i.A,{to:a,target:"_blank",children:n??(0,o.jsxs)("code",{children:[e,"()"]})})}},66086:(e,n,l)=>{l.d(n,{A:()=>t});const t=l.p+"assets/images/system-metrics-view-df348283b66821ca21f20d9170464250.png"},94712:(e,n,l)=>{l.r(n),l.d(n,{assets:()=>m,contentTitle:()=>a,default:()=>p,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"tracking/system-metrics/index","title":"System Metrics","description":"MLflow allows users to log system metrics including CPU stats, GPU stats, memory usage, network traffic, and","source":"@site/docs/classic-ml/tracking/system-metrics/index.mdx","sourceDirName":"tracking/system-metrics","slug":"/tracking/system-metrics/","permalink":"/docs/latest/ml/tracking/system-metrics/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"classicMLSidebar","previous":{"title":"Search Experiments","permalink":"/docs/latest/ml/search/search-experiments/"},"next":{"title":"Tracking APIs \ud83d\udee0\ufe0f","permalink":"/docs/latest/ml/tracking/tracking-api/"}}');var s=l(74848),i=l(28453),o=l(49374);const r={},a="System Metrics",m={},c=[{value:"Extra Dependencies",id:"extra-dependencies",level:2},{value:"Turn on/off System Metrics Logging",id:"turn-onoff-system-metrics-logging",level:2},{value:"Using the Environment Variable to Control System Metrics Logging",id:"using-the-environment-variable-to-control-system-metrics-logging",level:3},{value:"Using <code>mlflow.enable_system_metrics_logging()</code>",id:"using-mlflowenable_system_metrics_logging",level:3},{value:"Enabling System Metrics Logging for a Single Run",id:"enabling-system-metrics-logging-for-a-single-run",level:3},{value:"Types of System Metrics",id:"types-of-system-metrics",level:2},{value:"Viewing System Metrics within the MLflow UI",id:"viewing-system-metrics-within-the-mlflow-ui",level:2},{value:"Customizing System Metrics Logging",id:"customizing-system-metrics-logging",level:2},{value:"Customizing Logging Frequency",id:"customizing-logging-frequency",level:3}];function h(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"system-metrics",children:"System Metrics"})}),"\n",(0,s.jsx)(n.p,{children:"MLflow allows users to log system metrics including CPU stats, GPU stats, memory usage, network traffic, and\ndisk usage during the execution of an MLflow run. In this guide, we will walk through how to manage system\nmetrics logging with MLflow."}),"\n",(0,s.jsx)(n.h2,{id:"extra-dependencies",children:"Extra Dependencies"}),"\n",(0,s.jsxs)(n.p,{children:["To log system metrics in MLflow, please install ",(0,s.jsx)(n.code,{children:"psutil"}),". We explicitly don't include ",(0,s.jsx)(n.code,{children:"psutil"})," in MLflow's\ndependencies because ",(0,s.jsx)(n.code,{children:"psutil"})," wheel is not available for linux aarch64, and building from source fails intermittently.\nTo install ",(0,s.jsx)(n.code,{children:"psutil"}),", run the following command:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"pip install psutil\n"})}),"\n",(0,s.jsxs)(n.p,{children:["If you want to catch Nvidia GPU metrics, you also need to install ",(0,s.jsx)(n.code,{children:"pynvml"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"pip install pynvml\n"})}),"\n",(0,s.jsxs)(n.p,{children:["If you are using AMD/HIP GPUs, install ",(0,s.jsx)(n.a,{href:"https://github.com/ROCm/pyrsmi",children:"pyrsmi"})," instead of ",(0,s.jsx)(n.code,{children:"pynvml"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"pip install pyrsmi\n"})}),"\n",(0,s.jsx)(n.h2,{id:"turn-onoff-system-metrics-logging",children:"Turn on/off System Metrics Logging"}),"\n",(0,s.jsx)(n.p,{children:"There are three ways to enable or disable system metrics logging:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Set the environment variable ",(0,s.jsx)(n.code,{children:"MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING"})," to ",(0,s.jsx)(n.code,{children:"false"})," to turn off system metrics logging,\nor ",(0,s.jsx)(n.code,{children:"true"})," to enable it for all MLflow runs."]}),"\n",(0,s.jsxs)(n.li,{children:["Use ",(0,s.jsx)(o.B,{fn:"mlflow.enable_system_metrics_logging"})," to enable and\n",(0,s.jsx)(o.B,{fn:"mlflow.disable_system_metrics_logging"})," to disable system metrics logging for all MLflow runs."]}),"\n",(0,s.jsxs)(n.li,{children:["Use ",(0,s.jsx)(n.code,{children:"log_system_metrics"})," parameter in ",(0,s.jsx)(o.B,{fn:"mlflow.start_run"})," to control system metrics logging for\nthe current MLflow run, i.e., ",(0,s.jsx)(n.code,{children:"mlflow.start_run(log_system_metrics=True)"})," will enable system metrics logging."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"using-the-environment-variable-to-control-system-metrics-logging",children:"Using the Environment Variable to Control System Metrics Logging"}),"\n",(0,s.jsxs)(n.p,{children:["You can set the environment variable ",(0,s.jsx)(n.code,{children:"MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING"})," to ",(0,s.jsx)(n.code,{children:"true"})," to turn on system metrics\nlogging globally, as shown below:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"export MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING=true\n"})}),"\n",(0,s.jsxs)(n.p,{children:["However, if you are executing the command above from within Ipython notebook (Jupyter, Databricks notebook,\nGoogle Colab), the ",(0,s.jsx)(n.code,{children:"export"})," command will not work due to the segregated state of the ephemeral shell.\nInstead you can use the following code:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import os\n\nos.environ["MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING"] = "true"\n'})}),"\n",(0,s.jsx)(n.p,{children:"After setting the environment variable, you will see that starting an MLflow run will automatically collect\nand log the default system metrics. Try running the following code in your favorite environment and you\nshould see system metrics existing in the logged run data. Please note that you don't necessarilty need to\nstart an MLflow server, as the metrics are logged locally."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import mlflow\nimport time\n\nwith mlflow.start_run() as run:\n    time.sleep(15)\n\nprint(mlflow.MlflowClient().get_run(run.info.run_id).data)\n"})}),"\n",(0,s.jsx)(n.p,{children:"Your output should look like this:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"<RunData: metrics={'system/cpu_utilization_percentage': 12.4,\n'system/disk_available_megabytes': 213744.0,\n'system/disk_usage_megabytes': 28725.3,\n'system/disk_usage_percentage': 11.8,\n'system/network_receive_megabytes': 0.0,\n'system/network_transmit_megabytes': 0.0,\n'system/system_memory_usage_megabytes': 771.1,\n'system/system_memory_usage_percentage': 5.7}, params={}, tags={'mlflow.runName': 'nimble-auk-61',\n'mlflow.source.name': '/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py',\n'mlflow.source.type': 'LOCAL',\n'mlflow.user': 'root'}>\n"})}),"\n",(0,s.jsx)(n.p,{children:"To disable system metrics logging, you can use either of the following commands:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'export MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING="false"\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import os\n\ndel os.environ["MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING"]\n'})}),"\n",(0,s.jsx)(n.p,{children:"Rerunning the MLflow code above will not log system metrics."}),"\n",(0,s.jsxs)(n.h3,{id:"using-mlflowenable_system_metrics_logging",children:["Using ",(0,s.jsx)(n.code,{children:"mlflow.enable_system_metrics_logging()"})]}),"\n",(0,s.jsxs)(n.p,{children:["We also provide a pair of APIs ",(0,s.jsx)(n.code,{children:"mlflow.enable_system_metrics_logging()"})," and\n",(0,s.jsx)(n.code,{children:"mlflow.disable_system_metrics_logging()"})," to turn on/off system metrics logging globally for\nenvironments in which you do not have the appropriate access to set an environment variable.\nRunning the following code will have the same effect as setting\n",(0,s.jsx)(n.code,{children:"MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING"})," environment variable to ",(0,s.jsx)(n.code,{children:"true"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import mlflow\n\nmlflow.enable_system_metrics_logging()\n\nwith mlflow.start_run() as run:\n    time.sleep(15)\n\nprint(mlflow.MlflowClient().get_run(run.info.run_id).data)\n"})}),"\n",(0,s.jsx)(n.h3,{id:"enabling-system-metrics-logging-for-a-single-run",children:"Enabling System Metrics Logging for a Single Run"}),"\n",(0,s.jsxs)(n.p,{children:["In addition to controlling system metrics logging globally, you can also control it for a\nsingle run. To do so, set ",(0,s.jsx)(n.code,{children:"log_system_metrics"})," as ",(0,s.jsx)(n.code,{children:"True"})," or ",(0,s.jsx)(n.code,{children:"False"})," accordingly in ",(0,s.jsx)(o.B,{fn:"mlflow.start_run"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"with mlflow.start_run(log_system_metrics=True) as run:\n    time.sleep(15)\n\nprint(mlflow.MlflowClient().get_run(run.info.run_id).data)\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Please also note that using ",(0,s.jsx)(n.code,{children:"log_system_metrics"})," will ignore the global status of system metrics logging.\nIn other words, the above code will log system metrics for the specific run even if you have disabled\nsystem metrics logging by setting ",(0,s.jsx)(n.code,{children:"MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING"})," to ",(0,s.jsx)(n.code,{children:"false"})," or calling\n",(0,s.jsx)(n.code,{children:"mlflow.disable_system_metrics_logging()"}),"."]}),"\n",(0,s.jsx)(n.h2,{id:"types-of-system-metrics",children:"Types of System Metrics"}),"\n",(0,s.jsx)(n.p,{children:"By default, MLflow logs the following system metrics:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"cpu_utilization_percentage"}),"\n",(0,s.jsx)(n.li,{children:"system_memory_usage_megabytes"}),"\n",(0,s.jsx)(n.li,{children:"system_memory_usage_percentage"}),"\n",(0,s.jsx)(n.li,{children:"gpu_utilization_percentage"}),"\n",(0,s.jsx)(n.li,{children:"gpu_memory_usage_megabytes"}),"\n",(0,s.jsx)(n.li,{children:"gpu_memory_usage_percentage"}),"\n",(0,s.jsx)(n.li,{children:"gpu_power_usage_watts"}),"\n",(0,s.jsx)(n.li,{children:"gpu_power_usage_percentage"}),"\n",(0,s.jsx)(n.li,{children:"network_receive_megabytes"}),"\n",(0,s.jsx)(n.li,{children:"network_transmit_megabytes"}),"\n",(0,s.jsx)(n.li,{children:"disk_usage_megabytes"}),"\n",(0,s.jsx)(n.li,{children:"disk_available_megabytes"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["GPU metrics are only logged when a GPU is available and ",(0,s.jsx)(n.code,{children:"pynvml"})," is installed."]}),"\n",(0,s.jsxs)(n.p,{children:["Every system metric has a prefix ",(0,s.jsx)(n.code,{children:"system/"})," when logged for grouping purpose. So the actual metric name\nthat is logged will have ",(0,s.jsx)(n.code,{children:"system/"})," prepended, e.g, ",(0,s.jsx)(n.code,{children:"system/cpu_utilization_percentage"}),",\n",(0,s.jsx)(n.code,{children:"system/system_memory_usage_megabytes"}),", etc."]}),"\n",(0,s.jsx)(n.h2,{id:"viewing-system-metrics-within-the-mlflow-ui",children:"Viewing System Metrics within the MLflow UI"}),"\n",(0,s.jsx)(n.p,{children:"System metrics are available within the MLflow UI under the metrics section. In order to view\nthem, let's start our MLflow UI server, and log some system metrics to it:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"mlflow ui\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport time\n\nmlflow.set_tracking_uri("http://127.0.0.1:5000")\nwith mlflow.start_run() as run:\n    time.sleep(15)\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Navigate to ",(0,s.jsx)(n.code,{children:"http://127.0.0.1:5000"})," in your browser and open your run. You should see system metrics\nunder the metrics section, similar as shown by the screenshot below:"]}),"\n",(0,s.jsx)("div",{className:"center-div",style:{width:800,maxWidth:"100%"},children:(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"system metrics on MLflow UI",src:l(66086).A+"",width:"3404",height:"1488"})})}),"\n",(0,s.jsx)(n.h2,{id:"customizing-system-metrics-logging",children:"Customizing System Metrics Logging"}),"\n",(0,s.jsx)(n.h3,{id:"customizing-logging-frequency",children:"Customizing Logging Frequency"}),"\n",(0,s.jsxs)(n.p,{children:["By default, system metrics are sampled every 10 seconds and are directly logged after sampling. You can customize\nthe sampling frequency by setting environment variable ",(0,s.jsx)(n.code,{children:"MLFLOW_SYSTEM_METRICS_SAMPLING_INTERVAL"})," to an integer\nrepresenting the logging frequency in seconds or by using ",(0,s.jsx)(o.B,{fn:"mlflow.set_system_metrics_sampling_interval"}),"\nto set the interval, as shown below. In addition to setting the frequency of system metrics logging, you can\nalso customize the number of samples to aggregate. You can also customize the number of samples to aggregate\nbefore logging by setting environment variable ",(0,s.jsx)(n.code,{children:"MLFLOW_SYSTEM_METRICS_SAMPLES_BEFORE_LOGGING"})," or\nusing ",(0,s.jsx)(o.B,{fn:"mlflow.set_system_metrics_samples_before_logging"}),". The actual logging time window is the\nproduct of ",(0,s.jsx)(n.code,{children:"MLFLOW_SYSTEM_METRICS_SAMPLING_INTERVAL"})," and ",(0,s.jsx)(n.code,{children:"MLFLOW_SYSTEM_METRICS_SAMPLES_BEFORE_LOGGING"}),".\nFor example, if you set sample interval to 2 seconds and samples before logging to 3, then system metrics will be\ncollected every 2 seconds, then after 3 samples are collected (2 * 3 = 6s), we aggregate the metrics and log to MLflow\nserver. The aggregation logic depends on different system metrics. For example, for ",(0,s.jsx)(n.code,{children:"cpu_utilization_percentage"})," it's\nthe average of the samples."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import mlflow\n\nmlflow.set_system_metrics_sampling_interval(1)\nmlflow.set_system_metrics_samples_before_logging(3)\n\nwith mlflow.start_run(log_system_metrics=True) as run:\n    time.sleep(15)\n\nmetric_history = mlflow.MlflowClient().get_metric_history(\n    run.info.run_id,\n    "system/cpu_utilization_percentage",\n)\nprint(metric_history)\n'})}),"\n",(0,s.jsxs)(n.p,{children:["You will see ",(0,s.jsx)(n.code,{children:"system/cpu_utilization_percentage"})," logged a few times."]})]})}function p(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}}}]);