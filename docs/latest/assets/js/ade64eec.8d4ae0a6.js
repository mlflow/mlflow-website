"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4767],{24620:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/agent-trace-ui-83d8215ea40e973cff677b782c1e7579.png"},28453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>l});var i=t(96540);const o={},s=i.createContext(o);function a(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),i.createElement(s.Provider,{value:n},e.children)}},65537:(e,n,t)=>{t.d(n,{A:()=>_});var i=t(96540),o=t(34164),s=t(65627),a=t(56347),l=t(50372),r=t(30604),d=t(11861),c=t(78749);function h(e){return i.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,i.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function u(e){const{values:n,children:t}=e;return(0,i.useMemo)((()=>{const e=n??function(e){return h(e).map((e=>{let{props:{value:n,label:t,attributes:i,default:o}}=e;return{value:n,label:t,attributes:i,default:o}}))}(t);return function(e){const n=(0,d.XI)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,t])}function m(e){let{value:n,tabValues:t}=e;return t.some((e=>e.value===n))}function p(e){let{queryString:n=!1,groupId:t}=e;const o=(0,a.W6)(),s=function(e){let{queryString:n=!1,groupId:t}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:n,groupId:t});return[(0,r.aZ)(s),(0,i.useCallback)((e=>{if(!s)return;const n=new URLSearchParams(o.location.search);n.set(s,e),o.replace({...o.location,search:n.toString()})}),[s,o])]}function f(e){const{defaultValue:n,queryString:t=!1,groupId:o}=e,s=u(e),[a,r]=(0,i.useState)((()=>function(e){let{defaultValue:n,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!m({value:n,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const i=t.find((e=>e.default))??t[0];if(!i)throw new Error("Unexpected error: 0 tabValues");return i.value}({defaultValue:n,tabValues:s}))),[d,h]=p({queryString:t,groupId:o}),[f,g]=function(e){let{groupId:n}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(n),[o,s]=(0,c.Dv)(t);return[o,(0,i.useCallback)((e=>{t&&s.set(e)}),[t,s])]}({groupId:o}),x=(()=>{const e=d??f;return m({value:e,tabValues:s})?e:null})();(0,l.A)((()=>{x&&r(x)}),[x]);return{selectedValue:a,selectValue:(0,i.useCallback)((e=>{if(!m({value:e,tabValues:s}))throw new Error(`Can't select invalid tab value=${e}`);r(e),h(e),g(e)}),[h,g,s]),tabValues:s}}var g=t(9136);const x={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var y=t(74848);function w(e){let{className:n,block:t,selectedValue:i,selectValue:a,tabValues:l}=e;const r=[],{blockElementScrollPositionUntilNextRender:d}=(0,s.a_)(),c=e=>{const n=e.currentTarget,t=r.indexOf(n),o=l[t].value;o!==i&&(d(n),a(o))},h=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=r.indexOf(e.currentTarget)+1;n=r[t]??r[0];break}case"ArrowLeft":{const t=r.indexOf(e.currentTarget)-1;n=r[t]??r[r.length-1];break}}n?.focus()};return(0,y.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.A)("tabs",{"tabs--block":t},n),children:l.map((e=>{let{value:n,label:t,attributes:s}=e;return(0,y.jsx)("li",{role:"tab",tabIndex:i===n?0:-1,"aria-selected":i===n,ref:e=>{r.push(e)},onKeyDown:h,onClick:c,...s,className:(0,o.A)("tabs__item",x.tabItem,s?.className,{"tabs__item--active":i===n}),children:t??n},n)}))})}function j(e){let{lazy:n,children:t,selectedValue:s}=e;const a=(Array.isArray(t)?t:[t]).filter(Boolean);if(n){const e=a.find((e=>e.props.value===s));return e?(0,i.cloneElement)(e,{className:(0,o.A)("margin-top--md",e.props.className)}):null}return(0,y.jsx)("div",{className:"margin-top--md",children:a.map(((e,n)=>(0,i.cloneElement)(e,{key:n,hidden:e.props.value!==s})))})}function v(e){const n=f(e);return(0,y.jsxs)("div",{className:(0,o.A)("tabs-container",x.tabList),children:[(0,y.jsx)(w,{...n,...e}),(0,y.jsx)(j,{...n,...e})]})}function _(e){const n=(0,g.A)();return(0,y.jsx)(v,{...e,children:h(e.children)},String(n))}},67756:(e,n,t)=>{t.d(n,{B:()=>r});t(96540);const i=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var o=t(29030),s=t(56289),a=t(74848);const l=e=>{const n=e.split(".");for(let t=n.length;t>0;t--){const e=n.slice(0,t).join(".");if(i[e])return e}return null};function r(e){let{fn:n,children:t}=e;const r=l(n);if(!r)return(0,a.jsx)(a.Fragment,{children:t});const d=(0,o.Ay)(`/${i[r]}#${n}`);return(0,a.jsx)(s.A,{to:d,target:"_blank",children:t??(0,a.jsxs)("code",{children:[n,"()"]})})}},79329:(e,n,t)=>{t.d(n,{A:()=>a});t(96540);var i=t(34164);const o={tabItem:"tabItem_Ymn6"};var s=t(74848);function a(e){let{children:n,hidden:t,className:a}=e;return(0,s.jsx)("div",{role:"tabpanel",className:(0,i.A)(o.tabItem,a),hidden:t,children:n})}},89215:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/model-config-in-ui-54c3ee1bac15ce7bc93f7f8ee9256a0e.png"},90591:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>h,contentTitle:()=>c,default:()=>p,frontMatter:()=>d,metadata:()=>i,toc:()=>u});const i=JSON.parse('{"id":"llms/chat-model-guide/index","title":"Tutorial: Custom GenAI Models using ChatModel","description":"Starting in MLflow 3.0.0, we recommend ResponsesAgent instead of ChatModel. See more details in the ResponsesAgent Introduction.","source":"@site/docs/llms/chat-model-guide/index.mdx","sourceDirName":"llms/chat-model-guide","slug":"/llms/chat-model-guide/","permalink":"/docs/latest/llms/chat-model-guide/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"What is ChatModel?","permalink":"/docs/latest/llms/chat-model-intro/"},"next":{"title":"More Customization","permalink":"/docs/latest/llms/custom-pyfunc-for-llms/"}}');var o=t(74848),s=t(28453),a=t(65537),l=t(79329),r=t(67756);const d={},c="Tutorial: Custom GenAI Models using ChatModel",h={},u=[{value:"Choosing Between ChatModel and PythonModel",id:"choosing-between-chatmodel-and-pythonmodel",level:2},{value:"Purpose of this tutorial",id:"purpose-of-this-tutorial",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Core Concepts",id:"core-concepts",level:2},{value:"Tracing Customization for GenAI",id:"tracing-customization-for-genai",level:3},{value:"Decorator API",id:"decorator-api",level:4},{value:"Fluent API",id:"fluent-api",level:4},{value:"Traces in the MLflow UI",id:"traces-in-the-mlflow-ui",level:4},{value:"Model Customization for GenAI",id:"model-customization-for-genai",level:3},{value:"Standardization for GenAI Models",id:"standardization-for-genai-models",level:3},{value:"Common GenAI pitfalls in MLflow",id:"common-genai-pitfalls-in-mlflow",level:3},{value:"Not using a supported flavor",id:"not-using-a-supported-flavor",level:4},{value:"Misinterpreting what <code>load_context</code> does",id:"misinterpreting-what-load_context-does",level:4},{value:"Failing to Handle Secrets securely",id:"failing-to-handle-secrets-securely",level:4},{value:"Failing to use <code>input_example</code>",id:"failing-to-use-input_example",level:4},{value:"Failing to handle retries for Rate Limits being hit",id:"failing-to-handle-retries-for-rate-limits-being-hit",level:4},{value:"Not validating before deployment",id:"not-validating-before-deployment",level:4},{value:"Key Classes and Methods in our example",id:"key-classes-and-methods-in-our-example",level:2},{value:"Example of a custom ChatModel",id:"example-of-a-custom-chatmodel",level:2},{value:"Setting our <code>model_config</code> values",id:"setting-our-model_config-values",level:2},{value:"Why Decouple Configuration?",id:"why-decouple-configuration",level:3},{value:"Defining the Model Configuration",id:"defining-the-model-configuration",level:3},{value:"Benefits of External Configuration",id:"benefits-of-external-configuration",level:3},{value:"Defining an Input Example",id:"defining-an-input-example",level:2},{value:"Logging and Loading our custom Agent",id:"logging-and-loading-our-custom-agent",level:2},{value:"Conclusion",id:"conclusion",level:2}];function m(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"tutorial-custom-genai-models-using-chatmodel",children:"Tutorial: Custom GenAI Models using ChatModel"})}),"\n",(0,o.jsx)(n.admonition,{title:"attention",type:"warning",children:(0,o.jsxs)(n.p,{children:["Starting in MLflow 3.0.0, we recommend ",(0,o.jsx)(r.B,{fn:"mlflow.pyfunc.ResponsesAgent",children:(0,o.jsx)(n.code,{children:"ResponsesAgent"})})," instead of ",(0,o.jsx)(r.B,{fn:"mlflow.pyfunc.ChatModel",children:(0,o.jsx)(n.code,{children:"ChatModel"})}),". See more details in the ",(0,o.jsx)(n.a,{href:"/llms/responses-agent-intro",children:"ResponsesAgent Introduction"}),"."]})}),"\n",(0,o.jsxs)(n.p,{children:["The rapidly evolving landscape of Generative Artificial Intelligence (GenAI) presents exciting opportunities and integration challenges.\nTo leverage the latest GenAI advancements effectively, developers need a framework that balances flexibility with standardization.\nMLflow addresses this need with the ",(0,o.jsx)(r.B,{fn:"mlflow.pyfunc.ChatModel",children:(0,o.jsx)(n.code,{children:"mlflow.pyfunc.ChatModel"})})," class introduced in\n",(0,o.jsx)(n.a,{href:"https://mlflow.org/releases/2.11.0#chatmodel-interface-for-a-unified-chat-experience-with-pyfunc-models",children:"version 2.11.0"}),", providing a\nconsistent interface for GenAI applications while simplifying deployment and testing."]}),"\n",(0,o.jsx)(n.h2,{id:"choosing-between-chatmodel-and-pythonmodel",children:"Choosing Between ChatModel and PythonModel"}),"\n",(0,o.jsxs)(n.p,{children:["When building GenAI applications in MLflow, it's essential to choose the right model abstraction that balances ease of use with the level of\ncustomization you need. MLflow offers two primary classes for this purpose: ",(0,o.jsx)(r.B,{fn:"mlflow.pyfunc.ChatModel",children:(0,o.jsx)(n.code,{children:"mlflow.pyfunc.ChatModel"})}),"\nand ",(0,o.jsx)(r.B,{fn:"mlflow.pyfunc.PythonModel",children:(0,o.jsx)(n.code,{children:"mlflow.pyfunc.PythonModel"})}),". Each has its own strengths and trade-offs, making it crucial to understand which one best suits your use case."]}),"\n",(0,o.jsxs)("table",{children:[(0,o.jsx)("thead",{children:(0,o.jsxs)("tr",{children:[(0,o.jsx)("th",{}),(0,o.jsx)("th",{children:"ChatModel"}),(0,o.jsx)("th",{children:"PythonModel"})]})}),(0,o.jsxs)("tbody",{children:[(0,o.jsxs)("tr",{children:[(0,o.jsx)("td",{children:"When to use"}),(0,o.jsxs)("td",{children:["Use when you want to develop and deploy a conversational model with ",(0,o.jsx)(n.strong,{children:"standard"})," chat schema compatible with OpenAI spec."]}),(0,o.jsxs)("td",{children:["Use when you want ",(0,o.jsx)(n.strong,{children:"full control"})," over the model's interface or customize every aspect of your model's behavior."]})]}),(0,o.jsxs)("tr",{children:[(0,o.jsx)("td",{children:"Interface"}),(0,o.jsxs)("td",{children:[(0,o.jsx)(n.strong,{children:"Fixed"})," to OpenAI's chat schema."]}),(0,o.jsxs)("td",{children:[(0,o.jsx)(n.strong,{children:"Full control"})," over the model's input and output schema."]})]}),(0,o.jsxs)("tr",{children:[(0,o.jsx)("td",{children:"Setup"}),(0,o.jsxs)("td",{children:[(0,o.jsx)(n.strong,{children:"Quick"}),". Works out of the box for conversational applications, with pre-defined model signature and input example."]}),(0,o.jsxs)("td",{children:[(0,o.jsx)(n.strong,{children:"Custom"}),". You need to define model signature or input example yourself."]})]}),(0,o.jsxs)("tr",{children:[(0,o.jsx)("td",{children:"Complexity"}),(0,o.jsxs)("td",{children:[(0,o.jsx)(n.strong,{children:"Low"}),". Standardized interface simplified model deployment and integration."]}),(0,o.jsxs)("td",{children:[(0,o.jsx)(n.strong,{children:"High"}),". Deploying and integrating the custom PythonModel may not be straightforward. E.g., The model needs to handle Pandas DataFrames as MLflow converts input data to DataFrames before passing it to PythonModel."]})]})]})]}),"\n",(0,o.jsx)(n.h2,{id:"purpose-of-this-tutorial",children:"Purpose of this tutorial"}),"\n",(0,o.jsxs)(n.p,{children:["This tutorial will guide you through the process of creating a custom chat agent using MLflow's ",(0,o.jsx)(r.B,{fn:"mlflow.pyfunc.ChatModel",children:(0,o.jsx)(n.code,{children:"mlflow.pyfunc.ChatModel"})})," class."]}),"\n",(0,o.jsx)(n.p,{children:"By the end of this tutorial you will:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Integrate ",(0,o.jsx)(n.a,{href:"/tracing",children:"MLflow Tracing"})," into a custom ",(0,o.jsx)(r.B,{fn:"mlflow.pyfunc.ChatModel",children:(0,o.jsx)(n.code,{children:"mlflow.pyfunc.ChatModel"})})," instance."]}),"\n",(0,o.jsxs)(n.li,{children:["Customize your model using the ",(0,o.jsx)(n.code,{children:"model_config"})," parameter within ",(0,o.jsx)(r.B,{fn:"mlflow.pyfunc.log_model"}),"."]}),"\n",(0,o.jsx)(n.li,{children:"Leverage standardized signature interfaces for simplified deployment."}),"\n",(0,o.jsxs)(n.li,{children:["Recognize and avoid common pitfalls when extending the ",(0,o.jsx)(r.B,{fn:"mlflow.pyfunc.ChatModel",children:(0,o.jsx)(n.code,{children:"mlflow.pyfunc.ChatModel"})})," class."]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Familiarity with MLflow logging APIs and GenAI concepts."}),"\n",(0,o.jsxs)(n.li,{children:["MLflow version 2.11.0 or higher installed for use of ",(0,o.jsx)(r.B,{fn:"mlflow.pyfunc.ChatModel",children:(0,o.jsx)(n.code,{children:"mlflow.pyfunc.ChatModel"})}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["MLflow version 2.14.0 or higher installed for use of ",(0,o.jsx)(n.a,{href:"/tracing",children:"MLflow Tracing"}),"."]}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["This tutorial uses the ",(0,o.jsx)(n.a,{href:"https://docs.databricks.com/en/machine-learning/foundation-models/index.html",children:"Databricks Foundation Model APIs"})," purely as\nan example of interfacing with an external service. You can easily swap the\nprovider example to use any managed LLM hosting service with ease (",(0,o.jsx)(n.a,{href:"https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html",children:"Amazon Bedrock"}),",\n",(0,o.jsx)(n.a,{href:"https://learn.microsoft.com/en-us/azure/ai-studio/concepts/deployments-overview",children:"Azure AI Studio"}),",\n",(0,o.jsx)(n.a,{href:"https://platform.openai.com/docs/libraries/python-library",children:"OpenAI"}),", ",(0,o.jsx)(n.a,{href:"https://docs.anthropic.com/en/api/client-sdks#python",children:"Anthropic"}),", and many others)."]}),"\n",(0,o.jsx)(n.h2,{id:"core-concepts",children:"Core Concepts"}),"\n",(0,o.jsxs)(a.A,{children:[(0,o.jsxs)(l.A,{label:"Tracing",value:"tracing",children:[(0,o.jsx)(n.h3,{id:"tracing-customization-for-genai",children:"Tracing Customization for GenAI"}),(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"/tracing",children:"MLflow Tracing"})," allows you to monitor and log the execution of your model's methods, providing valuable insights during debugging and performance optimization."]}),(0,o.jsxs)(n.p,{children:["In our example ",(0,o.jsx)(n.code,{children:"BasicAgent"})," implementation we utilize two separate APIs for the initiation of trace spans: the decorator API and the fluent API."]}),(0,o.jsx)(n.h4,{id:"decorator-api",children:"Decorator API"}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'@mlflow.trace\ndef _get_system_message(self, role: str) -> Dict:\n    if role not in self.models:\n        raise ValueError(f"Unknown role: {role}")\n\n    instruction = self.models[role]["instruction"]\n    return ChatMessage(role="system", content=instruction).to_dict()\n'})}),(0,o.jsxs)(n.p,{children:["Using the ",(0,o.jsx)(r.B,{fn:"mlflow.trace",children:(0,o.jsx)(n.code,{children:"@mlflow.trace"})})," tracing decorator is the simplest way to add tracing functionality to functions and methods. By default, a span that is generated from\nthe application of this decorator will utilize the name of the function as the name of the span. It is possible to override this naming, as well as\nother parameters associated with the span, as follows:"]}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'@mlflow.trace(name="custom_span_name", attributes={"key": "value"}, span_type="func")\ndef _get_system_message(self, role: str) -> Dict:\n    if role not in self.models:\n        raise ValueError(f"Unknown role: {role}")\n\n    instruction = self.models[role]["instruction"]\n    return ChatMessage(role="system", content=instruction).to_dict()\n'})}),(0,o.jsx)(n.admonition,{type:"tip",children:(0,o.jsx)(n.p,{children:"It is always advised to set a human-readable name for any span that you generate, particularly if you are instrumenting private or generically\nnamed functions or methods. The MLflow Trace UI will display the name of the function or method by default, which can be confusing to follow\nif your functions and methods are ambiguously named."})}),(0,o.jsx)(n.h4,{id:"fluent-api",children:"Fluent API"}),(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(r.B,{fn:"mlflow.start_span",children:(0,o.jsx)(n.code,{children:"fluent APIs"})})," context handler implementation for initiating spans is useful when you need full control of the logging of each aspect of the span's data."]}),(0,o.jsxs)(n.p,{children:["The example from our application for ensuring that we're capturing the parameters that are set when loading the model via the ",(0,o.jsx)(n.code,{children:"load_context"})," method is\nshown below. We are pulling from the instance attributes ",(0,o.jsx)(n.code,{children:"self.models_config"})," and ",(0,o.jsx)(n.code,{children:"self.models"})," to set the attributes of the span."]}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'with mlflow.start_span("Audit Agent") as root_span:\n    root_span.set_inputs(messages)\n    attributes = {**params.to_dict(), **self.models_config, **self.models}\n    root_span.set_attributes(attributes)\n    # More span manipulation...\n'})}),(0,o.jsx)(n.h4,{id:"traces-in-the-mlflow-ui",children:"Traces in the MLflow UI"}),(0,o.jsx)(n.p,{children:"After running our example that includes these combined usage patterns for trace span generation and instrumentation,"}),(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"Traces in the MLflow UI for the Agent example",src:t(24620).A+"",width:"1641",height:"1059"})})]}),(0,o.jsxs)(l.A,{label:"Customization",value:"customization",children:[(0,o.jsx)(n.h3,{id:"model-customization-for-genai",children:"Model Customization for GenAI"}),(0,o.jsxs)(n.p,{children:["In order to control the behavior of our ",(0,o.jsx)(n.code,{children:"BasicAgent"})," model without having to hard-code configuration values directly into our model logic, specifying\nconfigurations within the ",(0,o.jsx)(n.code,{children:"model_config"})," parameter when logging the model gives some flexibility and versatility to our model definition."]}),(0,o.jsx)(n.p,{children:"This functionality allows us to:"}),(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Rapidly test"})," different configurations without having to make changes to source code"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"See the configuration"})," that was used when logging different iterations directly in the MLflow UI"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Simplify the model code"})," by decoupling the configuration from the implementation"]}),"\n"]}),(0,o.jsxs)(n.admonition,{type:"note",children:[(0,o.jsxs)(n.p,{children:["In our example model, we set a standard set of configurations that control the behavior of the ",(0,o.jsx)(n.code,{children:"BasicAgent"}),". The configuration\nstructure expected by the code is a dictionary with the following components:"]}),(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"models"}),": Defines the per-agent configurations."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"(model_name)"}),": Represents the role of the agent. This section contains:","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"endpoint"}),": The specific model type being used by the agent."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"instruction"}),": The prompt given to the model, describing its role and responsibilities."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"temperature"}),": The temperature setting controlling response variability."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"max_tokens"}),": The maximum token limit for generating responses."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"configuration"}),": Contains miscellaneous settings for the agent application.","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"user_response_instruction"}),": Provides context for the second agent by simulating a user response based on the first agent's output."]}),"\n"]}),"\n"]}),"\n"]})]}),(0,o.jsx)(n.p,{children:"This configuration structure definition will be:"}),(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Defined when logging the model"})," and structured to support the needs of the model's behavior"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Used by the load_context method"})," and applied to the model when loading"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Logged within the MLmodel file"})," and will be visible within the artifact viewer in the MLflow UI"]}),"\n"]}),(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"model_config"})," values that are submitted for our ",(0,o.jsx)(n.code,{children:"BasicAgent"})," example within this tutorial can be seen within the logged model's\n",(0,o.jsx)(n.code,{children:"MLmodel"})," file in the UI:"]}),(0,o.jsx)("div",{className:"center-div",style:{width:"50%"},children:(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"Model configuration in the MLflow UI",src:t(89215).A+"",width:"759",height:"689"})})})]}),(0,o.jsxs)(l.A,{label:"Standardization",value:"standardization",children:[(0,o.jsx)(n.h3,{id:"standardization-for-genai-models",children:"Standardization for GenAI Models"}),(0,o.jsxs)(n.p,{children:["One of the more complex tasks associated with deploying a GenAI application with MLflow arises when attempting to build a custom implementation\nthat is based on subclassing the ",(0,o.jsx)(r.B,{fn:"mlflow.pyfunc.PythonModel",children:(0,o.jsx)(n.code,{children:"mlflow.pyfunc.PythonModel"})})," abstraction."]}),(0,o.jsxs)(n.p,{children:["While ",(0,o.jsx)(n.code,{children:"PythonModel"})," is recommended for custom Deep Learning and traditional Machine Learning models (such as ",(0,o.jsx)(n.code,{children:"sklearn"})," or ",(0,o.jsx)(n.code,{children:"torch"})," models that require\nadditional processing logic apart from that of a base model), there are internal manipulations of the input data that occur\nwhen serving these models that introduce unnecessary complications with GenAI applications."]}),(0,o.jsxs)(n.p,{children:["Due to the fact that DL and traditional ML models largely rely on structured data, when input data is passed via a REST interface for model serving,\nthe ",(0,o.jsx)(n.code,{children:"PythonModel"})," implementation will convert JSON data into ",(0,o.jsx)(n.code,{children:"pandas.DataFrame"})," or ",(0,o.jsx)(n.code,{children:"numpy"})," objects. This conversion creates a confusing and difficult to\ndebug scenario when using GenAI models. GenAI implementations generally deal exclusively with JSON-conformant data structures and have no tabular\nrepresentation that makes intuitive sense, thereby creating a frustrating and complex conversion interface needed to make application deployment function\ncorrectly."]}),(0,o.jsxs)(n.p,{children:["To simplify this problem, the ",(0,o.jsx)(r.B,{fn:"mlflow.pyfunc.ChatModel",children:(0,o.jsx)(n.code,{children:"mlflow.pyfunc.ChatModel"})})," class was created to provide a simpler interface for handling of the data\npassed into and returned from a call to the ",(0,o.jsx)(n.code,{children:"predict()"})," method on custom Python models serving GenAI use cases."]}),(0,o.jsxs)(n.p,{children:["In the example tutorial code below, we subclass ",(0,o.jsx)(n.code,{children:"ChatModel"})," in order to utilize this simplified interface with its immutable input and output\nformats. Because of this immutability, we don't have to reason about model signatures, and can instead directly use API standards that have\nbeen broadly accepted throughout the GenAI industry."]}),(0,o.jsxs)(n.p,{children:["To illustrate why it is preferred to use ",(0,o.jsx)(n.code,{children:"ChatModel"})," as a super class to custom GenAI implementations in MLflow, here is the signature that\nwould otherwise need to be defined and supplied during model logging to conform to the ",(0,o.jsx)(n.code,{children:"OpenAI"})," API spec as of September 2024:"]}),(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Input Schema"})," as a ",(0,o.jsx)(n.code,{children:"dict"}),":"]}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'[\n    {\n        "type": "array",\n        "items": {\n            "type": "object",\n            "properties": {\n                "content": {"type": "string", "required": True},\n                "name": {"type": "string", "required": False},\n                "role": {"type": "string", "required": True},\n            },\n        },\n        "name": "messages",\n        "required": True,\n    },\n    {"type": "double", "name": "temperature", "required": False},\n    {"type": "long", "name": "max_tokens", "required": False},\n    {"type": "array", "items": {"type": "string"}, "name": "stop", "required": False},\n    {"type": "long", "name": "n", "required": False},\n    {"type": "boolean", "name": "stream", "required": False},\n    {"type": "double", "name": "top_p", "required": False},\n    {"type": "long", "name": "top_k", "required": False},\n    {"type": "double", "name": "frequency_penalty", "required": False},\n    {"type": "double", "name": "presence_penalty", "required": False},\n]\n'})}),(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsxs)(n.p,{children:["Agent-based (tool-calling) schemas are significantly more complex than the simpler chat interface example shown above. As GenAI frameworks and services\nevolve with increasingly sophisticated capabilities and features, the complexity of these interfaces will grow, making manual schema definitions a\nchallenging and time-consuming task. The structured input validation provided by the MLflow ",(0,o.jsx)(r.B,{fn:"mlflow.pyfunc.ChatModel",children:(0,o.jsx)(n.code,{children:"mlflow.pyfunc.ChatModel"})})," interface removes the burden of defining and\nmanaging these intricate signatures manually. By leveraging these pre-defined schemas, you gain robust input type safety and validation, ensuring your\ndeployed applications handle inputs consistently and correctly without additional effort. This approach not only reduces the risk of errors but also\nstreamlines the development process, allowing you to focus on building impactful GenAI solutions without the overhead of managing complex input specifications."]})}),(0,o.jsxs)(n.p,{children:["By using ",(0,o.jsx)(r.B,{fn:"mlflow.pyfunc.ChatModel",children:(0,o.jsx)(n.code,{children:"mlflow.pyfunc.ChatModel"})})," to base a custom implementation off of, we don't have to reason about this complex signature.\nIt is provided for us."]}),(0,o.jsxs)(n.p,{children:["The only two considerations to be aware of when interfacing with the static signatures of ",(0,o.jsx)(n.code,{children:"ChatModel"})," are:"]}),(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["If the service that your custom implementation is interfacing with doesn't adhere to the ",(0,o.jsx)(n.code,{children:"OpenAI"})," spec, you will need to extract data from the\nstandard structure of ",(0,o.jsx)(r.B,{fn:"mlflow.types.llm.ChatMessage",children:(0,o.jsx)(n.code,{children:"mlflow.types.llm.ChatMessage"})})," and ",(0,o.jsx)(r.B,{fn:"mlflow.types.llm.ChatParams",children:(0,o.jsx)(n.code,{children:"mlflow.types.llm.ChatParams"})})," and ensure that it conforms to what\nyour service is expecting."]}),"\n",(0,o.jsxs)(n.li,{children:["The returned response from ",(0,o.jsx)(n.code,{children:"predict"})," should adhere to the output structure defined within the ",(0,o.jsx)(n.code,{children:"ChatModel"})," output signature:\n",(0,o.jsx)(r.B,{fn:"mlflow.types.llm.ChatCompletionResponse",children:(0,o.jsx)(n.code,{children:"mlflow.types.llm.ChatCompletionResponse"})}),"."]}),"\n"]})]}),(0,o.jsxs)(l.A,{label:"Pitfalls",value:"pitfalls",children:[(0,o.jsx)(n.h3,{id:"common-genai-pitfalls-in-mlflow",children:"Common GenAI pitfalls in MLflow"}),(0,o.jsx)(n.p,{children:"There are a number of ways that building a custom implementation for a GenAI use case can be frustrating or not intuitive. Here are some of the\nmost common that we've heard from our users:"}),(0,o.jsx)(n.h4,{id:"not-using-a-supported-flavor",children:"Not using a supported flavor"}),(0,o.jsxs)(n.p,{children:["If you're working with a library that is natively supported in MLflow, leveraging the built-in support for logging and loading your implementation\nwill always be easier than implementing a custom model. It is recommended to check the ",(0,o.jsx)(n.a,{href:"/llms#model-packaging",children:"supported GenAI flavors"}),"\nto see if there is a built-in solution that will meet your use case needs in one of the many integrations that are available."]}),(0,o.jsxs)(n.h4,{id:"misinterpreting-what-load_context-does",children:["Misinterpreting what ",(0,o.jsx)(n.code,{children:"load_context"})," does"]}),(0,o.jsxs)(n.p,{children:['While subclassing one of the base model types for a custom model, it may appear that the class definition is a "what you see is what you get" standard\nPython class. However, when loading your custom model instance, the ',(0,o.jsx)(n.code,{children:"load_context"})," method is actually called by another loader object."]}),(0,o.jsxs)(n.p,{children:["Because of the implementation, you ",(0,o.jsx)(n.strong,{children:"cannot have direct assignment of undefined instance attributes"})," within ",(0,o.jsx)(n.code,{children:"load_context"}),"."]}),(0,o.jsx)(n.p,{children:"For example, this does not work:"}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from mlflow.pyfunc import ChatModel\n\n\nclass MyModel(ChatModel):\n    def __init__(self):\n        self.state = []\n\n    def load_context(self, context):\n        # This will fail on load as the instance attribute self.my_model_config is not defined\n        self.my_model_config = context.get("my_model_config")\n'})}),(0,o.jsxs)(n.p,{children:["Instead, ensure that any instance attributes that are set by the ",(0,o.jsx)(n.code,{children:"load_context"})," method are defined in the class constructor with a\nplaceholder value:"]}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from mlflow.pyfunc import ChatModel\n\n\nclass MyModel(ChatModel):\n    def __init__(self):\n        self.state = []\n        self.my_model_config = None  # Define the attribute here\n\n    def load_context(self, context):\n        self.my_model_config = context.get("my_model_config")\n'})}),(0,o.jsx)(n.h4,{id:"failing-to-handle-secrets-securely",children:"Failing to Handle Secrets securely"}),(0,o.jsxs)(n.p,{children:["It might be tempting to simplify your model's deployment by specifying authentication secrets within a configuration. However, any configuration\ndata that is defined within your ",(0,o.jsx)(n.code,{children:"model_config"})," parameters ",(0,o.jsx)(n.strong,{children:"is directly visible in the MLflow UI"})," and is not stored securely."]}),(0,o.jsxs)(n.p,{children:["The recommended approach for handling sensitive configuration data such as API keys or access tokens is to utilize a Secret Manager.\nThe configuration for ",(0,o.jsx)(n.strong,{children:"what to fetch"})," from your secrets management system can be stored within the ",(0,o.jsx)(n.code,{children:"model_config"})," definition and\nyour deployment environment can utilize a secure means of accessing the key reference for your secrets management service."]}),(0,o.jsxs)(n.p,{children:["An effective place to handle secrets assignment (generally set as environment variables or passed as a part of request headers) is to\nhandle the acquisition and per-session setting within ",(0,o.jsx)(n.code,{children:"load_context"}),". If you have rotating tokens, it is worthwhile to embed the acquisition\nof secrets and re-fetching of them upon expiry as part of a retry mechanism within the call stack of ",(0,o.jsx)(n.code,{children:"predict"}),"."]}),(0,o.jsxs)(n.h4,{id:"failing-to-use-input_example",children:["Failing to use ",(0,o.jsx)(n.code,{children:"input_example"})]}),(0,o.jsxs)(n.p,{children:["While it may seem that providing an ",(0,o.jsx)(n.code,{children:"input_example"})," when logging a model in MLflow is purely for cosmetic purposes within the artifact view\ndisplay within the MLflow UI, there is an additional bit of functionality that makes providing this data very useful, particularly for GenAI\nuse cases."]}),(0,o.jsxs)(n.p,{children:["When an ",(0,o.jsx)(n.code,{children:"input_example"})," is provided, MLflow will call your model's ",(0,o.jsx)(n.code,{children:"predict"})," method with the example data to validate that the input is\ncompatible with the model object that you are logging. If there are any failures that occur, you will receive an error message detailing\nwhat is wrong with the input syntax. This is very beneficial to ensure that, at the point of logging, you can ensure that your expected\ninput interface structure is what will be allowable for the deployed model, thereby saving you hours of debugging and troubleshooting later\nwhen attempting to deploy your solution."]}),(0,o.jsxs)(n.p,{children:["It is ",(0,o.jsx)(n.strong,{children:"highly recommended"})," to supply this example during logging."]}),(0,o.jsx)(n.h4,{id:"failing-to-handle-retries-for-rate-limits-being-hit",children:"Failing to handle retries for Rate Limits being hit"}),(0,o.jsx)(n.p,{children:"Nearly all GenAI provider services impose rate limits and token-based usage limits to prevent disruption to their service or to help protect\nusers from unexpected bills. When limits are reached, it is important that your prediction logic is robust to handle these failures to ensure\nthat a user of your deployed application understands why their request was not successful."}),(0,o.jsx)(n.p,{children:"It can be beneficial to introduce retry logic for certain errors, particularly those involving transient connection issues or per-unit-of-time\nrequest limits."}),(0,o.jsx)(n.h4,{id:"not-validating-before-deployment",children:"Not validating before deployment"}),(0,o.jsxs)(n.p,{children:["The process of deploying a GenAI application can a significant amount of time. When an implementation is finally ready to be submitted to a\nserving environment, the last thing that you want to deal with is a model that is incapable of being served due to some issue with a decoded\nJSON payload being submitted to your model's ",(0,o.jsx)(n.code,{children:"predict()"})," method."]}),(0,o.jsxs)(n.p,{children:["MLflow offers the ",(0,o.jsx)(r.B,{fn:"mlflow.models.validate_serving_input"})," API to ensure that the model that you have logged is capable of being interacted\nwith by emulating the data processing that occurs with a deployed model."]}),(0,o.jsx)(n.p,{children:"To use this API, simply navigate to your logged model with the MLflow UI's artifact viewer. The model display pane on the right side of\nthe artifact viewer contains the code snippet that you can execute in an interactive environment to ensure that your model is ready to\ndeploy."}),(0,o.jsx)(n.p,{children:"For the example in this tutorial, this is the generated code that is copied from the artifact viewer display:"}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from mlflow.models import validate_serving_input\n\nmodel_uri = "runs:/8935b7aff5a84f559b5fcc2af3e2ea31/model"\n\n# The model is logged with an input example. MLflow converts\n# it into the serving payload format for the deployed model endpoint,\n# and saves it to \'serving_input_payload.json\'\nserving_payload = """{\n"messages": [\n    {\n    "role": "user",\n    "content": "What is a good recipe for baking scones that doesn\'t require a lot of skill?"\n    }\n],\n"temperature": 1.0,\n"n": 1,\n"stream": false\n}"""\n\n# Validate the serving payload works on the model\nvalidate_serving_input(model_uri, serving_payload)\n'})})]})]}),"\n",(0,o.jsx)(n.h2,{id:"key-classes-and-methods-in-our-example",children:"Key Classes and Methods in our example"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"BasicAgent"}),": Our custom chat agent class that extends ",(0,o.jsx)(n.code,{children:"ChatModel"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"_get_system_message"}),": Retrieves the system message configuration for a specific role."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"get_agent_response"}),": Sends messages to an endpoint and retrieves responses."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"_call_agent"}),": Manages the conversation flow between the agent roles."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"prepare_message_list"}),": Prepares the list of messages for sending."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"load_context"}),": Initializes the model context and configurations."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"predict"}),": Handles the prediction logic for the chat model."]}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["Of these methods listed above, the methods ",(0,o.jsx)(n.code,{children:"load_context"})," and ",(0,o.jsx)(n.code,{children:"predict"})," override the base abstracted implementations of ",(0,o.jsx)(n.code,{children:"ChatModel"}),". In order to\ndefine a subclass of ",(0,o.jsx)(n.code,{children:"ChatModel"}),", you must implement (at a minimum), the ",(0,o.jsx)(n.code,{children:"predict"})," method. The ",(0,o.jsx)(n.code,{children:"load_context"})," method is only used if you are implementing (as we\nwill be below) custom loading logic where a static configuration needs to be loaded for the model object to work, or additional dependent logic needs\nto execute in order for the object instantiation to function correctly."]}),"\n",(0,o.jsx)(n.h2,{id:"example-of-a-custom-chatmodel",children:"Example of a custom ChatModel"}),"\n",(0,o.jsxs)(n.p,{children:["In the full example below, we're creating a custom chat agent by subclassing the ",(0,o.jsx)(r.B,{fn:"mlflow.pyfunc.ChatModel",children:(0,o.jsx)(n.code,{children:"mlflow.pyfunc.ChatModel"})}),". This agent, named ",(0,o.jsx)(n.code,{children:"BasicAgent"}),",\ntakes advantage of several important features that help streamline the development, deployment, and tracking of GenAI applications. By subclassing ",(0,o.jsx)(n.code,{children:"ChatModel"}),",\nwe ensure a consistent interface for handling conversational agents, while also avoiding common pitfalls associated with more general-purpose models."]}),"\n",(0,o.jsx)(n.p,{children:"The implementation below highlights the following key aspects:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Tracing"}),": We leverage MLflow's tracing functionality to track and log critical operations using both the decorator and fluent API context handler approaches.","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Decorator API"}),": This is used to easily trace methods such as ",(0,o.jsx)(n.em,{children:"_get_agent_response"})," and ",(0,o.jsx)(n.em,{children:"_call_agent"})," for automatic span creation."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Fluent API"}),": Provides fine-grained control over span creation, as shown in the ",(0,o.jsx)(n.em,{children:"predict"})," method for auditing key inputs and outputs during agent interactions."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Tip"}),": We ensure human-readable span names for easier debugging in the MLflow Trace UI and when fetching logged traces via the client API."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Custom Configuration"}),":","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Model Configuration"}),": By passing custom configurations during model logging (using the ",(0,o.jsx)(n.em,{children:"model_config"})," parameter), we decouple model behavior from\nhard-coded values. This allows rapid testing of different agent configurations without modifying the source code."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"load_context Method"}),": Ensures that configurations are loaded at runtime, initializing the agent with the necessary settings and preventing runtime\nfailures due to missing configurations."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Tip"}),": We avoid directly setting undefined instance attributes within ",(0,o.jsx)(n.em,{children:"load_context"}),". Instead, all attributes are initialized with default\nvalues in the class constructor to ensure proper loading of our model."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Conversation Management"}),":","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["We implement a multi-step agent interaction pattern using methods like ",(0,o.jsx)(n.em,{children:"_get_system_message"}),", ",(0,o.jsx)(n.em,{children:"_get_agent_response"}),", and ",(0,o.jsx)(n.em,{children:"_call_agent"}),'. These\nmethods manage the flow of communication between multiple agents, such as an "oracle" and a "judge" role, each configured with specific instructions\nand parameters.']}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Static Input/Output Structures"}),": By adhering to the ",(0,o.jsx)(n.code,{children:"ChatModel"}),"'s required input (",(0,o.jsx)(n.em,{children:"List[ChatMessage]"}),") and output (",(0,o.jsx)(n.em,{children:"ChatCompletionResponse"}),") formats,\nwe eliminate the complexities associated with converting JSON or tabular data, which is common in more general models like ",(0,o.jsx)(n.code,{children:"PythonModel"}),"."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Common Pitfalls Avoided"}),":","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Model Validation via Input Examples"}),": We provide an input example during model logging, allowing MLflow to validate the input interface and catch\nstructural issues early, reducing debugging time during deployment."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Models from code"}),":","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["MLflow recommends using ",(0,o.jsx)(n.a,{href:"/model/models-from-code",children:"models from code"})," when authoring GenAI agents or apps, for robust logging and straightforward\ndeployment of agents containing arbitrary Python code."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom mlflow.types.llm import ChatCompletionResponse, ChatMessage, ChatParams, ChatChoice\nfrom mlflow.pyfunc import ChatModel\nfrom mlflow import deployments\nfrom typing import List, Optional, Dict\n\n\nclass BasicAgent(ChatModel):\n    def __init__(self):\n        """Initialize the BasicAgent with placeholder values."""\n        self.deploy_client = None\n        self.models = {}\n        self.models_config = {}\n        self.conversation_history = []\n\n    def load_context(self, context):\n        """Initialize the connectors and model configurations."""\n        self.deploy_client = deployments.get_deploy_client("databricks")\n        self.models = context.model_config.get("models", {})\n        self.models_config = context.model_config.get("configuration", {})\n\n    def _get_system_message(self, role: str) -> Dict:\n        """\n        Get the system message configuration for the specified role.\n\n        Args:\n            role (str): The role of the agent (e.g., "oracle" or "judge").\n\n        Returns:\n            dict: The system message for the given role.\n        """\n        if role not in self.models:\n            raise ValueError(f"Unknown role: {role}")\n\n        instruction = self.models[role]["instruction"]\n        return ChatMessage(role="system", content=instruction).to_dict()\n\n    @mlflow.trace(name="Raw Agent Response")\n    def _get_agent_response(\n        self, message_list: List[Dict], endpoint: str, params: Optional[dict] = None\n    ) -> Dict:\n        """\n        Call the agent endpoint to get a response.\n\n        Args:\n            message_list (List[Dict]): List of messages for the agent.\n            endpoint (str): The agent\'s endpoint.\n            params (Optional[dict]): Additional parameters for the call.\n\n        Returns:\n            dict: The response from the agent.\n        """\n        response = self.deploy_client.predict(\n            endpoint=endpoint, inputs={"messages": message_list, **(params or {})}\n        )\n        return response["choices"][0]["message"]\n\n    @mlflow.trace(name="Agent Call")\n    def _call_agent(\n        self, message: ChatMessage, role: str, params: Optional[dict] = None\n    ) -> Dict:\n        """\n        Prepares and sends the request to a specific agent based on the role.\n\n        Args:\n            message (ChatMessage): The message to be processed.\n            role (str): The role of the agent (e.g., "oracle" or "judge").\n            params (Optional[dict]): Additional parameters for the call.\n\n        Returns:\n            dict: The response from the agent.\n        """\n        system_message = self._get_system_message(role)\n        message_list = self._prepare_message_list(system_message, message)\n\n        # Fetch agent response\n        agent_config = self.models[role]\n        response = self._get_agent_response(\n            message_list, agent_config["endpoint"], params\n        )\n\n        # Update conversation history\n        self.conversation_history.extend([message.to_dict(), response])\n        return response\n\n    @mlflow.trace(name="Assemble Conversation")\n    def _prepare_message_list(\n        self, system_message: Dict, user_message: ChatMessage\n    ) -> List[Dict]:\n        """\n        Prepare the list of messages to send to the agent.\n\n        Args:\n            system_message (dict): The system message dictionary.\n            user_message (ChatMessage): The user message.\n\n        Returns:\n            List[dict]: The complete list of messages to send.\n        """\n        user_prompt = {\n            "role": "user",\n            "content": self.models_config.get(\n                "user_response_instruction", "Can you make the answer better?"\n            ),\n        }\n        if self.conversation_history:\n            return [system_message, *self.conversation_history, user_prompt]\n        else:\n            return [system_message, user_message.to_dict()]\n\n    def predict(\n        self, context, messages: List[ChatMessage], params: Optional[ChatParams] = None\n    ) -> ChatCompletionResponse:\n        """\n        Predict method to handle agent conversation.\n\n        Args:\n            context: The MLflow context.\n            messages (List[ChatMessage]): List of messages to process.\n            params (Optional[ChatParams]): Additional parameters for the conversation.\n\n        Returns:\n            ChatCompletionResponse: The structured response object.\n        """\n        # Use the fluent API context handler to have added control over what is included in the span\n        with mlflow.start_span(name="Audit Agent") as root_span:\n            # Add the user input to the root span\n            root_span.set_inputs(messages)\n\n            # Add attributes to the root span\n            attributes = {**params.to_dict(), **self.models_config, **self.models}\n            root_span.set_attributes(attributes)\n\n            # Initiate the conversation with the oracle\n            oracle_params = self._get_model_params("oracle")\n            oracle_response = self._call_agent(messages[0], "oracle", oracle_params)\n\n            # Process the response with the judge\n            judge_params = self._get_model_params("judge")\n            judge_response = self._call_agent(\n                ChatMessage(**oracle_response), "judge", judge_params\n            )\n\n            # Reset the conversation history and return the final response\n            self.conversation_history = []\n\n            output = ChatCompletionResponse(\n                choices=[ChatChoice(index=0, message=ChatMessage(**judge_response))],\n                usage={},\n                model=judge_params.get("endpoint", "unknown"),\n            )\n\n            root_span.set_outputs(output)\n\n        return output\n\n    def _get_model_params(self, role: str) -> dict:\n        """\n        Retrieves model parameters for a given role.\n\n        Args:\n            role (str): The role of the agent (e.g., "oracle" or "judge").\n\n        Returns:\n            dict: A dictionary of parameters for the agent.\n        """\n        role_config = self.models.get(role, {})\n\n        return {\n            "temperature": role_config.get("temperature", 0.5),\n            "max_tokens": role_config.get("max_tokens", 500),\n        }\n\n\n# IMPORTANT: specifies the Python ChatModel instance to use for inference requests when\n# the model is loaded back\nagent = BasicAgent()\nmlflow.models.set_model(agent)\n'})}),"\n",(0,o.jsxs)(n.p,{children:["The snippet above defines our agent as a subclass of ",(0,o.jsx)(n.code,{children:"ChatModel"}),". With the models from code approach, we call\n",(0,o.jsx)(r.B,{fn:"mlflow.models.set_model",children:(0,o.jsx)(n.code,{children:"mlflow.models.set_model"})}),", passing an instance of our ",(0,o.jsx)(n.code,{children:"BasicAgent"}),", to indicate which model object to use for\ninference when our agent is loaded back."]}),"\n",(0,o.jsxs)(n.p,{children:["Save the agent code in a Python file, e.g. ",(0,o.jsx)(n.code,{children:"basic_agent.py"}),". ",(0,o.jsx)(n.strong,{children:"This is a key part of models from code"})," - it enables\nlogging a file containing the model's code, rather than a serialized model object, bypassing serialization issues."]}),"\n",(0,o.jsxs)(n.p,{children:["With our model defined in a code file, there's only one step left before we can log it:\nwe need to define the configuration for our model to be initialized with. This is done by defining our ",(0,o.jsx)(n.code,{children:"model_config"})," configuration."]}),"\n",(0,o.jsxs)(n.h2,{id:"setting-our-model_config-values",children:["Setting our ",(0,o.jsx)(n.code,{children:"model_config"})," values"]}),"\n",(0,o.jsx)(n.p,{children:"Before logging the model, we need to define the configuration that governs the behavior of our model's agents. This decoupling of configuration from the core logic of the model allows us to easily test and compare different agent behaviors without needing to modify the model implementation. By using a flexible configuration system, we can efficiently experiment with different settings, making it much easier to iterate and fine-tune our model."}),"\n",(0,o.jsx)(n.h3,{id:"why-decouple-configuration",children:"Why Decouple Configuration?"}),"\n",(0,o.jsxs)(n.p,{children:["In the context of Generative AI (GenAI), agent behavior can vary greatly depending on the instruction sets and parameters (such as ",(0,o.jsx)(n.code,{children:"temperature"})," or\n",(0,o.jsx)(n.code,{children:"max_tokens"}),") given to each agent. If we hardcoded these configurations directly into our model's logic, each new test would require changing the\nmodel's source code, leading to:"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Inefficiency"}),": Changing source code for each test slows down the experimentation process."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Increased Risk of Errors"}),": Constantly modifying the source increases the chance of introducing bugs or unintended side effects."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Lack of Reproducibility"}),": Without a clear separation between code and configuration, tracking and reproducing the exact configuration used for\na particular result becomes challenging."]}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["By setting these values externally via the ",(0,o.jsx)(n.code,{children:"model_config"})," parameter, we make the model flexible and adaptable to different test scenarios.\nThis approach also integrates seamlessly with MLflow's evaluation tools, such as ",(0,o.jsx)(r.B,{fn:"mlflow.evaluate"}),", which allows you to compare model\noutputs across different configurations systematically."]}),"\n",(0,o.jsx)(n.h3,{id:"defining-the-model-configuration",children:"Defining the Model Configuration"}),"\n",(0,o.jsx)(n.p,{children:"The configuration consists of two main sections:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Models"}),": This section defines agent-specific configurations, such as the ",(0,o.jsx)(n.code,{children:"judge"})," and ",(0,o.jsx)(n.code,{children:"oracle"})," roles in this example. Each agent has:"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["An ",(0,o.jsx)(n.strong,{children:"endpoint"}),": Specifies the model type or service being used for this agent."]}),"\n",(0,o.jsxs)(n.li,{children:["An ",(0,o.jsx)(n.strong,{children:"instruction"}),": Defines the role and responsibilities of the agent (e.g., answering questions, evaluating responses)."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Temperature and Max Tokens"}),": Controls the generation variability (",(0,o.jsx)(n.code,{children:"temperature"}),") and token limit for responses."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"General Configuration"}),": Additional settings for the overall behavior of the model, such as how user responses should be framed for subsequent agents."]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsxs)(n.p,{children:["There are two options available for setting a model configuration: directly within the logging code (shown below) or by writing a configuration file\nin ",(0,o.jsx)(n.code,{children:"yaml"})," format to a local location whose path can be specified when defining the ",(0,o.jsx)(n.code,{children:"model_config"})," argument during logging. To learn more about\nhow the ",(0,o.jsx)(n.code,{children:"model_config"})," parameter is utilized, ",(0,o.jsx)(n.a,{href:"/model#python-function-model-interfaces",children:"see the guide on model_config usage"}),"."]})}),"\n",(0,o.jsx)(n.p,{children:"Here's how we set the configuration for our agents:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'model_config = {\n    "models": {\n        "judge": {\n            "endpoint": "databricks-meta-llama-3-1-405b-instruct",\n            "instruction": (\n                "You are an evaluator of answers provided by others. Based on the context of both the question and the answer, "\n                "provide a corrected answer if it is incorrect; otherwise, enhance the answer with additional context and explanation."\n            ),\n            "temperature": 0.5,\n            "max_tokens": 2000,\n        },\n        "oracle": {\n            "endpoint": "databricks-mixtral-8x7b-instruct",\n            "instruction": (\n                "You are a knowledgeable source of information that excels at providing detailed, but brief answers to questions. "\n                "Provide an answer to the question based on the information provided."\n            ),\n            "temperature": 0.9,\n            "max_tokens": 5000,\n        },\n    },\n    "configuration": {\n        "user_response_instruction": "Can you evaluate and enhance this answer with the provided contextual history?"\n    },\n}\n'})}),"\n",(0,o.jsx)(n.h3,{id:"benefits-of-external-configuration",children:"Benefits of External Configuration"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Flexibility"}),": The decoupled configuration allows us to easily switch or adjust model behavior without modifying the core logic. For example, we can\nchange the model's instructions or adjust the ",(0,o.jsx)(n.code,{children:"temperature"})," to test different levels of creativity in the responses."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Scalability"}),": As more agents are added to the system or new roles are introduced, we can extend this configuration without cluttering the model's\ncode. This separation keeps the codebase cleaner and more maintainable."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Reproducibility and Comparison"}),": By keeping configuration external, we can log the specific settings used in each run with MLflow. This makes it\neasier to reproduce results and compare different experiments, ensuring a robust evaluation and adjudication process to select the best performing\nconfiguration."]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"With the configuration in place, we're now ready to log the model and run experiments using these settings. By leveraging MLflow's powerful tracking\nand logging features, we'll be able to manage the experiments efficiently and extract valuable insights from the agent's responses."}),"\n",(0,o.jsx)(n.h2,{id:"defining-an-input-example",children:"Defining an Input Example"}),"\n",(0,o.jsxs)(n.p,{children:["Before logging our model, it's important to provide an ",(0,o.jsx)(n.code,{children:"input_example"})," that demonstrates how to interact with the model. This example serves several key purposes:"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Validation at Logging Time"}),": Including an ",(0,o.jsx)(n.code,{children:"input_example"})," allows MLflow to execute the ",(0,o.jsx)(n.code,{children:"predict"})," method using this example during the logging\nprocess. This helps validate that your model can handle the expected input format and catch any issues early."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"UI Representation"}),": The ",(0,o.jsx)(n.code,{children:"input_example"})," is displayed in the MLflow UI under the model's artifacts. This provides a convenient reference for\nusers to understand the expected input structure when interacting with the deployed model."]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"By providing an input example, you ensure that your model is tested with real data, increasing confidence that it will behave as expected when deployed."}),"\n",(0,o.jsx)(n.admonition,{type:"tip",children:(0,o.jsxs)(n.p,{children:["When defining your GenAI application using the ",(0,o.jsx)(r.B,{fn:"mlflow.pyfunc.ChatModel",children:(0,o.jsx)(n.code,{children:"mlflow.pyfunc.ChatModel"})}),", a default placeholder input example will be used if none is provided.\nIf you notice an unfamiliar or generic input example in the MLflow UI\u2019s artifact viewer, it's likely the default placeholder assigned by the system.\nTo avoid this, ensure you specify a custom input example when saving your model."]})}),"\n",(0,o.jsx)(n.p,{children:"Here's the input example we'll use:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'input_example = {\n    "messages": [\n        {\n            "role": "user",\n            "content": "What is a good recipe for baking scones that doesn\'t require a lot of skill?",\n        }\n    ]\n}\n'})}),"\n",(0,o.jsxs)(n.p,{children:["This example represents a user asking for an easy scone recipe. It aligns with the input structure expected by our ",(0,o.jsx)(n.code,{children:"BasicAgent"})," model, which processes a\nlist of messages where each message includes a ",(0,o.jsx)(n.code,{children:"role"})," and ",(0,o.jsx)(n.code,{children:"content"}),"."]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Benefits of Providing an Input Example:"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Execution and Validation"}),": MLflow will pass this ",(0,o.jsx)(n.code,{children:"input_example"})," to the model's ",(0,o.jsx)(n.code,{children:"predict"})," method during logging to ensure that it can process\nthe input without errors. Any issues with input handling, such as incorrect data types or missing fields, will be caught at this stage, saving you time\ndebugging later."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"User Interface Display"}),": The ",(0,o.jsx)(n.code,{children:"input_example"})," will be visible in the MLflow UI within the model artifact view section. This helps users understand\nthe format of input data the model expects, making it easier to interact with the model once it's deployed."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Deployment Confidence"}),": By validating the model with an example input upfront, you gain additional assurance that the model will function correctly\nin a production environment, reducing the risk of unexpected behavior after deployment."]}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["Including an ",(0,o.jsx)(n.code,{children:"input_example"})," is a simple yet powerful step to verify that your model is ready for deployment and will behave as expected when\nreceiving input from users."]}),"\n",(0,o.jsx)(n.h2,{id:"logging-and-loading-our-custom-agent",children:"Logging and Loading our custom Agent"}),"\n",(0,o.jsx)(n.p,{children:"To log and load the model using MLflow, use:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'with mlflow.start_run():\n    model_info = mlflow.pyfunc.log_model(\n        name="model",\n        # If needed, update `python_model` to the Python file containing your agent code\n        python_model="basic_agent.py",\n        model_config=model_config,\n        input_example=input_example,\n    )\n\nloaded = mlflow.pyfunc.load_model(model_info.model_uri)\n\nresponse = loaded.predict(\n    {\n        "messages": [\n            {\n                "role": "user",\n                "content": "What is the best material to make a baseball bat out of?",\n            }\n        ]\n    }\n)\n'})}),"\n",(0,o.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,o.jsxs)(n.p,{children:["In this tutorial, you have explored the process of creating a custom GenAI chat agent using MLflow's ",(0,o.jsx)(r.B,{fn:"mlflow.pyfunc.ChatModel",children:(0,o.jsx)(n.code,{children:"mlflow.pyfunc.ChatModel"})})," class.\nWe demonstrated how to implement a flexible, scalable, and standardized approach to managing the deployment of GenAI applications, enabling you\nto harness the latest advancements in AI, even for libraries and frameworks that are not yet natively supported with a named flavor in MLflow."]}),"\n",(0,o.jsxs)(n.p,{children:["By using ",(0,o.jsx)(n.code,{children:"ChatModel"})," instead of the more generic ",(0,o.jsx)(n.code,{children:"PythonModel"}),", you can avoid many of the common pitfalls associated with deploying GenAI by\nleveraging the benefits of immutable signature interfaces that are consistent across any of your deployed GenAI interfaces, simplifying the\nuse of all of your solutions by providing a consistent experience."]}),"\n",(0,o.jsx)(n.p,{children:"Key takeaways from this tutorial include:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Tracing and Monitoring"}),": By integrating tracing directly into the model, you gain valuable insights into the internal workings of your application,\nmaking debugging and optimization more straightforward. Both the decorator and fluent API approaches offer versatile ways to manage tracing for\ncritical operations."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Flexible Configuration Management"}),": Decoupling configurations from your model code ensures that you can rapidly test and iterate without\nmodifying source code. This approach not only streamlines experimentation but also enhances reproducibility and scalability as your application evolves."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Standardized Input and Output Structures"}),": Leveraging the static signatures of ",(0,o.jsx)(n.code,{children:"ChatModel"})," simplifies the complexities of deploying and\nserving GenAI models. By adhering to established standards, you reduce the friction typically associated with integrating and validating input/output formats."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Avoiding Common Pitfalls"}),": Throughout the implementation, we highlighted best practices to avoid common issues, such as proper handling\nof secrets, validating input examples, and understanding the nuances of loading context. Following these practices ensures that your model\nremains secure, robust, and reliable in production environments."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Validation and Deployment Readiness"}),": The importance of validating your model before deployment cannot be overstated. By using tools\nlike ",(0,o.jsx)(r.B,{fn:"mlflow.models.validate_serving_input"}),", you can catch and resolve potential deployment issues early, saving time and effort\nduring the production deployment process."]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"As the landscape of Generative AI continues to evolve, building adaptable and standardized models will be crucial to leveraging the exciting\nand powerful capabilities that will be unlocked in the months and years ahead. The approach covered in this tutorial equips you with a robust\nframework for integrating and managing GenAI technologies within MLflow, empowering you to develop, track, and deploy sophisticated AI solutions with ease."}),"\n",(0,o.jsx)(n.p,{children:"We encourage you to extend and customize this foundational example to suit your specific needs and explore further enhancements. By leveraging\nMLflow's growing capabilities, you can continue to refine your GenAI models, ensuring they deliver impactful and reliable results in any application."})]})}function p(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(m,{...e})}):m(e)}}}]);