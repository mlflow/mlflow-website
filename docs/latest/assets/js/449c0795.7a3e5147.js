"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5238],{14234:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/images/mlflow_ui_chart_view-b6aac7263c29f4bb1a3a81bd79fa9de0.png"},16765:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/images/register_model_button-b08240156f1d2ea28cf3b1d6b34f6e3b.png"},25508:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/images/quickstart_tracking_overview-2fc1efa4bce294fc4114ce35fa34fe04.png"},28453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>i});var r=t(96540);const s={},a=r.createContext(s);function o(e){const n=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),r.createElement(a.Provider,{value:n},e.children)}},41106:(e,n,t)=>{t.d(n,{A:()=>r});const r=t.p+"assets/images/mlflow_ui_table_view-f15708222dfaba0945e76d859a74c6f1.png"},88451:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"getting-started/quickstart-2/index","title":"Quickstart: Compare runs, choose a model, and deploy it to a REST API","description":"In this quickstart, you will:","source":"@site/docs/getting-started/quickstart-2/index.mdx","sourceDirName":"getting-started/quickstart-2","slug":"/getting-started/quickstart-2/","permalink":"/docs/latest/getting-started/quickstart-2/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Try Managed MLflow","permalink":"/docs/latest/getting-started/databricks-trial/"},"next":{"title":"Tutorial Overview","permalink":"/docs/latest/getting-started/registering-first-model/"}}');var s=t(74848),a=t(28453);const o={},i="Quickstart: Compare runs, choose a model, and deploy it to a REST API",l={},d=[{value:"Set up",id:"set-up",level:2},{value:"Run a hyperparameter sweep",id:"run-a-hyperparameter-sweep",level:2},{value:"Compare the results",id:"compare-the-results",level:2},{value:"Register your best model",id:"register-your-best-model",level:2},{value:"Serve the model locally",id:"serve-the-model-locally",level:2},{value:"Build a container image for your model",id:"build-a-container-image-for-your-model",level:2},{value:"Deploying to a cloud platform",id:"deploying-to-a-cloud-platform",level:2}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"quickstart-compare-runs-choose-a-model-and-deploy-it-to-a-rest-api",children:"Quickstart: Compare runs, choose a model, and deploy it to a REST API"})}),"\n",(0,s.jsx)(n.p,{children:"In this quickstart, you will:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Run a hyperparameter sweep on a training script"}),"\n",(0,s.jsx)(n.li,{children:"Compare the results of the runs in the MLflow UI"}),"\n",(0,s.jsx)(n.li,{children:"Choose the best run and register it as a model"}),"\n",(0,s.jsx)(n.li,{children:"Deploy the model to a REST API"}),"\n",(0,s.jsx)(n.li,{children:"Build a container image suitable for deployment to a cloud platform"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"As an ML Engineer or MLOps professional, you can use MLflow to compare, share, and deploy the best models produced\nby the team. In this quickstart, you will use the MLflow Tracking UI to compare the results of a hyperparameter\nsweep, choose the best run, and register it as a model. Then, you will deploy the model to a REST API. Finally,\nyou will create a Docker container image suitable for deployment to a cloud platform."}),"\n",(0,s.jsx)("div",{className:"center-div",style:{width:800,maxWidth:"100%"},children:(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Diagram showing Data Science and MLOps workflow with MLflow",src:t(25508).A+"",width:"2342",height:"660"})})}),"\n",(0,s.jsx)(n.h2,{id:"set-up",children:"Set up"}),"\n",(0,s.jsxs)(n.p,{children:["For a comprehensive guide on getting an MLflow environment setup that will give you options on how to configure MLflow tracking\ncapabilities, you can ",(0,s.jsx)(n.a,{href:"/getting-started/running-notebooks/",children:"read the guide here"}),"."]}),"\n",(0,s.jsx)(n.h2,{id:"run-a-hyperparameter-sweep",children:"Run a hyperparameter sweep"}),"\n",(0,s.jsxs)(n.p,{children:["This example tries to optimize the RMSE metric of a Keras deep learning model on a wine quality dataset. It has\ntwo hyperparameters that it tries to optimize: ",(0,s.jsx)(n.code,{children:"learning_rate"})," and ",(0,s.jsx)(n.code,{children:"momentum"}),". We will use the\n",(0,s.jsx)(n.a,{href:"https://github.com/hyperopt/hyperopt",children:"Hyperopt"})," library to run a hyperparameter sweep across\ndifferent values of ",(0,s.jsx)(n.code,{children:"learning_rate"})," and ",(0,s.jsx)(n.code,{children:"momentum"})," and record the results in MLflow."]}),"\n",(0,s.jsxs)(n.p,{children:["Before running the hyperparameter sweep, let's set the ",(0,s.jsx)(n.code,{children:"MLFLOW_TRACKING_URI"})," environment variable to the URI of\nour MLflow tracking server:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"export MLFLOW_TRACKING_URI=http://localhost:5000\n"})}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsxs)(n.p,{children:["If you would like to explore the possibilities of other tracking server deployments, including a fully-managed\nfree-of-charge solution with the Databricks Free Trial, please see ",(0,s.jsx)(n.a,{href:"/getting-started/running-notebooks/",children:"this page"}),"."]})}),"\n",(0,s.jsx)(n.p,{children:"Import the following packages"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import keras\nimport numpy as np\nimport pandas as pd\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\nimport mlflow\nfrom mlflow.models import infer_signature\n"})}),"\n",(0,s.jsx)(n.p,{children:"Now load the dataset and split it into training, validation, and test sets."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Load dataset\ndata = pd.read_csv(\n    "https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv",\n    sep=";",\n)\n\n# Split the data into training, validation, and test sets\ntrain, test = train_test_split(data, test_size=0.25, random_state=42)\ntrain_x = train.drop(["quality"], axis=1).values\ntrain_y = train[["quality"]].values.ravel()\ntest_x = test.drop(["quality"], axis=1).values\ntest_y = test[["quality"]].values.ravel()\ntrain_x, valid_x, train_y, valid_y = train_test_split(\n    train_x, train_y, test_size=0.2, random_state=42\n)\nsignature = infer_signature(train_x, train_y)\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Then let's define the model architecture and train the model. The ",(0,s.jsx)(n.code,{children:"train_model"})," function uses MLflow to track the\nparameters, results, and model itself of each trial as a child run."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'def train_model(params, epochs, train_x, train_y, valid_x, valid_y, test_x, test_y):\n    # Define model architecture\n    mean = np.mean(train_x, axis=0)\n    var = np.var(train_x, axis=0)\n    model = keras.Sequential(\n        [\n            keras.Input([train_x.shape[1]]),\n            keras.layers.Normalization(mean=mean, variance=var),\n            keras.layers.Dense(64, activation="relu"),\n            keras.layers.Dense(1),\n        ]\n    )\n\n    # Compile model\n    model.compile(\n        optimizer=keras.optimizers.SGD(\n            learning_rate=params["lr"], momentum=params["momentum"]\n        ),\n        loss="mean_squared_error",\n        metrics=[keras.metrics.RootMeanSquaredError()],\n    )\n\n    # Train model with MLflow tracking\n    with mlflow.start_run(nested=True):\n        model.fit(\n            train_x,\n            train_y,\n            validation_data=(valid_x, valid_y),\n            epochs=epochs,\n            batch_size=64,\n        )\n        # Evaluate the model\n        eval_result = model.evaluate(valid_x, valid_y, batch_size=64)\n        eval_rmse = eval_result[1]\n\n        # Log parameters and results\n        mlflow.log_params(params)\n        mlflow.log_metric("eval_rmse", eval_rmse)\n\n        # Log model\n        mlflow.tensorflow.log_model(model, name="model", signature=signature)\n\n        return {"loss": eval_rmse, "status": STATUS_OK, "model": model}\n'})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"objective"})," function takes in the hyperparameters and returns the results of the ",(0,s.jsx)(n.code,{children:"train_model"}),"\nfunction for that set of hyperparameters."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"def objective(params):\n    # MLflow will track the parameters and results for each run\n    result = train_model(\n        params,\n        epochs=3,\n        train_x=train_x,\n        train_y=train_y,\n        valid_x=valid_x,\n        valid_y=valid_y,\n        test_x=test_x,\n        test_y=test_y,\n    )\n    return result\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Next, we will define the search space for Hyperopt. In this case, we want to try different values of\n",(0,s.jsx)(n.code,{children:"learning-rate"})," and ",(0,s.jsx)(n.code,{children:"momentum"}),". Hyperopt begins its optimization process by selecting an initial\nset of hyperparameters, typically chosen at random or based on a specified domain space. This domain\nspace defines the range and distribution of possible values for each hyperparameter. After evaluating\nthe initial set, Hyperopt uses the results to update its probabilistic model, guiding the selection\nof subsequent hyperparameter sets in a more informed manner, aiming to converge towards the optimal solution."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'space = {\n    "lr": hp.loguniform("lr", np.log(1e-5), np.log(1e-1)),\n    "momentum": hp.uniform("momentum", 0.0, 1.0),\n}\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Finally, we will run the hyperparameter sweep using Hyperopt, passing in the ",(0,s.jsx)(n.code,{children:"objective"})," function and search space.\nHyperopt will try different hyperparameter combinations and return the results of the best one. We will\nstore the best parameters, model, and evaluation metrics in MLflow."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'mlflow.set_experiment("/wine-quality")\nwith mlflow.start_run():\n    # Conduct the hyperparameter search using Hyperopt\n    trials = Trials()\n    best = fmin(\n        fn=objective,\n        space=space,\n        algo=tpe.suggest,\n        max_evals=8,\n        trials=trials,\n    )\n\n    # Fetch the details of the best run\n    best_run = sorted(trials.results, key=lambda x: x["loss"])[0]\n\n    # Log the best parameters, loss, and model\n    mlflow.log_params(best)\n    mlflow.log_metric("eval_rmse", best_run["loss"])\n    mlflow.tensorflow.log_model(best_run["model"], name="model", signature=signature)\n\n    # Print out the best parameters and corresponding loss\n    print(f"Best parameters: {best}")\n    print(f"Best eval rmse: {best_run[\'loss\']}")\n'})}),"\n",(0,s.jsx)(n.h2,{id:"compare-the-results",children:"Compare the results"}),"\n",(0,s.jsxs)(n.p,{children:["Open the MLflow UI in your browser at the ",(0,s.jsx)(n.code,{children:"MLFLOW_TRACKING_URI"}),". You should see a nested list of runs. In the\ndefault ",(0,s.jsx)(n.strong,{children:"Table view"}),", choose the ",(0,s.jsx)(n.strong,{children:"Columns"})," button and add the ",(0,s.jsx)(n.strong,{children:"Metrics | eval_rmse"})," column and\nthe ",(0,s.jsx)(n.strong,{children:"Parameters | lr"})," and ",(0,s.jsx)(n.strong,{children:"Parameters | momentum"})," column. To sort by RMSE ascending, click the ",(0,s.jsx)(n.strong,{children:"eval_rmse"}),"\ncolumn header. The best run typically has an RMSE on the ",(0,s.jsx)(n.strong,{children:"test"})," dataset of ~0.70. You can see the parameters\nof the best run in the ",(0,s.jsx)(n.strong,{children:"Parameters"})," column."]}),"\n",(0,s.jsx)("div",{className:"center-div",style:{width:800,maxWidth:"100%"},children:(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Screenshot of MLflow tracking UI table view showing runs",src:t(41106).A+"",width:"3346",height:"1663"})})}),"\n",(0,s.jsxs)(n.p,{children:["Choose ",(0,s.jsx)(n.strong,{children:"Chart view"}),". Choose the ",(0,s.jsx)(n.strong,{children:"Parallel coordinates"})," graph and configure it to show the ",(0,s.jsx)(n.strong,{children:"lr"})," and\n",(0,s.jsx)(n.strong,{children:"momentum"})," coordinates and the ",(0,s.jsx)(n.strong,{children:"eval_rmse"})," metric. Each line in this graph represents a run and associates\neach hyperparameter evaluation run's parameters to the evaluated error metric for the run."]}),"\n",(0,s.jsx)("div",{className:"center-div",style:{width:800,maxWidth:"100%"},children:(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Screenshot of MLflow tracking UI parallel coordinates graph showing runs",src:t(14234).A+"",width:"3316",height:"1692"})})}),"\n",(0,s.jsxs)(n.p,{children:["The red graphs on this graph are runs that fared poorly. The lowest one is a baseline run with both ",(0,s.jsx)(n.strong,{children:"lr"}),"\nand ",(0,s.jsx)(n.strong,{children:"momentum"})," set to 0.0. That baseline run has an RMSE of ~0.89. The other red lines show that\nhigh ",(0,s.jsx)(n.strong,{children:"momentum"})," can also lead to poor results with this problem and architecture."]}),"\n",(0,s.jsx)(n.p,{children:"The graphs shading towards blue are runs that fared better. Hover your mouse over individual runs to see their details."}),"\n",(0,s.jsx)(n.h2,{id:"register-your-best-model",children:"Register your best model"}),"\n",(0,s.jsxs)(n.p,{children:["Choose the best run and register it as a model. In the ",(0,s.jsx)(n.strong,{children:"Table view"}),", choose the best run. In the\n",(0,s.jsx)(n.strong,{children:"Run Detail"})," page, open the ",(0,s.jsx)(n.strong,{children:"Artifacts"})," section and select the ",(0,s.jsx)(n.strong,{children:"Register Model"})," button. In the\n",(0,s.jsx)(n.strong,{children:"Register Model"})," dialog, enter a name for the model, such as ",(0,s.jsx)(n.code,{children:"wine-quality"}),", and click ",(0,s.jsx)(n.strong,{children:"Register"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["Now, your model is available for deployment. You can see it in the ",(0,s.jsx)(n.strong,{children:"Models"})," page of the MLflow UI.\nOpen the page for the model you just registered."]}),"\n",(0,s.jsxs)(n.p,{children:["You can add a description for the model, add tags, and easily navigate back to the source run that generated\nthis model. You can also transition the model to different stages. For example, you can transition the model\nto ",(0,s.jsx)(n.strong,{children:"Staging"})," to indicate that it is ready for testing. You can transition it to ",(0,s.jsx)(n.strong,{children:"Production"})," to indicate\nthat it is ready for deployment."]}),"\n",(0,s.jsxs)(n.p,{children:["Transition the model to ",(0,s.jsx)(n.strong,{children:"Staging"})," by choosing the ",(0,s.jsx)(n.strong,{children:"Stage"})," dropdown:"]}),"\n",(0,s.jsx)("div",{className:"center-div",style:{width:800,maxWidth:"100%"},children:(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Screenshot of MLflow tracking UI models page showing the registered model",src:t(16765).A+"",width:"3367",height:"1777"})})}),"\n",(0,s.jsx)(n.h2,{id:"serve-the-model-locally",children:"Serve the model locally"}),"\n",(0,s.jsx)(n.p,{children:"MLflow allows you to easily serve models produced by any run or model version.\nYou can serve the model you just registered by running:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'mlflow models serve -m "models:/wine-quality/1" --port 5002\n'})}),"\n",(0,s.jsxs)(n.p,{children:["(Note that specifying the port as above will be necessary if you are running the tracking server on the\nsame machine at the default port of ",(0,s.jsx)(n.strong,{children:"5000"}),".)"]}),"\n",(0,s.jsxs)(n.p,{children:["You could also have used a ",(0,s.jsx)(n.code,{children:"runs:/<run_id>"})," URI to serve a model, or any supported URI described in ",(0,s.jsx)(n.a,{href:"/tracking#artifact-stores",children:"Artifact Store"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"Please note that for production, we do not recommend deploying your model in the same VM as the tracking server\nbecause of resource limitation, within this guide we just run everything from the same machine for simplicity."}),"\n",(0,s.jsxs)(n.p,{children:["To test the model, you can send a request to the REST API using the ",(0,s.jsx)(n.code,{children:"curl"})," command:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'curl -d \'{"dataframe_split": {\n"columns": ["fixed acidity","volatile acidity","citric acid","residual sugar","chlorides","free sulfur dioxide","total sulfur dioxide","density","pH","sulphates","alcohol"],\n"data": [[7,0.27,0.36,20.7,0.045,45,170,1.001,3,0.45,8.8]]}}\' \\\n-H \'Content-Type: application/json\' -X POST localhost:5002/invocations\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Inferencing is done with a JSON ",(0,s.jsx)(n.code,{children:"POST"})," request to the ",(0,s.jsx)(n.strong,{children:"invocations"})," path on ",(0,s.jsx)(n.strong,{children:"localhost"})," at the specified port.\nThe ",(0,s.jsx)(n.code,{children:"columns"})," key specifies the names of the columns in the input data. The ",(0,s.jsx)(n.code,{children:"data"})," value is a list of lists,\nwhere each inner list is a row of data. For brevity, the above only requests one prediction of wine\nquality (on a scale of 3-8). The response is a JSON object with a ",(0,s.jsx)(n.strong,{children:"predictions"})," key that contains a list of\npredictions, one for each row of data. In this case, the response is:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{ "predictions": [{ "0": 5.310967445373535 }] }\n'})}),"\n",(0,s.jsxs)(n.p,{children:["The schema for input and output is available in the MLflow UI in the ",(0,s.jsx)(n.strong,{children:"Artifacts | Model"})," description. The schema\nis available because the ",(0,s.jsx)(n.code,{children:"train.py"})," script used the ",(0,s.jsx)(n.code,{children:"mlflow.infer_signature"})," method and passed the result to\nthe ",(0,s.jsx)(n.code,{children:"mlflow.log_model"})," method. Passing the signature to the ",(0,s.jsx)(n.code,{children:"log_model"})," method is highly recommended, as it\nprovides clear error messages if the input request is malformed."]}),"\n",(0,s.jsx)(n.h2,{id:"build-a-container-image-for-your-model",children:"Build a container image for your model"}),"\n",(0,s.jsx)(n.p,{children:"Most routes toward deployment will use a container to package your model, its dependencies, and relevant portions of\nthe runtime environment. You can use MLflow to build a Docker image for your model."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'mlflow models build-docker --model-uri "models:/wine-quality/1" --name "qs_mlops"\n'})}),"\n",(0,s.jsxs)(n.p,{children:["This command builds a Docker image named ",(0,s.jsx)(n.code,{children:"qs_mlops"})," that contains your model and its dependencies. The ",(0,s.jsx)(n.code,{children:"model-uri"}),"\nin this case specifies a version number (",(0,s.jsx)(n.code,{children:"/1"}),") rather than a lifecycle stage (",(0,s.jsx)(n.code,{children:"/staging"}),"), but you can use\nwhichever integrates best with your workflow. It will take several minutes to build the image. Once it completes,\nyou can run the image to provide real-time inferencing locally, on-prem, on a bespoke Internet server, or cloud\nplatform. You can run it locally with:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"docker run -p 5002:8080 qs_mlops\n"})}),"\n",(0,s.jsxs)(n.p,{children:["This ",(0,s.jsx)(n.a,{href:"https://docs.docker.com/engine/reference/commandline/run/",children:"Docker run command"})," runs the image you just built\nand maps port ",(0,s.jsx)(n.strong,{children:"5002"})," on your local machine to port ",(0,s.jsx)(n.strong,{children:"8080"})," in the container. You can now send requests to the\nmodel using the same ",(0,s.jsx)(n.code,{children:"curl"})," command as before:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'curl -d \'{"dataframe_split": {"columns": ["fixed acidity","volatile acidity","citric acid","residual sugar","chlorides","free sulfur dioxide","total sulfur dioxide","density","pH","sulphates","alcohol"], "data": [[7,0.27,0.36,20.7,0.045,45,170,1.001,3,0.45,8.8]]}}\' -H \'Content-Type: application/json\' -X POST localhost:5002/invocations\n'})}),"\n",(0,s.jsx)(n.h2,{id:"deploying-to-a-cloud-platform",children:"Deploying to a cloud platform"}),"\n",(0,s.jsx)(n.p,{children:"Virtually all cloud platforms allow you to deploy a Docker image. The process varies considerably, so you will have\nto consult your cloud provider's documentation for details."}),"\n",(0,s.jsx)(n.p,{children:"In addition, some cloud providers have built-in support for MLflow:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/azure/machine-learning/",children:"Azure ML"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://www.databricks.com/product/managed-mlflow",children:"Databricks"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://docs.aws.amazon.com/sagemaker/latest/dg/mlflow.html",children:"Amazon SageMaker AI"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://cloud.google.com/doc",children:"Google Cloud"})}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Cloud platforms generally support multiple workflows for deployment: command-line, SDK-based, and web-based.\nYou can use MLflow in any of these workflows, although the details will vary between\nplatforms and versions. Again, you will need to consult your cloud provider's documentation for details."})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}}}]);