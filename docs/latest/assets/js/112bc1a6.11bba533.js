"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["2037"],{64049(e,n,t){t.r(n),t.d(n,{metadata:()=>s,default:()=>w,frontMatter:()=>g,contentTitle:()=>_,toc:()=>y,assets:()=>x});var s=JSON.parse('{"id":"version-tracking/compare-app-versions","title":"Compare App Versions","description":"Compare different application versions using traces to track improvements and identify the best performing iteration.","source":"@site/docs/genai/version-tracking/compare-app-versions.mdx","sourceDirName":"version-tracking","slug":"/version-tracking/compare-app-versions","permalink":"/mlflow-website/docs/latest/genai/version-tracking/compare-app-versions","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Compare App Versions","description":"Compare different application versions using traces to track improvements and identify the best performing iteration."},"sidebar":"genAISidebar","previous":{"title":"Track versions of Git-based applications with MLflow","permalink":"/mlflow-website/docs/latest/genai/version-tracking/track-application-versions-with-mlflow"},"next":{"title":"MLflow GenAI Packaging Integrations","permalink":"/mlflow-website/docs/latest/genai/flavors/"}}'),r=t(74848),i=t(28453),a=t(33508),o=t(34742),c=t(10440),l=t(77541),p=t(96844),d=t(76316),m=t(3160),h=t(44471),u=t(51004),f=t(22864),v=t(46858);let g={title:"Compare App Versions",description:"Compare different application versions using traces to track improvements and identify the best performing iteration."},_="Compare Application Versions with Traces",x={},y=[{value:"Why Trace-Based Comparison Works",id:"why-trace-based-comparison-works",level:2},{value:"Generate Traces for Different Versions",id:"generate-traces-for-different-versions",level:2},{value:"Systematic Trace-Based Version Analysis",id:"systematic-trace-based-version-analysis",level:2},{value:"Collect and Analyze Version Traces",id:"collect-and-analyze-version-traces",level:3},{value:"Next Steps",id:"next-steps",level:2}];function A(e){let n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",pre:"pre",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"compare-application-versions-with-traces",children:"Compare Application Versions with Traces"})}),"\n",(0,r.jsx)(n.p,{children:"Objective version comparison drives successful GenAI development. MLflow's trace-based comparison enables you to analyze performance differences, validate improvements, and make data-driven deployment decisions across application iterations."}),"\n",(0,r.jsx)(n.h2,{id:"why-trace-based-comparison-works",children:"Why Trace-Based Comparison Works"}),"\n",(0,r.jsx)(a.A,{features:[{icon:p.A,title:"Complete Execution Context",description:"Traces capture the full application flow - inputs, outputs, intermediate steps, and performance metrics for comprehensive analysis."},{icon:d.A,title:"Objective Performance Metrics",description:"Compare latency, token usage, error rates, and quality metrics across versions with precise, measurable data."},{icon:m.A,title:"Detect Subtle Regressions",description:"Identify performance degradations or behavioral changes that might not be obvious from simple input/output comparison."},{icon:h.A,title:"Development Decision Support",description:"Make data-driven decisions about when to ship improvements, iterate further, or try different approaches based on trace analysis."}]}),"\n",(0,r.jsx)(n.h2,{id:"generate-traces-for-different-versions",children:"Generate Traces for Different Versions"}),"\n",(0,r.jsx)(n.p,{children:"Create traces for multiple application versions to enable systematic comparison:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport openai\n\n\n@mlflow.trace\ndef basic_agent(question: str) -> str:\n    """Basic customer support agent."""\n    client = openai.OpenAI()\n\n    response = client.chat.completions.create(\n        model="gpt-4o-mini",\n        messages=[\n            {"role": "system", "content": "You are a helpful customer support agent."},\n            {"role": "user", "content": question},\n        ],\n        temperature=0.3,\n        max_tokens=100,\n    )\n\n    return response.choices[0].message.content\n\n\n@mlflow.trace\ndef empathetic_agent(question: str) -> str:\n    """Enhanced customer support agent with empathetic prompting."""\n    client = openai.OpenAI()\n\n    # Enhanced system prompt\n    system_prompt = """You are a caring and empathetic customer support agent.\n    Always acknowledge the customer\'s feelings before providing solutions.\n    Use phrases like \'I understand how frustrating this must be\'.\n    Provide clear, actionable steps with a warm, supportive tone."""\n\n    response = client.chat.completions.create(\n        model="gpt-4o-mini",\n        messages=[\n            {"role": "system", "content": system_prompt},\n            {"role": "user", "content": question},\n        ],\n        temperature=0.7,\n        max_tokens=150,\n    )\n\n    return response.choices[0].message.content\n\n\nprint("\u2705 Agent functions ready for comparison")\n'})}),"\n",(0,r.jsx)(n.p,{children:"Generate comparable traces by testing both versions on the same inputs:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Test scenarios for fair comparison\ntest_questions = [\n    "How can I track my package?",\n    "What\'s your return policy?",\n    "I need help with my account login",\n    "My order arrived damaged, what should I do?",\n    "Can I cancel my subscription?",\n]\n\nprint("\u{1F504} Generating traces for version comparison...")\n\n# Run both versions on the same inputs\nfor i, question in enumerate(test_questions):\n    print(f"Testing scenario {i+1}: {question[:30]}...")\n\n    # Generate trace for v1\n    v1_response = basic_agent(question)\n\n    # Generate trace for v2\n    v2_response = empathetic_agent(question)\n\n    print(f"  V1 response: {v1_response[:50]}...")\n    print(f"  V2 response: {v2_response[:50]}...")\n\nprint(f"\\n\u2705 Generated {len(test_questions) * 2} traces for comparison")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"systematic-trace-based-version-analysis",children:"Systematic Trace-Based Version Analysis"}),"\n",(0,r.jsx)(o.A,{concepts:[{icon:u.A,title:"Trace Collection & Filtering",description:"Use MLflow's search_traces API to collect and filter traces by version metadata, enabling precise version-to-version comparisons."},{icon:f.A,title:"Performance Metric Analysis",description:"Extract and compare execution time, token usage, and quality metrics from traces to identify performance improvements or regressions."},{icon:v.A,title:"Automated Deployment Logic",description:"Build quality gates that automatically analyze trace metrics and determine deployment readiness based on performance thresholds."}]}),"\n",(0,r.jsx)(n.h3,{id:"collect-and-analyze-version-traces",children:"Collect and Analyze Version Traces"}),"\n",(0,r.jsxs)(n.p,{children:["Use ",(0,r.jsx)(n.code,{children:"search_traces"})," to systematically compare version performance:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from datetime import datetime, timedelta\nimport pandas as pd\n\n# Search for traces from the last hour (adjust timeframe as needed)\nrecent_time = datetime.now() - timedelta(hours=1)\n\n# Get traces for both versions\nall_traces = mlflow.search_traces(\n    filter_string=f"timestamp >= \'{recent_time.isoformat()}\'", max_results=100\n)\n\nprint(f"Found {len(all_traces)} recent traces\\n")\n\n# Separate traces by version using trace metadata\nv1_traces = []\nv2_traces = []\n\nfor trace in all_traces:\n    # Parse trace data to get metadata\n    trace_data = trace if isinstance(trace, dict) else trace.to_dict()\n\n    if "customer_support_v1" in trace_data.get("info", {}).get("name", ""):\n        v1_traces.append(trace_data)\n    elif "customer_support_v2" in trace_data.get("info", {}).get("name", ""):\n        v2_traces.append(trace_data)\n\nprint(f"Version 1 traces: {len(v1_traces)}")\nprint(f"Version 2 traces: {len(v2_traces)}")\n\n\n# Calculate performance metrics for each version\ndef analyze_traces(traces, version_name):\n    """Extract key metrics from a list of traces."""\n    if not traces:\n        return {}\n\n    execution_times = []\n    response_lengths = []\n\n    for trace in traces:\n        # Extract execution time (in milliseconds)\n        exec_time = trace.get("info", {}).get("execution_time_ms", 0)\n        execution_times.append(exec_time)\n\n        # Extract response length from spans\n        spans = trace.get("data", {}).get("spans", [])\n        if spans:\n            # Get the root span\'s output\n            root_span = spans[0]\n            output = root_span.get("outputs", "")\n            response_lengths.append(len(str(output)) if output else 0)\n\n    return {\n        "version": version_name,\n        "trace_count": len(traces),\n        "avg_execution_time_ms": sum(execution_times) / len(execution_times)\n        if execution_times\n        else 0,\n        "avg_response_length": sum(response_lengths) / len(response_lengths)\n        if response_lengths\n        else 0,\n        "min_execution_time_ms": min(execution_times) if execution_times else 0,\n        "max_execution_time_ms": max(execution_times) if execution_times else 0,\n    }\n\n\n# Analyze both versions\nv1_metrics = analyze_traces(v1_traces, "v1.0")\nv2_metrics = analyze_traces(v2_traces, "v2.0")\n\nprint("\\n\u{1F4CA} Version Performance Comparison:")\nprint(\n    f"V1 - Avg Execution: {v1_metrics[\'avg_execution_time_ms\']:.1f}ms, Avg Response: {v1_metrics[\'avg_response_length\']:.0f} chars"\n)\nprint(\n    f"V2 - Avg Execution: {v2_metrics[\'avg_execution_time_ms\']:.1f}ms, Avg Response: {v2_metrics[\'avg_response_length\']:.0f} chars"\n)\n'})}),"\n",(0,r.jsx)(n.p,{children:"This gives you a clear, data-driven view of how your application versions compare in terms of performance and reliability. You can use these metrics to make informed decisions about which version to deploy or iterate on further."}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsxs)(c.A,{children:[(0,r.jsx)(l.A,{href:"/genai/version-tracking",title:"Version Tracking",description:"Learn more about tracking application versions with MLflow",icon:u.A}),(0,r.jsx)(l.A,{href:"/genai/tracing",title:"MLflow Tracing",description:"Explore MLflow's comprehensive tracing capabilities for GenAI applications",icon:p.A})]})]})}function w(e={}){let{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(A,{...e})}):A(e)}},75689(e,n,t){t.d(n,{A:()=>c});var s=t(96540);let r=e=>{let n=e.replace(/^([A-Z])|[\s-_]+(\w)/g,(e,n,t)=>t?t.toUpperCase():n.toLowerCase());return n.charAt(0).toUpperCase()+n.slice(1)},i=(...e)=>e.filter((e,n,t)=>!!e&&""!==e.trim()&&t.indexOf(e)===n).join(" ").trim();var a={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};let o=(0,s.forwardRef)(({color:e="currentColor",size:n=24,strokeWidth:t=2,absoluteStrokeWidth:r,className:o="",children:c,iconNode:l,...p},d)=>(0,s.createElement)("svg",{ref:d,...a,width:n,height:n,stroke:e,strokeWidth:r?24*Number(t)/Number(n):t,className:i("lucide",o),...!c&&!(e=>{for(let n in e)if(n.startsWith("aria-")||"role"===n||"title"===n)return!0})(p)&&{"aria-hidden":"true"},...p},[...l.map(([e,n])=>(0,s.createElement)(e,n)),...Array.isArray(c)?c:[c]])),c=(e,n)=>{let t=(0,s.forwardRef)(({className:t,...a},c)=>(0,s.createElement)(o,{ref:c,iconNode:n,className:i(`lucide-${r(e).replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()}`,`lucide-${e}`,t),...a}));return t.displayName=r(e),t}},96844(e,n,t){t.d(n,{A:()=>s});let s=(0,t(75689).A)("activity",[["path",{d:"M22 12h-2.48a2 2 0 0 0-1.93 1.46l-2.35 8.36a.25.25 0 0 1-.48 0L9.24 2.18a.25.25 0 0 0-.48 0l-2.35 8.36A2 2 0 0 1 4.49 12H2",key:"169zse"}]])},22864(e,n,t){t.d(n,{A:()=>s});let s=(0,t(75689).A)("chart-column",[["path",{d:"M3 3v16a2 2 0 0 0 2 2h16",key:"c24i48"}],["path",{d:"M18 17V9",key:"2bz60n"}],["path",{d:"M13 17V5",key:"1frdt8"}],["path",{d:"M8 17v-3",key:"17ska0"}]])},44471(e,n,t){t.d(n,{A:()=>s});let s=(0,t(75689).A)("circle-check-big",[["path",{d:"M21.801 10A10 10 0 1 1 17 3.335",key:"yps3ct"}],["path",{d:"m9 11 3 3L22 4",key:"1pflzl"}]])},51004(e,n,t){t.d(n,{A:()=>s});let s=(0,t(75689).A)("database",[["ellipse",{cx:"12",cy:"5",rx:"9",ry:"3",key:"msslwz"}],["path",{d:"M3 5V19A9 3 0 0 0 21 19V5",key:"1wlel7"}],["path",{d:"M3 12A9 3 0 0 0 21 12",key:"mv7ke4"}]])},3160(e,n,t){t.d(n,{A:()=>s});let s=(0,t(75689).A)("eye",[["path",{d:"M2.062 12.348a1 1 0 0 1 0-.696 10.75 10.75 0 0 1 19.876 0 1 1 0 0 1 0 .696 10.75 10.75 0 0 1-19.876 0",key:"1nclc0"}],["circle",{cx:"12",cy:"12",r:"3",key:"1v7zrd"}]])},76316(e,n,t){t.d(n,{A:()=>s});let s=(0,t(75689).A)("trending-up",[["path",{d:"M16 7h6v6",key:"box55l"}],["path",{d:"m22 7-8.5 8.5-5-5L2 17",key:"1t1m79"}]])},46858(e,n,t){t.d(n,{A:()=>s});let s=(0,t(75689).A)("zap",[["path",{d:"M4 14a1 1 0 0 1-.78-1.63l9.9-10.2a.5.5 0 0 1 .86.46l-1.92 6.02A1 1 0 0 0 13 10h7a1 1 0 0 1 .78 1.63l-9.9 10.2a.5.5 0 0 1-.86-.46l1.92-6.02A1 1 0 0 0 11 14z",key:"1xq2db"}]])},34742(e,n,t){t.d(n,{A:()=>r});var s=t(74848);t(96540);function r({concepts:e,title:n}){return(0,s.jsxs)("div",{className:"conceptOverview_x8T_",children:[n&&(0,s.jsx)("h3",{className:"overviewTitle_HyAI",children:n}),(0,s.jsx)("div",{className:"conceptGrid_uJNV",children:e.map((e,n)=>(0,s.jsxs)("div",{className:"conceptCard_oday",children:[(0,s.jsxs)("div",{className:"conceptHeader_HCk5",children:[e.icon&&(0,s.jsx)("div",{className:"conceptIcon_gejw",children:(0,s.jsx)(e.icon,{size:20})}),(0,s.jsx)("h4",{className:"conceptTitle_TGMM",children:e.title})]}),(0,s.jsx)("p",{className:"conceptDescription_ZyDn",children:e.description})]},n))})]})}},33508(e,n,t){t.d(n,{A:()=>r});var s=t(74848);t(96540);function r({features:e,col:n=2}){return(0,s.jsx)("div",{className:"featureHighlights_Ardf",style:{gridTemplateColumns:`repeat(${n}, 1fr)`},children:e.map((e,n)=>(0,s.jsxs)("div",{className:"highlightItem_XPnN",children:[e.icon&&(0,s.jsx)("div",{className:"highlightIcon_SUR8",children:(0,s.jsx)(e.icon,{size:24})}),(0,s.jsxs)("div",{className:"highlightContent_d0XP",children:[(0,s.jsx)("h4",{children:e.title}),(0,s.jsx)("p",{children:e.description})]})]},n))})}},77541(e,n,t){t.d(n,{A:()=>l});var s=t(74848);t(96540);var r=t(95310),i=t(34164);let a="tileImage_O4So";var o=t(66497),c=t(92802);function l({icon:e,image:n,imageDark:t,imageWidth:l,imageHeight:p,iconSize:d=32,containerHeight:m,title:h,description:u,href:f,linkText:v="Learn more \u2192",className:g}){if(!e&&!n)throw Error("TileCard requires either an icon or image prop");let _=m?{height:`${m}px`}:{},x={};return l&&(x.width=`${l}px`),p&&(x.height=`${p}px`),(0,s.jsxs)(r.A,{href:f,className:(0,i.A)("tileCard_NHsj",g),children:[(0,s.jsx)("div",{className:"tileIcon_pyoR",style:_,children:e?(0,s.jsx)(e,{size:d}):t?(0,s.jsx)(c.A,{sources:{light:(0,o.default)(n),dark:(0,o.default)(t)},alt:h,className:a,style:x}):(0,s.jsx)("img",{src:(0,o.default)(n),alt:h,className:a,style:x})}),(0,s.jsx)("h3",{children:h}),(0,s.jsx)("p",{children:u}),(0,s.jsx)("div",{className:"tileLink_iUbu",children:v})]})}},10440(e,n,t){t.d(n,{A:()=>i});var s=t(74848);t(96540);var r=t(34164);function i({children:e,className:n}){return(0,s.jsx)("div",{className:(0,r.A)("tilesGrid_hB9N",n),children:e})}},28453(e,n,t){t.d(n,{R:()=>a,x:()=>o});var s=t(96540);let r={},i=s.createContext(r);function a(e){let n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);