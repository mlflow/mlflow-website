"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4814],{28453:(e,l,o)=>{o.d(l,{R:()=>r,x:()=>a});var n=o(96540);const t={},i=n.createContext(t);function r(e){const l=n.useContext(i);return n.useMemo((function(){return"function"==typeof e?e(l):{...l,...e}}),[l,e])}function a(e){let l;return l=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),n.createElement(i.Provider,{value:l},e.children)}},49374:(e,l,o)=>{o.d(l,{B:()=>s});o(96540);const n=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var t=o(86025),i=o(28774),r=o(74848);const a=e=>{const l=e.split(".");for(let o=l.length;o>0;o--){const e=l.slice(0,o).join(".");if(n[e])return e}return null};function s({fn:e,children:l}){const o=a(e);if(!o)return(0,r.jsx)(r.Fragment,{children:l});const s=(0,t.Ay)(`/${n[o]}#${e}`);return(0,r.jsx)(i.A,{to:s,target:"_blank",children:l??(0,r.jsxs)("code",{children:[e,"()"]})})}},98101:(e,l,o)=>{o.r(l),o.d(l,{assets:()=>p,contentTitle:()=>m,default:()=>d,frontMatter:()=>s,metadata:()=>n,toc:()=>c});const n=JSON.parse('{"id":"traditional-ml/tutorials/serving-multiple-models-with-pyfunc/index","title":"Serving Multiple Models on a Single Endpoint with a Custom PyFunc Model","description":"This tutorial addresses a common scenario in machine learning: serving multiple models through a","source":"@site/docs/classic-ml/traditional-ml/tutorials/serving-multiple-models-with-pyfunc/index.mdx","sourceDirName":"traditional-ml/tutorials/serving-multiple-models-with-pyfunc","slug":"/traditional-ml/tutorials/serving-multiple-models-with-pyfunc/","permalink":"/docs/latest/ml/traditional-ml/tutorials/serving-multiple-models-with-pyfunc/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"classicMLSidebar","previous":{"title":"Customizing the `predict` method","permalink":"/docs/latest/ml/traditional-ml/tutorials/creating-custom-pyfunc/notebooks/override-predict"},"next":{"title":"Notebooks","permalink":"/docs/latest/ml/traditional-ml/tutorials/serving-multiple-models-with-pyfunc/notebooks/MME_Tutorial"}}');var t=o(74848),i=o(28453),r=o(28774),a=o(49374);const s={sidebar_position:3},m="Serving Multiple Models on a Single Endpoint with a Custom PyFunc Model",p={},c=[{value:"What&#39;s in this tutorial?",id:"whats-in-this-tutorial",level:2},{value:"What is PyFunc?",id:"what-is-pyfunc",level:2},{value:"What do I need to do?",id:"what-do-i-need-to-do",level:2}];function h(e){const l={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(l.header,{children:(0,t.jsx)(l.h1,{id:"serving-multiple-models-on-a-single-endpoint-with-a-custom-pyfunc-model",children:"Serving Multiple Models on a Single Endpoint with a Custom PyFunc Model"})}),"\n",(0,t.jsx)(l.p,{children:"This tutorial addresses a common scenario in machine learning: serving multiple models through a\nsingle endpoint. Utilizing services like Sagemaker's Multi-Model Endpoints, you can host numerous\nmodels under one endpoint, simplifying deployment and cutting costs. We'll replicate this\nfunctionality using any MLflow-compatible service combined with a custom PyFunc implementation."}),"\n",(0,t.jsx)(l.admonition,{type:"tip",children:(0,t.jsxs)(l.p,{children:['MLflow 2.12.2 introduced the feature "models from code", which greatly simplifies the process of serializing and deploying custom models through the use\nof script serialization. While the tutorial here is valuable as a point of reference, we strongly recommend migrating custom model implementations to this\nnew paradigm. You can learn more about models from code within the ',(0,t.jsx)(l.a,{href:"/ml/model/models-from-code",children:"Models From Code Guide"}),"."]})}),"\n",(0,t.jsx)(l.p,{children:"Here are some reasons to consider this design:"}),"\n",(0,t.jsxs)(l.ul,{children:["\n",(0,t.jsxs)(l.li,{children:[(0,t.jsx)(l.strong,{children:"Simplified Inference"}),": We will maintain a single model endpoint instead of one per model, which dramatically reduces maintenance and provisioning complexity."]}),"\n",(0,t.jsxs)(l.li,{children:[(0,t.jsx)(l.strong,{children:"Reduced Serving Cost"}),": Endpoints cost money! If your hosting service charges for compute and not memory, this will save you money."]}),"\n"]}),"\n",(0,t.jsx)(l.h2,{id:"whats-in-this-tutorial",children:"What's in this tutorial?"}),"\n",(0,t.jsx)(l.p,{children:"This guide walks you through the steps to serve multiple models from a single endpoint, breaking\ndown the process into:"}),"\n",(0,t.jsxs)(l.ol,{children:["\n",(0,t.jsx)(l.li,{children:"Create many demo sklearn models, each trained on data corresponding to a single day of the week."}),"\n",(0,t.jsx)(l.li,{children:"Wrap those models in a custom PyFunc model to support multi-model inference."}),"\n",(0,t.jsx)(l.li,{children:"Perform inference on the custom PyFunc model."}),"\n",(0,t.jsx)(l.li,{children:"Locally serve the custom PyFunc model and query our endpoint."}),"\n"]}),"\n",(0,t.jsx)(l.p,{children:"After completing this tutorial, you'll be equipped to efficiently serve multiple models from a\nsingle endpoint."}),"\n",(0,t.jsx)(l.h2,{id:"what-is-pyfunc",children:"What is PyFunc?"}),"\n",(0,t.jsxs)(l.p,{children:["Custom PyFunc models are a powerful MLflow feature that lets users customize model functionality\nwhere named flavors may be lacking. Going forward we assume basic working knowledge of PyFunc, so if\nyou're unfamiliar, check out the ",(0,t.jsx)(l.a,{href:"/ml/traditional-ml/tutorials/creating-custom-pyfunc",children:"Creating Custom PyFunc"}),"\ntutorial."]}),"\n",(0,t.jsx)(l.h2,{id:"what-do-i-need-to-do",children:"What do I need to do?"}),"\n",(0,t.jsxs)(l.p,{children:["To create an MME, you'll create a child implementation of ",(0,t.jsx)(a.B,{fn:"mlflow.pyfunc.PythonModel",children:(0,t.jsx)(l.code,{children:"PythonModel"})}),".\nMore specifically, we'll need to focus on the below components..."]}),"\n",(0,t.jsxs)(l.ul,{children:["\n",(0,t.jsxs)(l.li,{children:[(0,t.jsx)(a.B,{fn:"mlflow.pyfunc.PythonModel.load_context",children:(0,t.jsx)(l.code,{children:"PythonModel.load_context()"})}),": This method defines artifacts from the specified PythonModelContext that can be used by ",(0,t.jsx)(l.code,{children:"predict()"})," when evaluating inputs. When loading an MLflow model with load_model(), this method is called as soon as the PythonModel is constructed. In our example, this method will load our models from MLflow model registry."]}),"\n",(0,t.jsxs)(l.li,{children:[(0,t.jsx)(a.B,{fn:"mlflow.pyfunc.PythonModel.predict",children:(0,t.jsx)(l.code,{children:"PythonModel.predict()"})}),": This method evaluates a pyfunc-compatible input and produces a pyfunc-compatible output. In our example, it analyzes the input payload and, based on its parameters, selects and applies the appropriate model to return predictions."]}),"\n",(0,t.jsxs)(l.li,{children:[(0,t.jsx)(a.B,{fn:"mlflow.models.ModelSignature",children:(0,t.jsx)(l.code,{children:"ModelSignatures"})}),": This class defines the expected input, output and params format. In our example, the signature object will be passed when registering our custom PyFunc model and inputs to the model will be validated against the signature."]}),"\n"]}),"\n",(0,t.jsx)(l.p,{children:"Ready to see this in action? Check out the accompanying notebooks for a hands-on experience. Let's dive in!"}),"\n",(0,t.jsx)(r.A,{className:"button button--primary",to:"./notebooks/MME_Tutorial",children:(0,t.jsx)("span",{children:"View the Notebook"})})]})}function d(e={}){const{wrapper:l}={...(0,i.R)(),...e.components};return l?(0,t.jsx)(l,{...e,children:(0,t.jsx)(h,{...e})}):h(e)}}}]);