"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[6972],{14433:(e,n,l)=>{l.d(n,{A:()=>o});const o=l.p+"assets/images/pytorch-guide-basic-example-ui-cf99aaf7644ae4e390f28f6be1ba594c.png"},17367:(e,n,l)=>{l.r(n),l.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>m,frontMatter:()=>a,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"deep-learning/pytorch/guide/index","title":"PyTorch within MLflow","description":"PyTorch has emerged as one of the leading deep learning frameworks, renowned for its intuitive design, dynamic computation graphs, and seamless debugging capabilities. By combining PyTorch\'s flexibility with MLflow\'s experiment tracking, you gain a powerful workflow for developing, monitoring, and deploying machine learning models.","source":"@site/docs/classic-ml/deep-learning/pytorch/guide/index.mdx","sourceDirName":"deep-learning/pytorch/guide","slug":"/deep-learning/pytorch/guide/","permalink":"/docs/latest/ml/deep-learning/pytorch/guide/","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"classicMLSidebar","previous":{"title":"Quickstart","permalink":"/docs/latest/ml/deep-learning/pytorch/quickstart/quickstart-pytorch"},"next":{"title":"TensorFlow","permalink":"/docs/latest/ml/deep-learning/tensorflow/"}}');var t=l(74848),i=l(28453),r=l(49374);const a={},s="PyTorch within MLflow",c={},d=[{value:"Dynamic Computation Design",id:"dynamic-computation-design",level:4},{value:"Powerful Ecosystem",id:"powerful-ecosystem",level:4},{value:"Why MLflow + PyTorch?",id:"why-mlflow--pytorch",level:2},{value:"Logging PyTorch Experiments to MLflow",id:"logging-pytorch-experiments-to-mlflow",level:2},{value:"Understanding PyTorch Autologging Limitations",id:"understanding-pytorch-autologging-limitations",level:3},{value:"Manually Logging PyTorch Experiments",id:"manually-logging-pytorch-experiments",level:3},{value:"Initialization Phase",id:"initialization-phase",level:4},{value:"Training Phase",id:"training-phase",level:4},{value:"Finalization Phase",id:"finalization-phase",level:4},{value:"Complete PyTorch Logging Example",id:"complete-pytorch-logging-example",level:3},{value:"Saving Your PyTorch Model to MLflow",id:"saving-your-pytorch-model-to-mlflow",level:2},{value:"Basic Model Saving",id:"basic-model-saving",level:3},{value:"Model Signatures",id:"model-signatures",level:3},{value:"Advanced PyTorch Tracking",id:"advanced-pytorch-tracking",level:2},{value:"Custom Training Loop with Detailed Metrics",id:"custom-training-loop-with-detailed-metrics",level:3},{value:"Hyperparameter Optimization",id:"hyperparameter-optimization",level:3},{value:"Real-World Applications",id:"real-world-applications",level:2},{value:"Conclusion",id:"conclusion",level:2}];function p(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components},{Details:o}=n;return o||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"pytorch-within-mlflow",children:"PyTorch within MLflow"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"PyTorch"})," has emerged as one of the leading deep learning frameworks, renowned for its intuitive design, dynamic computation graphs, and seamless debugging capabilities. By combining PyTorch's flexibility with MLflow's experiment tracking, you gain a powerful workflow for developing, monitoring, and deploying machine learning models."]}),"\n",(0,t.jsxs)(o,{children:[(0,t.jsx)("summary",{children:"Why PyTorch is a Researcher's Favorite"}),(0,t.jsx)(n.h4,{id:"dynamic-computation-design",children:"Dynamic Computation Design"}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\ud83d\udd04 ",(0,t.jsx)(n.strong,{children:"Dynamic Computation Graphs"}),": Build and modify neural networks on-the-fly"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udc1e ",(0,t.jsx)(n.strong,{children:"Intuitive Debugging"}),": Step through code execution like normal Python code"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udd2c ",(0,t.jsx)(n.strong,{children:"Research-First Philosophy"}),": Designed with experimentation and rapid prototyping in mind"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83e\udde9 ",(0,t.jsx)(n.strong,{children:"Pythonic Interface"}),": Feels natural and familiar to Python developers"]}),"\n"]}),(0,t.jsx)(n.h4,{id:"powerful-ecosystem",children:"Powerful Ecosystem"}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\ud83d\udee0\ufe0f ",(0,t.jsx)(n.strong,{children:"Rich Library Support"}),": From computer vision (torchvision) to NLP (transformers)"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\ude80 ",(0,t.jsx)(n.strong,{children:"Optimized Performance"}),": C++ backend with CUDA support for GPU acceleration"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udc65 ",(0,t.jsx)(n.strong,{children:"Vibrant Community"}),": Extensive documentation, tutorials, and pre-trained models"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83c\udfe2 ",(0,t.jsx)(n.strong,{children:"Industry Adoption"}),": Widely used in both academic research and production environments"]}),"\n"]})]}),"\n",(0,t.jsx)(n.h2,{id:"why-mlflow--pytorch",children:"Why MLflow + PyTorch?"}),"\n",(0,t.jsx)(n.p,{children:"The integration of MLflow with PyTorch creates a streamlined workflow for deep learning practitioners:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\ud83d\udcca ",(0,t.jsx)(n.strong,{children:"Comprehensive Tracking"}),": Capture parameters, metrics, model architecture, and artifacts in one place"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udd04 ",(0,t.jsx)(n.strong,{children:"Reproducible Experiments"}),": Every training run is fully documented and can be reproduced exactly"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udcc8 ",(0,t.jsx)(n.strong,{children:"Visual Performance Analysis"}),": Compare model performance across different architectures and hyperparameters"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83c\udfd7\ufe0f ",(0,t.jsx)(n.strong,{children:"Model Versioning"}),": Track model lineage and evolution throughout the development lifecycle"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udc65 ",(0,t.jsx)(n.strong,{children:"Collaborative Development"}),": Share experiments and results with team members through MLflow's intuitive UI"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\ude80 ",(0,t.jsx)(n.strong,{children:"Simplified Deployment"}),": Package models for easy deployment across various production environments"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"logging-pytorch-experiments-to-mlflow",children:"Logging PyTorch Experiments to MLflow"}),"\n",(0,t.jsx)(n.h3,{id:"understanding-pytorch-autologging-limitations",children:"Understanding PyTorch Autologging Limitations"}),"\n",(0,t.jsx)(n.p,{children:"Unlike other deep learning frameworks, MLflow doesn't provide automatic logging for vanilla PyTorch because of its custom training loop paradigm."}),"\n",(0,t.jsxs)(o,{children:[(0,t.jsx)("summary",{children:"Alternative: PyTorch Lightning Autologging"}),(0,t.jsxs)(n.p,{children:["If you want to use autologging with PyTorch, ",(0,t.jsx)(n.a,{href:"https://lightning.ai",children:"Lightning"})," provides a structured framework that works seamlessly with MLflow's autologging capabilities:"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import mlflow\nimport pytorch_lightning as pl\n\n# Enable autologging with Lightning\nmlflow.pytorch.autolog()\n\n# Define your Lightning module and train as usual\ntrainer = pl.Trainer(max_epochs=10)\ntrainer.fit(model, train_dataloader, val_dataloader)\n"})}),(0,t.jsx)(n.p,{children:"With Lightning + MLflow, you get:"}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\ud83d\udd04 ",(0,t.jsx)(n.strong,{children:"Automatic Metric Logging"}),": Training/validation metrics captured at each epoch"]}),"\n",(0,t.jsxs)(n.li,{children:["\u2699\ufe0f ",(0,t.jsx)(n.strong,{children:"Hyperparameter Tracking"}),": Model parameters and training configuration logged automatically"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udce6 ",(0,t.jsx)(n.strong,{children:"Model Checkpointing"}),": Best models saved and logged to MLflow"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udcca ",(0,t.jsx)(n.strong,{children:"TensorBoard Integration"}),": TensorBoard logs accessible through MLflow"]}),"\n"]}),(0,t.jsx)(n.p,{children:"For more details on Lightning integration, refer to the MLflow Lightning Developer Guide."})]}),"\n",(0,t.jsx)(n.h3,{id:"manually-logging-pytorch-experiments",children:"Manually Logging PyTorch Experiments"}),"\n",(0,t.jsx)(n.p,{children:"For standard PyTorch workflows, you can easily integrate MLflow logging into your training loops using these key APIs:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(r.B,{fn:"mlflow.log_metric"})," / ",(0,t.jsx)(r.B,{fn:"mlflow.log_metrics"}),": Log metrics like accuracy and loss during training"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(r.B,{fn:"mlflow.log_param"})," / ",(0,t.jsx)(r.B,{fn:"mlflow.log_params"}),": Log parameters like learning rate and batch size"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(r.B,{fn:"mlflow.pytorch.log_model"}),": Save your PyTorch model to MLflow"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(r.B,{fn:"mlflow.log_artifact"}),": Log artifacts like model checkpoints and visualizations"]}),"\n"]}),"\n",(0,t.jsxs)(o,{children:[(0,t.jsx)("summary",{children:"Best Practices for PyTorch Logging"}),(0,t.jsx)(n.h4,{id:"initialization-phase",children:"Initialization Phase"}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\ud83d\udccb ",(0,t.jsx)(n.strong,{children:"Log Configuration Parameters"}),": Use ",(0,t.jsx)(r.B,{fn:"mlflow.log_params"})," at the beginning of training to record learning rate, batch size, optimizer configuration, etc."]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83c\udfd7\ufe0f ",(0,t.jsx)(n.strong,{children:"Log Model Architecture"}),": Use ",(0,t.jsx)(n.code,{children:"torchinfo"})," to generate a model summary and log it via ",(0,t.jsx)(r.B,{fn:"mlflow.log_artifact"})]}),"\n",(0,t.jsxs)(n.li,{children:["\u2699\ufe0f ",(0,t.jsx)(n.strong,{children:"Log Dependencies"}),": Record PyTorch version and key packages to ensure reproducibility"]}),"\n"]}),(0,t.jsx)(n.h4,{id:"training-phase",children:"Training Phase"}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\ud83d\udcca ",(0,t.jsx)(n.strong,{children:"Batch vs. Epoch Logging"}),": For long epochs, log key metrics every N batches; otherwise, log per epoch"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udcc8 ",(0,t.jsx)(n.strong,{children:"Use Batched Logging"}),": Prefer ",(0,t.jsx)(r.B,{fn:"mlflow.log_metrics"})," over multiple ",(0,t.jsx)(r.B,{fn:"mlflow.log_metric"})," calls for better performance"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udd04 ",(0,t.jsx)(n.strong,{children:"Track Training Dynamics"}),": Log not just final metrics but their evolution throughout training"]}),"\n"]}),(0,t.jsx)(n.h4,{id:"finalization-phase",children:"Finalization Phase"}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\ud83d\udcbe ",(0,t.jsx)(n.strong,{children:"Save Final Model"}),": Use ",(0,t.jsx)(r.B,{fn:"mlflow.pytorch.log_model"})," to save the trained model"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udcca ",(0,t.jsx)(n.strong,{children:"Log Performance Visualizations"}),": Create and save plots of training curves, confusion matrices, etc."]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udcdd ",(0,t.jsx)(n.strong,{children:"Add Model Signature"}),": Include input/output signatures for better model understanding"]}),"\n"]})]}),"\n",(0,t.jsx)(n.h3,{id:"complete-pytorch-logging-example",children:"Complete PyTorch Logging Example"}),"\n",(0,t.jsx)(n.p,{children:"Here's an end-to-end example of tracking a PyTorch experiment with MLflow:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom torchinfo import summary\n\n# Define device\ndevice = torch.device("cuda" if torch.cuda.is_available() else "cpu")\n\n# Load and prepare data\ntransform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n)\ntrain_dataset = datasets.FashionMNIST(\n    "data", train=True, download=True, transform=transform\n)\ntest_dataset = datasets.FashionMNIST("data", train=False, transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=1000)\n\n\n# Define the model\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28 * 28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10),\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n\n\n# Training parameters\nparams = {\n    "epochs": 3,\n    "learning_rate": 1e-3,\n    "batch_size": 64,\n    "optimizer": "SGD",\n    "model_type": "MLP",\n    "hidden_units": [512, 512],\n}\n\n# Training and logging\nwith mlflow.start_run():\n    # 1. Log parameters\n    mlflow.log_params(params)\n\n    # 2. Create and prepare model\n    model = NeuralNetwork().to(device)\n    loss_fn = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=params["learning_rate"])\n\n    # 3. Log model architecture\n    with open("model_summary.txt", "w") as f:\n        f.write(str(summary(model, input_size=(1, 1, 28, 28))))\n    mlflow.log_artifact("model_summary.txt")\n\n    # 4. Training loop with metric logging\n    for epoch in range(params["epochs"]):\n        model.train()\n        train_loss = 0\n        correct = 0\n        total = 0\n\n        for batch_idx, (data, target) in enumerate(train_loader):\n            data, target = data.to(device), target.to(device)\n\n            # Forward pass\n            optimizer.zero_grad()\n            output = model(data)\n            loss = loss_fn(output, target)\n\n            # Backward pass\n            loss.backward()\n            optimizer.step()\n\n            # Calculate metrics\n            train_loss += loss.item()\n            _, predicted = output.max(1)\n            total += target.size(0)\n            correct += predicted.eq(target).sum().item()\n\n            # Log batch metrics (every 100 batches)\n            if batch_idx % 100 == 0:\n                batch_loss = train_loss / (batch_idx + 1)\n                batch_acc = 100.0 * correct / total\n                mlflow.log_metrics(\n                    {"batch_loss": batch_loss, "batch_accuracy": batch_acc},\n                    step=epoch * len(train_loader) + batch_idx,\n                )\n\n        # Calculate epoch metrics\n        epoch_loss = train_loss / len(train_loader)\n        epoch_acc = 100.0 * correct / total\n\n        # Validation\n        model.eval()\n        val_loss = 0\n        val_correct = 0\n        val_total = 0\n\n        with torch.no_grad():\n            for data, target in test_loader:\n                data, target = data.to(device), target.to(device)\n                output = model(data)\n                loss = loss_fn(output, target)\n\n                val_loss += loss.item()\n                _, predicted = output.max(1)\n                val_total += target.size(0)\n                val_correct += predicted.eq(target).sum().item()\n\n        # Calculate and log epoch validation metrics\n        val_loss = val_loss / len(test_loader)\n        val_acc = 100.0 * val_correct / val_total\n\n        # Log epoch metrics\n        mlflow.log_metrics(\n            {\n                "train_loss": epoch_loss,\n                "train_accuracy": epoch_acc,\n                "val_loss": val_loss,\n                "val_accuracy": val_acc,\n            },\n            step=epoch,\n        )\n\n        print(\n            f"Epoch {epoch+1}/{params[\'epochs\']}, "\n            f"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}%, "\n            f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%"\n        )\n\n    # 5. Log the trained model\n    model_info = mlflow.pytorch.log_model(model, name="model")\n\n    # 6. Final evaluation\n    model.eval()\n    test_loss = 0\n    test_correct = 0\n    test_total = 0\n\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            loss = loss_fn(output, target)\n\n            test_loss += loss.item()\n            _, predicted = output.max(1)\n            test_total += target.size(0)\n            test_correct += predicted.eq(target).sum().item()\n\n    # Calculate and log final test metrics\n    test_loss = test_loss / len(test_loader)\n    test_acc = 100.0 * test_correct / test_total\n\n    mlflow.log_metrics({"test_loss": test_loss, "test_accuracy": test_acc})\n\n    print(f"Final Test Accuracy: {test_acc:.2f}%")\n'})}),"\n",(0,t.jsx)(n.p,{children:"If you run this code with a local MLflow server, you'll see comprehensive tracking in the MLflow UI:"}),"\n",(0,t.jsx)("div",{className:"center-div",style:{width:"90%"},children:(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Basic Example of PyTorch with MLflow",src:l(14433).A+"",width:"3418",height:"1780"})})}),"\n",(0,t.jsx)(n.h2,{id:"saving-your-pytorch-model-to-mlflow",children:"Saving Your PyTorch Model to MLflow"}),"\n",(0,t.jsx)(n.h3,{id:"basic-model-saving",children:"Basic Model Saving"}),"\n",(0,t.jsx)(n.p,{children:"MLflow makes it easy to save and load PyTorch models for reproducible inference:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport numpy as np\nimport torch\nimport torch.nn as nn\n\n\n# Define model\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28 * 28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10),\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n\n\nmodel = NeuralNetwork()\n\n# Train your model (code omitted for brevity)\n\nmodel_info = mlflow.pytorch.log_model(model, name="model")\n\n# Load and use the model\nloaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n\n# Make predictions\nsample_input = np.random.uniform(size=[1, 28, 28]).astype(np.float32)\npredictions = loaded_model.predict(sample_input)\nprint("Predictions:", predictions)\n'})}),"\n",(0,t.jsxs)(o,{children:[(0,t.jsx)("summary",{children:"TorchScript Compatibility"}),(0,t.jsx)(n.p,{children:"MLflow seamlessly works with TorchScript, which can optimize your models for production:"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Create a scripted version of your model\nscripted_model = torch.jit.script(model)\n\n# Log the scripted model to MLflow\nmodel_info = mlflow.pytorch.log_model(scripted_model, name="scripted_model")\n\n# The logged model will contain the compiled graph\n'})}),(0,t.jsx)(n.p,{children:"Benefits of using TorchScript with MLflow:"}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\u26a1 ",(0,t.jsx)(n.strong,{children:"Performance Optimization"}),": Compiled graphs for faster inference"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udd12 ",(0,t.jsx)(n.strong,{children:"Deployment Security"}),": Protected model architecture for secure deployment"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83c\udf09 ",(0,t.jsx)(n.strong,{children:"Language Interoperability"}),": Use models in C++ environments"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udcf1 ",(0,t.jsx)(n.strong,{children:"Mobile Deployment"}),": Optimized for resource-constrained devices"]}),"\n"]})]}),"\n",(0,t.jsx)(n.p,{children:"You can view the saved model in the MLflow UI:"}),"\n",(0,t.jsx)("div",{className:"center-div",style:{width:"90%"},children:(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Basic PyTorch Saving",src:l(35706).A+"",width:"3430",height:"1298"})})}),"\n",(0,t.jsx)(n.h3,{id:"model-signatures",children:"Model Signatures"}),"\n",(0,t.jsx)(n.p,{children:"A model signature defines the schema of inputs and outputs, enhancing model understanding and enabling validation. The simplest way to add a signature is using automatic inference:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import mlflow\nfrom mlflow.models import infer_signature\nimport numpy as np\nimport torch\n\n# Create sample input and predictions\nsample_input = np.random.uniform(size=[1, 28, 28]).astype(np.float32)\n\n# Get model output - convert tensor to numpy\nwith torch.no_grad():\n    output = model(torch.tensor(sample_input))\n    sample_output = output.numpy()\n\n# Infer signature automatically\nsignature = infer_signature(sample_input, sample_output)\n\n# Log model with signature\nmodel_info = mlflow.pytorch.log_model(model, name="model", signature=signature)\n'})}),"\n",(0,t.jsx)(n.admonition,{title:"attention",type:"warning",children:(0,t.jsxs)(n.p,{children:["As of MLflow 2.9.1, input and output to ",(0,t.jsx)(n.code,{children:"mlflow.models.infer_signature()"})," must be ",(0,t.jsx)(n.code,{children:"numpy.ndarray"}),", not ",(0,t.jsx)(n.code,{children:"torch.Tensor"}),". Always convert tensors to numpy arrays first."]})}),"\n",(0,t.jsx)(n.p,{children:"The signature will appear in the MLflow UI:"}),"\n",(0,t.jsx)("div",{className:"center-div",style:{width:"90%"},children:(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"PyTorch Model Signature",src:l(62945).A+"",width:"3376",height:"1712"})})}),"\n",(0,t.jsxs)(o,{children:[(0,t.jsx)("summary",{children:"Manual Signature Definition"}),(0,t.jsx)(n.p,{children:"For complete control over your model signature, you can manually define the input and output schemas:"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport numpy as np\nfrom mlflow.types import Schema, TensorSpec\nfrom mlflow.models import ModelSignature\n\n# Manually define input and output schemas\ninput_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 28, 28))])\noutput_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 10))])\nsignature = ModelSignature(inputs=input_schema, outputs=output_schema)\n\n# Log model with signature\nmodel_info = mlflow.pytorch.log_model(model, name="model", signature=signature)\n'})}),(0,t.jsx)(n.p,{children:"Manual definition is useful when:"}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"You need precise control over tensor specifications"}),"\n",(0,t.jsx)(n.li,{children:"Working with complex input/output structures"}),"\n",(0,t.jsx)(n.li,{children:"The automatic inference doesn't capture your intended schema"}),"\n",(0,t.jsx)(n.li,{children:"You want to specify exact data types and shapes upfront"}),"\n"]})]}),"\n",(0,t.jsx)(n.h2,{id:"advanced-pytorch-tracking",children:"Advanced PyTorch Tracking"}),"\n",(0,t.jsx)(n.h3,{id:"custom-training-loop-with-detailed-metrics",children:"Custom Training Loop with Detailed Metrics"}),"\n",(0,t.jsx)(n.p,{children:"For more sophisticated tracking, you can implement custom callbacks and visualizations:"}),"\n",(0,t.jsxs)(o,{children:[(0,t.jsx)("summary",{children:"Comprehensive Tracking with Visualizations"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport torch\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\n\n\nclass MLflowTracker:\n    def __init__(self, model, classes):\n        self.model = model\n        self.classes = classes\n        self.train_losses = []\n        self.val_losses = []\n        self.train_accs = []\n        self.val_accs = []\n\n    def log_epoch(self, epoch, train_loss, train_acc, val_loss, val_acc):\n        """Log metrics for an epoch."""\n        self.train_losses.append(train_loss)\n        self.val_losses.append(val_loss)\n        self.train_accs.append(train_acc)\n        self.val_accs.append(val_acc)\n\n        mlflow.log_metrics(\n            {\n                "train_loss": train_loss,\n                "train_accuracy": train_acc,\n                "val_loss": val_loss,\n                "val_accuracy": val_acc,\n            },\n            step=epoch,\n        )\n\n    def log_confusion_matrix(self, val_loader, device):\n        """Generate and log confusion matrix."""\n        self.model.eval()\n        all_preds = []\n        all_targets = []\n\n        with torch.no_grad():\n            for inputs, targets in val_loader:\n                inputs, targets = inputs.to(device), targets.to(device)\n                outputs = self.model(inputs)\n                _, preds = torch.max(outputs, 1)\n\n                all_preds.extend(preds.cpu().numpy())\n                all_targets.extend(targets.cpu().numpy())\n\n        # Create confusion matrix\n        cm = confusion_matrix(all_targets, all_preds)\n\n        # Plot\n        plt.figure(figsize=(10, 8))\n        sns.heatmap(\n            cm,\n            annot=True,\n            fmt="d",\n            cmap="Blues",\n            xticklabels=self.classes,\n            yticklabels=self.classes,\n        )\n        plt.title("Confusion Matrix")\n        plt.ylabel("True Label")\n        plt.xlabel("Predicted Label")\n        plt.tight_layout()\n\n        # Save and log\n        plt.savefig("confusion_matrix.png")\n        mlflow.log_artifact("confusion_matrix.png")\n        plt.close()\n\n    def log_training_curves(self):\n        """Generate and log training curves."""\n        plt.figure(figsize=(12, 5))\n\n        # Loss subplot\n        plt.subplot(1, 2, 1)\n        plt.plot(self.train_losses, label="Train Loss")\n        plt.plot(self.val_losses, label="Validation Loss")\n        plt.title("Loss Curves")\n        plt.xlabel("Epoch")\n        plt.ylabel("Loss")\n        plt.legend()\n\n        # Accuracy subplot\n        plt.subplot(1, 2, 2)\n        plt.plot(self.train_accs, label="Train Accuracy")\n        plt.plot(self.val_accs, label="Validation Accuracy")\n        plt.title("Accuracy Curves")\n        plt.xlabel("Epoch")\n        plt.ylabel("Accuracy (%)")\n        plt.legend()\n\n        plt.tight_layout()\n        plt.savefig("training_curves.png")\n        mlflow.log_artifact("training_curves.png")\n        plt.close()\n'})}),(0,t.jsx)(n.p,{children:"Usage in training loop:"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Initialize tracker\ntracker = MLflowTracker(\n    model,\n    classes=[\n        "T-shirt",\n        "Trouser",\n        "Pullover",\n        "Dress",\n        "Coat",\n        "Sandal",\n        "Shirt",\n        "Sneaker",\n        "Bag",\n        "Ankle boot",\n    ],\n)\n\nwith mlflow.start_run():\n    mlflow.log_params(params)\n\n    for epoch in range(params["epochs"]):\n        # Training code...\n\n        # Log epoch metrics\n        tracker.log_epoch(epoch, train_loss, train_acc, val_loss, val_acc)\n\n    # Log final visualizations\n    tracker.log_confusion_matrix(test_loader, device)\n    tracker.log_training_curves()\n\n    # Log model\n    model_info = mlflow.pytorch.log_model(model, name="model")\n'})})]}),"\n",(0,t.jsx)(n.h3,{id:"hyperparameter-optimization",children:"Hyperparameter Optimization"}),"\n",(0,t.jsx)(n.p,{children:"Combine PyTorch with hyperparameter optimization tools while tracking everything in MLflow:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport optuna\nfrom functools import partial\n\n\ndef objective(trial, train_loader, val_loader, device):\n    # Suggest hyperparameters\n    lr = trial.suggest_float("lr", 1e-5, 1e-1, log=True)\n    optimizer_name = trial.suggest_categorical("optimizer", ["Adam", "SGD"])\n    hidden_size = trial.suggest_categorical("hidden_size", [128, 256, 512])\n\n    with mlflow.start_run(nested=True):\n        # Log hyperparameters\n        params = {\n            "lr": lr,\n            "optimizer": optimizer_name,\n            "hidden_size": hidden_size,\n            "batch_size": 64,\n            "epochs": 3,\n        }\n        mlflow.log_params(params)\n\n        # Create model\n        model = NeuralNetwork(hidden_size=hidden_size).to(device)\n        loss_fn = nn.CrossEntropyLoss()\n\n        # Configure optimizer\n        if optimizer_name == "Adam":\n            optimizer = optim.Adam(model.parameters(), lr=lr)\n        else:\n            optimizer = optim.SGD(model.parameters(), lr=lr)\n\n        # Train for a few epochs\n        best_val_acc = 0\n        for epoch in range(params["epochs"]):\n            # Training code (abbreviated)...\n            train_loss, train_acc = train_epoch(\n                model, train_loader, loss_fn, optimizer, device\n            )\n            val_loss, val_acc = evaluate(model, val_loader, loss_fn, device)\n\n            mlflow.log_metrics(\n                {\n                    "train_loss": train_loss,\n                    "train_acc": train_acc,\n                    "val_loss": val_loss,\n                    "val_acc": val_acc,\n                },\n                step=epoch,\n            )\n\n            best_val_acc = max(best_val_acc, val_acc)\n\n        # Final logging\n        mlflow.log_metric("best_val_acc", best_val_acc)\n        mlflow.pytorch.log_model(model, name="model")\n\n        return best_val_acc\n\n\n# Execute hyperparameter search\nwith mlflow.start_run(run_name="hyperparam_optimization"):\n    study = optuna.create_study(direction="maximize")\n    objective_func = partial(\n        objective, train_loader=train_loader, val_loader=val_loader, device=device\n    )\n    study.optimize(objective_func, n_trials=20)\n\n    # Log best parameters and score\n    mlflow.log_params(study.best_params)\n    mlflow.log_metric("best_val_accuracy", study.best_value)\n'})}),"\n",(0,t.jsx)(n.h2,{id:"real-world-applications",children:"Real-World Applications"}),"\n",(0,t.jsx)(n.p,{children:"The MLflow-PyTorch integration excels in scenarios such as:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\ud83d\uddbc\ufe0f ",(0,t.jsx)(n.strong,{children:"Computer Vision"}),": Track CNN architectures, data augmentation strategies, and performance for image classification, object detection, and segmentation"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udcdd ",(0,t.jsx)(n.strong,{children:"Natural Language Processing"}),": Monitor transformer models, embeddings, and generation quality for language understanding and text generation"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udd0a ",(0,t.jsx)(n.strong,{children:"Audio Processing"}),": Log spectrograms, model performance, and audio samples for speech recognition and music generation"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83c\udfae ",(0,t.jsx)(n.strong,{children:"Reinforcement Learning"}),": Track agent performance, reward optimization, and environment interactions"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83e\uddec ",(0,t.jsx)(n.strong,{children:"Scientific Research"}),": Monitor model convergence and validation metrics for complex scientific applications"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83c\udfed ",(0,t.jsx)(n.strong,{children:"Industrial Applications"}),": Version models from development to deployment with full lineage tracking"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,t.jsx)(n.p,{children:"The MLflow-PyTorch integration provides a comprehensive solution for tracking, managing, and deploying deep learning experiments. By combining PyTorch's flexibility with MLflow's experiment tracking capabilities, you create a workflow that is:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\ud83d\udd0d ",(0,t.jsx)(n.strong,{children:"Transparent"}),": Every aspect of training is visible and trackable"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udd04 ",(0,t.jsx)(n.strong,{children:"Reproducible"}),": Experiments can be recreated exactly"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udcca ",(0,t.jsx)(n.strong,{children:"Comparable"}),": Different approaches can be evaluated side-by-side"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udcc8 ",(0,t.jsx)(n.strong,{children:"Scalable"}),": From simple prototypes to complex production models"]}),"\n",(0,t.jsxs)(n.li,{children:["\ud83d\udc65 ",(0,t.jsx)(n.strong,{children:"Collaborative"}),": Team members can share and build upon each other's work"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Whether you're a researcher exploring new architectures or an engineer deploying models to production, the MLflow-PyTorch integration provides the foundation for organized, reproducible, and scalable deep learning development."})]})}function m(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(p,{...e})}):p(e)}},28453:(e,n,l)=>{l.d(n,{R:()=>r,x:()=>a});var o=l(96540);const t={},i=o.createContext(t);function r(e){const n=o.useContext(i);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),o.createElement(i.Provider,{value:n},e.children)}},35706:(e,n,l)=>{l.d(n,{A:()=>o});const o=l.p+"assets/images/pytorch-guide-basic-saving-af066edf360c780042fd3085792ec1d2.png"},49374:(e,n,l)=>{l.d(n,{B:()=>s});l(96540);const o=JSON.parse('{"mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html"}');var t=l(86025),i=l(28774),r=l(74848);const a=e=>{const n=e.split(".");for(let l=n.length;l>0;l--){const e=n.slice(0,l).join(".");if(o[e])return e}return null};function s({fn:e,children:n}){const l=a(e);if(!l)return(0,r.jsx)(r.Fragment,{children:n});const s=(0,t.Ay)(`/${o[l]}#${e}`);return(0,r.jsx)(i.A,{to:s,target:"_blank",children:n??(0,r.jsxs)("code",{children:[e,"()"]})})}},62945:(e,n,l)=>{l.d(n,{A:()=>o});const o=l.p+"assets/images/pytorch-guide-model-signature-f8e63d83e73f9283d985016616ae1cab.png"}}]);