"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["162"],{52340(e,n,t){t.r(n),t.d(n,{metadata:()=>r,default:()=>g,frontMatter:()=>m,contentTitle:()=>d,toc:()=>u,assets:()=>h});var r=JSON.parse('{"id":"tracing/app-instrumentation/manual-tracing","title":"Manual Tracing","description":"In addition to the Auto Tracing integrations, you can instrument your GenAI application by using MLflow\'s manual tracing APIs.","source":"@site/docs/genai/tracing/app-instrumentation/manual-tracing.mdx","sourceDirName":"tracing/app-instrumentation","slug":"/tracing/app-instrumentation/manual-tracing","permalink":"/mlflow-website/docs/latest/genai/tracing/app-instrumentation/manual-tracing","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"genAISidebar","previous":{"title":"Automatic Tracing","permalink":"/mlflow-website/docs/latest/genai/tracing/app-instrumentation/automatic"},"next":{"title":"Tracing with OpenTelemetry","permalink":"/mlflow-website/docs/latest/genai/tracing/app-instrumentation/opentelemetry"}}'),a=t(74848),o=t(28453),s=t(54725),l=t(66497),i=t(78010),c=t(57250),p=t(95986);let m={},d="Manual Tracing",h={},u=[{value:"Decorator",id:"decorator",level:2},{value:"Function Wrapping",id:"function-wrapping",level:2},{value:"Customizing Spans",id:"customizing-spans",level:2},{value:"Adding Trace Tags",id:"adding-trace-tags",level:2},{value:"Customizing Request and Response Previews in the UI",id:"customizing-request-and-response-previews-in-the-ui",level:2},{value:"Code Block",id:"code-block",level:2},{value:"Automatic Exception Handling",id:"automatic-exception-handling",level:2},{value:"Using <code>@mlflow.trace</code> with Other Decorators",id:"using-mlflowtrace-with-other-decorators",level:2},{value:"Streaming",id:"streaming",level:2},{value:"Multi Threading",id:"multi-threading",level:2},{value:"Async Support",id:"async-support",level:2},{value:"Next Steps",id:"next-steps",level:2}];function f(e){let n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",hr:"hr",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"manual-tracing",children:"Manual Tracing"})}),"\n",(0,a.jsxs)(n.p,{children:["In addition to the ",(0,a.jsx)(n.a,{href:"/genai/tracing/app-instrumentation/automatic",children:"Auto Tracing"})," integrations, you can instrument your GenAI application by using MLflow's manual tracing APIs."]}),"\n",(0,a.jsx)(n.h2,{id:"decorator",children:"Decorator"}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"mlflow.trace"})," decorator allows you to create a span for any function. This approach provides a simple yet effective way to add tracing to your code with minimal effort:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\u{1F517} ",(0,a.jsx)(n.strong,{children:"MLflow detects the parent-child relationships"})," between functions, making it compatible with auto-tracing integrations."]}),"\n",(0,a.jsxs)(n.li,{children:["\u{1F6E1}\uFE0F ",(0,a.jsx)(n.strong,{children:"Captures exceptions"})," during function execution and records them as span events."]}),"\n",(0,a.jsxs)(n.li,{children:["\u{1F4CA} ",(0,a.jsx)(n.strong,{children:"Automatically logs the function's name, inputs, outputs, and execution time"}),"."]}),"\n",(0,a.jsxs)(n.li,{children:["\u{1F91D} ",(0,a.jsx)(n.strong,{children:"Can be used alongside auto-tracing"})," features."]}),"\n"]}),"\n",(0,a.jsx)(p.A,{children:(0,a.jsxs)(i.A,{groupId:"programming-language",children:[(0,a.jsxs)(c.A,{value:"python",label:"Python",default:!0,children:[(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"@mlflow.trace"})," decorator currently supports the following types of functions:"]}),(0,a.jsxs)(n.table,{children:[(0,a.jsx)(n.thead,{children:(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.th,{children:"Function Type"}),(0,a.jsx)(n.th,{children:"Supported"})]})}),(0,a.jsxs)(n.tbody,{children:[(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Sync"}),(0,a.jsx)(n.td,{children:"Yes"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Async"}),(0,a.jsx)(n.td,{children:"Yes (>= 2.16.0)"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Generator"}),(0,a.jsx)(n.td,{children:"Yes (>= 2.20.2)"})]}),(0,a.jsxs)(n.tr,{children:[(0,a.jsx)(n.td,{children:"Async Generator"}),(0,a.jsx)(n.td,{children:"Yes (>= 2.20.2)"})]})]})]}),(0,a.jsx)(n.p,{children:"The following code is a minimum example of using the decorator for tracing Python functions."}),(0,a.jsx)(n.admonition,{title:"Decorator Order",type:"tip",children:(0,a.jsxs)(n.p,{children:["To ensure complete observability, the ",(0,a.jsx)(n.code,{children:"@mlflow.trace"})," decorator should generally be the ",(0,a.jsx)(n.strong,{children:"outermost"})," one if using multiple decorators. See ",(0,a.jsx)(n.a,{href:"#using-mlflowtrace-with-other-decorators",children:"Using @mlflow.trace with Other Decorators"})," for a detailed explanation and examples."]})}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\n\n\n@mlflow.trace(span_type="func", attributes={"key": "value"})\ndef add_1(x):\n    return x + 1\n\n\n@mlflow.trace(span_type="func", attributes={"key1": "value1"})\ndef minus_1(x):\n    return x - 1\n\n\n@mlflow.trace(name="Trace Test")\ndef trace_test(x):\n    step1 = add_1(x)\n    return minus_1(step1)\n\n\ntrace_test(4)\n'})})]}),(0,a.jsxs)(c.A,{value:"typescript",label:"TypeScript",children:[(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"@mlflow.trace"})," decorator is useful when you want to trace a class method."]}),(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsx)(n.p,{children:"Decorator requires TypeScript version 5.0+ and it can only be applied to class method."})}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import * as mlflow from "mlflow-tracing";\n\nclass MyClass {\n    @mlflow.trace({ spanType: mlflow.SpanType.LLM })\n    generateText(prompt: string) {\n        return "It\'s sunny in Seattle!";\n    }\n}\n'})})]})]})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Tracing Decorator",src:t(10550).A+"",width:"1354",height:"417"})}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["When a trace contains multiple spans with same name, MLflow appends an auto-incrementing suffix to them, such as ",(0,a.jsx)(n.code,{children:"_1"}),", ",(0,a.jsx)(n.code,{children:"_2"}),"."]})}),"\n",(0,a.jsx)(n.h2,{id:"function-wrapping",children:"Function Wrapping"}),"\n",(0,a.jsxs)(n.p,{children:["Function wrapping provides a flexible way to add tracing to existing functions without modifying their definitions. This is particularly useful when you want to add tracing to third-party functions or functions defined outside of your control. By wrapping an external function with ",(0,a.jsx)(n.code,{children:"mlflow.trace"}),", you can capture its inputs, outputs, and execution context."]}),"\n",(0,a.jsx)(p.A,{children:(0,a.jsxs)(i.A,{groupId:"programming-language",children:[(0,a.jsxs)(c.A,{value:"python",label:"Python",default:!0,children:[(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsx)(n.p,{children:'When wrapping functions dynamically, the concept of "outermost" still applies. The tracing wrapper should be applied at the point where you want to capture the entire call to the wrapped function.'})}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import math\nimport mlflow\n\n\ndef invocation(x, y, exp=2):\n    # Wrap an external function from the math library\n    traced_pow = mlflow.trace(math.pow)\n    raised = traced_pow(x, exp)\n\n    traced_factorial = mlflow.trace(math.factorial)\n    factorial = traced_factorial(int(raised))\n    return factorial\n\n\ninvocation(4, 2)\n"})})]}),(0,a.jsxs)(c.A,{value:"typescript",label:"TypeScript",children:[(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Named Function"}),":"]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"import * as mlflow from \"mlflow-tracing\";\n\nconst getWeather = async (city: string) => {\n    return `The weather in ${city} is sunny`;\n};\n\n// Wrap the function with mlflow.trace to create a traced function.\nconst tracedGetWeather = mlflow.trace(\n    getWeather,\n    { name: 'get-weather' }\n);\n\n// Invoke the traced function as usual.\nawait tracedGetWeather('San Francisco');\n"})}),(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Anonymous Function"}),":"]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"import * as mlflow from \"mlflow-tracing\";\n\nconst getWeather = mlflow.trace(\n    (city: string) => {\n        return `The weather in ${city} is sunny`;\n    },\n    // When wrapping an anonymous function, you need to specify the span name.\n    { name: 'get-weather' }\n);\n\n// Invoke the traced function as usual.\ngetWeather('San Francisco');\n"})})]})]})}),"\n",(0,a.jsx)(n.h2,{id:"customizing-spans",children:"Customizing Spans"}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"mlflow.trace"})," decorator accepts following arguments to customize the span to be created:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\u{1F3F7}\uFE0F ",(0,a.jsxs)(n.strong,{children:[(0,a.jsx)(n.code,{children:"name"})," parameter"]})," to override the span name from the default (the name of decorated function)"]}),"\n",(0,a.jsxs)(n.li,{children:["\u{1F3AF} ",(0,a.jsxs)(n.strong,{children:[(0,a.jsx)(n.code,{children:"span_type"})," parameter"]})," to set the type of span. Set either one of built-in ",(0,a.jsx)(n.a,{href:"/genai/concepts/span#span-types",children:"Span Types"})," or a string."]}),"\n",(0,a.jsxs)(n.li,{children:["\u{1F3D7}\uFE0F ",(0,a.jsxs)(n.strong,{children:[(0,a.jsx)(n.code,{children:"attributes"})," parameter"]})," to add custom attributes to the span."]}),"\n"]}),"\n",(0,a.jsx)(p.A,{children:(0,a.jsxs)(i.A,{groupId:"programming-language",children:[(0,a.jsx)(c.A,{value:"python",label:"Python",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from mlflow.entities import SpanType\n\n\n@mlflow.trace(\n    name="call-local-llm", span_type=SpanType.LLM, attributes={"model": "gpt-4o-mini"}\n)\ndef invoke(prompt: str):\n    return client.invoke(\n        messages=[{"role": "user", "content": prompt}], model="gpt-4o-mini"\n    )\n'})})}),(0,a.jsx)(c.A,{value:"typescript",label:"TypeScript",children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import * as mlflow from "mlflow-tracing";\n\nclass MyClass {\n    @mlflow.trace({\n        name: "call-local-llm",\n        spanType: mlflow.SpanType.LLM,\n        attributes: {"model": "gpt-4o-mini"}\n    })\n    generateText(prompt: string) {\n        return "It\'s sunny in Seattle!";\n    }\n}\n'})})})]})}),"\n",(0,a.jsx)(n.p,{children:"Alternatively, you can update the span dynamically inside the function."}),"\n",(0,a.jsx)(p.A,{children:(0,a.jsxs)(i.A,{groupId:"programming-language",children:[(0,a.jsxs)(c.A,{value:"python",label:"Python",default:!0,children:[(0,a.jsxs)(n.p,{children:["Use the ",(0,a.jsx)(s.B,{fn:"mlflow.get_current_active_span"})," API."]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from mlflow.entities import SpanType\n\n\n@mlflow.trace(span_type=SpanType.LLM)\ndef invoke(prompt: str):\n    model_id = "gpt-4o-mini"\n    # Get the current span (created by the @mlflow.trace decorator)\n    span = mlflow.get_current_active_span()\n    # Set the attribute to the span\n    span.set_attributes({"model": model_id})\n    return client.invoke(messages=[{"role": "user", "content": prompt}], model=model_id)\n'})})]}),(0,a.jsxs)(c.A,{value:"typescript",label:"TypeScript",children:[(0,a.jsxs)(n.p,{children:["Use the ",(0,a.jsx)(n.code,{children:"mlflow.getCurrentActiveSpan"})," API."]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import * as mlflow from "mlflow-tracing";\n\nclass MyClass {\n    @mlflow.trace({ spanType: mlflow.SpanType.LLM })\n    generateText(prompt: string) {\n        const modelId = "gpt-4o-mini";\n        const span = mlflow.getCurrentActiveSpan();\n        span?.setAttribute("model", modelId);\n        return "It\'s sunny in Seattle!";\n    }\n}\n'})})]})]})}),"\n",(0,a.jsx)(n.h2,{id:"adding-trace-tags",children:"Adding Trace Tags"}),"\n",(0,a.jsxs)(n.p,{children:["Tags can be added to traces to provide additional metadata at the trace level. There are a few different ways to set tags on a trace. Please refer to the ",(0,a.jsx)(n.a,{href:"/genai/tracing/attach-tags",children:"how-to guide"})," for the other methods."]}),"\n",(0,a.jsx)(p.A,{children:(0,a.jsxs)(i.A,{groupId:"programming-language",children:[(0,a.jsx)(c.A,{value:"python",label:"Python",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'@mlflow.trace\ndef my_func(x):\n    mlflow.update_current_trace(tags={"fruit": "apple"})\n    return x + 1\n'})})}),(0,a.jsx)(c.A,{value:"typescript",label:"TypeScript",children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import * as mlflow from "mlflow-tracing";\n\nclass MyClass {\n    @mlflow.trace({ spanType: mlflow.SpanType.LLM })\n    generateText(prompt: string) {\n        mlflow.updateCurrentTrace({ tags: { fruit: "apple" } });\n        return "It\'s sunny in Seattle!";\n    }\n}\n'})})})]})}),"\n",(0,a.jsx)(n.h2,{id:"customizing-request-and-response-previews-in-the-ui",children:"Customizing Request and Response Previews in the UI"}),"\n",(0,a.jsxs)(n.p,{children:["The Traces tab in the MLflow UI displays a list of traces, and the ",(0,a.jsx)(n.code,{children:"Request"})," and ",(0,a.jsx)(n.code,{children:"Response"})," columns show a preview of the end-to-end input and output of each trace. This allows you to quickly understand what each trace represents."]}),"\n",(0,a.jsxs)(n.p,{children:["By default, these previews are truncated to a fixed number of characters. However, you can customize what's shown in these columns by using the ",(0,a.jsx)(n.code,{children:"request_preview"})," and ",(0,a.jsx)(n.code,{children:"response_preview"})," parameters. This is particularly useful for complex inputs or outputs where the default truncation might not show the most relevant information."]}),"\n",(0,a.jsxs)(n.p,{children:["Below is an example of setting a custom request preview for a trace that processes a long document and user instructions, aiming to render the most relevant information in the UI's ",(0,a.jsx)(n.code,{children:"Request"})," column:"]}),"\n",(0,a.jsx)(p.A,{children:(0,a.jsxs)(i.A,{groupId:"programming-language",children:[(0,a.jsx)(c.A,{value:"python",label:"Python",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\n\n\n@mlflow.trace(name="Summarization Pipeline")\ndef summarize_document(document_content: str, user_instructions: str):\n    # Construct a custom preview for the request column\n    # For example, show beginning of document and user instructions\n    request_p = f"Doc: {document_content[:30]}... Instr: {user_instructions[:30]}..."\n    mlflow.update_current_trace(request_preview=request_p)\n\n    # Simulate LLM call\n    # messages = [\n    #     {"role": "system", "content": "Summarize the following document based on user instructions."},\n    #     {"role": "user", "content": f"Document: {document_content}\\nInstructions: {user_instructions}"}\n    # ]\n    # completion = client.chat.completions.create(model="gpt-4o-mini", messages=messages)\n    # summary = completion.choices[0].message.content\n    summary = f"Summary of document starting with \'{document_content[:20]}...\' based on \'{user_instructions}\'"\n\n    # Customize the response preview\n    response_p = f"Summary: {summary[:50]}..."\n    mlflow.update_current_trace(response_preview=response_p)\n\n    return summary\n\n\n# Example Call\nlong_document = (\n    "This is a very long document that contains many details about various topics..."\n    * 10\n)\ninstructions = "Focus on the key takeaways regarding topic X."\nsummary_result = summarize_document(long_document, instructions)\n'})})}),(0,a.jsx)(c.A,{value:"typescript",label:"TypeScript",children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import * as mlflow from "mlflow-tracing";\n\nclass MyClass {\n    @mlflow.trace({ name: "Summarization Pipeline" })\n    summarizeDocument(documentContent: string, userInstructions: string) {\n        // Construct a custom preview for the request column\n        // For example, show beginning of document and user instructions\n        const requestPreview = `Doc: ${documentContent.slice(0, 30)}... Instr: ${userInstructions.slice(0, 30)}...`;\n        mlflow.updateCurrentTrace({ requestPreview: requestPreview });\n\n        // Simulate LLM call\n        // const messages = [\n        //   { role: "system", content: "Summarize the following document based on user instructions." },\n        //   { role: "user", content: `Document: ${documentContent}\\nInstructions: ${userInstructions}` }\n        // ];\n        // const completion = await client.chat.completions.create({ model: "gpt-4o-mini", messages });\n        // const summary = completion.choices[0].message.content;\n        const summary = `Summary of document starting with \'${documentContent.slice(0, 20)}...\' based on \'${userInstructions}\'`;\n\n        // Customize the response preview\n        const responsePreview = `Summary: ${summary.slice(0, 50)}...`;\n        mlflow.updateCurrentTrace({ responsePreview: responsePreview });\n\n        return summary;\n    }\n}\n'})})})]})}),"\n",(0,a.jsxs)(n.p,{children:["By setting ",(0,a.jsx)(n.code,{children:"request_preview"})," and ",(0,a.jsx)(n.code,{children:"response_preview"})," on the trace (typically the root span), you control how the overall interaction is summarized in the main trace list view, making it easier to identify and understand traces at a glance."]}),"\n",(0,a.jsx)(n.h2,{id:"code-block",children:"Code Block"}),"\n",(0,a.jsx)(n.p,{children:"In addition to the decorator, MLflow allows for creating a span that can then be accessed within any encapsulated arbitrary code block. It can be useful for capturing complex interactions within your code in finer detail than what is possible by capturing the boundaries of a single function."}),"\n",(0,a.jsx)(n.p,{children:"Similarly to the decorator, the code block automatically captures parent-child relationship, exceptions, execution time, and works with auto-tracing. However, the name, inputs, and outputs of the span must be provided manually."}),"\n",(0,a.jsx)(p.A,{children:(0,a.jsxs)(i.A,{groupId:"programming-language",children:[(0,a.jsxs)(c.A,{value:"python",label:"Python",default:!0,children:[(0,a.jsxs)(n.p,{children:["Use the ",(0,a.jsx)(s.B,{fn:"mlflow.start_span"})," context manager."]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\n\nwith mlflow.start_span(name="my_span") as span:\n    span.set_inputs({"x": 1, "y": 2})\n    z = x + y\n    span.set_outputs(z)\n'})})]}),(0,a.jsxs)(c.A,{value:"typescript",label:"TypeScript",children:[(0,a.jsxs)(n.p,{children:["Use the ",(0,a.jsx)(n.code,{children:"mlflow.withSpan"})," function wrapper."]}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import * as mlflow from "mlflow-tracing";\n\nconst result = await mlflow.withSpan(\n    async (span: mlflow.Span) => {\n        const x = 1;\n        const y = 2;\n        span.setInputs({ "x": x, "y": y });\n        const z = x + y;\n        span.setOutputs(z);\n    },\n    {\n        name: "MySpan",\n    }\n);\n'})})]})]})}),"\n",(0,a.jsx)(n.p,{children:"Below is a slightly more complex example that uses code block in conjunction with both the decorator and auto-tracing for OpenAI."}),"\n",(0,a.jsx)(p.A,{children:(0,a.jsxs)(i.A,{groupId:"programming-language",children:[(0,a.jsx)(c.A,{value:"python",label:"Python",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport openai\nfrom mlflow.entities import SpanType\n\n# Enable auto-tracing for OpenAI\nmlflow.openai.autolog()\n\n\n@mlflow.trace(span_type=SpanType.CHAIN)\ndef start_session():\n    messages = [{"role": "system", "content": "You are a friendly chat bot"}]\n    while True:\n        with mlflow.start_span(name="User") as span:\n            span.set_inputs(messages)\n            user_input = input(">> ")\n            span.set_outputs(user_input)\n\n        if user_input == "BYE":\n            break\n\n        messages.append({"role": "user", "content": user_input})\n\n        response = openai.OpenAI().chat.completions.create(\n            model="gpt-4o-mini",\n            max_tokens=100,\n            messages=messages,\n        )\n        answer = response.choices[0].message.content\n        print(f"\u{1F916}: {answer}")\n\n        messages.append({"role": "assistant", "content": answer})\n\n\nstart_session()\n'})})}),(0,a.jsx)(c.A,{value:"typescript",label:"TypeScript",children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import * as mlflow from "mlflow-tracing";\nimport { tracedOpenAI } from "mlflow-openai";\nimport { OpenAI } from "openai";\nimport * as readline from "readline";\n\nconst openai = tracedOpenAI(new OpenAI());\n\nclass MyClass {\n    @mlflow.trace({ spanType: mlflow.SpanType.CHAIN })\n    async startSession() {\n        var messages: OpenAI.ChatCompletionMessageParam[] = [{"role": "system", "content": "You are a friendly chat bot"}];\n        // Create readline interface for user input\n        const rl = readline.createInterface({\n            input: process.stdin,\n            output: process.stdout\n        });\n\n        const getUserInput = (prompt: string): Promise<string> => {\n            return new Promise((resolve) => {\n                    rl.question(prompt, (answer) => {\n                    resolve(answer);\n                });\n            });\n        };\n\n        while (true) {\n            let userInput: string = "";\n\n            await mlflow.withSpan(\n                async (span) => {\n                    span.setInputs({ messages });\n                    userInput = await getUserInput(">> ");\n                    span.setOutputs({ userInput });\n                },\n                { name: "User" }\n            );\n\n            if (userInput === "BYE") {\n                break;\n            }\n\n            messages.push({ role: "user", content: userInput });\n\n            const response = await openai.chat.completions.create({\n                model: "gpt-4o-mini",\n                max_tokens: 100,\n                messages: messages\n            });\n\n            const answer = response.choices[0].message.content || "";\n            console.log(`\u{1F916}: ${answer}`);\n\n            messages.push({ role: "assistant", content: answer });\n        }\n\n        rl.close();\n    }\n}\n\nconst myClass = new MyClass();\nmyClass.startSession();\n'})})})]})}),"\n",(0,a.jsx)(n.h2,{id:"automatic-exception-handling",children:"Automatic Exception Handling"}),"\n",(0,a.jsxs)(n.p,{children:["If an ",(0,a.jsx)(n.code,{children:"Exception"})," is raised during processing of a trace-instrumented operation, an indication will be shown within the UI that the invocation was not successful and a partial capture of data will be available to aid in debugging. Additionally, details about the Exception that was raised will be included within ",(0,a.jsx)(n.code,{children:"Events"})," of the partially completed span, further aiding the identification of where issues are occurring within your code."]}),"\n",(0,a.jsx)("video",{src:(0,l.default)("/images/llms/tracing/trace-exception.mp4"),controls:!0,loop:!0,autoPlay:!0,muted:!0,"aria-label":"Trace Error"}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.admonition,{title:"Python Only Features",type:"note",children:(0,a.jsx)(n.p,{children:"The below documentation applies only to the MLflow Python SDK."})}),"\n",(0,a.jsxs)(n.h2,{id:"using-mlflowtrace-with-other-decorators",children:["Using ",(0,a.jsx)(n.code,{children:"@mlflow.trace"})," with Other Decorators"]}),"\n",(0,a.jsxs)(n.p,{children:["When applying multiple decorators to a single function, it's crucial to place ",(0,a.jsx)(n.code,{children:"@mlflow.trace"})," as the ",(0,a.jsx)(n.strong,{children:"outermost"})," decorator (the one at the very top). This ensures that MLflow can capture the entire execution of the function, including the behavior of any inner decorators."]}),"\n",(0,a.jsxs)(n.p,{children:["If ",(0,a.jsx)(n.code,{children:"@mlflow.trace"})," is not the outermost decorator, its visibility into the function's execution may be limited or incorrect, potentially leading to incomplete traces or misrepresentation of the function's inputs, outputs, and execution time."]}),"\n",(0,a.jsx)(n.p,{children:"Consider the following conceptual example:"}),"\n",(0,a.jsx)(p.A,{children:(0,a.jsx)(i.A,{groupId:"programming-language",children:(0,a.jsx)(c.A,{value:"python",label:"Python",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport functools\nimport time\n\n\n# A hypothetical additional decorator\ndef simple_timing_decorator(func):\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        start_time = time.time()\n        result = func(*args, **kwargs)\n        end_time = time.time()\n        print(\n            f"{func.__name__} executed in {end_time - start_time:.4f} seconds by simple_timing_decorator."\n        )\n        return result\n\n    return wrapper\n\n\n# Correct order: @mlflow.trace is outermost\n@mlflow.trace(name="my_decorated_function_correct_order")\n@simple_timing_decorator\n# @another_framework_decorator # e.g., @app.route("/mypath") from Flask\ndef my_complex_function(x, y):\n    # Function logic here\n    time.sleep(0.1)  # Simulate work\n    return x + y\n\n\n# Incorrect order: @mlflow.trace is NOT outermost\n@simple_timing_decorator\n@mlflow.trace(name="my_decorated_function_incorrect_order")\n# @another_framework_decorator\ndef my_other_complex_function(x, y):\n    time.sleep(0.1)\n    return x * y\n\n\n# Example calls\nif __name__ == "__main__":\n    print("Calling function with correct decorator order:")\n    my_complex_function(5, 3)\n\n    print("\\nCalling function with incorrect decorator order:")\n    my_other_complex_function(5, 3)\n'})})})})}),"\n",(0,a.jsxs)(n.p,{children:["In the ",(0,a.jsx)(n.code,{children:"my_complex_function"})," example (correct order), ",(0,a.jsx)(n.code,{children:"@mlflow.trace"})," will capture the full execution, including the time added by ",(0,a.jsx)(n.code,{children:"simple_timing_decorator"}),". In ",(0,a.jsx)(n.code,{children:"my_other_complex_function"})," (incorrect order), the trace captured by MLflow might not accurately reflect the total execution time or could miss modifications to inputs/outputs made by ",(0,a.jsx)(n.code,{children:"simple_timing_decorator"})," before ",(0,a.jsx)(n.code,{children:"@mlflow.trace"})," sees them."]}),"\n",(0,a.jsx)(n.h2,{id:"streaming",children:"Streaming"}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"@mlflow.trace"})," decorator can be used to trace functions that return a generator or an iterator, since MLflow 2.20.2."]}),"\n",(0,a.jsx)(p.A,{children:(0,a.jsx)(i.A,{groupId:"programming-language",children:(0,a.jsx)(c.A,{value:"python",label:"Python",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"@mlflow.trace\ndef stream_data():\n    for i in range(5):\n        yield i\n"})})})})}),"\n",(0,a.jsxs)(n.p,{children:["The above example will generate a trace with a single span for the ",(0,a.jsx)(n.code,{children:"stream_data"})," function. By default, MLflow will capture all elements yielded by the generator as a list in the span's output. In the example above, the output of the span will be ",(0,a.jsx)(n.code,{children:"[0, 1, 2, 3, 4]"}),"."]}),"\n",(0,a.jsx)(n.admonition,{type:"note",children:(0,a.jsxs)(n.p,{children:["A span for a stream function will start when the returned iterator starts to be ",(0,a.jsx)(n.strong,{children:"consumed"}),", and will end when the iterator is exhausted, or an exception is raised during the iteration."]})}),"\n",(0,a.jsxs)(n.p,{children:["If you want to aggregate the elements to be a single span output, you can use the ",(0,a.jsx)(n.code,{children:"output_reducer"})," parameter to specify a custom function to aggregate the elements. The custom function should take a list of yielded elements as inputs."]}),"\n",(0,a.jsx)(p.A,{children:(0,a.jsx)(i.A,{groupId:"programming-language",children:(0,a.jsx)(c.A,{value:"python",label:"Python",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'@mlflow.trace(output_reducer=lambda x: ",".join(x))\ndef stream_data():\n    for c in "hello":\n        yield c\n'})})})})}),"\n",(0,a.jsxs)(n.p,{children:["In the example above, the output of the span will be ",(0,a.jsx)(n.code,{children:'"h,e,l,l,o"'}),". The raw chunks can still be found in the ",(0,a.jsx)(n.code,{children:"Events"})," tab of the span."]}),"\n",(0,a.jsxs)(n.p,{children:["The following is an advanced example that uses the ",(0,a.jsx)(n.code,{children:"output_reducer"})," to consolidate ChatCompletionChunk output from an OpenAI LLM into a single message object."]}),"\n",(0,a.jsx)(n.admonition,{type:"tip",children:(0,a.jsxs)(n.p,{children:["Of course, we recommend using the ",(0,a.jsx)(n.a,{href:"/genai/tracing/integrations/listing/openai",children:"auto-tracing for OpenAI"})," for examples like this, which does the same job but with one-liner code. The example below is for demonstration purposes."]})}),"\n",(0,a.jsx)(p.A,{children:(0,a.jsx)(i.A,{groupId:"programming-language",children:(0,a.jsx)(c.A,{value:"python",label:"Python",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport openai\nfrom openai.types.chat import *\nfrom typing import Optional\n\n\ndef aggregate_chunks(outputs: list[ChatCompletionChunk]) -> Optional[ChatCompletion]:\n    """Consolidate ChatCompletionChunks to a single ChatCompletion"""\n    if not outputs:\n        return None\n\n    first_chunk = outputs[0]\n    delta = first_chunk.choices[0].delta\n    message = ChatCompletionMessage(\n        role=delta.role, content=delta.content, tool_calls=delta.tool_calls or []\n    )\n    finish_reason = first_chunk.choices[0].finish_reason\n    for chunk in outputs[1:]:\n        delta = chunk.choices[0].delta\n        message.content += delta.content or ""\n        message.tool_calls += delta.tool_calls or []\n        finish_reason = finish_reason or chunk.choices[0].finish_reason\n\n    base = ChatCompletion(\n        id=first_chunk.id,\n        choices=[Choice(index=0, message=message, finish_reason=finish_reason)],\n        created=first_chunk.created,\n        model=first_chunk.model,\n        object="chat.completion",\n    )\n    return base\n\n\n@mlflow.trace(output_reducer=aggregate_chunks)\ndef predict(messages: list[dict]):\n    stream = openai.OpenAI().chat.completions.create(\n        model="gpt-4o-mini",\n        messages=messages,\n        stream=True,\n    )\n    for chunk in stream:\n        yield chunk\n\n\nfor chunk in predict([{"role": "user", "content": "Hello"}]):\n    print(chunk)\n'})})})})}),"\n",(0,a.jsxs)(n.p,{children:["In the example above, the generated ",(0,a.jsx)(n.code,{children:"predict"})," span will have a single chat completion message as the output, which is aggregated by the custom reducer function."]}),"\n",(0,a.jsx)(n.h2,{id:"multi-threading",children:"Multi Threading"}),"\n",(0,a.jsx)(n.p,{children:"MLflow Tracing is thread-safe, traces are isolated by default per thread. But you can also create a trace that spans multiple threads with a few additional steps."}),"\n",(0,a.jsxs)(n.p,{children:["MLflow uses Python's built-in ",(0,a.jsx)(n.a,{href:"https://docs.python.org/3/library/contextvars.html",children:"ContextVar"})," mechanism to ensure thread safety, which is not propagated across threads by default. Therefore, you need to manually copy the context from the main thread to the worker thread, as shown in the example below."]}),"\n",(0,a.jsx)(p.A,{children:(0,a.jsx)(i.A,{groupId:"programming-language",children:(0,a.jsx)(c.A,{value:"python",label:"Python",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import contextvars\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nimport mlflow\nfrom mlflow.entities import SpanType\nimport openai\n\nclient = openai.OpenAI()\n\n# Enable MLflow Tracing for OpenAI\nmlflow.openai.autolog()\n\n\n@mlflow.trace\ndef worker(question: str) -> str:\n    messages = [\n        {"role": "system", "content": "You are a helpful assistant."},\n        {"role": "user", "content": question},\n    ]\n    response = client.chat.completions.create(\n        model="gpt-4o-mini",\n        messages=messages,\n        temperature=0.1,\n        max_tokens=100,\n    )\n    return response.choices[0].message.content\n\n\n@mlflow.trace\ndef main(questions: list[str]) -> list[str]:\n    results = []\n    # Almost same as how you would use ThreadPoolExecutor, but two additional steps\n    #  1. Copy the context in the main thread using copy_context()\n    #  2. Use ctx.run() to run the worker in the copied context\n    with ThreadPoolExecutor(max_workers=2) as executor:\n        futures = []\n        for question in questions:\n            ctx = contextvars.copy_context()\n            futures.append(executor.submit(ctx.run, worker, question))\n        for future in as_completed(futures):\n            results.append(future.result())\n    return results\n\n\nquestions = [\n    "What is the capital of France?",\n    "What is the capital of Germany?",\n]\n\nmain(questions)\n'})})})})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Multi threaded tracing",src:t(18186).A+"",width:"1140",height:"426"})}),"\n",(0,a.jsx)(n.admonition,{type:"tip",children:(0,a.jsxs)(n.p,{children:["In contrast, ",(0,a.jsx)(n.code,{children:"ContextVar"})," is copied to ",(0,a.jsx)(n.strong,{children:"async"})," tasks by default. Therefore, you don't need to manually copy the context when using ",(0,a.jsx)(n.code,{children:"asyncio"}),", which might be an easier way to handle concurrent I/O-bound tasks in Python with MLflow Tracing."]})}),"\n",(0,a.jsx)(n.h2,{id:"async-support",children:"Async Support"}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"@mlflow.trace"})," decorator works seamlessly with async functions:"]}),"\n",(0,a.jsx)(p.A,{children:(0,a.jsx)(i.A,{groupId:"programming-language",children:(0,a.jsx)(c.A,{value:"python",label:"Python",default:!0,children:(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import asyncio\nimport mlflow\n\n\n@mlflow.trace\nasync def async_operation(data: str) -> str:\n    # Simulate async work\n    await asyncio.sleep(0.1)\n    return f"Processed: {data}"\n\n\n@mlflow.trace\nasync def async_pipeline(items: list[str]) -> list[str]:\n    results = []\n    for item in items:\n        result = await async_operation(item)\n        results.append(result)\n    return results\n\n\n# Run the async pipeline\nasyncio.run(async_pipeline(["item1", "item2", "item3"]))\n'})})})})}),"\n",(0,a.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.a,{href:"/genai/tracing/app-instrumentation/automatic#combining-manual-and-automatic-tracing",children:"Combining with Auto-Tracing"})}),": Mix automatic and manual tracing for optimal observability"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.a,{href:"/genai/concepts/trace",children:"Trace Concepts"})}),": Understand the structure and components of MLflow traces"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.a,{href:"/genai/tracing/search-traces",children:"Querying Traces"})}),": Programmatically search and analyze your traces"]})]})}function g(e={}){let{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(f,{...e})}):f(e)}},10550(e,n,t){t.d(n,{A:()=>r});let r=t.p+"assets/images/trace-decorator-8ae22208121b562582947549f8b9a46e.png"},18186(e,n,t){t.d(n,{A:()=>r});let r=t.p+"assets/images/tracing-multi-thread-acfb6f382ce45e030c95b7c0536749bf.png"},57250(e,n,t){t.d(n,{A:()=>o});var r=t(74848);t(96540);var a=t(34164);function o({children:e,hidden:n,className:t}){return(0,r.jsx)("div",{role:"tabpanel",className:(0,a.A)("tabItem_Ymn6",t),hidden:n,children:e})}},78010(e,n,t){t.d(n,{A:()=>x});var r=t(74848),a=t(96540),o=t(34164),s=t(88287),l=t(28584),i=t(56347),c=t(99989),p=t(96629),m=t(80618),d=t(41367);function h(e){return a.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,a.isValidElement)(e)&&function(e){let{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function u({value:e,tabValues:n}){return n.some(n=>n.value===e)}var f=t(19863);function g({className:e,block:n,selectedValue:t,selectValue:a,tabValues:s}){let i=[],{blockElementScrollPositionUntilNextRender:c}=(0,l.a_)(),p=e=>{let n=e.currentTarget,r=s[i.indexOf(n)].value;r!==t&&(c(n),a(r))},m=e=>{let n=null;switch(e.key){case"Enter":p(e);break;case"ArrowRight":{let t=i.indexOf(e.currentTarget)+1;n=i[t]??i[0];break}case"ArrowLeft":{let t=i.indexOf(e.currentTarget)-1;n=i[t]??i[i.length-1]}}n?.focus()};return(0,r.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.A)("tabs",{"tabs--block":n},e),children:s.map(({value:e,label:n,attributes:a})=>(0,r.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{i.push(e)},onKeyDown:m,onClick:p,...a,className:(0,o.A)("tabs__item","tabItem_LNqP",a?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function w({lazy:e,children:n,selectedValue:t}){let s=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){let e=s.find(e=>e.props.value===t);return e?(0,a.cloneElement)(e,{className:(0,o.A)("margin-top--md",e.props.className)}):null}return(0,r.jsx)("div",{className:"margin-top--md",children:s.map((e,n)=>(0,a.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function y(e){let n=function(e){let n,{defaultValue:t,queryString:r=!1,groupId:o}=e,s=function(e){let{values:n,children:t}=e;return(0,a.useMemo)(()=>{let e=n??h(t).map(({props:{value:e,label:n,attributes:t,default:r}})=>({value:e,label:n,attributes:t,default:r})),r=(0,m.XI)(e,(e,n)=>e.value===n.value);if(r.length>0)throw Error(`Docusaurus error: Duplicate values "${r.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`);return e},[n,t])}(e),[l,f]=(0,a.useState)(()=>(function({defaultValue:e,tabValues:n}){if(0===n.length)throw Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!u({value:e,tabValues:n}))throw Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}let t=n.find(e=>e.default)??n[0];if(!t)throw Error("Unexpected error: 0 tabValues");return t.value})({defaultValue:t,tabValues:s})),[g,w]=function({queryString:e=!1,groupId:n}){let t=(0,i.W6)(),r=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,p.aZ)(r),(0,a.useCallback)(e=>{if(!r)return;let n=new URLSearchParams(t.location.search);n.set(r,e),t.replace({...t.location,search:n.toString()})},[r,t])]}({queryString:r,groupId:o}),[y,x]=function({groupId:e}){let n=e?`docusaurus.tab.${e}`:null,[t,r]=(0,d.Dv)(n);return[t,(0,a.useCallback)(e=>{n&&r.set(e)},[n,r])]}({groupId:o}),_=u({value:n=g??y,tabValues:s})?n:null;return(0,c.A)(()=>{_&&f(_)},[_]),{selectedValue:l,selectValue:(0,a.useCallback)(e=>{if(!u({value:e,tabValues:s}))throw Error(`Can't select invalid tab value=${e}`);f(e),w(e),x(e)},[w,x,s]),tabValues:s}}(e);return(0,r.jsxs)("div",{className:(0,o.A)(s.G.tabs.container,"tabs-container","tabList__CuJ"),children:[(0,r.jsx)(g,{...n,...e}),(0,r.jsx)(w,{...n,...e})]})}function x(e){let n=(0,f.A)();return(0,r.jsx)(y,{...e,children:h(e.children)},String(n))}},54725(e,n,t){t.d(n,{B:()=>s});var r=t(74848);t(96540);var a=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}'),o=t(66497);function s({fn:e,children:n,hash:t}){let s=(e=>{let n=e.split(".");for(let e=n.length;e>0;e--){let t=n.slice(0,e).join(".");if(a[t])return t}return null})(e);if(!s)return(0,r.jsx)(r.Fragment,{children:n});let l=(0,o.default)(`/${a[s]}#${t??e}`);return(0,r.jsx)("a",{href:l,target:"_blank",children:n??(0,r.jsxs)("code",{children:[e,"()"]})})}},95986(e,n,t){t.d(n,{A:()=>a});var r=t(74848);t(96540);function a({children:e}){return(0,r.jsx)("div",{className:"wrapper_sf5q",children:e})}},28453(e,n,t){t.d(n,{R:()=>s,x:()=>l});var r=t(96540);let a={},o=r.createContext(a);function s(e){let n=r.useContext(o);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),r.createElement(o.Provider,{value:n},e.children)}}}]);