"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[231],{2406:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>m});const i=JSON.parse('{"id":"prompt-registry/optimize-prompts","title":"Optimize Prompts (Experimental)","description":"MLflow allows you to plug your prompts into advanced prompt optimization techniques through MLflow\'s unified interface using the  API.","source":"@site/docs/genai/prompt-registry/optimize-prompts.mdx","sourceDirName":"prompt-registry","slug":"/prompt-registry/optimize-prompts","permalink":"/mlflow-website/docs/latest/genai/prompt-registry/optimize-prompts","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"sidebar_label":"Optimize Prompts \ud83c\udd95"},"sidebar":"genAISidebar","previous":{"title":"Structured Output","permalink":"/mlflow-website/docs/latest/genai/prompt-registry/structured-output"},"next":{"title":"Prompt Engineering UI","permalink":"/mlflow-website/docs/latest/genai/prompt-registry/prompt-engineering"}}');var o=n(74848),r=n(28453),s=n(49374);const a={sidebar_position:5,sidebar_label:"Optimize Prompts \ud83c\udd95"},l="Optimize Prompts (Experimental)",p={},m=[{value:"Optimization Overview",id:"optimization-overview",level:2},{value:"Getting Started",id:"getting-started",level:2},{value:"Configuration",id:"configuration",level:2},{value:"Custom Optimizers",id:"custom-optimizers",level:2},{value:"BasePromptOptimizer",id:"basepromptoptimizer",level:3},{value:"DSPyPromptOptimizer",id:"dspypromptoptimizer",level:3},{value:"Performance Benchmarks",id:"performance-benchmarks",level:2},{value:"FAQ",id:"faq",level:2},{value:"What are the supported Dataset formats?",id:"what-are-the-supported-dataset-formats",level:3},{value:"How to combine multiple scorers?",id:"how-to-combine-multiple-scorers",level:3},{value:"How to create custom optimizers?",id:"how-to-create-custom-optimizers",level:3}];function c(e){const t={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.header,{children:(0,o.jsx)(t.h1,{id:"optimize-prompts-experimental",children:"Optimize Prompts (Experimental)"})}),"\n",(0,o.jsxs)(t.p,{children:["MLflow allows you to plug your prompts into advanced prompt optimization techniques through MLflow's unified interface using the ",(0,o.jsx)(s.B,{fn:"mlflow.genai.optimize_prompt"})," API.\nThis feature helps you improve your prompts automatically by leveraging evaluation metrics and labeled data. MLflow provides built-in support for optimization algorithms such as ",(0,o.jsx)(t.a,{href:"https://dspy.ai/api/optimizers/MIPROv2/",children:"DSPy's MIPROv2 algorithm"}),". You can also implement custom optimization algorithms by extending MLflow's base optimizer class ",(0,o.jsx)(s.B,{fn:"mlflow.genai.optimize.BasePromptOptimizer",children:"BasePromptOptimizer"}),"."]}),"\n",(0,o.jsx)(t.admonition,{title:"Key Benefits",type:"tip",children:(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Unified Interface"}),": Access to the state-of-the-art prompt optimization algorithms through a neutral interface."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Extensible"}),": Create custom optimization algorithms by extending base optimizer classes."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Prompt Management"}),": Integrate with MLflow Prompt Registry to gain reusability, version control and lineage."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"Evaluation"}),": Evaluate prompt performance comprehensively with MLflow's evaluation features."]}),"\n"]})}),"\n",(0,o.jsx)(t.h2,{id:"optimization-overview",children:"Optimization Overview"}),"\n",(0,o.jsxs)(t.p,{children:["In order to use ",(0,o.jsx)(s.B,{fn:"mlflow.genai.optimize_prompt"})," API, you need to prepare the following:"]}),"\n",(0,o.jsxs)("table",{style:{width:"100%"},children:[(0,o.jsx)("thead",{children:(0,o.jsxs)("tr",{children:[(0,o.jsx)("th",{style:{width:"30%"},children:"Component"}),(0,o.jsx)("th",{style:{width:"70%"},children:"Example"})]})}),(0,o.jsxs)("tbody",{children:[(0,o.jsxs)("tr",{children:[(0,o.jsxs)("td",{children:[(0,o.jsx)("strong",{children:"Prompt"}),(0,o.jsx)("br",{}),(0,o.jsx)("small",{children:"Registered in MLflow"})]}),(0,o.jsx)("td",{children:(0,o.jsx)("pre",{children:(0,o.jsx)("code",{children:'mlflow.register_prompt(name="qa", template="Answer {{question}}")'})})})]}),(0,o.jsxs)("tr",{children:[(0,o.jsxs)("td",{children:[(0,o.jsx)("strong",{children:"Scorer"}),(0,o.jsx)("br",{}),(0,o.jsx)("small",{children:"Evaluates prompt quality"})]}),(0,o.jsx)("td",{children:(0,o.jsx)("pre",{children:(0,o.jsxs)("code",{children:["@scorer",(0,o.jsx)("br",{}),"def exact_match(expectations, outputs):",(0,o.jsx)("br",{}),"    return expectations == outputs"]})})})]}),(0,o.jsxs)("tr",{children:[(0,o.jsxs)("td",{children:[(0,o.jsx)("strong",{children:"Data"}),(0,o.jsx)("br",{}),(0,o.jsx)("small",{children:"Inputs & expectations"})]}),(0,o.jsx)("td",{children:(0,o.jsx)("pre",{children:(0,o.jsxs)("code",{children:["[",(0,o.jsx)("br",{}),'  {"inputs": {"question": "2+2"}, "expectations": {"answer": "4"}},',(0,o.jsx)("br",{}),'  {"inputs": {"question": "2+3"}, "expectations": {"answer": "5"}}',(0,o.jsx)("br",{}),"]"]})})})]}),(0,o.jsxs)("tr",{children:[(0,o.jsxs)("td",{children:[(0,o.jsx)("strong",{children:"Target LLM"}),(0,o.jsx)("br",{}),(0,o.jsx)("small",{children:"Model to optimize for"})]}),(0,o.jsx)("td",{children:(0,o.jsx)("pre",{children:(0,o.jsx)("code",{children:'LLMParams(model_name="openai/gpt-4.1-mini")'})})})]}),(0,o.jsxs)("tr",{children:[(0,o.jsxs)("td",{children:[(0,o.jsx)("strong",{children:"Optimizer Config"}),(0,o.jsx)("br",{}),(0,o.jsx)("small",{children:"Optimization settings"})]}),(0,o.jsx)("td",{children:(0,o.jsx)("pre",{children:(0,o.jsxs)("code",{children:["OptimizerConfig(",(0,o.jsx)("br",{}),'  algorithm="DSPy/MIPROv2",',(0,o.jsx)("br",{}),"  num_instruction_candidates=6,",(0,o.jsx)("br",{}),"  max_few_show_examples=2",(0,o.jsx)("br",{}),")"]})})})]})]})]}),"\n",(0,o.jsx)(t.h2,{id:"getting-started",children:"Getting Started"}),"\n",(0,o.jsx)(t.p,{children:"Here's a simple example of optimizing a question-answering prompt:"}),"\n",(0,o.jsx)(t.p,{children:"As a prerequisite, you need to install DSPy."}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-bash",children:"$ pip install dspy>=2.6.0 mlflow>=3.1.0\n"})}),"\n",(0,o.jsx)(t.p,{children:"Then, run the following code to register the initial prompt and optimize it."}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'import os\nfrom typing import Any\nimport mlflow\nfrom mlflow.genai.scorers import scorer\nfrom mlflow.genai.optimize import OptimizerConfig, LLMParams\n\nos.environ["OPENAI_API_KEY"] = "<YOUR_OPENAI_API_KEY>"\n\n\n# Define a custom scorer function to evaluate prompt performance with the @scorer decorator.\n# The scorer function for optimization can take inputs, outputs, and expectations.\n@scorer\ndef exact_match(expectations: dict[str, Any], outputs: dict[str, Any]) -> bool:\n    return expectations["answer"] == outputs["answer"]\n\n\n# Register the initial prompt\ninitial_template = """\nAnswer to this math question: {{question}}.\nReturn the result in a JSON string in the format of {"answer": "xxx"}.\n"""\n\nprompt = mlflow.genai.register_prompt(\n    name="math",\n    template=initial_template,\n)\n\n# The data can be a list of dictionaries, a pandas DataFrame, or an mlflow.genai.EvaluationDataset\n# It needs to contain inputs and expectations where each row is a dictionary.\ntrain_data = [\n    {\n        "inputs": {"question": "Given that $y=3$, evaluate $(1+y)^y$."},\n        "expectations": {"answer": "64"},\n    },\n    {\n        "inputs": {\n            "question": "The midpoint of the line segment between $(x,y)$ and $(-9,1)$ is $(3,-5)$. Find $(x,y)$."\n        },\n        "expectations": {"answer": "(15,-11)"},\n    },\n    {\n        "inputs": {\n            "question": "What is the value of $b$ if $5^b + 5^b + 5^b + 5^b + 5^b = 625^{(b-1)}$? Express your answer as a common fraction."\n        },\n        "expectations": {"answer": "\\\\frac{5}{3}"},\n    },\n    {\n        "inputs": {"question": "Evaluate the expression $a^3\\\\cdot a^2$ if $a= 5$."},\n        "expectations": {"answer": "3125"},\n    },\n    {\n        "inputs": {"question": "Evaluate $\\\\lceil 8.8 \\\\rceil+\\\\lceil -8.8 \\\\rceil$."},\n        "expectations": {"answer": "17"},\n    },\n]\n\neval_data = [\n    {\n        "inputs": {\n            "question": "The sum of 27 consecutive positive integers is $3^7$. What is their median?"\n        },\n        "expectations": {"answer": "81"},\n    },\n    {\n        "inputs": {"question": "What is the value of $x$ if $x^2 - 10x + 25 = 0$?"},\n        "expectations": {"answer": "5"},\n    },\n    {\n        "inputs": {\n            "question": "If $a\\\\ast b = 2a+5b-ab$, what is the value of $3\\\\ast10$?"\n        },\n        "expectations": {"answer": "26"},\n    },\n    {\n        "inputs": {\n            "question": "Given that $-4$ is a solution to $x^2 + bx -36 = 0$, what is the value of $b$?"\n        },\n        "expectations": {"answer": "-5"},\n    },\n]\n\n# Optimize the prompt\nresult = mlflow.genai.optimize_prompt(\n    target_llm_params=LLMParams(model_name="openai/gpt-4.1-mini"),\n    prompt=prompt,\n    train_data=train_data,\n    eval_data=eval_data,\n    scorers=[exact_match],\n    optimizer_config=OptimizerConfig(\n        num_instruction_candidates=8,\n        max_few_show_examples=2,\n    ),\n)\n\n# The optimized prompt is automatically registered as a new version\nprint(result.prompt.uri)\n'})}),"\n",(0,o.jsx)(t.p,{children:"In the example above the average performance score increased from 0 to 0.5.\nAfter the optimization process is completed, you can visit the MLflow Prompt Registry page and see the optimized prompt."}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"Optimized Prompt",src:n(44198).A+"",width:"3456",height:"1780"})}),"\n",(0,o.jsxs)(t.p,{children:["Note that the optimized prompt of ",(0,o.jsx)(s.B,{fn:"mlflow.genai.optimize_prompt"})," expects the output to be a JSON string.\nTherefore, you need to parse the output using ",(0,o.jsx)(t.code,{children:"json.loads"})," in your application. See ",(0,o.jsx)(t.a,{href:"/genai/prompt-registry/#4-load-and-use-the-prompt",children:"Load and Use the Prompt"})," for how to load the optimized prompt."]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'import mlflow\nimport json\nimport openai\n\n\ndef predict(question: str, prompt_uri: str) -> str:\n    prompt = mlflow.genai.load_prompt(prompt_uri)\n    content = prompt.format(question=question)\n    completion = openai.chat.completions.create(\n        model="gpt-4.1-mini",\n        messages=[{"role": "user", "content": content}],\n        temperature=0.1,\n    )\n\n    return json.loads(completion.choices[0].message.content)["answer"]\n'})}),"\n",(0,o.jsx)(t.h2,{id:"configuration",children:"Configuration"}),"\n",(0,o.jsxs)(t.p,{children:["You can customize the optimization process using ",(0,o.jsx)(t.code,{children:"OptimizerConfig"}),", which includes the following parameters:"]}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"algorithm"}),': The optimization algorithm to use. Can be a string (e.g., "DSPy/MIPROv2") or a custom optimizer class. Default: "DSPy/MIPROv2"']}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"num_instruction_candidates"}),": The number of candidate instructions to try. Default: 6"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"max_few_show_examples"}),": The maximum number of examples to show in few-shot demonstrations. Default: 6"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"optimizer_llm"}),": The LLM to use for optimization. Default: None (uses target LLM)"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"extract_instructions"}),": Whether to extract instructions from the initial prompt template. Default: True"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"verbose"}),": Whether to show optimizer logs during optimization. Default: False"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:"autolog"}),": Whether to log the optimization parameters, datasets and metrics. If set to True, a MLflow run is automatically created to store them. Default: False"]}),"\n"]}),"\n",(0,o.jsxs)(t.p,{children:["See ",(0,o.jsx)(s.B,{fn:"mlflow.genai.OptimizerConfig"})," for more details."]}),"\n",(0,o.jsx)(t.h2,{id:"custom-optimizers",children:"Custom Optimizers"}),"\n",(0,o.jsx)(t.p,{children:"MLflow supports creating custom prompt optimization algorithms by extending the base optimizer classes. This allows you to implement domain-specific optimization strategies or integrate with other optimization libraries."}),"\n",(0,o.jsx)(t.h3,{id:"basepromptoptimizer",children:"BasePromptOptimizer"}),"\n",(0,o.jsxs)(t.p,{children:["For custom optimization logic, extend the ",(0,o.jsx)(s.B,{fn:"mlflow.genai.optimize.BasePromptOptimizer",children:"BasePromptOptimizer"})," class:"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'from mlflow.genai.optimize import BasePromptOptimizer, OptimizerConfig, OptimizerOutput\nfrom mlflow.genai.optimize.types import LLMParams\nfrom mlflow.entities.model_registry import PromptVersion\nfrom mlflow.genai.scorers import Scorer\nfrom typing import Optional, Callable, Any\nimport pandas as pd\n\n\nclass CustomOptimizer(BasePromptOptimizer):\n    # Inherit the BasePromptOptimizer class and implement the `optimize` method.\n    def optimize(\n        self,\n        prompt: PromptVersion,\n        target_llm_params: LLMParams,\n        train_data: pd.DataFrame,\n        scorers: list[Scorer],\n        objective: Optional[Callable[[dict[str, Any]], float]] = None,\n        eval_data: Optional[pd.DataFrame] = None,\n    ) -> OptimizerOutput:\n        # Implement your custom optimization logic here\n\n        optimized_template = f"Please answer accurately: {prompt.template}"\n\n        return OptimizerOutput(\n            optimized_prompt=optimized_template,\n            optimizer_name="CustomOptimizer",\n            final_eval_score=0.85,\n            initial_eval_score=0.75,\n        )\n\n\n# Use the custom optimizer\nresult = mlflow.genai.optimize_prompt(\n    target_llm_params=LLMParams(model_name="openai/gpt-4o-mini"),\n    prompt=prompt,\n    train_data=train_data,\n    scorers=[exact_match],\n    optimizer_config=OptimizerConfig(algorithm=CustomOptimizer),\n)\n'})}),"\n",(0,o.jsx)(t.h3,{id:"dspypromptoptimizer",children:"DSPyPromptOptimizer"}),"\n",(0,o.jsxs)(t.p,{children:["For DSPy-based optimizations, extend the ",(0,o.jsx)(s.B,{fn:"mlflow.genai.optimize.DSPyPromptOptimizer",children:"DSPyPromptOptimizer"})," class, which provides DSPy integration infrastructure:"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'import dspy\nfrom typing import Callable\nfrom mlflow.genai.optimize import (\n    DSPyPromptOptimizer,\n    OptimizerOutput,\n    format_dspy_prompt,\n)\nfrom mlflow.entities.model_registry import PromptVersion\n\n\nclass CustomDSPyOptimizer(DSPyPromptOptimizer):\n    # Inherit the DSPyPromptOptimizer class and implement the `run_optimization` method.\n    def run_optimization(\n        self,\n        prompt: PromptVersion,\n        program: dspy.Module,\n        metric: Callable[[dspy.Example], float],\n        train_data: list,\n        eval_data: list,\n    ) -> OptimizerOutput:\n        # Use DSPy\'s optimization components with your custom logic\n        # Example using DSPy\'s BootstrapFewShot optimizer\n        optimizer = dspy.BootstrapFewShot(\n            metric=metric,\n            max_bootstrapped_demos=self.optimizer_config.max_few_show_examples,\n        )\n\n        # Compile the program\n        compiled_program = optimizer.compile(\n            student=program,\n            trainset=train_data,\n        )\n\n        return OptimizerOutput(\n            optimized_prompt=format_dspy_prompt(compiled_program),\n            optimizer_name="BootstrapFewShot",\n        )\n\n\n# Use the custom DSPy optimizer\nresult = mlflow.genai.optimize_prompt(\n    target_llm_params=LLMParams(model_name="openai/gpt-4o-mini"),\n    prompt=prompt,\n    train_data=train_data,\n    scorers=[exact_match],\n    optimizer_config=OptimizerConfig(algorithm=CustomDSPyOptimizer),\n)\n'})}),"\n",(0,o.jsx)(t.admonition,{type:"note",children:(0,o.jsxs)(t.p,{children:["When using custom optimizers, ensure they return an ",(0,o.jsx)(t.code,{children:"OptimizerOutput"})," object with the optimized prompt and evaluation scores."]})}),"\n",(0,o.jsx)(t.h2,{id:"performance-benchmarks",children:"Performance Benchmarks"}),"\n",(0,o.jsx)(t.admonition,{type:"info",children:(0,o.jsx)(t.p,{children:"We are actively working on the benchmarking.\nThese benchmarks results are preliminary and subject to change."})}),"\n",(0,o.jsx)(t.p,{children:"MLflow prompt optimization can improve your application's performance across various tasks. Here are the results from testing MLflow's optimization capabilities on several datasets:"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.a,{href:"https://huggingface.co/datasets/allenai/ai2_arc",children:(0,o.jsx)(t.strong,{children:"ARC-Challenge"})}),": The ai2_arc dataset contains a set of multiple choice science questions"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.a,{href:"https://huggingface.co/datasets/openai/gsm8k",children:(0,o.jsx)(t.strong,{children:"GSM8K"})}),": The gsm8k dataset contains a set of linguistically diverse grade school math word problems"]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.a,{href:"https://huggingface.co/datasets/DigitalLearningGmbH/MATH-lighteval",children:(0,o.jsx)(t.strong,{children:"MATH"})}),": Competition mathematics problems requiring advanced reasoning and problem-solving skills"]}),"\n"]}),"\n",(0,o.jsxs)(t.table,{children:[(0,o.jsx)(t.thead,{children:(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.th,{children:"Dataset"}),(0,o.jsx)(t.th,{children:"Model"}),(0,o.jsx)(t.th,{children:"Baseline"}),(0,o.jsx)(t.th,{children:"Optimized"})]})}),(0,o.jsxs)(t.tbody,{children:[(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.strong,{children:"MATH"})}),(0,o.jsx)(t.td,{children:"gpt-4.1o-nano"}),(0,o.jsx)(t.td,{children:"17.25%"}),(0,o.jsx)(t.td,{children:(0,o.jsx)(t.strong,{children:"18.48%"})})]}),(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.strong,{children:"GSM8K"})}),(0,o.jsx)(t.td,{children:"gpt-4.1o-nano"}),(0,o.jsx)(t.td,{children:"21.46%"}),(0,o.jsx)(t.td,{children:(0,o.jsx)(t.strong,{children:"49.89%"})})]}),(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.strong,{children:"ARC-Challenge"})}),(0,o.jsx)(t.td,{children:"gpt-4.1o-nano"}),(0,o.jsx)(t.td,{children:"71.42%"}),(0,o.jsx)(t.td,{children:(0,o.jsx)(t.strong,{children:"89.25%"})})]}),(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.strong,{children:"MATH"})}),(0,o.jsx)(t.td,{children:"Llama4-maverick"}),(0,o.jsx)(t.td,{children:"33.06%"}),(0,o.jsx)(t.td,{children:(0,o.jsx)(t.strong,{children:"33.26%"})})]}),(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.strong,{children:"GSM8K"})}),(0,o.jsx)(t.td,{children:"Llama4-maverick"}),(0,o.jsx)(t.td,{children:"55.80%"}),(0,o.jsx)(t.td,{children:(0,o.jsx)(t.strong,{children:"58.22%"})})]}),(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:(0,o.jsx)(t.strong,{children:"ARC-Challenge"})}),(0,o.jsx)(t.td,{children:"Llama4-maverick"}),(0,o.jsx)(t.td,{children:"0.17%"}),(0,o.jsx)(t.td,{children:(0,o.jsx)(t.strong,{children:"93.17%"})})]})]})]}),"\n",(0,o.jsxs)(t.p,{children:["The results above are benchmarks tested against ",(0,o.jsx)(t.code,{children:"gpt-4.1o-nano"})," and ",(0,o.jsx)(t.code,{children:"Llama4-maverick"})," with DSPy's MIPROv2 algorithm and default settings, using specific evaluation metrics for each task.\nThe results might change if you use a different model, configuration, dataset, or starting prompt(s).\nThese results show that MLflow's prompt optimization can solve many of the challenges, delivering measurable performance gains with minimal effort."]}),"\n",(0,o.jsx)(t.h2,{id:"faq",children:"FAQ"}),"\n",(0,o.jsx)(t.h3,{id:"what-are-the-supported-dataset-formats",children:"What are the supported Dataset formats?"}),"\n",(0,o.jsxs)(t.p,{children:["The training and evaluation data for the ",(0,o.jsx)(s.B,{fn:"mlflow.genai.optimize_prompt"})," API can be a list of dictionaries, a pandas DataFrame, a spark DataFrame, or an ",(0,o.jsx)(s.B,{fn:"mlflow.genai.EvaluationDataset",children:"mlflow.genai.EvaluationDataset"}),".\nIn any case, the data needs to contain inputs and expectations columns that contains a dictionary of input fields and expected output fields.\nEach inputs or expectations dictionary can contain primitive types, lists, nested dictionaries, and Pydantic models. Data types are inferred from the first row of the dataset."]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'# \u2705 OK\n[\n    {\n        "inputs": {"question": "What is the capital of France?"},\n        "expectations": {"answer": "Paris"},\n    },\n]\n\n# \u2705 OK\n[\n    {\n        "inputs": {"question": "What are the three largest cities of Japan?"},\n        "expectations": {"answer": ["Tokyo", "Osaka", "Nagoya"]},\n    },\n]\n\n# \u2705 OK\nfrom pydantic import BaseModel\n\n\nclass Country(BaseModel):\n    name: str\n    capital: str\n    population: int\n\n\n[\n    {\n        "inputs": {"question": "What is the capital of France?"},\n        "expectations": {\n            "answer": Country(name="France", capital="Paris", population=68000000)\n        },\n    },\n]\n\n# \u274c NG\n[\n    {\n        "inputs": "What is the capital of France?",\n        "expectations": "Paris",\n    },\n]\n'})}),"\n",(0,o.jsx)(t.h3,{id:"how-to-combine-multiple-scorers",children:"How to combine multiple scorers?"}),"\n",(0,o.jsxs)(t.p,{children:["While the ",(0,o.jsx)(s.B,{fn:"mlflow.genai.optimize_prompt"})," API accepts multiple scorers, the optimizer needs to combine them into a single score during the optimization process.\nBy default, the optimizer computes the total score of all scorers with numeric or boolean values.\nIf you want to use a custom aggregation function or use scorers that return non-numeric values, you can pass a custom aggregation function to the ",(0,o.jsx)(t.code,{children:"objective"})," parameter."]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'@scorer\ndef safeness(outputs: dict[str, Any]) -> bool:\n    return "death" not in outputs["answer"].lower()\n\n\n@scorer\ndef relevance(expectations: dict[str, Any], outputs: dict[str, Any]) -> bool:\n    return expectations["answer"] in outputs["answer"]\n\n\ndef objective(scores: dict[str, Any]) -> float:\n    if not scores["safeness"]:\n        return -1\n    return scores["relevance"]\n\n\nresult = mlflow.genai.optimize_prompt(\n    target_llm_params=LLMParams(model_name="openai/gpt-4.1-mini"),\n    prompt=prompt,\n    train_data=train_data,\n    eval_data=eval_data,\n    scorers=[safeness, relevance],\n    objective=objective,\n)\n'})}),"\n",(0,o.jsx)(t.h3,{id:"how-to-create-custom-optimizers",children:"How to create custom optimizers?"}),"\n",(0,o.jsx)(t.p,{children:"MLflow provides two base classes for creating custom optimizers:"}),"\n",(0,o.jsxs)(t.ol,{children:["\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:(0,o.jsx)(s.B,{fn:"mlflow.genai.optimize.BasePromptOptimizer",children:"BasePromptOptimizer"})}),": For custom optimization logic. In order to customize, you must implement your own ",(0,o.jsx)(t.code,{children:"optimize"})," method."]}),"\n",(0,o.jsxs)(t.li,{children:[(0,o.jsx)(t.strong,{children:(0,o.jsx)(s.B,{fn:"mlflow.genai.optimize.DSPyPromptOptimizer",children:"DSPyPromptOptimizer"})}),": For DSPy-based optimizations. Customization of this optimizer involves building a",(0,o.jsx)(t.code,{children:"run_optimization"})," method. MLflow will handle the required DSPy setup for utilizing your custom interface."]}),"\n"]}),"\n",(0,o.jsxs)(t.p,{children:["Choose ",(0,o.jsx)(s.B,{fn:"mlflow.genai.optimize.BasePromptOptimizer",children:"BasePromptOptimizer"})," when you want complete control over the optimization process, or ",(0,o.jsx)(s.B,{fn:"mlflow.genai.optimize.DSPyPromptOptimizer",children:"DSPyPromptOptimizer"})," when you want to leverage DSPy's ecosystem while customizing the optimization strategy."]})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},28453:(e,t,n)=>{n.d(t,{R:()=>s,x:()=>a});var i=n(96540);const o={},r=i.createContext(o);function s(e){const t=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),i.createElement(r.Provider,{value:t},e.children)}},44198:(e,t,n)=>{n.d(t,{A:()=>i});const i=n.p+"assets/images/registered_prompt-979a351f289dc9b8c6ba24ea856e1398.png"},49374:(e,t,n)=>{n.d(t,{B:()=>a});n(96540);const i=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.promptflow":"api_reference/python_api/mlflow.promptflow.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}');var o=n(86025),r=n(74848);const s=e=>{const t=e.split(".");for(let n=t.length;n>0;n--){const e=t.slice(0,n).join(".");if(i[e])return e}return null};function a({fn:e,children:t,hash:n}){const a=s(e);if(!a)return(0,r.jsx)(r.Fragment,{children:t});const l=(0,o.Ay)(`/${i[a]}#${n??e}`);return(0,r.jsx)("a",{href:l,target:"_blank",children:t??(0,r.jsxs)("code",{children:[e,"()"]})})}}}]);