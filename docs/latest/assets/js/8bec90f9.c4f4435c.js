"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["7058"],{91429(e,t,n){n.r(t),n.d(t,{metadata:()=>a,default:()=>k,frontMatter:()=>v,contentTitle:()=>x,toc:()=>j,assets:()=>y});var a=JSON.parse('{"id":"eval-monitor/running-evaluation/traces","title":"Evaluating (Production) Traces","description":"Traces are the core data of MLflow. They capture the complete execution flow of your LLM applications. Evaluating traces is a powerful way to understand the performance of your LLM applications and get insights for quality improvement.","source":"@site/docs/genai/eval-monitor/running-evaluation/traces.mdx","sourceDirName":"eval-monitor/running-evaluation","slug":"/eval-monitor/running-evaluation/traces","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/running-evaluation/traces","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"genAISidebar","previous":{"title":"Evaluate Agents","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/running-evaluation/agents"},"next":{"title":"Evaluate Conversations","permalink":"/mlflow-website/docs/latest/genai/eval-monitor/running-evaluation/multi-turn"}}'),r=n(74848),i=n(28453),o=n(54725),s=n(46077),l=n(81956),c=n(10440),p=n(77541),m=n(92457),d=n(98445),h=n(47792),u=n(85731),f=n(93164),w=n(96844),g=n(46858),_=n(74990);let v={},x="Evaluating (Production) Traces",y={},j=[{value:"Workflow",id:"workflow",level:2},{value:"Example: Evaluating Production Traces",id:"example-evaluating-production-traces",level:2},{value:"Prerequisites",id:"prerequisites",level:3},..._.RM,{value:"Step 0: Simulate Production Traces",id:"step-0-simulate-production-traces",level:3},{value:"Step 1: Search and retrieve traces",id:"step-1-search-and-retrieve-traces",level:3},{value:"Step 2: Define application-specific scorers",id:"step-2-define-application-specific-scorers",level:3},{value:"Step 3: Evaluate trace quality",id:"step-3-evaluate-trace-quality",level:3},{value:"Annotate Traces with Ground Truth and Manual Feedbacks",id:"annotate-traces-with-ground-truth-and-manual-feedbacks",level:2},{value:"Recording End-user Feedbacks from Production",id:"recording-end-user-feedbacks-from-production",level:2},{value:"Next steps",id:"next-steps",level:2}];function b(e){let t={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"evaluating-production-traces",children:"Evaluating (Production) Traces"})}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.a,{href:"/genai/tracing",children:"Traces"})," are the core data of MLflow. They capture the complete execution flow of your LLM applications. Evaluating traces is a powerful way to understand the performance of your LLM applications and get insights for quality improvement."]}),"\n",(0,r.jsx)(t.p,{children:"Evaluating traces is also a useful trick for offline evaluation. Instead of running prediction on every evaluation run, you can generate traces at once and re-use them for multiple evaluation runs, to reduce the computation and LLM costs."}),"\n",(0,r.jsx)(s.A,{src:"/images/mlflow-3/eval-monitor/trace-evaluation-hero.png",alt:"Evaluate traces overview",width:"95%"}),"\n",(0,r.jsx)(t.h2,{id:"workflow",children:"Workflow"}),"\n",(0,r.jsx)(l.A,{steps:[{icon:m.A,title:"Annotate traces with ground truth (Optional)",description:"Add expected outputs and ground truth labels to traces to establish evaluation baselines and correct answers."},{icon:d.A,title:"Search and retrieve traces",description:"Find and collect traces from your MLflow tracking server using filters for time range, experiment, or trace status."},{icon:h.A,title:"Define scorers",description:"Create built-in and custom scorers to measure quality, accuracy, latency, and trace-specific metrics."},{icon:u.A,title:"Run evaluation",description:"Execute the evaluation on your trace collection and analyze results in MLflow UI for insights."}]}),"\n",(0,r.jsx)(t.h2,{id:"example-evaluating-production-traces",children:"Example: Evaluating Production Traces"}),"\n",(0,r.jsx)(t.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsx)(t.p,{children:"First, install the required packages by running the following command:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",children:"pip install --upgrade 'mlflow[genai]>=3.3' openai\n"})}),"\n",(0,r.jsx)(t.p,{children:"MLflow stores evaluation results in a tracking server. Connect your local environment to the tracking server by one of the following methods."}),"\n",(0,r.jsx)(_.Ay,{}),"\n",(0,r.jsx)(t.h3,{id:"step-0-simulate-production-traces",children:"Step 0: Simulate Production Traces"}),"\n",(0,r.jsx)(t.p,{children:"First, let's simulate some production traces to use for evaluation. Here we define a simple email automation app that uses a CRM database to generate emails. If you already have traces, you can skip this step."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'import mlflow\nfrom mlflow.entities import Document\nimport openai\n\nclient = openai.OpenAI()\nmlflow.openai.autolog()  # Enable automatic tracing for OpenAI calls\n\n# Simulated CRM database\nCRM_DATA = {\n    "Acme Corp": {\n        "contact_name": "Alice Chen",\n        "recent_meeting": "Product demo on Monday, very interested in enterprise features. They asked about: advanced analytics, real-time dashboards, API integrations, custom reporting, multi-user support, SSO authentication, data export capabilities, and pricing for 500+ users",\n        "support_tickets": [\n            "Ticket #123: API latency issue (resolved last week)",\n            "Ticket #124: Feature request for bulk import",\n            "Ticket #125: Question about GDPR compliance",\n        ],\n    },\n    "TechStart": {\n        "contact_name": "Bob Martinez",\n        "recent_meeting": "Initial sales call last Thursday, requested pricing",\n        "support_tickets": [\n            "Ticket #456: Login issues (open - critical)",\n            "Ticket #457: Performance degradation reported",\n            "Ticket #458: Integration failing with their CRM",\n        ],\n    },\n    "Global Retail": {\n        "contact_name": "Carol Wang",\n        "recent_meeting": "Quarterly review yesterday, happy with platform performance",\n        "support_tickets": [],\n    },\n}\n\n\n@mlflow.trace(span_type="RETRIEVER")\ndef retrieve_customer_info(customer_name: str) -> list[Document]:\n    """Retrieve customer information from CRM database"""\n    if data := CRM_DATA.get(customer_name):\n        return [\n            Document(\n                id=f"{customer_name}_meeting",\n                page_content=f"Recent meeting: {data[\'recent_meeting\']}",\n            ),\n            Document(\n                id=f"{customer_name}_tickets",\n                page_content=f"Support tickets: {\', \'.join(data[\'support_tickets\']) if data[\'support_tickets\'] else \'No open tickets\'}",\n            ),\n            Document(\n                id=f"{customer_name}_contact",\n                page_content=f"Contact: {data[\'contact_name\']}",\n            ),\n        ]\n    return []\n\n\n@mlflow.trace(span_type="AGENT")\ndef generate_sales_email(customer_name: str, user_instructions: str) -> dict[str, str]:\n    """Generate personalized sales email based on customer data & given objective."""\n    # Retrieve customer information\n    customer_docs = retrieve_customer_info(customer_name)\n    context = "\\n".join([doc.page_content for doc in customer_docs])\n\n    # Generate email using retrieved context\n    prompt = f"""You are a sales representative. Based on the customer information below,\n    write a brief follow-up email that addresses their request.\n\n    Customer Information: {context}\n\n    User instructions: {user_instructions}"""\n\n    response = client.chat.completions.create(\n        model="gpt-4o-mini",\n        messages=[{"role": "user", "content": prompt}],\n        max_tokens=2000,\n    )\n    return {"email": response.choices[0].message.content}\n'})}),"\n",(0,r.jsx)(t.p,{children:"Let's run the app and generate some traces."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'test_requests = [\n    {"customer_name": "Acme Corp", "user_instructions": "Follow up after product demo"},\n    {\n        "customer_name": "TechStart",\n        "user_instructions": "Check on support ticket status",\n    },\n    {\n        "customer_name": "Global Retail",\n        "user_instructions": "Send quarterly review summary",\n    },\n    {\n        "customer_name": "Acme Corp",\n        "user_instructions": "Write a very detailed email explaining all our product features, pricing tiers, implementation timeline, and support options",\n    },\n    {\n        "customer_name": "TechStart",\n        "user_instructions": "Send an enthusiastic thank you for their business!",\n    },\n    {"customer_name": "Global Retail", "user_instructions": "Send a follow-up email"},\n    {\n        "customer_name": "Acme Corp",\n        "user_instructions": "Just check in to see how things are going",\n    },\n]\n\n# Run requests and capture traces\nprint("Simulating production traffic...")\nfor req in test_requests:\n    try:\n        result = generate_sales_email(**req)\n        print(f"\u2713 Generated email for {req[\'customer_name\']}")\n    except Exception as e:\n        print(f"\u2717 Error for {req[\'customer_name\']}: {e}")\n'})}),"\n",(0,r.jsx)(t.p,{children:"This generates a list of traces as follows:"}),"\n",(0,r.jsx)(s.A,{src:"/images/mlflow-3/eval-monitor/trace-evaluation-list.png",alt:"Simulated traces",width:"95%"}),"\n",(0,r.jsx)(t.h3,{id:"step-1-search-and-retrieve-traces",children:"Step 1: Search and retrieve traces"}),"\n",(0,r.jsxs)(t.p,{children:["Traces stored in the MLflow backend can be retrieved using the ",(0,r.jsx)(o.B,{fn:"mlflow.search_traces"})," API.\nThe following code retrieves all traces from the last 24 hours. See ",(0,r.jsx)(t.a,{href:"/genai/tracing/search-traces/",children:"Searching for traces"})," for the full supported syntax."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'import mlflow\nfrom datetime import datetime, timedelta\n\n# Get traces from the last 24 hours\nyesterday = datetime.now() - timedelta(days=1)\ntraces = mlflow.search_traces(\n    filter_string=f"timestamp > {int(yesterday.timestamp() * 1000)}"\n)\n'})}),"\n",(0,r.jsxs)(t.p,{children:["The API returns a set of traces as a pandas DataFrame, where various data in the trace is expanded into columns. The dataframe can be directly passed into the ",(0,r.jsx)(o.B,{fn:"mlflow.genai.evaluate"})," function for evaluation."]}),"\n",(0,r.jsx)(t.h3,{id:"step-2-define-application-specific-scorers",children:"Step 2: Define application-specific scorers"}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.a,{href:"/genai/eval-monitor/scorers",children:"Scorer"})," is the core component of evaluation, which defines the criteria for evaluating the quality of the traces. MLflow provides a set of built-in scorers for common evaluation criteria, and you can also define your own custom scorers for application-specific criteria."]}),"\n",(0,r.jsx)(t.p,{children:"In this example, we use three different types of scorers:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(o.B,{fn:"mlflow.genai.scorers.RetrievalGroundedness",children:"RetrievalGroundedness"}),": Built-in scorer checks if the output is grounded in the retrieved data."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(o.B,{fn:"mlflow.genai.scorers.RelevanceToQuery",children:"RelevanceToQuery"}),": Built-in scorer checks if the output is relevant to the user's request."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(o.B,{fn:"mlflow.genai.scorers.Guidelines",children:"Guidelines"}),": Built-in scorer that allows you to judge the output against custom guidelines using LLMs."]}),"\n"]}),"\n",(0,r.jsxs)(t.p,{children:["These scorers uses LLM for judging the criteria. The default model is ",(0,r.jsx)(t.code,{children:"openai:/gpt-4.1-mini"}),". You can also specify a different model by passing the ",(0,r.jsx)(t.code,{children:"model"})," parameter to the scorer constructor."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'email_scorers = [\n    RetrievalGroundedness(),\n    RelevanceToQuery(),  # Checks if email addresses the user\'s request\n    Guidelines(\n        name="follows_objective",\n        guidelines="The generated email must follow the objective in the request.",\n    ),\n    Guidelines(\n        name="concise_communication",\n        guidelines="The email MUST be concise and to the point. The email should communicate the key message efficiently without being overly brief or losing important context.",\n    ),\n    Guidelines(\n        name="professional_tone",\n        guidelines="The email must be in a professional tone.",\n    ),\n]\n'})}),"\n",(0,r.jsx)(t.admonition,{title:"Scoring Intermediate Information in Traces",type:"tip",children:(0,r.jsxs)(t.p,{children:["Scorers have access to the complete MLflow traces, including spans, attributes, and outputs. This allows you to evaluate the agent's behavior precisely, not only the final output, such as the ",(0,r.jsx)(t.strong,{children:"tool call trajectory"}),", the ",(0,r.jsx)(t.strong,{children:"sub-agents routing"}),", the ",(0,r.jsx)(t.strong,{children:"retrieved document recall"}),", etc. See ",(0,r.jsx)("ins",{children:(0,r.jsx)(t.a,{href:"/genai/eval-monitor/scorers/custom#parsing-traces-for-scoring",children:"Parsing Traces for Scoring"})})," for more details."]})}),"\n",(0,r.jsx)(t.h3,{id:"step-3-evaluate-trace-quality",children:"Step 3: Evaluate trace quality"}),"\n",(0,r.jsxs)(t.p,{children:["Now we are ready to run the evaluation. One notable difference from other examples is that we don't need to specify a ",(0,r.jsx)(t.code,{children:"predict_fn"})," function. The ",(0,r.jsx)(o.B,{fn:"mlflow.genai.evaluate"})," function will automatically extract the inputs, outputs, and other intermediate information from the trace object and use them for scoring."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:"results = mlflow.genai.evaluate(\n    data=traces,\n    scorers=email_scorers,\n)\n"})}),"\n",(0,r.jsx)(t.p,{children:"Once the evaluation is done, open the MLflow UI in your browser and navigate to the experiment page. You should see MLflow creates a new Run and logs the evaluation results."}),"\n",(0,r.jsx)(s.A,{src:"/images/mlflow-3/eval-monitor/trace-evaluation-result.png",alt:"Evaluate traces result",width:"95%"}),"\n",(0,r.jsx)(t.p,{children:"By clicking on the each row in the result, you can open the trace and see the detailed score and rationale."}),"\n",(0,r.jsx)(t.h2,{id:"annotate-traces-with-ground-truth-and-manual-feedbacks",children:"Annotate Traces with Ground Truth and Manual Feedbacks"}),"\n",(0,r.jsx)(t.p,{children:"Some evaluation criteria require ground truths to be defined. MLflow allows you to directly annotate traces with ground truths and any other human feedbacks."}),"\n",(0,r.jsxs)(t.p,{children:["To annotate a trace with ground truth or manual feedback, open the trace in the MLflow UI and click the ",(0,r.jsx)(t.strong,{children:"Assessments"})," button to add expectations or feedback directly through the web interface."]}),"\n",(0,r.jsx)(s.A,{src:"/images/mlflow-3/eval-monitor/trace-evaluation-assessments.png",alt:"Annotate traces with ground truth",width:"80%"}),"\n",(0,r.jsxs)(t.p,{children:["Alternatively, you can also annotate traces with ground truth or manual feedbacks using the ",(0,r.jsx)(o.B,{fn:"mlflow.log_expectation"})," and the ",(0,r.jsx)(o.B,{fn:"mlflow.log_feedback"})," APIs respectively."]}),"\n",(0,r.jsx)(t.h2,{id:"recording-end-user-feedbacks-from-production",children:"Recording End-user Feedbacks from Production"}),"\n",(0,r.jsxs)(t.p,{children:["Using the ",(0,r.jsx)(o.B,{fn:"mlflow.log_feedback"})," API, you can record end-user feedbacks from your production application directly and monitor them in MLflow."]}),"\n",(0,r.jsx)(s.A,{src:"/images/mlflow-3/eval-monitor/trace-evaluation-user-feedback.png",alt:"Annotate traces with feedback",width:"95%"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'# Decorate the endpoint with MLflow tracing\n@mlflow.trace(span_type="LLM")\n@app.post("/chat", response_model=ChatResponse)\nasync def chat(request: ChatRequest):\n    """\n    Chat endpoint that answers user questions and returns response with MLflow trace ID.\n    """\n    try:\n        response = await openai.AsyncOpenAI().chat.completions.create(\n            model="gpt-4o-mini",\n            messages=[{"role": "user", "content": request.prompt}],\n        )\n\n        # Get the active trace ID for the request\n        trace_id = mlflow.get_current_active_span().trace_id\n\n        return ChatResponse(\n            response=response.choices[0].message.content,\n            trace_id=trace_id,\n            timestamp=time.time(),\n        )\n    except Exception as e:\n        raise HTTPException(\n            status_code=500, detail=f"Error processing chat request: {str(e)}"\n        )\n\n\n@app.post("/feedback", response_model=FeedbackResponse)\nasync def feedback(request: FeedbackRequest):\n    """\n    Feedback endpoint that annotates MLflow traces with user feedback.\n    """\n    try:\n        # Record the given user feedback to the Trace\n        mlflow.log_feedback(\n            trace_id=request.trace_id,\n            name="user_satisfaction",\n            value=request.thumbs_up,\n            source=AssessmentSource(\n                source_type=AssessmentSourceType.HUMAN, source_id=request.user_id\n            ),\n            rationale=request.rationale,\n        )\n        return FeedbackResponse(\n            message="Feedback recorded successfully", trace_id=request.trace_id\n        )\n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(\n            status_code=500, detail=f"Error processing feedback: {str(e)}"\n        )\n'})}),"\n",(0,r.jsx)(t.h2,{id:"next-steps",children:"Next steps"}),"\n",(0,r.jsxs)(c.A,{children:[(0,r.jsx)(p.A,{icon:f.A,iconSize:48,title:"Custom Scorers",description:"Build advanced evaluation criteria and metrics tailored to your specific trace analysis needs.",href:"/genai/eval-monitor/scorers",linkText:"Create custom scorers \u2192",containerHeight:64}),(0,r.jsx)(p.A,{icon:w.A,iconSize:48,title:"Production Monitoring",description:"Optimize trace collection in production environments for efficient monitoring and analysis.",href:"/genai/tracing/prod-tracing",linkText:"Set up monitoring \u2192",containerHeight:64}),(0,r.jsx)(p.A,{icon:g.A,iconSize:48,title:"Tracing Integrations",description:"Use MLflow Tracing with other LLM providers and frameworks, such as LangGraph, Pydantic AI.",href:"/genai/tracing/integrations",linkText:"Explore integrations \u2192",containerHeight:64})]})]})}function k(e={}){let{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(b,{...e})}):b(e)}},74990(e,t,n){n.d(t,{Ay:()=>p,RM:()=>l});var a=n(74848),r=n(28453),i=n(78010),o=n(57250),s=n(95986);let l=[];function c(e){let t={a:"a",code:"code",p:"p",pre:"pre",strong:"strong",...(0,r.R)(),...e.components};return(0,a.jsx)(s.A,{children:(0,a.jsxs)(i.A,{children:[(0,a.jsxs)(o.A,{value:"uv",label:"Local (uv)",default:!0,children:[(0,a.jsxs)(t.p,{children:["Install the Python package manager ",(0,a.jsx)(t.a,{href:"https://docs.astral.sh/uv/getting-started/installation/",children:"uv"}),"\n(that will also install ",(0,a.jsxs)(t.a,{href:"https://docs.astral.sh/uv/guides/tools/",children:[(0,a.jsx)(t.code,{children:"uvx"})," command"]})," to invoke Python tools without installing them)."]}),(0,a.jsx)(t.p,{children:"Start a MLflow server locally."}),(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-shell",children:"uvx mlflow server\n"})})]}),(0,a.jsxs)(o.A,{value:"local",label:"Local (pip)",children:[(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"Python Environment"}),": Python 3.10+"]}),(0,a.jsxs)(t.p,{children:["Install the ",(0,a.jsx)(t.code,{children:"mlflow"})," Python package via ",(0,a.jsx)(t.code,{children:"pip"})," and start a MLflow server locally."]}),(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-shell",children:"pip install --upgrade 'mlflow[genai]'\nmlflow server\n"})})]}),(0,a.jsxs)(o.A,{value:"docker",label:"Local (docker)",children:[(0,a.jsx)(t.p,{children:"MLflow provides a Docker Compose file to start a local MLflow server with a PostgreSQL database and a MinIO server."}),(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-shell",children:"git clone --depth 1 --filter=blob:none --sparse https://github.com/mlflow/mlflow.git\ncd mlflow\ngit sparse-checkout set docker-compose\ncd docker-compose\ncp .env.dev.example .env\ndocker compose up -d\n"})}),(0,a.jsxs)(t.p,{children:["Refer to the ",(0,a.jsx)(t.a,{href:"https://github.com/mlflow/mlflow/tree/master/docker-compose/README.md",children:"instruction"})," for more details (e.g., overriding the default environment variables)."]})]})]})})}function p(e={}){let{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},54725(e,t,n){n.d(t,{B:()=>o});var a=n(74848);n(96540);var r=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}'),i=n(66497);function o({fn:e,children:t,hash:n}){let o=(e=>{let t=e.split(".");for(let e=t.length;e>0;e--){let n=t.slice(0,e).join(".");if(r[n])return n}return null})(e);if(!o)return(0,a.jsx)(a.Fragment,{children:t});let s=(0,i.default)(`/${r[o]}#${n??e}`);return(0,a.jsx)("a",{href:s,target:"_blank",children:t??(0,a.jsxs)("code",{children:[e,"()"]})})}},46077(e,t,n){n.d(t,{A:()=>i});var a=n(74848);n(96540);var r=n(66497);function i({src:e,alt:t,width:n,caption:i,className:o}){return(0,a.jsxs)("div",{className:`container_JwLF ${o||""}`,children:[(0,a.jsx)("div",{className:"imageWrapper_RfGN",style:n?{width:n}:{},children:(0,a.jsx)("img",{src:(0,r.default)(e),alt:t,className:"image_bwOA"})}),i&&(0,a.jsx)("p",{className:"caption_jo2G",children:i})]})}},95986(e,t,n){n.d(t,{A:()=>r});var a=n(74848);n(96540);function r({children:e}){return(0,a.jsx)("div",{className:"wrapper_sf5q",children:e})}},77541(e,t,n){n.d(t,{A:()=>c});var a=n(74848);n(96540);var r=n(95310),i=n(34164);let o="tileImage_O4So";var s=n(66497),l=n(92802);function c({icon:e,image:t,imageDark:n,imageWidth:c,imageHeight:p,iconSize:m=32,containerHeight:d,title:h,description:u,href:f,linkText:w="Learn more \u2192",className:g}){if(!e&&!t)throw Error("TileCard requires either an icon or image prop");let _=d?{height:`${d}px`}:{},v={};return c&&(v.width=`${c}px`),p&&(v.height=`${p}px`),(0,a.jsxs)(r.A,{href:f,className:(0,i.A)("tileCard_NHsj",g),children:[(0,a.jsx)("div",{className:"tileIcon_pyoR",style:_,children:e?(0,a.jsx)(e,{size:m}):n?(0,a.jsx)(l.A,{sources:{light:(0,s.default)(t),dark:(0,s.default)(n)},alt:h,className:o,style:v}):(0,a.jsx)("img",{src:(0,s.default)(t),alt:h,className:o,style:v})}),(0,a.jsx)("h3",{children:h}),(0,a.jsx)("p",{children:u}),(0,a.jsx)("div",{className:"tileLink_iUbu",children:w})]})}},10440(e,t,n){n.d(t,{A:()=>i});var a=n(74848);n(96540);var r=n(34164);function i({children:e,className:t}){return(0,a.jsx)("div",{className:(0,r.A)("tilesGrid_hB9N",t),children:e})}},81956(e,t,n){n.d(t,{A:()=>i});var a=n(74848);n(96540);var r=n(46077);let i=({steps:e,title:t,screenshot:n,width:i="normal"})=>(0,a.jsxs)("div",{className:"workflowContainer__N1v",children:[t&&(0,a.jsx)("h3",{className:"workflowTitle_QrAr",children:t}),n&&(0,a.jsx)("div",{className:"screenshotContainer_OwzZ",children:(0,a.jsx)(r.A,{src:n.src,alt:n.alt,width:n.width||"90%"})}),(0,a.jsx)("div",{className:"stepsContainer_IGeu",style:{maxWidth:"wide"===i?"850px":"700px"},children:e.map((t,n)=>(0,a.jsxs)("div",{className:"stepItem_GyHJ",children:[(0,a.jsxs)("div",{className:"stepIndicator_U2Wb",children:[(0,a.jsx)("div",{className:"stepNumber_vINc",children:t.icon?(0,a.jsx)(t.icon,{size:16}):(0,a.jsx)("span",{className:"stepNumberText_eLd7",children:n+1})}),n<e.length-1&&(0,a.jsx)("div",{className:"stepConnector_Si86"})]}),(0,a.jsxs)("div",{className:"stepContent_D0CA",children:[(0,a.jsx)("h4",{className:"stepTitle_wujx",children:t.title}),(0,a.jsx)("p",{className:"stepDescription_PIaE",children:t.description})]})]},n))})]})}}]);