"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([["202"],{33721(e,t,a){a.r(t),a.d(t,{metadata:()=>l,default:()=>A,frontMatter:()=>_,contentTitle:()=>g,toc:()=>b,assets:()=>k});var l=JSON.parse('{"id":"concepts/feedback","title":"Feedback Concepts","description":"What is Feedback?","source":"@site/docs/genai/concepts/feedback.mdx","sourceDirName":"concepts","slug":"/concepts/feedback","permalink":"/mlflow-website/docs/latest/genai/concepts/feedback","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"genAISidebar","previous":{"title":"Span","permalink":"/mlflow-website/docs/latest/genai/concepts/span"},"next":{"title":"Expectations","permalink":"/mlflow-website/docs/latest/genai/concepts/expectations"}}'),r=a(74848),n=a(28453),i=a(54725),s=a(46077),o=a(33508),c=a(10440),d=a(77541),h=a(75689);let p=(0,h.A)("clipboard-check",[["rect",{width:"8",height:"4",x:"8",y:"2",rx:"1",ry:"1",key:"tgr4d6"}],["path",{d:"M16 4h2a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V6a2 2 0 0 1 2-2h2",key:"116196"}],["path",{d:"m9 14 2 2 4-4",key:"df797q"}]]),m=(0,h.A)("user-check",[["path",{d:"m16 11 2 2 4-4",key:"9rsbq5"}],["path",{d:"M16 21v-2a4 4 0 0 0-4-4H6a4 4 0 0 0-4 4v2",key:"1yyitq"}],["circle",{cx:"9",cy:"7",r:"4",key:"nufk8"}]]);var f=a(42640);let u=(0,h.A)("users-round",[["path",{d:"M18 21a8 8 0 0 0-16 0",key:"3ypg7q"}],["circle",{cx:"10",cy:"8",r:"5",key:"o932ke"}],["path",{d:"M22 20c0-3.37-2-6.5-4-8a5 5 0 0 0-.45-8.3",key:"10s06x"}]]);var x=a(80827),y=a(47504),w=a(47792);let j=a.p+"assets/images/feedback_architecture-4294fe94ea1d82f20b5b16edddeab840.png",_={},g="Feedback Concepts",k={},b=[{value:"What is Feedback?",id:"what-is-feedback",level:2},{value:"Use Cases",id:"use-cases",level:2},{value:"Core Structure",id:"core-structure",level:2},{value:"Feedback Object Schema",id:"feedback-object-schema",level:2},{value:"Feedback Examples",id:"feedback-examples",level:2},{value:"Next Steps",id:"next-steps",level:2}];function v(e){let t={code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,n.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"feedback-concepts",children:"Feedback Concepts"})}),"\n",(0,r.jsx)(t.h2,{id:"what-is-feedback",children:"What is Feedback?"}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.strong,{children:"Feedback"})," in MLflow represents the result of any quality assessment performed on your GenAI application outputs. It provides a standardized way to capture evaluations, whether they come from automated systems, LLM judges, or human reviewers."]}),"\n",(0,r.jsx)(t.p,{children:"Feedback serves as the bridge between running your application and understanding its quality, enabling you to systematically track performance across different dimensions like correctness, relevance, safety, and adherence to guidelines."}),"\n",(0,r.jsx)(s.A,{src:"/images/llms/tracing/genai-human-feedback.png",alt:"Feedbacks attached to traces",width:"70%",caption:"Feedbacks attached to traces"}),"\n",(0,r.jsx)(t.h2,{id:"use-cases",children:"Use Cases"}),"\n",(0,r.jsx)(o.A,{features:[{icon:p,title:"Manual Quality Checks",description:"Manual quality checks are important for ensuring the quality of your GenAI application. For example, you can attach a feedback to indicate the hallucination in the response and compare quality between different models."},{icon:m,title:"End-User Feedbacks",description:"Feedbacks from end-users are precious for improving the quality of your GenAI application. By storing feedbacks on your traces, you can easily monitor the user satisfaction of your application over time."},{icon:f.A,title:"LLM Judge Evaluation",description:"LLM judges are powerful tools for systematically running quality checks at scale. When using MLflow's GenAI Evaluation, Feedbacks from LLM judges are attached to the traces, enabling you to track evaluation results in the unified way as manual quality checks."},{icon:u,title:"Collaborative Annotation",description:"Quality checks are often performed by multiple annotators to ensure the robustness of the output. MLflow tracks metadata and revision history of the feedbacks and supports aggregation of feedbacks from multiple annotators."}]}),"\n",(0,r.jsx)(t.h2,{id:"core-structure",children:"Core Structure"}),"\n",(0,r.jsx)("div",{style:{display:"flex",justifyContent:"center"},children:(0,r.jsx)("img",{src:j,alt:"Feedback Architecture",style:{width:"60%"}})}),"\n",(0,r.jsxs)(t.p,{children:["Feedback is often created by different sources, such as human annotators, LLM judges, or real user's feedback in the application. The ",(0,r.jsx)(i.B,{fn:"mlflow.entities.Feedback",children:(0,r.jsx)(t.code,{children:"Feedback"})})," object in MLflow is a standard container for storing these signals along with metadata to track\nhow they are created. Feedbacks are associated with a Trace, or a particular Span in the Trace."]}),"\n",(0,r.jsx)(t.h2,{id:"feedback-object-schema",children:"Feedback Object Schema"}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Field"}),(0,r.jsx)(t.th,{children:"Type"}),(0,r.jsx)(t.th,{children:"Description"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"name"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"str"})}),(0,r.jsx)(t.td,{children:"A string identifying the specific quality aspect being assessed"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"value"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"Any"})}),(0,r.jsxs)(t.td,{children:["The actual feedback value, which can be ",(0,r.jsx)("br",{}),(0,r.jsx)("br",{})," ",(0,r.jsxs)("ul",{children:[(0,r.jsxs)("li",{children:["Numeric scores (e.g., ",(0,r.jsx)(t.code,{children:"0.0"})," to ",(0,r.jsx)(t.code,{children:"1.0"}),", ",(0,r.jsx)(t.code,{children:"1"})," to ",(0,r.jsx)(t.code,{children:"5"}),")"]}),(0,r.jsxs)("li",{children:["Boolean values (",(0,r.jsx)(t.code,{children:"True"}),"/",(0,r.jsx)(t.code,{children:"False"}),")"]}),(0,r.jsxs)("li",{children:["Categorical labels (e.g., ",(0,r.jsx)(t.code,{children:'"PASS"'}),", ",(0,r.jsx)(t.code,{children:'"FAIL"'}),", ",(0,r.jsx)(t.code,{children:'"EXCELLENT"'}),")"]}),(0,r.jsxs)("li",{children:["Structured data (e.g., ",(0,r.jsx)(t.code,{children:'{"score": 0.8, "confidence": 0.9}'}),")"]})]})]})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"rationale"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"str"})}),(0,r.jsx)(t.td,{children:"A string explaining why the feedback is given to the trace."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"source"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"AssessmentSource"})}),(0,r.jsxs)(t.td,{children:["The source of the feedback, composed of the type of the source and ID. ",(0,r.jsx)("br",{}),(0,r.jsx)("br",{})," ",(0,r.jsxs)("ul",{children:[(0,r.jsxs)("li",{children:[(0,r.jsx)(t.code,{children:"HUMAN"}),": Represents a human review. ID can be the identifier for the annotator, such as name, account, email, etc."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)(t.code,{children:"LLM_JUDGE"}),': Represents an LLM-based evaluation. ID may be the name of the judge model e.g., "openai:/4o-mini".']}),(0,r.jsxs)("li",{children:[(0,r.jsx)(t.code,{children:"CODE"}),": Represents any other programmatic check."]})]})]})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"error"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"Optional[AssessmentError]"})}),(0,r.jsx)(t.td,{children:"An optional error associated with the feedback. This is used to indicate that the feedback was not processed successfully, for example, an exception from the LLM judge execution."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"metadata"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"Optional[dict[str, str]]"})}),(0,r.jsx)(t.td,{children:"Optional key-value pairs associated with the feedback."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"create_time_ms"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"int"})}),(0,r.jsx)(t.td,{children:"The timestamp of when the feedback is created, in milliseconds."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"last_update_time_ms"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"int"})}),(0,r.jsx)(t.td,{children:"The timestamp of when the feedback is updated, in milliseconds."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"trace_id"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"str"})}),(0,r.jsx)(t.td,{children:"The ID of the trace that the feedback is attached to."})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"span_id"})}),(0,r.jsx)(t.td,{children:(0,r.jsx)(t.code,{children:"Optional[str]"})}),(0,r.jsx)(t.td,{children:"The ID of the span that the feedback is attached to, if it is associated with a particular span in the trace. For example, you can give a feedback to the specific retriever output in the RAG application."})]})]})]}),"\n",(0,r.jsx)(t.h2,{id:"feedback-examples",children:"Feedback Examples"}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"Human Feedback for Hallucination in the Response"})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-json",children:'{\n    "name": "hallucination",\n    "value": false,\n    "rationale": "The response is factual and does not contain any hallucinations.",\n    "source": {\n        "source_type": "HUMAN",\n        "source_id": "john@example.com"\n    }\n}\n'})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"LLM Judge Feedback for Factual Accuracy"})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-json",children:'{\n    "name": "factual_accuracy",\n    "value": 0.85,\n    "rationale": "The response correctly identifies 3 out of 4 key facts about MLflow, but incorrectly states the founding year.",\n    "source": {\n        "source_type": "LLM_JUDGE",\n        "source_id": "openai:/4o-mini"\n    },\n    "metadata": {\n        # Store link to the prompt used for the judge, registered in MLflow Prompt Registry\n        "judge_prompt": "prompts:factual_accuracy_judge/1"\n    }\n}\n'})}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.strong,{children:"Error Feedback from LLM Judge (Rate Limit Exceeded)"})}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-json",children:'{\n    "name": "safety",\n    "error": {\n        "error_code": "RATE_LIMIT_EXCEEDED",\n        "error_message": "Rate limit for the judge exceeded.",\n        "stack_trace": "..."\n    },\n    "source": {\n        "source_type": "LLM_JUDGE",\n        "source_id": "openai:/4o-mini"\n    }\n}\n'})}),"\n",(0,r.jsx)(t.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsxs)(c.A,{children:[(0,r.jsx)(d.A,{icon:x.A,iconSize:48,title:"Feedback Guide",description:"Complete guide for using mlflow.log_feedback with practical examples and code samples",href:"/genai/assessments/feedback",linkText:"View the feedback guide \u2192",containerHeight:64}),(0,r.jsx)(d.A,{icon:y.A,iconSize:48,title:"Expectations Concepts",description:"Learn how to define ground truth expectations for comprehensive evaluation",href:"/genai/concepts/expectations",linkText:"Learn about expectations \u2192",containerHeight:64}),(0,r.jsx)(d.A,{icon:w.A,iconSize:48,title:"Ground Truth Expectations",description:"Understand how to define expected outputs for comprehensive evaluation",href:"/genai/assessments/expectations",linkText:"Learn about expectations \u2192",containerHeight:64})]})]})}function A(e={}){let{wrapper:t}={...(0,n.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(v,{...e})}):v(e)}},75689(e,t,a){a.d(t,{A:()=>o});var l=a(96540);let r=e=>{let t=e.replace(/^([A-Z])|[\s-_]+(\w)/g,(e,t,a)=>a?a.toUpperCase():t.toLowerCase());return t.charAt(0).toUpperCase()+t.slice(1)},n=(...e)=>e.filter((e,t,a)=>!!e&&""!==e.trim()&&a.indexOf(e)===t).join(" ").trim();var i={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};let s=(0,l.forwardRef)(({color:e="currentColor",size:t=24,strokeWidth:a=2,absoluteStrokeWidth:r,className:s="",children:o,iconNode:c,...d},h)=>(0,l.createElement)("svg",{ref:h,...i,width:t,height:t,stroke:e,strokeWidth:r?24*Number(a)/Number(t):a,className:n("lucide",s),...!o&&!(e=>{for(let t in e)if(t.startsWith("aria-")||"role"===t||"title"===t)return!0})(d)&&{"aria-hidden":"true"},...d},[...c.map(([e,t])=>(0,l.createElement)(e,t)),...Array.isArray(o)?o:[o]])),o=(e,t)=>{let a=(0,l.forwardRef)(({className:a,...i},o)=>(0,l.createElement)(s,{ref:o,iconNode:t,className:n(`lucide-${r(e).replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase()}`,`lucide-${e}`,a),...i}));return a.displayName=r(e),a}},42640(e,t,a){a.d(t,{A:()=>l});let l=(0,a(75689).A)("bot",[["path",{d:"M12 8V4H8",key:"hb8ula"}],["rect",{width:"16",height:"12",x:"4",y:"8",rx:"2",key:"enze0r"}],["path",{d:"M2 14h2",key:"vft8re"}],["path",{d:"M20 14h2",key:"4cs60a"}],["path",{d:"M15 13v2",key:"1xurst"}],["path",{d:"M9 13v2",key:"rq6x2g"}]])},80827(e,t,a){a.d(t,{A:()=>l});let l=(0,a(75689).A)("file-text",[["path",{d:"M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z",key:"1rqfz7"}],["path",{d:"M14 2v4a2 2 0 0 0 2 2h4",key:"tnqrlb"}],["path",{d:"M10 9H8",key:"b1mrlr"}],["path",{d:"M16 13H8",key:"t4e002"}],["path",{d:"M16 17H8",key:"z1uh3a"}]])},47504(e,t,a){a.d(t,{A:()=>l});let l=(0,a(75689).A)("message-square",[["path",{d:"M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z",key:"1lielz"}]])},47792(e,t,a){a.d(t,{A:()=>l});let l=(0,a(75689).A)("target",[["circle",{cx:"12",cy:"12",r:"10",key:"1mglay"}],["circle",{cx:"12",cy:"12",r:"6",key:"1vlfrh"}],["circle",{cx:"12",cy:"12",r:"2",key:"1c9p78"}]])},54725(e,t,a){a.d(t,{B:()=>i});var l=a(74848);a(96540);var r=JSON.parse('{"mlflow.ag2":"api_reference/python_api/mlflow.ag2.html","mlflow.agno":"api_reference/python_api/mlflow.agno.html","mlflow.anthropic":"api_reference/python_api/mlflow.anthropic.html","mlflow.artifacts":"api_reference/python_api/mlflow.artifacts.html","mlflow.autogen":"api_reference/python_api/mlflow.autogen.html","mlflow.bedrock":"api_reference/python_api/mlflow.bedrock.html","mlflow.catboost":"api_reference/python_api/mlflow.catboost.html","mlflow.client":"api_reference/python_api/mlflow.client.html","mlflow.config":"api_reference/python_api/mlflow.config.html","mlflow.crewai":"api_reference/python_api/mlflow.crewai.html","mlflow.data":"api_reference/python_api/mlflow.data.html","mlflow.deployments":"api_reference/python_api/mlflow.deployments.html","mlflow.diviner":"api_reference/python_api/mlflow.diviner.html","mlflow.dspy":"api_reference/python_api/mlflow.dspy.html","mlflow.entities":"api_reference/python_api/mlflow.entities.html","mlflow.environment_variables":"api_reference/python_api/mlflow.environment_variables.html","mlflow.gateway":"api_reference/python_api/mlflow.gateway.html","mlflow.gemini":"api_reference/python_api/mlflow.gemini.html","mlflow.genai":"api_reference/python_api/mlflow.genai.html","mlflow.groq":"api_reference/python_api/mlflow.groq.html","mlflow.h2o":"api_reference/python_api/mlflow.h2o.html","mlflow.johnsnowlabs":"api_reference/python_api/mlflow.johnsnowlabs.html","mlflow.keras":"api_reference/python_api/mlflow.keras.html","mlflow.langchain":"api_reference/python_api/mlflow.langchain.html","mlflow.lightgbm":"api_reference/python_api/mlflow.lightgbm.html","mlflow.litellm":"api_reference/python_api/mlflow.litellm.html","mlflow.llama_index":"api_reference/python_api/mlflow.llama_index.html","mlflow.metrics":"api_reference/python_api/mlflow.metrics.html","mlflow.mistral":"api_reference/python_api/mlflow.mistral.html","mlflow.models":"api_reference/python_api/mlflow.models.html","mlflow.onnx":"api_reference/python_api/mlflow.onnx.html","mlflow.openai":"api_reference/python_api/mlflow.openai.html","mlflow.paddle":"api_reference/python_api/mlflow.paddle.html","mlflow.pmdarima":"api_reference/python_api/mlflow.pmdarima.html","mlflow.projects":"api_reference/python_api/mlflow.projects.html","mlflow.prophet":"api_reference/python_api/mlflow.prophet.html","mlflow.pydantic_ai":"api_reference/python_api/mlflow.pydantic_ai.html","mlflow.pyfunc":"api_reference/python_api/mlflow.pyfunc.html","mlflow.pyspark.ml":"api_reference/python_api/mlflow.pyspark.ml.html","mlflow.pytorch":"api_reference/python_api/mlflow.pytorch.html","mlflow":"api_reference/python_api/mlflow.html","mlflow.sagemaker":"api_reference/python_api/mlflow.sagemaker.html","mlflow.sentence_transformers":"api_reference/python_api/mlflow.sentence_transformers.html","mlflow.server":"api_reference/python_api/mlflow.server.html","mlflow.shap":"api_reference/python_api/mlflow.shap.html","mlflow.sklearn":"api_reference/python_api/mlflow.sklearn.html","mlflow.smolagents":"api_reference/python_api/mlflow.smolagents.html","mlflow.spacy":"api_reference/python_api/mlflow.spacy.html","mlflow.spark":"api_reference/python_api/mlflow.spark.html","mlflow.statsmodels":"api_reference/python_api/mlflow.statsmodels.html","mlflow.system_metrics":"api_reference/python_api/mlflow.system_metrics.html","mlflow.tensorflow":"api_reference/python_api/mlflow.tensorflow.html","mlflow.tracing":"api_reference/python_api/mlflow.tracing.html","mlflow.transformers":"api_reference/python_api/mlflow.transformers.html","mlflow.types":"api_reference/python_api/mlflow.types.html","mlflow.utils":"api_reference/python_api/mlflow.utils.html","mlflow.webhooks":"api_reference/python_api/mlflow.webhooks.html","mlflow.xgboost":"api_reference/python_api/mlflow.xgboost.html","mlflow.server.auth":"api_reference/auth/python-api.html","mlflow.server.cli":"api_reference/cli.html","mlflow.r":"api_reference/R-api.html","mlflow.java":"api_reference/java_api/index.html","mlflow.python":"api_reference/python_api/index.html","mlflow.rest":"api_reference/rest-api.html","mlflow.typescript":"api_reference/typescript_api/index.html","mlflow.llms.deployments.api":"api_reference/llms/deployments/api.html"}'),n=a(66497);function i({fn:e,children:t,hash:a}){let i=(e=>{let t=e.split(".");for(let e=t.length;e>0;e--){let a=t.slice(0,e).join(".");if(r[a])return a}return null})(e);if(!i)return(0,l.jsx)(l.Fragment,{children:t});let s=(0,n.default)(`/${r[i]}#${a??e}`);return(0,l.jsx)("a",{href:s,target:"_blank",children:t??(0,l.jsxs)("code",{children:[e,"()"]})})}},33508(e,t,a){a.d(t,{A:()=>r});var l=a(74848);a(96540);function r({features:e,col:t=2}){return(0,l.jsx)("div",{className:"featureHighlights_Ardf",style:{gridTemplateColumns:`repeat(${t}, 1fr)`},children:e.map((e,t)=>(0,l.jsxs)("div",{className:"highlightItem_XPnN",children:[e.icon&&(0,l.jsx)("div",{className:"highlightIcon_SUR8",children:(0,l.jsx)(e.icon,{size:24})}),(0,l.jsxs)("div",{className:"highlightContent_d0XP",children:[(0,l.jsx)("h4",{children:e.title}),(0,l.jsx)("p",{children:e.description})]})]},t))})}},46077(e,t,a){a.d(t,{A:()=>n});var l=a(74848);a(96540);var r=a(66497);function n({src:e,alt:t,width:a,caption:n,className:i}){return(0,l.jsxs)("div",{className:`container_JwLF ${i||""}`,children:[(0,l.jsx)("div",{className:"imageWrapper_RfGN",style:a?{width:a}:{},children:(0,l.jsx)("img",{src:(0,r.default)(e),alt:t,className:"image_bwOA"})}),n&&(0,l.jsx)("p",{className:"caption_jo2G",children:n})]})}},77541(e,t,a){a.d(t,{A:()=>c});var l=a(74848);a(96540);var r=a(95310),n=a(34164);let i="tileImage_O4So";var s=a(66497),o=a(92802);function c({icon:e,image:t,imageDark:a,imageWidth:c,imageHeight:d,iconSize:h=32,containerHeight:p,title:m,description:f,href:u,linkText:x="Learn more \u2192",className:y}){if(!e&&!t)throw Error("TileCard requires either an icon or image prop");let w=p?{height:`${p}px`}:{},j={};return c&&(j.width=`${c}px`),d&&(j.height=`${d}px`),(0,l.jsxs)(r.A,{href:u,className:(0,n.A)("tileCard_NHsj",y),children:[(0,l.jsx)("div",{className:"tileIcon_pyoR",style:w,children:e?(0,l.jsx)(e,{size:h}):a?(0,l.jsx)(o.A,{sources:{light:(0,s.default)(t),dark:(0,s.default)(a)},alt:m,className:i,style:j}):(0,l.jsx)("img",{src:(0,s.default)(t),alt:m,className:i,style:j})}),(0,l.jsx)("h3",{children:m}),(0,l.jsx)("p",{children:f}),(0,l.jsx)("div",{className:"tileLink_iUbu",children:x})]})}},10440(e,t,a){a.d(t,{A:()=>n});var l=a(74848);a(96540);var r=a(34164);function n({children:e,className:t}){return(0,l.jsx)("div",{className:(0,r.A)("tilesGrid_hB9N",t),children:e})}},28453(e,t,a){a.d(t,{R:()=>i,x:()=>s});var l=a(96540);let r={},n=l.createContext(r);function i(e){let t=l.useContext(n);return l.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),l.createElement(n.Provider,{value:t},e.children)}}}]);