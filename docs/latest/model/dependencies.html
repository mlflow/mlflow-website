
  

<!DOCTYPE html>
<!-- source: docs/source/model/dependencies.rst -->
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Managing Dependencies in MLflow Models &mdash; MLflow 2.14.2.dev0 documentation</title>
  
   
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <link rel="canonical" href="https://mlflow.org/docs/latest/model/dependencies.html">
  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    

    

  
    
        <!-- Google Tag Manager -->
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer',"GTM-N6WMTTJ");</script>
        <!-- End Google Tag Manager -->
    

  

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/cards.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/grids.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/mobile.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/simple-cards.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/tabs.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="MLflow 2.14.2.dev0 documentation" href="../index.html"/>
        <link rel="up" title="MLflow Models" href="../models.html"/>
        <link rel="next" title="MLflow Model Signatures and Input Examples Guide" href="/signatures.html"/>
        <link rel="prev" title="MLflow Models" href="/../models.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>
<script type="text/javascript" src="../_static/jquery.js"></script>
<script type="text/javascript" src="../_static/underscore.js"></script>
<script type="text/javascript" src="../_static/doctools.js"></script>
<script type="text/javascript" src="../_static/tabs.js"></script>
<script type="text/javascript" src="../_static/languagesections.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>

<body class="wy-body-for-nav" role="document">
  
    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->
  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <ul>
  <li class="menu-toggle">
    <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
    <a href="../index.html" class="wy-nav-top-logo"
      ><img src="../_static/MLflow-logo-final-black.png" alt="MLflow"
    /></a>
    <span class="version">2.14.2.dev0</span>
  </li>
</ul>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side relative">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
  </form>
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../index.html" class="main-navigation-home"><img src="../_static/icons/nav-home.svg"> MLflow</a>
    

    
      

      
        <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../introduction/index.html">What is MLflow?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting-started/index.html">Getting Started with MLflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../new-features/index.html">New Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../llms/index.html">LLMs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model-evaluation/index.html">Model Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deep-learning/index.html">Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../traditional-ml/index.html">Traditional ML</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deployment/index.html">Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tracking.html">MLflow Tracking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../system-metrics/index.html">System Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../projects.html">MLflow Projects</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../models.html">MLflow Models</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../models.html#storage-format">Storage Format</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../models.html#mlmodel-file">MLmodel file</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../models.html#additional-logged-files">Additional Logged Files</a><ul class="current">
<li class="toctree-l4 current"><a class="current reference internal" href="#">Managing Dependencies in MLflow Models</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../models.html#managing-model-dependencies">Managing Model Dependencies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models.html#model-signatures-and-input-examples">Model Signatures And Input Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models.html#model-api">Model API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models.html#built-in-model-flavors">Built-In Model Flavors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models.html#model-evaluation">Model Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models.html#model-customization">Model Customization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models.html#built-in-deployment-tools">Built-In Deployment Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models.html#export-a-python-function-model-as-an-apache-spark-udf">Export a <code class="docutils literal notranslate"><span class="pre">python_function</span></code> model as an Apache Spark UDF</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models.html#deployment-to-custom-targets">Deployment to Custom Targets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../models.html#id11">Community Model Flavors</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../model-registry.html">MLflow Model Registry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes.html">MLflow Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../plugins.html">MLflow Plugins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auth/index.html">MLflow Authentication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../search-runs.html">Search Runs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../search-experiments.html">Search Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../R-api.html">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../java_api/index.html">Java API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rest-api.html">REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../docker.html">Official MLflow Docker Image</a></li>
<li class="toctree-l1"><a class="reference internal" href="../community-model-flavors.html">Community Model Flavors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials-and-examples/index.html">Tutorials and Examples</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            










<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="../models.html">MLflow Models</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Managing Dependencies in MLflow Models</li>
    
    
    <!-- <li class="wy-breadcrumbs-aside">
      <a href="https://github.com/mlflow/mlflow/blob/master/docs/source/model/dependencies.rst" class="fa fa-github"> Edit on GitHub</a>
    </li> -->
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  <div class="section" id="managing-dependencies-in-mlflow-models">
<h1>Managing Dependencies in MLflow Models<a class="headerlink" href="#managing-dependencies-in-mlflow-models" title="Permalink to this headline"> </a></h1>
<p><a class="reference external" href="../models.html">MLflow Model</a> is a standard format that packages a machine learning model with its dependencies and other metadata.
Building a model with its dependencies allows for reproducibility and portability across a variety of platforms and tools.</p>
<p>When you create an MLflow model using the <a class="reference external" href="../tracking.html">MLflow Tracking APIs</a>, for instance, <a class="reference internal" href="../python_api/mlflow.pytorch.html#mlflow.pytorch.log_model" title="mlflow.pytorch.log_model"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.pytorch.log_model()</span></code></a>,
MLflow automatically infers the required dependencies for the model flavor you’re using and records them as a part of Model metadata. Then, when you
serve the model for prediction, MLflow automatically installs the dependencies to the environment. Therefore, you normally won’t need to
worry about managing dependencies in MLflow Model.</p>
<p>However, in some cases, you may need to add or modify some dependencies. This page provides a high-level description of how MLflow manages
dependencies and guidance for how to customize dependencies for your use case.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>One tip for improving MLflow’s dependency inference accuracy is to add an <code class="docutils literal notranslate"><span class="pre">input_example</span></code> when saving your model. This enables MLflow to
perform a model prediction before saving the model, thereby capturing the dependencies used during the prediction.
Please refer to <a class="reference internal" href="signatures.html#input-example"><span class="std std-ref">Model Input Example</span></a> for additional, detailed usage of this parameter.</p>
</div>
<div class="contents local topic" id="table-of-contents">
<p class="topic-title">Table of Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#how-mlflow-records-model-dependencies" id="id7">How MLflow Records Model Dependencies</a></p></li>
<li><p><a class="reference internal" href="#adding-extra-dependencies-to-an-mlflow-model" id="id8">Adding Extra Dependencies to an MLflow Model</a></p></li>
<li><p><a class="reference internal" href="#defining-all-dependencies-by-yourself" id="id9">Defining All Dependencies by Yourself</a></p></li>
<li><p><a class="reference internal" href="#saving-extra-code-dependencies-with-an-mlflow-model-automatic-inference" id="id10">Saving Extra Code dependencies with an MLflow Model - Automatic inference</a></p></li>
<li><p><a class="reference internal" href="#saving-extra-code-with-an-mlflow-model-manual-declaration" id="id11">Saving Extra Code with an MLflow Model - Manual Declaration</a></p></li>
<li><p><a class="reference internal" href="#validating-environment-for-prediction" id="id12">Validating Environment for Prediction</a></p></li>
<li><p><a class="reference internal" href="#troubleshooting" id="id13">Troubleshooting</a></p></li>
</ul>
</div>
<div class="section" id="how-mlflow-records-model-dependencies">
<span id="how-mlflow-records-dependencies"></span><h2><a class="toc-backref" href="#id7">How MLflow Records Model Dependencies</a><a class="headerlink" href="#how-mlflow-records-model-dependencies" title="Permalink to this headline"> </a></h2>
<p>An MLflow Model is saved within a specified directory with the following structure:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>my_model/
├── MLmodel
├── model.pkl
├── conda.yaml
├── python_env.yaml
└── requirements.txt
</pre></div>
</div>
<p>Model dependencies are defined by the following files (For other files, please refer to the guidance provided in the section discussing <a class="reference internal" href="../models.html#model-storage-format"><span class="std std-ref">Storage Format</span></a>):</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">python_env.yaml</span></code> - This file contains the information required to restore the model environment using virtualenv (1) python version (2) build tools like pip, setuptools, and wheel (3) pip requirements of the model (a reference to requirements.txt)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">requirements.txt</span></code> - Defines the set of pip dependencies required to run the model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">conda.yaml</span></code> - Defines the conda environment required to run the model. This is used when you specify <code class="docutils literal notranslate"><span class="pre">conda</span></code> as the environment manager for restoring the model environment.</p></li>
</ul>
<p>Please note that <strong>it is not recommended to edit these files manually</strong> to add or remove dependencies.
They are automatically generated by MLflow and any change you make manually will be overwritten when you save the model again.
Instead, you should use one of the recommended methods described in the following sections.</p>
<div class="section" id="example">
<h3>Example<a class="headerlink" href="#example" title="Permalink to this headline"> </a></h3>
<p>The following shows an example of environment files generated by MLflow when logging a model with <code class="docutils literal notranslate"><span class="pre">mlflow.sklearn.log_model</span></code>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">python_env.yaml</span></code></p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">python</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3.9.8</span>
<span class="nt">build_dependencies</span><span class="p">:</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pip==23.3.2</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">setuptools==69.0.3</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">wheel==0.42.0</span>
<span class="nt">dependencies</span><span class="p">:</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">-r requirements.txt</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">requirements.txt</span></code></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>mlflow==2.9.2
scikit-learn==1.3.2
cloudpickle==3.0.0
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">conda.yaml</span></code></p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">mlflow-env</span>
<span class="nt">channels</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">conda-forge</span>
<span class="nt">dependencies</span><span class="p">:</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">python=3.9.8</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pip</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">pip</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">mlflow==2.9.2</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">scikit-learn==1.3.2</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">cloudpickle==3.0.0</span>
</pre></div>
</div>
</li>
</ul>
</div>
</div>
<div class="section" id="adding-extra-dependencies-to-an-mlflow-model">
<h2><a class="toc-backref" href="#id8">Adding Extra Dependencies to an MLflow Model</a><a class="headerlink" href="#adding-extra-dependencies-to-an-mlflow-model" title="Permalink to this headline"> </a></h2>
<p>MLflow infers dependencies required for the model flavor library, but your model may depend on other libraries e.g. data
preprocessing. In this case, you can add extra dependencies to the model by specifying the <strong>extra_pip_requirements</strong> param
when logging the model. For example,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlflow</span>


<span class="k">class</span> <span class="nc">CustomModel</span><span class="p">(</span><span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">PythonModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">model_input</span><span class="p">):</span>
        <span class="c1"># your model depends on pandas</span>
        <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

        <span class="o">...</span>
        <span class="k">return</span> <span class="n">prediction</span>


<span class="c1"># Log the model</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">()</span> <span class="k">as</span> <span class="n">run</span><span class="p">:</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
        <span class="n">python_model</span><span class="o">=</span><span class="n">CustomModel</span><span class="p">(),</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
        <span class="n">extra_pip_requirements</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;pandas==2.0.3&quot;</span><span class="p">],</span>
        <span class="n">input_example</span><span class="o">=</span><span class="n">input_data</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>The extra dependencies will be added to <code class="docutils literal notranslate"><span class="pre">requirements.txt</span></code> as follows (and similarly to <code class="docutils literal notranslate"><span class="pre">conda.yaml</span></code>):</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">mlflow==2.9.2</span>
<span class="l l-Scalar l-Scalar-Plain">cloudpickle==3.0.0</span>
<span class="l l-Scalar l-Scalar-Plain">pandas==2.0.3</span><span class="w">  </span><span class="c1"># added</span>
</pre></div>
</div>
<p>In this case, MLflow will install Pandas 2.0.3 in addition to the inferred dependencies when serving the model for prediction.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Once you log the model with dependencies, it is advisable to test it in a sandbox environment to avoid any dependency
issues when deploying the model to production. Since MLflow 2.10.0, you can use the <a class="reference internal" href="../python_api/mlflow.models.html#mlflow.models.predict" title="mlflow.models.predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.models.predict()</span></code></a> API to quickly test
your model in a virtual environment. Please refer to <a class="reference internal" href="#validating-environment-for-prediction"><span class="std std-ref">Validating Environment for Prediction</span></a> for more details.</p>
</div>
</div>
<div class="section" id="defining-all-dependencies-by-yourself">
<h2><a class="toc-backref" href="#id9">Defining All Dependencies by Yourself</a><a class="headerlink" href="#defining-all-dependencies-by-yourself" title="Permalink to this headline"> </a></h2>
<p>Alternatively, you can also define all dependencies from scratch rather than adding extra ones. To do so,
specify <strong>pip_requirements</strong> when logging the model. For example,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlflow</span>

<span class="c1"># Log the model</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">()</span> <span class="k">as</span> <span class="n">run</span><span class="p">:</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
        <span class="n">sk_model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
        <span class="n">pip_requirements</span><span class="o">=</span><span class="p">[</span>
            <span class="s2">&quot;mlflow-skinny==2.9.2&quot;</span><span class="p">,</span>
            <span class="s2">&quot;cloudpickle==2.5.8&quot;</span><span class="p">,</span>
            <span class="s2">&quot;scikit-learn==1.3.1&quot;</span><span class="p">,</span>
        <span class="p">],</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>The manually defined dependencies will override the default ones MLflow detects from the model flavor library:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">mlflow-skinny==2.9.2</span>
<span class="l l-Scalar l-Scalar-Plain">cloudpickle==2.5.8</span>
<span class="l l-Scalar l-Scalar-Plain">scikit-learn==1.3.1</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Please be careful when declaring dependencies that are different from those used during training, as it can be dangerous
and prone to unexpected behavior. The safest way to ensure consistency is to rely on the default dependencies inferred by MLflow.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Once you log the model with dependencies, it is advisable to test it in a sandbox environment to avoid any dependency
issues when deploying the model to production. Since MLflow 2.10.0, you can use the <a class="reference internal" href="../python_api/mlflow.models.html#mlflow.models.predict" title="mlflow.models.predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.models.predict()</span></code></a> API to quickly
test your model in a virtual environment. Please refer to <a class="reference internal" href="#validating-environment-for-prediction"><span class="std std-ref">Validating Environment for Prediction</span></a> for more details.</p>
</div>
</div>
<div class="section" id="saving-extra-code-dependencies-with-an-mlflow-model-automatic-inference">
<h2><a class="toc-backref" href="#id10">Saving Extra Code dependencies with an MLflow Model - Automatic inference</a><a class="headerlink" href="#saving-extra-code-dependencies-with-an-mlflow-model-automatic-inference" title="Permalink to this headline"> </a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Automatic code dependency inference is a feature that was introduced in MLflow 2.13.0 and is marked as Experimental. The base implementation may be
modified, improved, and adjusted with no prior notice in order to address potential issues and edge cases.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Automatic code dependency inference is currently supported for Python Function Models only. Support for additional named model flavors will be coming in
future releases of MLflow.</p>
</div>
<p>In the MLflow 2.13.0 release, a new method of including custom dependent code was introduced that expands on the existing feature of declaring <code class="docutils literal notranslate"><span class="pre">code_paths</span></code> when
saving or logging a model. This new feature utilizes import dependency analysis to automatically infer the code dependencies required by the model by checking which
modules are imported within the references of a Python Model’s definition.</p>
<p>In order to use this new feature, you can simply set the argument <code class="docutils literal notranslate"><span class="pre">infer_code_paths</span></code> (Default <code class="docutils literal notranslate"><span class="pre">False</span></code>) to <code class="docutils literal notranslate"><span class="pre">True</span></code> when logging. You do not have to define
file locations explicitly via declaring <code class="docutils literal notranslate"><span class="pre">code_paths</span></code> directory locations when utilizing this method of dependency inference, as you would have had to
prior to MLflow 2.13.0.</p>
<p>An example of using this feature is shown below, where we are logging a model that contains an external dependency.
In the first section, we are defining an external module named <code class="docutils literal notranslate"><span class="pre">custom_code</span></code> that exists in a different than our model definition.</p>
<div class="literal-block-wrapper docutils container" id="id4">
<div class="code-block-caption"><span class="caption-text">custom_code.py</span><a class="headerlink" href="#id4" title="Permalink to this code"> </a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>

<span class="n">iris_types</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;setosa&quot;</span><span class="p">,</span> <span class="s2">&quot;versicolor&quot;</span><span class="p">,</span> <span class="s2">&quot;viginica&quot;</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">map_iris_types</span><span class="p">(</span><span class="n">predictions</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">iris_types</span><span class="p">[</span><span class="n">pred</span><span class="p">]</span> <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>With this <code class="docutils literal notranslate"><span class="pre">custom_code.py</span></code> module defined, it is ready for use in our Python Model:</p>
<div class="literal-block-wrapper docutils container" id="id5">
<div class="code-block-caption"><span class="caption-text">model.py</span><a class="headerlink" href="#id5" title="Permalink to this code"> </a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span>

<span class="kn">from</span> <span class="nn">custom_code</span> <span class="kn">import</span> <span class="n">map_iris_types</span>  <span class="c1"># import the external reference</span>

<span class="kn">import</span> <span class="nn">mlflow</span>


<span class="k">class</span> <span class="nc">FlowerMapping</span><span class="p">(</span><span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">PythonModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Custom model with an external dependency&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">model_input</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">pred</span> <span class="o">%</span> <span class="mi">3</span> <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">model_input</span><span class="p">]</span>

        <span class="c1"># Call the external function</span>
        <span class="k">return</span> <span class="n">map_iris_types</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>


<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>
    <span class="n">model_info</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;flowers&quot;</span><span class="p">,</span>
        <span class="n">python_model</span><span class="o">=</span><span class="n">FlowerMapping</span><span class="p">(),</span>
        <span class="n">infer_code_paths</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># Enabling automatic code dependency inference</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<p>With <code class="docutils literal notranslate"><span class="pre">infer_code_paths</span></code> set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, the dependency of <code class="docutils literal notranslate"><span class="pre">map_iris_types</span></code> will be analyzed, its source declaration detected as originating in
the <code class="docutils literal notranslate"><span class="pre">custom_code.py</span></code> module, and the code reference within <code class="docutils literal notranslate"><span class="pre">custom_code.py</span></code> will be stored along with the model artifact. Note that defining the
external code dependency by using the <code class="docutils literal notranslate"><span class="pre">code_paths</span></code> argument (discussed in the next section) is not needed.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Only modules that are within the current working directory are accessible. Dependency inference will not work across module boundaries or if your
custom code is defined in an entirely different library. If your code base is structured in such a way that common modules are entirely external to
the path that your model logging code is executing within, the original <code class="docutils literal notranslate"><span class="pre">code_paths</span></code> option is required in order to log these dependencies, as
<code class="docutils literal notranslate"><span class="pre">infer_code_paths</span></code> dependency inference will not capture those requirements.</p>
</div>
<div class="section" id="restrictions-with-infer-code-paths">
<h3>Restrictions with <code class="docutils literal notranslate"><span class="pre">infer_code_paths</span></code><a class="headerlink" href="#restrictions-with-infer-code-paths" title="Permalink to this headline"> </a></h3>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Before using dependency inference via <code class="docutils literal notranslate"><span class="pre">infer_code_paths</span></code>, ensure that your dependent code modules do not have sensitive data hard-coded within the modules (e.g., passwords,
access tokens, or secrets). Code inference does not obfuscate sensitive information and will capture and log (save) the module, regardless of what it contains.</p>
</div>
<p>An important aspect to note about code structure when using <code class="docutils literal notranslate"><span class="pre">infer_code_paths</span></code> is to avoid defining dependencies within a main entry point to your code.
When a Python code file is loaded as the <code class="docutils literal notranslate"><span class="pre">__main__</span></code> module, it cannot be inferred as a code path file. This means that if you run your script directly
(e.g., using <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">script.py</span></code>), the functions and classes defined in that script will be part of the <code class="docutils literal notranslate"><span class="pre">__main__</span></code> module and not easily accessible by
other modules.</p>
<p>If your model depends on these classes or functions, this can pose a problem because they are not part of the standard module namespace and thus not
straightforward to serialize. To handle this situation, you should use <code class="docutils literal notranslate"><span class="pre">cloudpickle</span></code> to serialize your model instance. <code class="docutils literal notranslate"><span class="pre">cloudpickle</span></code> is an
extended version of Python’s <code class="docutils literal notranslate"><span class="pre">pickle</span></code> module that can serialize a wider range of Python objects, including functions and classes defined in
the <code class="docutils literal notranslate"><span class="pre">__main__</span></code> module.</p>
<dl class="simple">
<dt><strong>Why This Matters</strong>:</dt><dd><ul class="simple">
<li><p><strong>Code Path Inference</strong>: MLflow uses the code path to understand and log the code associated with your model. When the script is executed as <code class="docutils literal notranslate"><span class="pre">__main__</span></code>, the code path cannot be inferred, which complicates the tracking and reproducibility of your MLflow experiments.</p></li>
<li><p><strong>Serialization</strong>: Standard serialization methods like <code class="docutils literal notranslate"><span class="pre">pickle</span></code> may not work with <code class="docutils literal notranslate"><span class="pre">__main__</span></code> module objects, leading to issues when trying to save and load models. <code class="docutils literal notranslate"><span class="pre">cloudpickle</span></code> provides a workaround by enabling the serialization of these objects, ensuring that your model can be correctly saved and restored.</p></li>
</ul>
</dd>
<dt><strong>Best Practices</strong>:</dt><dd><ul class="simple">
<li><p>Avoid defining critical functions and classes in the <code class="docutils literal notranslate"><span class="pre">__main__</span></code> module. Instead, place them in separate module files that can be imported as needed.</p></li>
<li><p>If you must define functions and classes in the <code class="docutils literal notranslate"><span class="pre">__main__</span></code> module, use <code class="docutils literal notranslate"><span class="pre">cloudpickle</span></code> to serialize your model to ensure that all dependencies are correctly handled.</p></li>
</ul>
</dd>
</dl>
</div>
</div>
<div class="section" id="saving-extra-code-with-an-mlflow-model-manual-declaration">
<h2><a class="toc-backref" href="#id11">Saving Extra Code with an MLflow Model - Manual Declaration</a><a class="headerlink" href="#saving-extra-code-with-an-mlflow-model-manual-declaration" title="Permalink to this headline"> </a></h2>
<p>MLflow also supports saving your custom Python code as dependencies to the model. This is particularly useful
when you want to deploy your custom modules that are required for prediction with the model.
To do so, specify <strong>code_paths</strong> when logging the model. For example, if you have the following file structure in your project:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>my_project/
├── utils.py
└── train.py
</pre></div>
</div>
<div class="literal-block-wrapper docutils container" id="id6">
<div class="code-block-caption"><span class="caption-text">train.py</span><a class="headerlink" href="#id6" title="Permalink to this code"> </a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlflow</span>


<span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">PythonModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">model_input</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">my_func</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">my_func</span><span class="p">(</span><span class="n">model_input</span><span class="p">)</span>
        <span class="c1"># .. your prediction logic</span>
        <span class="k">return</span> <span class="n">prediction</span>


<span class="c1"># Log the model</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">()</span> <span class="k">as</span> <span class="n">run</span><span class="p">:</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
        <span class="n">python_model</span><span class="o">=</span><span class="n">MyModel</span><span class="p">(),</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
        <span class="n">input_example</span><span class="o">=</span><span class="n">input_data</span><span class="p">,</span>
        <span class="n">code_paths</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;utils.py&quot;</span><span class="p">],</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<p>Then MLflow will save <code class="docutils literal notranslate"><span class="pre">utils.py</span></code> under <code class="docutils literal notranslate"><span class="pre">code/</span></code> directory in the model directory:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>model/
├── MLmodel
├── ...
└── code/
    └── utils.py
</pre></div>
</div>
<p>When MLflow loads the model for serving, the <code class="docutils literal notranslate"><span class="pre">code</span></code> directory will be added to the system path so that you can use the module in your model
code like <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">utils</span> <span class="pre">import</span> <span class="pre">my_func</span></code>. You can also specify a directory path as <code class="docutils literal notranslate"><span class="pre">code_paths</span></code> to save multiple files under the directory:</p>
<div class="section" id="caveats-of-code-paths-option">
<h3>Caveats of <code class="docutils literal notranslate"><span class="pre">code_paths</span></code> Option<a class="headerlink" href="#caveats-of-code-paths-option" title="Permalink to this headline"> </a></h3>
<p>When using the <code class="docutils literal notranslate"><span class="pre">code_paths</span></code> option, please be aware of the limitation that the specified file or directory <strong>must be in the same directory as your model script</strong>.
If the specified file or directory is in a parent or child directory like <code class="docutils literal notranslate"><span class="pre">my_project/src/utils.py</span></code>, model serving will fail with <code class="docutils literal notranslate"><span class="pre">ModuleNotFoundError</span></code>.
For example, let’s say that you have the following file structure in your project</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>my_project/
|── train.py
└── src/
    └──  utils.py
</pre></div>
</div>
<p>Then the following model code does <strong>not</strong> work:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">PythonModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">model_input</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">src.utils</span> <span class="kn">import</span> <span class="n">my_func</span>

        <span class="c1"># .. your prediction logic</span>
        <span class="k">return</span> <span class="n">prediction</span>


<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">()</span> <span class="k">as</span> <span class="n">run</span><span class="p">:</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
        <span class="n">python_model</span><span class="o">=</span><span class="n">MyModel</span><span class="p">(),</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
        <span class="n">input_example</span><span class="o">=</span><span class="n">input_data</span><span class="p">,</span>
        <span class="n">code_paths</span><span class="o">=</span><span class="p">[</span>
            <span class="s2">&quot;src/utils.py&quot;</span>
        <span class="p">],</span>  <span class="c1"># the file will be saved at code/utils.py not code/src/utils.py</span>
    <span class="p">)</span>

<span class="c1"># =&gt; Model serving will fail with ModuleNotFoundError: No module named &#39;src&#39;</span>
</pre></div>
</div>
<p>This limitation is due to how MLflow saves and loads the specified files and directories. When it copies the specified files or directories in <code class="docutils literal notranslate"><span class="pre">code/</span></code> target,
it does <strong>not</strong> preserve the relative paths that they were originally residing within. For instance, in the above example, MLflow will copy <code class="docutils literal notranslate"><span class="pre">utils.py</span></code> to <code class="docutils literal notranslate"><span class="pre">code/utils.py</span></code>, not
<code class="docutils literal notranslate"><span class="pre">code/src/utils.py</span></code>. As a result, it has to be imported as <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">utils</span> <span class="pre">import</span> <span class="pre">my_func</span></code>, instead of <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">src.utils</span> <span class="pre">import</span> <span class="pre">my_func</span></code>.
However, this may not be pleasant, as the import path is different from the original training script.</p>
<p>To workaround this issue, the <code class="docutils literal notranslate"><span class="pre">code_paths</span></code> should specify the parent directory, which is <code class="docutils literal notranslate"><span class="pre">code_paths=[&quot;src&quot;]</span></code> in this example.
This way, MLflow will copy the entire <code class="docutils literal notranslate"><span class="pre">src/</span></code> directory under <code class="docutils literal notranslate"><span class="pre">code/</span></code> and your model code will be able to import <code class="docutils literal notranslate"><span class="pre">src.utils</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">PythonModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">model_input</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">src.utils</span> <span class="kn">import</span> <span class="n">my_func</span>

        <span class="c1"># .. your prediction logic</span>
        <span class="k">return</span> <span class="n">prediction</span>


<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">()</span> <span class="k">as</span> <span class="n">run</span><span class="p">:</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
        <span class="n">python_model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
        <span class="n">input_example</span><span class="o">=</span><span class="n">input_data</span><span class="p">,</span>
        <span class="n">code_paths</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;src&quot;</span><span class="p">],</span>  <span class="c1"># the whole /src directory will be saved at code/src</span>
    <span class="p">)</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>By the same reason, the <code class="docutils literal notranslate"><span class="pre">code_paths</span></code> option doesn’t handle the relative import of <code class="docutils literal notranslate"><span class="pre">code_paths=[&quot;../src&quot;]</span></code>.</p>
</div>
</div>
<div class="section" id="limitation-of-code-paths-in-loading-multiple-models-with-the-same-module-name-but-different-implementations">
<h3>Limitation of <code class="docutils literal notranslate"><span class="pre">code_paths</span></code> in loading multiple models with the same module name but different implementations<a class="headerlink" href="#limitation-of-code-paths-in-loading-multiple-models-with-the-same-module-name-but-different-implementations" title="Permalink to this headline"> </a></h3>
<p>The current implementation of the <code class="docutils literal notranslate"><span class="pre">code_paths</span></code> option has a limitation that it doesn’t support loading multiple models that depend on modules with the same name but different implementations within the same Python process, as illustrated in the following example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">importlib</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">mlflow</span>

<span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">TemporaryDirectory</span><span class="p">()</span> <span class="k">as</span> <span class="n">tmpdir</span><span class="p">:</span>
    <span class="n">tmpdir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">tmpdir</span><span class="p">)</span>
    <span class="n">my_model_path</span> <span class="o">=</span> <span class="n">tmpdir</span> <span class="o">/</span> <span class="s2">&quot;my_model.py&quot;</span>
    <span class="n">code_template</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">import mlflow</span>

<span class="s2">class MyModel(mlflow.pyfunc.PythonModel):</span>
<span class="s2">    def predict(self, context, model_input):</span>
<span class="s2">        return [</span><span class="si">{n}</span><span class="s2">] * len(model_input)</span>
<span class="s2">&quot;&quot;&quot;</span>

    <span class="n">my_model_path</span><span class="o">.</span><span class="n">write_text</span><span class="p">(</span><span class="n">code_template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

    <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">tmpdir</span><span class="p">))</span>
    <span class="kn">import</span> <span class="nn">my_model</span>

    <span class="c1"># model 1</span>
    <span class="n">model1</span> <span class="o">=</span> <span class="n">my_model</span><span class="o">.</span><span class="n">MyModel</span><span class="p">()</span>
    <span class="k">assert</span> <span class="n">model1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">model_input</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>
        <span class="n">info1</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
            <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
            <span class="n">python_model</span><span class="o">=</span><span class="n">model1</span><span class="p">,</span>
            <span class="n">code_paths</span><span class="o">=</span><span class="p">[</span><span class="n">my_model_path</span><span class="p">],</span>
        <span class="p">)</span>

    <span class="c1"># model 2</span>
    <span class="n">my_model_path</span><span class="o">.</span><span class="n">write_text</span><span class="p">(</span><span class="n">code_template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
    <span class="n">importlib</span><span class="o">.</span><span class="n">reload</span><span class="p">(</span><span class="n">my_model</span><span class="p">)</span>
    <span class="n">model2</span> <span class="o">=</span> <span class="n">my_model</span><span class="o">.</span><span class="n">MyModel</span><span class="p">()</span>
    <span class="k">assert</span> <span class="n">model2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">model_input</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span>

    <span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>
        <span class="n">info2</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
            <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
            <span class="n">python_model</span><span class="o">=</span><span class="n">model2</span><span class="p">,</span>
            <span class="n">code_paths</span><span class="o">=</span><span class="p">[</span><span class="n">my_model_path</span><span class="p">],</span>
        <span class="p">)</span>

<span class="c1"># To simulate a fresh Python process, remove the `my_model` module from the cache</span>
<span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;my_model&quot;</span><span class="p">)</span>

<span class="c1"># Now we have two models that depend on modules with the same name but different implementations.</span>
<span class="c1"># Let&#39;s load them and check the prediction results.</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">info1</span><span class="o">.</span><span class="n">model_uri</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>
<span class="k">assert</span> <span class="n">pred</span> <span class="o">==</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">pred</span>  <span class="c1"># passes</span>

<span class="c1"># As the `my_model` module was loaded and cached in the previous `load_model` call,</span>
<span class="c1"># the next `load_model` call will reuse it and return the wrong prediction result.</span>
<span class="k">assert</span> <span class="s2">&quot;my_model&quot;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">modules</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">info2</span><span class="o">.</span><span class="n">model_uri</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span>
<span class="k">assert</span> <span class="n">pred</span> <span class="o">==</span> <span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">pred</span>  <span class="c1"># doesn&#39;t pass, `pred` is [1]</span>
</pre></div>
</div>
<p>To work around this limitation, you can remove the module from the cache before loading the model. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model1</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">info1</span><span class="o">.</span><span class="n">model_uri</span><span class="p">)</span>
<span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;my_model&quot;</span><span class="p">)</span>
<span class="n">model2</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">info2</span><span class="o">.</span><span class="n">model_uri</span><span class="p">)</span>
</pre></div>
</div>
<p>Another workaround is to use different module names for different implementations. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
    <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;model1&quot;</span><span class="p">,</span>
    <span class="n">python_model</span><span class="o">=</span><span class="n">model1</span><span class="p">,</span>
    <span class="n">code_paths</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;my_model1.py&quot;</span><span class="p">],</span>
<span class="p">)</span>

<span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
    <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
    <span class="n">python_model</span><span class="o">=</span><span class="n">model2</span><span class="p">,</span>
    <span class="n">code_paths</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;my_model2.py&quot;</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="recommended-project-structure">
<h3>Recommended Project Structure<a class="headerlink" href="#recommended-project-structure" title="Permalink to this headline"> </a></h3>
<p>With this limitation for <code class="docutils literal notranslate"><span class="pre">code_paths</span></code> in mind, the recommended project structure looks like the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>my_project/
|-- model.py # Defines the custom pyfunc model
|── train.py # Trains and logs the model
|── core/    # Required modules for prediction
|   |── preprocessing.py
|   └── ...
└── helper/  # Other helper modules used for training, evaluation
    |── evaluation.py
    └── ...
</pre></div>
</div>
<p>This way you can log the model with <code class="docutils literal notranslate"><span class="pre">code_paths=[&quot;core&quot;]</span></code> to include the required modules for prediction, while excluding the helper modules
that are only used for development.</p>
</div>
</div>
<div class="section" id="validating-environment-for-prediction">
<span id="id1"></span><h2><a class="toc-backref" href="#id12">Validating Environment for Prediction</a><a class="headerlink" href="#validating-environment-for-prediction" title="Permalink to this headline"> </a></h2>
<p>Validating your model before deployment is a critical step to ensure production readiness.
MLflow provides a few ways to test your model locally, either in a virtual environment or a Docker container.
If you find any dependency issues during validation, please follow the guidance in <a class="reference internal" href="#how-to-fix-dependency-errors-in-model"><span class="std std-ref">How to fix dependency errors when serving my model?</span></a></p>
<div class="section" id="testing-offline-prediction-with-a-virtual-environment">
<h3>Testing offline prediction with a virtual environment<a class="headerlink" href="#testing-offline-prediction-with-a-virtual-environment" title="Permalink to this headline"> </a></h3>
<p>You can use MLflow Models <strong>predict</strong> API via Python or CLI to make test predictions with your model.
This will load your model from the model URI, create a virtual environment with the model dependencies (defined in MLflow Model),
and run offline predictions with the model.
Please refer to <a class="reference internal" href="../python_api/mlflow.models.html#mlflow.models.predict" title="mlflow.models.predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.models.predict()</span></code></a> or the <a class="reference external" href="../cli.html#mlflow-models">CLI reference</a> for more detailed usage for the predict API.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The Python API is available since MLflow 2.10.0. If you are using an older version, please use the CLI option.</p>
</div>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" role="tablist"><button aria-controls="panel-0-UHl0aG9u" aria-selected="true" class="sphinx-tabs-tab code-tab group-tab" id="tab-0-UHl0aG9u" name="UHl0aG9u" role="tab" tabindex="0">Python</button><button aria-controls="panel-0-QmFzaA==" aria-selected="false" class="sphinx-tabs-tab code-tab group-tab" id="tab-0-QmFzaA==" name="QmFzaA==" role="tab" tabindex="-1">Bash</button></div><div aria-labelledby="tab-0-UHl0aG9u" class="sphinx-tabs-panel code-tab group-tab" id="panel-0-UHl0aG9u" name="UHl0aG9u" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlflow</span>

<span class="n">mlflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
    <span class="n">model_uri</span><span class="o">=</span><span class="s2">&quot;runs:/&lt;run_id&gt;/model&quot;</span><span class="p">,</span>
    <span class="n">input_data</span><span class="o">=&lt;</span><span class="n">input_data</span><span class="o">&gt;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-0-QmFzaA==" class="sphinx-tabs-panel code-tab group-tab" hidden="true" id="panel-0-QmFzaA==" name="QmFzaA==" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mlflow<span class="w"> </span>models<span class="w"> </span>predict<span class="w"> </span>-m<span class="w"> </span>runs:/&lt;run_id&gt;/model-i<span class="w"> </span>&lt;input_path&gt;
</pre></div>
</div>
</div></div>
<p>Using the <a class="reference internal" href="../python_api/mlflow.models.html#mlflow.models.predict" title="mlflow.models.predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.models.predict()</span></code></a> API is convenient for testing your model and inference environment quickly.
However, it may not be a perfect simulation of the serving because it does not start the online inference server. That
said, it’s a great way to test whether your prediction inputs are correctly formatted.</p>
<p>Formatting is subject to the types supported by the <code class="docutils literal notranslate"><span class="pre">predict()</span></code> method of your logged model. If the model was logged with a
signature, the input data should be viewable from the MLflow UI or via <a class="reference internal" href="../python_api/mlflow.models.html#mlflow.models.get_model_info" title="mlflow.models.get_model_info"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.models.get_model_info()</span></code></a>,
which has the field <code class="docutils literal notranslate"><span class="pre">signature</span></code>.</p>
<p>More generally, MLflow has the ability to support a variety of flavor-specfic input types, such as a tensorflow tensor.
MLflow also supports types that are not specific to a given flavor, such as a pandas DataFrame, numpy ndarray, python Dict,
python List, scipy.sparse matrix, and spark data frame.</p>
</div>
<div class="section" id="testing-online-inference-endpoint-with-a-virtual-environment">
<h3>Testing online inference endpoint with a virtual environment<a class="headerlink" href="#testing-online-inference-endpoint-with-a-virtual-environment" title="Permalink to this headline"> </a></h3>
<p>If you want to test your model by actually running the online inference server, you can use the  MLflow <code class="docutils literal notranslate"><span class="pre">serve</span></code> API.
This will create a virtual environment with your model and dependencies, similarly to the <code class="docutils literal notranslate"><span class="pre">predict</span></code> API, but will start the inference server
and expose the REST endpoints. Then you can send a test request and validate the response.
Please refer to the <a class="reference external" href="../cli.html#mlflow-models">CLI reference</a> for more detailed usage for the <code class="docutils literal notranslate"><span class="pre">serve</span></code> API.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mlflow<span class="w"> </span>models<span class="w"> </span>serve<span class="w"> </span>-m<span class="w"> </span>runs:/&lt;run_id&gt;/model<span class="w"> </span>-p<span class="w"> </span>&lt;port&gt;
<span class="c1"># In another terminal</span>
curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--data<span class="w"> </span><span class="s1">&#39;{&quot;inputs&quot;: [[1, 2], [3, 4]]}&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>http://localhost:&lt;port&gt;/invocations
</pre></div>
</div>
<p>While this is a reliable way to test your model before deployment, one caveat is that the virtual environment doesn’t absorb the OS-level differences
between your machine and the production environment. For example, if you are using MacOS as a local dev machine but your deployment target is
running on Linux, you may encounter some issues that are not reproducible in the virtual environment.</p>
<p>In this case, you can use a Docker container to test your model. While it doesn’t provide full OS-level isolation unlike virtual machines e.g. we
can’t run Windows containers on Linux machines, Docker covers some popular test scenarios such as running different versions of Linux or simulating
Linux environments on Mac or Windows.</p>
</div>
<div class="section" id="testing-online-inference-endpoint-with-a-docker-container">
<h3>Testing online inference endpoint with a Docker container<a class="headerlink" href="#testing-online-inference-endpoint-with-a-docker-container" title="Permalink to this headline"> </a></h3>
<p>MLflow <code class="docutils literal notranslate"><span class="pre">build-docker</span></code> API for CLI and Python is capable of building an Ubuntu-based Docker image for serving your model.
The image will contain your model and dependencies, as well as having an entrypoint that is used to start the inference server. Similarly to the <cite>serve</cite> API,
you can send a test request and validate the response.
Please refer to the <a class="reference external" href="../cli.html#mlflow-models">CLI reference</a> for more detailed usage for the <code class="docutils literal notranslate"><span class="pre">build-docker</span></code> API.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mlflow<span class="w"> </span>models<span class="w"> </span>build-docker<span class="w"> </span>-m<span class="w"> </span>runs:/&lt;run_id&gt;/model<span class="w"> </span>-n<span class="w"> </span>&lt;image_name&gt;
docker<span class="w"> </span>run<span class="w"> </span>-p<span class="w"> </span>&lt;port&gt;:8080<span class="w"> </span>&lt;image_name&gt;
<span class="c1"># In another terminal</span>
curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--data<span class="w"> </span><span class="s1">&#39;{&quot;inputs&quot;: [[1, 2], [3, 4]]}&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>http://localhost:&lt;port&gt;/invocations
</pre></div>
</div>
</div>
</div>
<div class="section" id="troubleshooting">
<span id="model-dependencies-troubleshooting"></span><h2><a class="toc-backref" href="#id13">Troubleshooting</a><a class="headerlink" href="#troubleshooting" title="Permalink to this headline"> </a></h2>
<div class="section" id="how-to-fix-dependency-errors-when-serving-my-model">
<span id="how-to-fix-dependency-errors-in-model"></span><h3>How to Fix Dependency Errors when Serving my Model<a class="headerlink" href="#how-to-fix-dependency-errors-when-serving-my-model" title="Permalink to this headline"> </a></h3>
<p>One of the most common issues experienced during model deployment centers around dependency issues. When logging or saving your model, MLflow tries to infer the
model dependencies and save them as part of the MLflow Model metadata. However, this might not always be complete and miss some dependencies e.g. [extras] dependencies
for certain libraries. This can cause errors when serving your model, such as “ModuleNotFoundError” or “ImportError”. Below are some steps that can help to diagnose
and fix missing dependency errors.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>To reduce the possibility of dependency errors, you can add <code class="docutils literal notranslate"><span class="pre">input_example</span></code> when saving your model. This enables MLflow to
perform a model prediction before saving the model, thereby capturing the dependencies used during the prediction.
Please refer to <a class="reference internal" href="signatures.html#input-example"><span class="std std-ref">Model Input Example</span></a> for additional, detailed usage of this parameter.</p>
</div>
<div class="section" id="check-the-missing-dependencies">
<h4>1. Check the missing dependencies<a class="headerlink" href="#check-the-missing-dependencies" title="Permalink to this headline"> </a></h4>
<p>The missing dependencies are listed in the error message. For example, if you see the following error message:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ModuleNotFoundError:<span class="w"> </span>No<span class="w"> </span>module<span class="w"> </span>named<span class="w"> </span><span class="s1">&#39;cv2&#39;</span>
</pre></div>
</div>
</div>
<div class="section" id="try-adding-the-dependencies-using-the-predict-api">
<h4>2. Try adding the dependencies using the <code class="docutils literal notranslate"><span class="pre">predict</span></code> API<a class="headerlink" href="#try-adding-the-dependencies-using-the-predict-api" title="Permalink to this headline"> </a></h4>
<p>Now that you know the missing dependencies, you can create a new model version with the correct dependencies.
However, creating a new model for trying new dependencies might be a bit tedious, particularly because you may need to
iterate multiple times to find the correct solution. Instead, you can use the <a class="reference internal" href="../python_api/mlflow.models.html#mlflow.models.predict" title="mlflow.models.predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.models.predict()</span></code></a> API to test your change without
actually needing to re-log the model repeatedly while troubleshooting the installation errors.</p>
<p>To do so, use the <strong>pip-requirements-override</strong> option to specify pip dependencies like <code class="docutils literal notranslate"><span class="pre">opencv-python==4.8.0</span></code>.</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" role="tablist"><button aria-controls="panel-1-UHl0aG9u" aria-selected="true" class="sphinx-tabs-tab code-tab group-tab" id="tab-1-UHl0aG9u" name="UHl0aG9u" role="tab" tabindex="0">Python</button><button aria-controls="panel-1-QmFzaA==" aria-selected="false" class="sphinx-tabs-tab code-tab group-tab" id="tab-1-QmFzaA==" name="QmFzaA==" role="tab" tabindex="-1">Bash</button></div><div aria-labelledby="tab-1-UHl0aG9u" class="sphinx-tabs-panel code-tab group-tab" id="panel-1-UHl0aG9u" name="UHl0aG9u" role="tabpanel" tabindex="0"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlflow</span>

<span class="n">mlflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
    <span class="n">model_uri</span><span class="o">=</span><span class="s2">&quot;runs:/&lt;run_id&gt;/&lt;model_path&gt;&quot;</span><span class="p">,</span>
    <span class="n">input_data</span><span class="o">=&lt;</span><span class="n">input_data</span><span class="o">&gt;</span><span class="p">,</span>
    <span class="n">pip_requirements_override</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;opencv-python==4.8.0&quot;</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-1-QmFzaA==" class="sphinx-tabs-panel code-tab group-tab" hidden="true" id="panel-1-QmFzaA==" name="QmFzaA==" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mlflow<span class="w"> </span>models<span class="w"> </span>predict<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-m<span class="w"> </span>runs:/&lt;run_id&gt;/&lt;model_path&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-I<span class="w"> </span>&lt;input_path&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pip-requirements-override<span class="w"> </span>opencv-python<span class="o">==</span><span class="m">4</span>.8.0
</pre></div>
</div>
</div></div>
<p>The specified dependencies will be installed to the virtual environment in addition to (or instead of) the dependencies
defined in the model metadata. Since this doesn’t mutate the model, you can iterate quickly and safely to find the correct dependencies.</p>
<p>Note that for <code class="docutils literal notranslate"><span class="pre">input_data</span></code> parameter in the python implementation, the function takes a Python object that is supported by your
model’s <code class="docutils literal notranslate"><span class="pre">predict()</span></code> function. Some examples may include flavor-specific input types, such as a
tensorflow tensor, or more generic types such as a pandas DataFrame, numpy ndarray, python Dict, or
python List. When working with the CLI, we cannot pass python objects and instead look to pass the path
to a CSV or JSON file containing the input payload.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">pip-requirements-override</span></code> option is available since MLflow 2.10.0.</p>
</div>
</div>
<div class="section" id="update-the-model-metadata">
<h4>3. Update the model metadata<a class="headerlink" href="#update-the-model-metadata" title="Permalink to this headline"> </a></h4>
<p>Once you find the correct dependencies, you can create a new model with the correct dependencies.
To do so, specify the <code class="docutils literal notranslate"><span class="pre">extra_pip_requirements</span></code> option when logging the model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlflow</span>

<span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
    <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
    <span class="n">python_model</span><span class="o">=</span><span class="n">python_model</span><span class="p">,</span>
    <span class="n">extra_pip_requirements</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;opencv-python==4.8.0&quot;</span><span class="p">],</span>
    <span class="n">input_example</span><span class="o">=</span><span class="n">input_data</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Note that you can also leverage the CLI to update model dependencies in-place and thereby avoid
re-logging the model.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mlflow<span class="w"> </span>models<span class="w"> </span>update-pip-requirements<span class="w"> </span>-m<span class="w"> </span>runs:/&lt;run_id&gt;/&lt;model_path&gt;<span class="w"> </span>add<span class="w"> </span><span class="s2">&quot;opencv-python==4.8.0&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="how-to-migrate-anaconda-dependency-for-license-change">
<h3>How to Migrate Anaconda Dependency for License Change<a class="headerlink" href="#how-to-migrate-anaconda-dependency-for-license-change" title="Permalink to this headline"> </a></h3>
<p>Anaconda Inc. updated their <a class="reference external" href="https://www.anaconda.com/terms-of-service">terms of service</a> for anaconda.org channels. Based on the new terms of service you may require a commercial license if you rely on Anaconda’s packaging and distribution. See <a class="reference external" href="https://www.anaconda.com/blog/anaconda-commercial-edition-faq">Anaconda Commercial Edition FAQ</a> for more information. Your use of any Anaconda channels is governed by their terms of service.</p>
<p>MLflow models logged before <a class="reference external" href="https://mlflow.org/news/2021/06/18/1.18.0-release/index.html">v1.18</a> were by default logged with the conda <code class="docutils literal notranslate"><span class="pre">defaults</span></code> channel (<a class="reference external" href="https://repo.anaconda.com/pkgs/">https://repo.anaconda.com/pkgs/</a>) as a dependency. Because of this license change, MLflow has stopped the use of the <code class="docutils literal notranslate"><span class="pre">defaults</span></code> channel for models logged using MLflow v1.18 and above. The default channel logged is now <code class="docutils literal notranslate"><span class="pre">conda-forge</span></code>, which points at the community managed <a class="reference external" href="https://conda-forge.org/">https://conda-forge.org/</a>.</p>
<p>If you logged a model before MLflow v1.18 without excluding the <code class="docutils literal notranslate"><span class="pre">defaults</span></code> channel from the conda environment for the model, that model may have a dependency on the <code class="docutils literal notranslate"><span class="pre">defaults</span></code> channel that you may not have intended.
To manually confirm whether a model has this dependency, you can examine the <code class="docutils literal notranslate"><span class="pre">channel</span></code> value in the <code class="docutils literal notranslate"><span class="pre">conda.yaml</span></code> file that is packaged with the logged model. For example, a model’s <code class="docutils literal notranslate"><span class="pre">conda.yaml</span></code> with a <code class="docutils literal notranslate"><span class="pre">defaults</span></code> channel dependency may look like this:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">mlflow-env</span>
<span class="nt">channels</span><span class="p">:</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">defaults</span>
<span class="nt">dependencies</span><span class="p">:</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">python=3.8.8</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pip</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">pip</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">mlflow==2.3</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">scikit-learn==0.23.2</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">cloudpickle==1.6.0</span>
</pre></div>
</div>
<p>If you would like to change the channel used in a model’s environment, you can re-register the model to the model registry with a new <code class="docutils literal notranslate"><span class="pre">conda.yaml</span></code>. You can do this by specifying the channel in the <code class="docutils literal notranslate"><span class="pre">conda_env</span></code> parameter of <code class="docutils literal notranslate"><span class="pre">log_model()</span></code>.</p>
<p>For more information on the <code class="docutils literal notranslate"><span class="pre">log_model()</span></code> API, see the MLflow documentation for the model flavor you are working with, for example, <a class="reference internal" href="../python_api/mlflow.sklearn.html#mlflow.sklearn.log_model" title="mlflow.sklearn.log_model"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.sklearn.log_model()</span></code></a>.</p>
</div>
</div>
</div>


              </div>
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../models.html" class="btn btn-neutral" title="MLflow Models" accesskey="p"><span class="db-icon db-icon-chevron-left"></span> Previous</a>
      
      
        <a href="signatures.html" class="btn btn-neutral" title="MLflow Model Signatures and Input Examples Guide" accesskey="n">Next <span class="db-icon db-icon-chevron-right"></span></a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; MLflow Project, a Series of LF Projects, LLC. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'../',
      VERSION:'2.14.2.dev0',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      LINK_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  

  <script type="text/javascript" src="../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../_static/js/jquery.waypoints.min.js"></script>

  
  
  
  <script type="text/javascript">var CLIPPY_SVG_PATH = "../_static/clippy.svg";</script>
  <script type="text/javascript" src="../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  

  
  <script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        function copyToClipboard(text) {
            const textarea = document.createElement('textarea');
            textarea.value = text;
            document.body.appendChild(textarea);
            textarea.select();
            document.execCommand('copy');
            document.body.removeChild(textarea);
        }
        // Get the code block designator class entries
        const allHighlights = document.querySelectorAll('.highlight');
        // Disable copyable links for notebook cell numbering and for cell outputs
        const highlights = Array.from(allHighlights).filter(highlight => !highlight.closest('.highlight-none') && 
            !highlight.closest('.nboutput'));
    
        highlights.forEach(function(highlight) {
            const copyIcon = document.createElement('span');
            copyIcon.classList.add('copy-icon');
            copyIcon.innerHTML = '&#xf0ea;';

            copyIcon.addEventListener('click', function() {
                const code = highlight.querySelector('pre').textContent;
                copyToClipboard(code);

                // Flash effect on click
                this.style.color = '#0194E2';
                setTimeout(() => {
                    this.style.color = ''; 
                }, 100);

                // Display "Code copied to clipboard" near the clicked icon
                const message = document.createElement('span');
                message.textContent = "Copied!";
                message.classList.add('copy-message'); 

                // Append the message to the icon
                this.appendChild(message);

                setTimeout(() => {
                    this.removeChild(message);
                }, 500);
            });

            highlight.appendChild(copyIcon);
        });
    });
  </script>


<script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        // Force download for notebook-download-btn
        const downloadButtons = document.querySelectorAll('.notebook-download-btn');
        downloadButtons.forEach(function(button) {
            button.addEventListener('click', function(event) {
                event.preventDefault(); // Prevent default behavior

                // Fetch the raw content of the notebook from GitHub
                fetch(button.href)
                    .then(response => response.blob())
                    .then(blob => {
                        const url = window.URL.createObjectURL(blob);
                        const link = document.createElement('a');
                        link.style.display = 'none';
                        link.href = url;
                        const filename = button.href.split('/').pop();
                        link.download = filename; 

                        document.body.appendChild(link);
                        link.click();

                        window.URL.revokeObjectURL(url);
                        document.body.removeChild(link);
                    })
                    .catch(err => console.error('Error fetching the notebook:', err));
            });
        });
    });
</script> 
</body>
</html>