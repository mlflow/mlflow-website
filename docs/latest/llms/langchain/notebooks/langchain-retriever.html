

<!DOCTYPE html>
<!-- source: docs/source/llms/langchain/notebooks/langchain-retriever.ipynb -->
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Introduction to RAG with MLflow and LangChain</title>
  
   
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <link rel="canonical" href="https://mlflow.org/docs/latest/llms/langchain/notebooks/langchain-retriever.html">
  
  
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    

    

  
    
        <!-- Google Tag Manager -->
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer',"GTM-N6WMTTJ");</script>
        <!-- End Google Tag Manager -->
    

  

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/cards.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/grids.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/mobile.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/simple-cards.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/tabs.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="../../../genindex.html"/>
        <link rel="search" title="Search" href="../../../search.html"/>
    <link rel="top" title="MLflow 2.17.1.dev0 documentation" href="../../../index.html"/>
        <link rel="up" title="MLflow LangChain Flavor" href="../index.html"/>
        <link rel="next" title="LangChain within MLflow (Experimental)" href="/../guide/index.html"/>
        <link rel="prev" title="Introduction to Using LangChain with MLflow" href="/langchain-quickstart.html"/> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>
<script type="text/javascript" src="../../../_static/jquery.js"></script>
<script type="text/javascript" src="../../../_static/underscore.js"></script>
<script type="text/javascript" src="../../../_static/doctools.js"></script>
<script type="text/javascript" src="../../../_static/languagesections.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/javascript" src="../../../None"></script>
<script type="text/javascript" src="../../../_static/runllm.js"></script>

<body class="wy-body-for-nav" role="document">
  
    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->
  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <ul>
  <li class="menu-toggle">
    <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
    <a href="../../../index.html" class="wy-nav-top-logo"
      ><img src="../../../_static/MLflow-logo-final-black.png" alt="MLflow"
    /></a>
    <span class="version">2.17.1.dev0</span>
  </li>
</ul>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side relative">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
  </form>
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../../index.html" class="main-navigation-home"><img src="../../../_static/icons/nav-home.svg"> MLflow</a>
    

    
      

      
        <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../introduction/index.html">MLflow Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting-started/index.html">Getting Started with MLflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../new-features/index.html">New Features</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">LLMs</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../index.html#tutorials-and-use-case-guides-for-genai-applications-in-mlflow">Tutorials and Use Case Guides for GenAI applications in MLflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#id1">MLflow Tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#id2">MLflow AI Gateway for LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#id3">LLM Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#id4">Prompt Engineering UI</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../index.html#native-mlflow-flavors-for-llms">Native MLflow Flavors for LLMs</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../../transformers/index.html">MLflow Transformers Flavor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../openai/index.html">MLflow OpenAI Flavor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../sentence-transformers/index.html">MLflow Sentence-Transformers Flavor</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../index.html">MLflow LangChain Flavor</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../index.html#why-use-mlflow-with-langchain">Why use MLflow with LangChain?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../index.html#automatic-logging">Automatic Logging</a></li>
<li class="toctree-l4"><a class="reference internal" href="../index.html#supported-elements-in-mlflow-langchain-integration">Supported Elements in MLflow LangChain Integration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../index.html#overview-of-chains-agents-and-retrievers">Overview of Chains, Agents, and Retrievers</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="../index.html#getting-started-with-the-mlflow-langchain-flavor-tutorials-and-guides">Getting Started with the MLflow LangChain Flavor - Tutorials and Guides</a></li>
<li class="toctree-l4"><a class="reference internal" href="../index.html#id4">Detailed Documentation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../index.html#faq">FAQ</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../llama-index/index.html">MLflow LlamaIndex Flavor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../index.html#explore-the-native-llm-flavors">Explore the Native LLM Flavors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#id5">LLM Tracking in MLflow</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../tracing/index.html">MLflow Tracing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../model-evaluation/index.html">Model Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deep-learning/index.html">Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../traditional-ml/index.html">Traditional ML</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deployment/index.html">Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tracking.html">MLflow Tracking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../system-metrics/index.html">System Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects.html">MLflow Projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">MLflow Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../model-registry.html">MLflow Model Registry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../recipes.html">MLflow Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../plugins.html">MLflow Plugins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../auth/index.html">MLflow Authentication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../search-runs.html">Search Runs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../search-experiments.html">Search Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../R-api.html">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../java_api/index.html">Java API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../rest-api.html">REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docker.html">Official MLflow Docker Image</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../community-model-flavors.html">Community Model Flavors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials-and-examples/index.html">Tutorials and Examples</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            










<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="../../index.html">LLMs</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="../index.html">MLflow LangChain Flavor</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Introduction to RAG with MLflow and LangChain</li>
    
    
    <!-- <li class="wy-breadcrumbs-aside">
      <a href="https://github.com/mlflow/mlflow/blob/master/docs/source/llms/langchain/notebooks/langchain-retriever.ipynb" class="fa fa-github"> Edit on GitHub</a>
    </li> -->
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Introduction-to-RAG-with-MLflow-and-LangChain">
<h1>Introduction to RAG with MLflow and LangChain<a class="headerlink" href="#Introduction-to-RAG-with-MLflow-and-LangChain" title="Permalink to this headline"> </a></h1>
<a href="https://raw.githubusercontent.com/mlflow/mlflow/master/docs/source/llms/langchain/notebooks/langchain-retriever.ipynb" class="notebook-download-btn"><i class="fas fa-download"></i>Download this Notebook</a><br><div class="section" id="Tutorial-Overview">
<h2>Tutorial Overview<a class="headerlink" href="#Tutorial-Overview" title="Permalink to this headline"> </a></h2>
<p>Welcome to this tutorial, where we explore the integration of Retrieval Augmented Generation (RAG) with MLflow and LangChain. Our focus is on demonstrating how to create advanced RAG systems and showcasing the unique capabilities enabled by MLflow in these applications.</p>
<div class="section" id="Understanding-RAG-and-how-to-develop-one-with-MLflow">
<h3>Understanding RAG and how to develop one with MLflow<a class="headerlink" href="#Understanding-RAG-and-how-to-develop-one-with-MLflow" title="Permalink to this headline"> </a></h3>
<p>Retrieval Augmented Generation (RAG) combines the power of language model generation with information retrieval, allowing language models to access and incorporate external data. This approach significantly enriches the model’s responses with detailed and context-specific information.</p>
<p>MLflow is instrumental in this process. As an open-source platform, it facilitates the logging, tracking, and deployment of complex models, including RAG chains. With MLflow, integrating LangChain becomes more streamlined, enhancing the development, evaluation, and deployment processes of RAG models.</p>
<blockquote>
<div><p>NOTE: In this tutorial, we’ll be using GPT-3.5 as our base language model. It’s important to note that the results obtained from a RAG system will differ from those obtained by interfacing directly with GPT models. RAG’s unique approach of combining external data retrieval with language model generation creates more nuanced and contextually rich responses.</p>
</div></blockquote>
<div style="text-align: center;"><p><img alt="fd9140939075499293851bfec53ce3ea" src="https://i.imgur.com/uwo1PCj.png" /></p>
</div></div>
</div>
<div class="section" id="Learning-Outcomes">
<h2>Learning Outcomes<a class="headerlink" href="#Learning-Outcomes" title="Permalink to this headline"> </a></h2>
<p>By the end of this tutorial, you will learn: - How to establish a RAG chain using LangChain and MLflow. - Techniques for scraping and processing documents to feed into a RAG system. - Best practices for deploying and using RAG models to answer complex queries. - Understanding the practical implications and differences in responses when using RAG in comparison to direct language model interactions.</p>
</div>
<div class="section" id="Setting-up-our-Retriever-Dependencies">
<h2>Setting up our Retriever Dependencies<a class="headerlink" href="#Setting-up-our-Retriever-Dependencies" title="Permalink to this headline"> </a></h2>
<p>In order to have a place to store our vetted data (the information that we’re going to be retrieving), we’re going to use a Vector Database. The framework that we’re choosing to use (due to its simplicity, capabilities, and free-to-use characteristics) is FAISS, from <strong>Meta</strong>.</p>
</div>
<div class="section" id="FAISS-Installation-for-the-Tutorial">
<h2>FAISS Installation for the Tutorial<a class="headerlink" href="#FAISS-Installation-for-the-Tutorial" title="Permalink to this headline"> </a></h2>
<div class="section" id="Understanding-FAISS">
<h3>Understanding FAISS<a class="headerlink" href="#Understanding-FAISS" title="Permalink to this headline"> </a></h3>
<p>For this tutorial, we will be utilizing <a class="reference external" href="https://github.com/facebookresearch/faiss/wiki">FAISS</a> (Facebook AI Similarity Search, developed and maintained by the <a class="reference external" href="https://ai.meta.com/tools/faiss/">Meta AI research group</a>), an efficient similarity search and clustering library. It’s a highly useful library that easily handles large datasets and is capable of performing operations such as nearest neighbor search, which are critical in Retrieval Augmented Generation (RAG) systems. There are
numerous other vector database solutions that can perform similar functionality; we are using FAISS in this tutorial due to its simplicity, ease of use, and fantastic performance.</p>
</div>
</div>
<div class="section" id="Notebook-compatibility">
<h2>Notebook compatibility<a class="headerlink" href="#Notebook-compatibility" title="Permalink to this headline"> </a></h2>
<p>With rapidly changing libraries such as <code class="docutils literal notranslate"><span class="pre">langchain</span></code>, examples can become outdated rather quickly and will no longer work. For the purposes of demonstration, here are the critical dependencies that are recommended to use to effectively run this notebook:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 64%" />
<col style="width: 36%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Package</p></th>
<th class="head"><p>Version</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>langchain</p></td>
<td><p><strong>0.1.16</strong></p></td>
</tr>
<tr class="row-odd"><td><p>lanchain-community</p></td>
<td><p><strong>0.0.33</strong></p></td>
</tr>
<tr class="row-even"><td><p>langchain-openai</p></td>
<td><p><strong>0.0.8</strong></p></td>
</tr>
<tr class="row-odd"><td><p>openai</p></td>
<td><p><strong>1.12.0</strong></p></td>
</tr>
<tr class="row-even"><td><p>tiktoken</p></td>
<td><p><strong>0.6.0</strong></p></td>
</tr>
<tr class="row-odd"><td><p>mlflow</p></td>
<td><p><strong>2.12.1</strong></p></td>
</tr>
<tr class="row-even"><td><p>faiss-cpu</p></td>
<td><p><strong>1.7.4</strong></p></td>
</tr>
</tbody>
</table>
<p>If you attempt to execute this notebook with different versions, it may function correctly, but it is recommended to use the precise versions above to ensure that your code executes properly.</p>
<div class="section" id="Installing-Requirements">
<h3>Installing Requirements<a class="headerlink" href="#Installing-Requirements" title="Permalink to this headline"> </a></h3>
<p>Before proceeding with the tutorial, ensure that you have FAISS and <a class="reference external" href="https://pypi.org/project/beautifulsoup4/">Beautiful Soup</a> installed via <code class="docutils literal notranslate"><span class="pre">pip</span></code>. The version specifiers for other packages are guaranteed to work with this notebook. Other versions of these packages may not function correctly due to breaking changes their APIs.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>beautifulsoup4<span class="w"> </span>faiss-cpu<span class="o">==</span><span class="m">1</span>.7.4<span class="w"> </span><span class="nv">langchain</span><span class="o">==</span><span class="m">0</span>.1.16<span class="w"> </span>langchain-community<span class="o">==</span><span class="m">0</span>.0.33<span class="w"> </span>langchain-openai<span class="o">==</span><span class="m">0</span>.0.8<span class="w"> </span><span class="nv">openai</span><span class="o">==</span><span class="m">1</span>.12.0<span class="w"> </span><span class="nv">tiktoken</span><span class="o">==</span><span class="m">0</span>.6.0
</pre></div>
</div>
<blockquote>
<div><p>NOTE: If you’d like to run this using your GPU, you can install <code class="docutils literal notranslate"><span class="pre">faiss-gpu</span></code> instead.</p>
</div></blockquote>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">import</span> <span class="nn">tempfile</span>

<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">RetrievalQA</span>
<span class="kn">from</span> <span class="nn">langchain.document_loaders</span> <span class="kn">import</span> <span class="n">TextLoader</span>
<span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">CharacterTextSplitter</span>
<span class="kn">from</span> <span class="nn">langchain.vectorstores</span> <span class="kn">import</span> <span class="n">FAISS</span>
<span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">OpenAI</span><span class="p">,</span> <span class="n">OpenAIEmbeddings</span>

<span class="kn">import</span> <span class="nn">mlflow</span>

<span class="k">assert</span> <span class="s2">&quot;OPENAI_API_KEY&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">,</span> <span class="s2">&quot;Please set the OPENAI_API_KEY environment variable.&quot;</span>
</pre></div>
</div>
</div>
<blockquote>
<div><p><strong>NOTE: If you’d like to use Azure OpenAI with LangChain, you need to install ``openai&gt;=1.10.0`` and ``langchain-openai&gt;=0.0.6``, as well as to specify the following credentials and parameters:</strong></p>
</div></blockquote>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">AzureOpenAI</span><span class="p">,</span> <span class="n">AzureOpenAIEmbeddings</span>

<span class="c1"># Set this to `azure`</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OPENAI_API_TYPE&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;azure&quot;</span>
<span class="c1"># The API version you want to use: set this to `2023-05-15` for the released version.</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OPENAI_API_VERSION&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;2023-05-15&quot;</span>
<span class="k">assert</span> <span class="p">(</span>
    <span class="s2">&quot;AZURE_OPENAI_ENDPOINT&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span>
<span class="p">),</span> <span class="s2">&quot;Please set the AZURE_OPENAI_ENDPOINT environment variable. It is the base URL for your Azure OpenAI resource. You can find this in the Azure portal under your Azure OpenAI resource.&quot;</span>
<span class="k">assert</span> <span class="p">(</span>
    <span class="s2">&quot;OPENAI_API_KEY&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span>
<span class="p">),</span> <span class="s2">&quot;Please set the OPENAI_API_KEY environment variable. It is the API key for your Azure OpenAI resource. You can find this in the Azure portal under your Azure OpenAI resource.&quot;</span>

<span class="n">azure_openai_llm</span> <span class="o">=</span> <span class="n">AzureOpenAI</span><span class="p">(</span>
    <span class="n">deployment_name</span><span class="o">=</span><span class="s2">&quot;&lt;your-deployment-name&gt;&quot;</span><span class="p">,</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;gpt-4o-mini&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">azure_openai_embeddings</span> <span class="o">=</span> <span class="n">AzureOpenAIEmbeddings</span><span class="p">(</span>
    <span class="n">azure_deployment</span><span class="o">=</span><span class="s2">&quot;&lt;your-deployment-name&gt;&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Scraping-Federal-Documents-for-RAG-Processing">
<h2>Scraping Federal Documents for RAG Processing<a class="headerlink" href="#Scraping-Federal-Documents-for-RAG-Processing" title="Permalink to this headline"> </a></h2>
<p>In this section of the tutorial, we will demonstrate how to scrape content from federal document webpages for use in our RAG system. We’ll be focusing on extracting transcripts from specific sections of webpages, which will then be used to feed our Retrieval Augmented Generation (RAG) model. This process is crucial for providing the RAG system with relevant external data.</p>
<div class="section" id="Function-Overview">
<h3>Function Overview<a class="headerlink" href="#Function-Overview" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p>The function <code class="docutils literal notranslate"><span class="pre">fetch_federal_document</span></code> is designed to scrape and return the transcript of specific federal documents.</p></li>
<li><p>It takes two arguments: <code class="docutils literal notranslate"><span class="pre">url</span></code> (the webpage URL) and <code class="docutils literal notranslate"><span class="pre">div_class</span></code> (the class of the div element containing the transcript).</p></li>
<li><p>The function handles web requests, parses HTML content, and extracts the desired transcript text.</p></li>
</ul>
<p>This step is integral to building a RAG system that relies on external, context-specific data. By effectively fetching and processing this data, we can enrich our model’s responses with accurate information directly sourced from authoritative documents.</p>
<blockquote>
<div><p><strong>NOTE</strong>: In a real-world scenario, you would have your specific text data located on disk somewhere (either locally or on your cloud provider) and the process of loading the embedded data into a vector search database would be entirely external to this active fetching displayed below. We’re simply showing the entire process here for demonstration purposes to show the entire end-to-end workflow for interfacing with a RAG model.</p>
</div></blockquote>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fetch_federal_document</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">div_class</span><span class="p">):</span>  <span class="c1"># noqa: D417</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Scrapes the transcript of the Act Establishing Yellowstone National Park from the given URL.</span>

<span class="sd">    Args:</span>
<span class="sd">    url (str): URL of the webpage to scrape.</span>

<span class="sd">    Returns:</span>
<span class="sd">    str: The transcript text of the Act.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Sending a request to the URL</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>
        <span class="c1"># Parsing the HTML content of the page</span>
        <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s2">&quot;html.parser&quot;</span><span class="p">)</span>

        <span class="c1"># Finding the transcript section by its HTML structure</span>
        <span class="n">transcript_section</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;div&quot;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="n">div_class</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">transcript_section</span><span class="p">:</span>
            <span class="n">transcript_text</span> <span class="o">=</span> <span class="n">transcript_section</span><span class="o">.</span><span class="n">get_text</span><span class="p">(</span><span class="n">separator</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">strip</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">transcript_text</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;Transcript section not found.&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;Failed to retrieve the webpage. Status code: </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">status_code</span><span class="si">}</span><span class="s2">&quot;</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Document-Fetching-and-FAISS-Database-Creation">
<h2>Document Fetching and FAISS Database Creation<a class="headerlink" href="#Document-Fetching-and-FAISS-Database-Creation" title="Permalink to this headline"> </a></h2>
<p>In this next part, we focus on two key processes:</p>
<ol class="arabic simple">
<li><p><strong>Document Fetching</strong>:</p>
<ul class="simple">
<li><p>We use <code class="docutils literal notranslate"><span class="pre">fetch_and_save_documents</span></code> to retrieve documents from specified URLs.</p></li>
<li><p>This function takes a list of URLs and a file path as inputs.</p></li>
<li><p>Each document fetched from the URLs is appended to a single file at the given path.</p></li>
</ul>
</li>
<li><p><strong>FAISS Database Creation</strong>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">create_faiss_database</span></code> is responsible for creating a FAISS database from the documents saved in the previous step.</p></li>
<li><p>The function leverages <code class="docutils literal notranslate"><span class="pre">TextLoader</span></code> to load the text, <code class="docutils literal notranslate"><span class="pre">CharacterTextSplitter</span></code> for document splitting, and <code class="docutils literal notranslate"><span class="pre">OpenAIEmbeddings</span></code> for generating embeddings.</p></li>
<li><p>The resulting FAISS database, which facilitates efficient similarity searches, is saved to a specified directory and returned for further use.</p></li>
</ul>
</li>
</ol>
<p>These functions streamline the process of gathering relevant documents and setting up a FAISS database, essential for implementing advanced Retrieval-Augmented Generation (RAG) applications in MLflow. By modularizing these steps, we ensure code reusability and maintainability.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fetch_and_save_documents</span><span class="p">(</span><span class="n">url_list</span><span class="p">,</span> <span class="n">doc_path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fetches documents from given URLs and saves them to a specified file path.</span>

<span class="sd">    Args:</span>
<span class="sd">        url_list (list): List of URLs to fetch documents from.</span>
<span class="sd">        doc_path (str): Path to the file where documents will be saved.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">url_list</span><span class="p">:</span>
        <span class="n">document</span> <span class="o">=</span> <span class="n">fetch_federal_document</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="s2">&quot;col-sm-9&quot;</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">doc_path</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
            <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">create_faiss_database</span><span class="p">(</span><span class="n">document_path</span><span class="p">,</span> <span class="n">database_save_directory</span><span class="p">,</span> <span class="n">chunk_size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates and saves a FAISS database using documents from the specified file.</span>

<span class="sd">    Args:</span>
<span class="sd">        document_path (str): Path to the file containing documents.</span>
<span class="sd">        database_save_directory (str): Directory where the FAISS database will be saved.</span>
<span class="sd">        chunk_size (int, optional): Size of each document chunk. Default is 500.</span>
<span class="sd">        chunk_overlap (int, optional): Overlap between consecutive chunks. Default is 10.</span>

<span class="sd">    Returns:</span>
<span class="sd">        FAISS database instance.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Load documents from the specified file</span>
    <span class="n">document_loader</span> <span class="o">=</span> <span class="n">TextLoader</span><span class="p">(</span><span class="n">document_path</span><span class="p">)</span>
    <span class="n">raw_documents</span> <span class="o">=</span> <span class="n">document_loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>

    <span class="c1"># Split documents into smaller chunks with specified size and overlap</span>
    <span class="n">document_splitter</span> <span class="o">=</span> <span class="n">CharacterTextSplitter</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="n">chunk_size</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="n">chunk_overlap</span><span class="p">)</span>
    <span class="n">document_chunks</span> <span class="o">=</span> <span class="n">document_splitter</span><span class="o">.</span><span class="n">split_documents</span><span class="p">(</span><span class="n">raw_documents</span><span class="p">)</span>

    <span class="c1"># Generate embeddings for each document chunk</span>
    <span class="n">embedding_generator</span> <span class="o">=</span> <span class="n">OpenAIEmbeddings</span><span class="p">()</span>
    <span class="n">faiss_database</span> <span class="o">=</span> <span class="n">FAISS</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">document_chunks</span><span class="p">,</span> <span class="n">embedding_generator</span><span class="p">)</span>

    <span class="c1"># Save the FAISS database to the specified directory</span>
    <span class="n">faiss_database</span><span class="o">.</span><span class="n">save_local</span><span class="p">(</span><span class="n">database_save_directory</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">faiss_database</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Setting-Up-the-Working-Environment-and-FAISS-Database">
<h2>Setting Up the Working Environment and FAISS Database<a class="headerlink" href="#Setting-Up-the-Working-Environment-and-FAISS-Database" title="Permalink to this headline"> </a></h2>
<p>This section of the tutorial deals with the setup for our Retrieval-Augmented Generation (RAG) application. We’ll establish the working environment and create the necessary FAISS database:</p>
<ol class="arabic simple">
<li><p><strong>Temporary Directory Creation</strong>:</p>
<ul class="simple">
<li><p>A temporary directory is created using <code class="docutils literal notranslate"><span class="pre">tempfile.mkdtemp()</span></code>. This directory serves as a workspace for storing our documents and the FAISS database.</p></li>
</ul>
</li>
<li><p><strong>Document Path and FAISS Index Directory</strong>:</p>
<ul class="simple">
<li><p>Paths for storing the fetched documents and FAISS database are defined within this temporary directory.</p></li>
</ul>
</li>
<li><p><strong>Document Fetching</strong>:</p>
<ul class="simple">
<li><p>We have a list of URLs (<code class="docutils literal notranslate"><span class="pre">url_listings</span></code>) containing the documents we need to fetch.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fetch_and_save_documents</span></code> function is used to retrieve and save the documents from these URLs into a single file located at <code class="docutils literal notranslate"><span class="pre">doc_path</span></code>.</p></li>
</ul>
</li>
<li><p><strong>FAISS Database Creation</strong>:</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">create_faiss_database</span></code> function is then called to create a FAISS database from the saved documents, using the default <code class="docutils literal notranslate"><span class="pre">chunk_size</span></code> and <code class="docutils literal notranslate"><span class="pre">chunk_overlap</span></code> values.</p></li>
<li><p>This database (<code class="docutils literal notranslate"><span class="pre">vector_db</span></code>) is crucial for the RAG process, as it enables efficient similarity searches on the loaded documents.</p></li>
</ul>
</li>
</ol>
<p>By the end of this process, we have all documents consolidated in a single location and a FAISS database ready to be used for retrieval purposes in our MLflow-enabled RAG application.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">temporary_directory</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">mkdtemp</span><span class="p">()</span>

<span class="n">doc_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">temporary_directory</span><span class="p">,</span> <span class="s2">&quot;docs.txt&quot;</span><span class="p">)</span>
<span class="n">persist_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">temporary_directory</span><span class="p">,</span> <span class="s2">&quot;faiss_index&quot;</span><span class="p">)</span>

<span class="n">url_listings</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;https://www.archives.gov/milestone-documents/act-establishing-yellowstone-national-park#transcript&quot;</span><span class="p">,</span>
    <span class="s2">&quot;https://www.archives.gov/milestone-documents/sherman-anti-trust-act#transcript&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">fetch_and_save_documents</span><span class="p">(</span><span class="n">url_listings</span><span class="p">,</span> <span class="n">doc_path</span><span class="p">)</span>

<span class="n">vector_db</span> <span class="o">=</span> <span class="n">create_faiss_database</span><span class="p">(</span><span class="n">doc_path</span><span class="p">,</span> <span class="n">persist_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Establishing-RetrievalQA-Chain-and-Logging-with-MLflow">
<h2>Establishing RetrievalQA Chain and Logging with MLflow<a class="headerlink" href="#Establishing-RetrievalQA-Chain-and-Logging-with-MLflow" title="Permalink to this headline"> </a></h2>
<p>In this final setup phase, we focus on creating the RetrievalQA chain and integrating it with MLflow:</p>
<ol class="arabic simple">
<li><p><strong>Initializing the RetrievalQA Chain</strong>:</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">RetrievalQA</span></code> chain is initialized using the OpenAI language model (<code class="docutils literal notranslate"><span class="pre">llm</span></code>) and the retriever from our previously created FAISS database (<code class="docutils literal notranslate"><span class="pre">vector_db.as_retriever()</span></code>).</p></li>
<li><p>This chain will use the OpenAI model for generating responses and the FAISS retriever for document-based information retrieval.</p></li>
</ul>
</li>
<li><p><strong>Loader Function for Retrieval</strong>:</p>
<ul class="simple">
<li><p>A <code class="docutils literal notranslate"><span class="pre">load_retriever</span></code> function is defined to load the retriever from the FAISS database saved in the specified directory.</p></li>
<li><p>This function is crucial for reloading the retriever when the model is used later.</p></li>
</ul>
</li>
<li><p><strong>Logging the Model with MLflow</strong>:</p>
<ul class="simple">
<li><p>The RetrievalQA chain is logged using <code class="docutils literal notranslate"><span class="pre">mlflow.langchain.log_model</span></code>.</p></li>
<li><p>This process includes specifying the <code class="docutils literal notranslate"><span class="pre">artifact_path</span></code>, the <code class="docutils literal notranslate"><span class="pre">loader_fn</span></code> for the retriever, and the <code class="docutils literal notranslate"><span class="pre">persist_dir</span></code> where the FAISS database is stored.</p></li>
<li><p>Logging the model with MLflow ensures it is tracked and can be easily retrieved for future use.</p></li>
</ul>
</li>
</ol>
<p>Through these steps, we successfully integrate a complex RAG application with MLflow, showcasing its capability to handle advanced NLP tasks.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;Legal RAG&quot;</span><span class="p">)</span>

<span class="n">retrievalQA</span> <span class="o">=</span> <span class="n">RetrievalQA</span><span class="o">.</span><span class="n">from_llm</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">OpenAI</span><span class="p">(),</span> <span class="n">retriever</span><span class="o">=</span><span class="n">vector_db</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">())</span>


<span class="c1"># Log the retrievalQA chain</span>
<span class="k">def</span> <span class="nf">load_retriever</span><span class="p">(</span><span class="n">persist_directory</span><span class="p">):</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">OpenAIEmbeddings</span><span class="p">()</span>
    <span class="n">vectorstore</span> <span class="o">=</span> <span class="n">FAISS</span><span class="o">.</span><span class="n">load_local</span><span class="p">(</span>
        <span class="n">persist_directory</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">,</span>
        <span class="n">allow_dangerous_deserialization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># This is required to load the index from MLflow</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">vectorstore</span><span class="o">.</span><span class="n">as_retriever</span><span class="p">()</span>


<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">()</span> <span class="k">as</span> <span class="n">run</span><span class="p">:</span>
    <span class="n">model_info</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">langchain</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
        <span class="n">retrievalQA</span><span class="p">,</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;retrieval_qa&quot;</span><span class="p">,</span>
        <span class="n">loader_fn</span><span class="o">=</span><span class="n">load_retriever</span><span class="p">,</span>
        <span class="n">persist_dir</span><span class="o">=</span><span class="n">persist_dir</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<blockquote>
<div><p><strong>IMPORTANT</strong>: In order to load a stored vectorstore instance such as our FAISS instance above, we need to specify within the load function the argument <code class="docutils literal notranslate"><span class="pre">allow_dangeous_deserialization</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code> in order for the load to succeed. This is due to a safety warning that was introduced in <code class="docutils literal notranslate"><span class="pre">langchain</span></code> for loading objects that have been serialized using <code class="docutils literal notranslate"><span class="pre">pickle</span></code> or <code class="docutils literal notranslate"><span class="pre">cloudpickle</span></code>. While this issue of remote code execution is not a risk with using MLflow, as the serialization and
deserialization happens entirely via API and within your environment, the argument must be set in order to prevent an Exception from being thrown at load time.</p>
</div></blockquote>
</div>
<div class="section" id="Our-RAG-application-in-the-MLflow-UI">
<h2>Our RAG application in the MLflow UI<a class="headerlink" href="#Our-RAG-application-in-the-MLflow-UI" title="Permalink to this headline"> </a></h2>
<p><img alt="Our Model in the UI" src="https://i.imgur.com/u9zdkmM.png" /></p>
</div>
<div class="section" id="Testing-our-RAG-Model">
<h2>Testing our RAG Model<a class="headerlink" href="#Testing-our-RAG-Model" title="Permalink to this headline"> </a></h2>
<p>Now that we have the model stored in MLflow, we can load it back as a <code class="docutils literal notranslate"><span class="pre">pyfunc</span></code> and see how well it answers a few critically important questions about these acts of Congress in America.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">loaded_model</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">model_info</span><span class="o">.</span><span class="n">model_uri</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">print_formatted_response</span><span class="p">(</span><span class="n">response_list</span><span class="p">,</span> <span class="n">max_line_length</span><span class="o">=</span><span class="mi">80</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Formats and prints responses with a maximum line length for better readability.</span>

<span class="sd">    Args:</span>
<span class="sd">    response_list (list): A list of strings representing responses.</span>
<span class="sd">    max_line_length (int): Maximum number of characters in a line. Defaults to 80.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">response_list</span><span class="p">:</span>
        <span class="n">words</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
        <span class="n">line</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&lt;=</span> <span class="n">max_line_length</span><span class="p">:</span>
                <span class="n">line</span> <span class="o">+=</span> <span class="n">word</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
                <span class="n">line</span> <span class="o">=</span> <span class="n">word</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Let’s-make-sure-that-this-thing-works">
<h2>Let’s make sure that this thing works<a class="headerlink" href="#Let’s-make-sure-that-this-thing-works" title="Permalink to this headline"> </a></h2>
<p>Let’s try out our Retriever model by sending it a fairly simple but purposefully vague question.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">answer1</span> <span class="o">=</span> <span class="n">loaded_model</span><span class="o">.</span><span class="n">predict</span><span class="p">([{</span><span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="s2">&quot;What does the document say about trespassers?&quot;</span><span class="p">}])</span>

<span class="n">print_formatted_response</span><span class="p">(</span><span class="n">answer1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
The document states that all persons who shall locate or settle upon or occupy
the land reserved for the public park, except as provided, shall be considered
trespassers and removed from the park.
</pre></div></div>
</div>
</div>
<div class="section" id="Understanding-the-RetrievalQA-Response">
<h2>Understanding the RetrievalQA Response<a class="headerlink" href="#Understanding-the-RetrievalQA-Response" title="Permalink to this headline"> </a></h2>
<p>With this model, our approach combines text retrieval from a database with language model generation to answer specific queries.</p>
<div class="section" id="How-It-Works:">
<h3>How It Works:<a class="headerlink" href="#How-It-Works:" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p><strong>RetrievalQA Model</strong>: This model, a part of the LangChain suite, is designed to first retrieve relevant information from a predefined database and then use a language model to generate a response based on this information.</p></li>
<li><p><strong>Database Integration</strong>: In this example, we’ve created a FAISS database from historical documents, such as the Act Establishing Yellowstone National Park. This database is used by the RetrievalQA model to find relevant sections of text.</p></li>
<li><p><strong>Query Processing</strong>: When we execute <code class="docutils literal notranslate"><span class="pre">loaded_model.predict([{&quot;query&quot;:</span> <span class="pre">&quot;What</span> <span class="pre">does</span> <span class="pre">the</span> <span class="pre">document</span> <span class="pre">say</span> <span class="pre">about</span> <span class="pre">trespassers?&quot;}])</span></code>, the model first searches the database for parts of the document that are most relevant to the query about trespassers.</p></li>
</ul>
</div>
<div class="section" id="Why-Is-This-Response-Different?">
<h3>Why Is This Response Different?<a class="headerlink" href="#Why-Is-This-Response-Different?" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p><strong>Context-Specific Answers</strong>: Unlike a direct query to GPT-3.5, which might generate an answer based on its training data without specific context, the RetrievalQA model provides a response directly derived from the specific documents in the database.</p></li>
<li><p><strong>Accurate and Relevant</strong>: The response is more accurate and contextually relevant because it’s based on the actual content of the specific document being queried.</p></li>
<li><p><strong>No Generalization</strong>: There’s less generalization or assumption in the response. The RetrievalQA model is not “guessing” based on its training; it’s providing information directly sourced from the document.</p></li>
</ul>
</div>
<div class="section" id="Key-Takeaway:">
<h3>Key Takeaway:<a class="headerlink" href="#Key-Takeaway:" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p>This methodology demonstrates how MLflow and LangChain facilitate complex RAG use cases, where direct interaction with historical or specific texts yields more precise answers than generic language model predictions.</p></li>
<li><p>The tutorial highlights how leveraging RAG can be particularly useful in scenarios where responses need to be grounded in specific texts or documents, showcasing a powerful blend of retrieval and generation capabilities.</p></li>
</ul>
</div>
</div>
<div class="section" id="Analyzing-the-Bridle-Path-Query-Response">
<h2>Analyzing the Bridle-Path Query Response<a class="headerlink" href="#Analyzing-the-Bridle-Path-Query-Response" title="Permalink to this headline"> </a></h2>
<p>This section of the tutorial showcases an interesting aspect of the RetrievalQA model’s capabilities, particularly in handling queries that involve both specific information retrieval and additional context generation.</p>
<div class="section" id="Query-and-Response-Breakdown:">
<h3>Query and Response Breakdown:<a class="headerlink" href="#Query-and-Response-Breakdown:" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p><strong>Query</strong>: The user asks, “What is a bridle-path and can I use one at Yellowstone?”</p></li>
<li><p><strong>Response</strong>: The model responds by explaining what a bridle-path is and confirms that bridle-paths can be used at Yellowstone based on the act.</p></li>
</ul>
</div>
<div class="section" id="Understanding-the-Response-Dynamics:">
<h3>Understanding the Response Dynamics:<a class="headerlink" href="#Understanding-the-Response-Dynamics:" title="Permalink to this headline"> </a></h3>
<ol class="arabic simple">
<li><p><strong>Combining Document Data with LLM Context</strong>:</p>
<ul class="simple">
<li><p>The query about bridle-paths isn’t directly answered in the act establishing Yellowstone.</p></li>
<li><p>The model uses its language understanding capabilities to provide a definition of a bridle-path.</p></li>
<li><p>It then merges this information with the context it retrieves from the FAISS database about the act, particularly regarding the construction of roads and bridle-paths in the park.</p></li>
</ul>
</li>
<li><p><strong>Enhanced Contextual Understanding</strong>:</p>
<ul class="simple">
<li><p>The RetrievalQA model demonstrates an ability to supplement direct information from the database with additional context through its language model.</p></li>
<li><p>This approach provides a more comprehensive answer that aligns with the user’s query, showing a blend of document-specific data and general knowledge.</p></li>
</ul>
</li>
<li><p><strong>Why This Is Notable</strong>:</p>
<ul class="simple">
<li><p>Unlike a standard LLM response, the RetrievalQA model doesn’t solely rely on its training data for general responses.</p></li>
<li><p>It effectively integrates specific document information with broader contextual understanding, offering a more nuanced answer.</p></li>
</ul>
</li>
</ol>
</div>
<div class="section" id="id1">
<h3>Key Takeaway:<a class="headerlink" href="#id1" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p>This example highlights how MLflow and LangChain, through the RetrievalQA model, facilitate a sophisticated response mechanism. The model not only retrieves relevant document information but also intelligently fills in gaps with its own language understanding capabilities.</p></li>
<li><p>Such a response mechanism is particularly useful when dealing with queries that require both specific document references and additional contextual information, showcasing the advanced capabilities of RAG in practical applications.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">answer2</span> <span class="o">=</span> <span class="n">loaded_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
    <span class="p">[{</span><span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="s2">&quot;What is a bridle-path and can I use one at Yellowstone?&quot;</span><span class="p">}]</span>
<span class="p">)</span>

<span class="n">print_formatted_response</span><span class="p">(</span><span class="n">answer2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
A bridle-path is a narrow path or trail designed for horseback riding. Yes, you
can use a bridle-path at Yellowstone as it is designated for the enjoyment and
benefit of the people visiting the park. However, it may be subject to certain
regulations and restrictions set by the Secretary of the Interior.
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="A-most-serious-question">
<h2>A most serious question<a class="headerlink" href="#A-most-serious-question" title="Permalink to this headline"> </a></h2>
<p>In this section of our tutorial, we delve into a whimsically ridiculous query and how our model tackles it with a blend of accuracy and a hint of humor.</p>
<div class="section" id="Query-Overview:">
<h3>Query Overview:<a class="headerlink" href="#Query-Overview:" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p><strong>The Query</strong>: “Can I buy Yellowstone from the Federal Government to set up a buffalo-themed day spa?”</p></li>
<li><p><strong>The Response</strong>: The model, with a straight face, responds, “No, you cannot buy Yellowstone from the Federal Government to set up a buffalo-themed day spa.”</p></li>
</ul>
</div>
<div class="section" id="A-Peek-into-the-Model’s-Thought-Process:">
<h3>A Peek into the Model’s Thought Process:<a class="headerlink" href="#A-Peek-into-the-Model’s-Thought-Process:" title="Permalink to this headline"> </a></h3>
<ol class="arabic simple">
<li><p><strong>Direct and No-Nonsense Response</strong>:</p>
<ul class="simple">
<li><p>Despite the query’s comedic undertone, the model gives a direct and clear-cut response. It’s like the model is saying, “Nice try, but no, you can’t do that.”</p></li>
<li><p>This highlights the model’s ability to remain factual, even when faced with a question that’s clearly more humorous than serious.</p></li>
</ul>
</li>
<li><p><strong>Understanding Legal Boundaries</strong>:</p>
<ul class="simple">
<li><p>The response respects the legal and regulatory sanctity of national parks. It seems our model takes the protection of national treasures like Yellowstone pretty seriously!</p></li>
<li><p>The model’s training on legal and general knowledge assists in delivering a response that’s accurate, albeit the question being a facetious one.</p></li>
</ul>
</li>
<li><p><strong>Contrast with Traditional LLM Responses</strong>:</p>
<ul class="simple">
<li><p>A traditional LLM might have given a more generic answer. In contrast, our model, equipped with context-specific data, promptly debunks the whimsical idea of buying a national park for a spa.</p></li>
</ul>
</li>
</ol>
</div>
<div class="section" id="A-Dash-of-Humor-in-Learning:">
<h3>A Dash of Humor in Learning:<a class="headerlink" href="#A-Dash-of-Humor-in-Learning:" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p>The query, while absurd, serves as an amusing example of the model’s capability to provide contextually relevant answers to even the most far-fetched questions.</p></li>
<li><p>It’s a reminder that learning can be both informative and entertaining. In this case, the model plays the role of a straight-faced comedian, addressing a wildly imaginative business proposal with a firm yet comical “No.”</p></li>
</ul>
<p>So, while you can’t buy Yellowstone for your buffalo-themed spa dreams, you can certainly enjoy the park’s natural beauty… just as a visitor, not as a spa owner!</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">answer3</span> <span class="o">=</span> <span class="n">loaded_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="s2">&quot;Can I buy Yellowstone from the Federal Government to set up a buffalo-themed day spa?&quot;</span>
        <span class="p">}</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">print_formatted_response</span><span class="p">(</span><span class="n">answer3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
No, you cannot buy Yellowstone from the Federal Government to set up a
buffalo-themed day spa. The land near the headwaters of the Yellowstone River
has been reserved and withdrawn from settlement, occupancy, or sale under the
laws of the United States and dedicated and set apart as a public park for the
benefit and enjoyment of the people. The Secretary of the Interior has control
over the park and is responsible for making and publishing rules and
regulations for its management. Leases for building purposes are only granted
for small parcels of ground for the accommodation of visitors, and the proceeds
are used for the management of the park and the construction of roads and
bridle-paths. Additionally, the wanton destruction of fish and game within the
park is prohibited. Furthermore, the Act to protect trade and commerce against
unlawful restraints and monopolies (approved July 2, 1890) states that any
contract, combination, or conspiracy in restraint of trade or commerce in any
Territory or the District of Columbia is illegal. Thus, buying land to set up a
buffalo-themed day spa would likely be considered a violation of this act.
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Maintaining-Composure:-Answering-Another-Whimsical-Query">
<h2>Maintaining Composure: Answering Another Whimsical Query<a class="headerlink" href="#Maintaining-Composure:-Answering-Another-Whimsical-Query" title="Permalink to this headline"> </a></h2>
<p>In this part of our tutorial, we explore another amusing question about leasing land in Yellowstone for a buffalo-themed day spa. Let’s see how our model, with unflappable composure, responds to this quirky inquiry.</p>
<div class="section" id="Query-and-Response:">
<h3>Query and Response:<a class="headerlink" href="#Query-and-Response:" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p><strong>The Query</strong>: “Can I lease a small parcel of land from the Federal Government for a small buffalo-themed day spa for visitors to the park?”</p></li>
<li><p><strong>The Response</strong>: “No, you cannot lease a small parcel of land from the Federal Government for a small buffalo-themed day spa for visitors to the park…”</p></li>
</ul>
</div>
<div class="section" id="Insights-into-the-Model’s-Response:">
<h3>Insights into the Model’s Response:<a class="headerlink" href="#Insights-into-the-Model’s-Response:" title="Permalink to this headline"> </a></h3>
<ol class="arabic simple">
<li><p><strong>Factual and Unwavering</strong>:</p>
<ul class="simple">
<li><p>Despite the continued outlandish line of questioning, our model remains as cool as a cucumber. It patiently explains the limitations and actual purposes of leasing land in Yellowstone.</p></li>
<li><p>The response cites Section 2 of the act, adding legal precision to its rebuttal.</p></li>
</ul>
</li>
<li><p><strong>A Lawyer’s Patience Tested?</strong>:</p>
<ul class="simple">
<li><p>Imagine if this question was posed to an actual lawyer. By now, they might be rubbing their temples! But our model is unfazed and continues to provide factual answers.</p></li>
<li><p>This showcases the model’s ability to handle repetitive and unusual queries without losing its ‘cool’.</p></li>
</ul>
</li>
</ol>
<p>In conclusion, while our model firmly closes the door on the buffalo-themed day spa dreams, it does so with informative grace, demonstrating its ability to stay on course no matter how imaginative the queries get.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">answer4</span> <span class="o">=</span> <span class="n">loaded_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="s2">&quot;Can I lease a small parcel of land from the Federal Government for a small &quot;</span>
            <span class="s2">&quot;buffalo-themed day spa for visitors to the park?&quot;</span>
        <span class="p">}</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">print_formatted_response</span><span class="p">(</span><span class="n">answer4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
No, according to the context provided, the Secretary of the Interior may grant
leases for building purposes for terms not exceeding ten years, but only for
the accommodation of visitors. It does not specifically mention a
buffalo-themed day spa as a possible use for the leased land.
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Another-Attempt-at-the-Buffalo-Themed-Day-Spa-Dream">
<h2>Another Attempt at the Buffalo-Themed Day Spa Dream<a class="headerlink" href="#Another-Attempt-at-the-Buffalo-Themed-Day-Spa-Dream" title="Permalink to this headline"> </a></h2>
<p>Once more, we pose an imaginative question to our model, this time adding a hotel to the buffalo-themed day spa scenario. The reason for this modification is to evaluate whether the RAG application can discern a nuanced element of the intentionally vague wording of the two acts that we’ve loaded. Let’s see the response to determine if it can resolve both bits of information!</p>
<div class="section" id="Quick-Takeaway:">
<h3>Quick Takeaway:<a class="headerlink" href="#Quick-Takeaway:" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p>The model, sticking to its informative nature, clarifies the leasing aspects based on the Act’s provisions.</p></li>
<li><p>It interestingly connects the query to another act related to trade and commerce, showing its ability to cross-reference related legal documents.</p></li>
<li><p>This response demonstrates the model’s capacity to provide detailed, relevant information, even when faced with quirky and hypothetical scenarios.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">answer5</span> <span class="o">=</span> <span class="n">loaded_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="s2">&quot;Can I lease a small parcel of land from the Federal Government for a small &quot;</span>
            <span class="s2">&quot;buffalo-themed day spa and hotel for visitors to stay in and relax at while visiting the park?&quot;</span>
        <span class="p">}</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">print_formatted_response</span><span class="p">(</span><span class="n">answer5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
No, it is not possible to lease land from the Federal Government for a
commercial purpose within the designated park area. The Secretary of the
Interior may grant leases for building purposes for terms not exceeding ten
years, but only for small parcels of ground for the accommodation of visitors.
Additionally, all proceeds from leases and other revenues must be used for the
management of the park and the construction of roads and bridle-paths.
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Well,-what-can-I-do-then?">
<h2>Well, what can I do then?<a class="headerlink" href="#Well,-what-can-I-do-then?" title="Permalink to this headline"> </a></h2>
<div class="section" id="Takeaway:">
<h3>Takeaway:<a class="headerlink" href="#Takeaway:" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p>The response reassuringly confirms that one can enjoy Yellowstone’s natural beauty, provided park rules and regulations are respected.</p></li>
<li><p>This illustrates the model’s ability to provide straightforward, practical advice in response to simple, real-world questions. It clearly has the context of the original act and is able to infer what is permissible (enjoying the reserved land).</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">answer6</span> <span class="o">=</span> <span class="n">loaded_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
    <span class="p">[{</span><span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="s2">&quot;Can I just go to the park and peacefully enjoy the natural splendor?&quot;</span><span class="p">}]</span>
<span class="p">)</span>

<span class="n">print_formatted_response</span><span class="p">(</span><span class="n">answer6</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Yes, according to the context, the park was set apart as a public park or
pleasuring-ground for the benefit and enjoyment of the people. However, the
park is under the exclusive control of the Secretary of the Interior who has
the authority to make and publish rules and regulations for the care and
management of the park. Therefore, it is important to follow any rules or
regulations set by the Secretary to ensure the preservation and protection of
the park for future enjoyment.
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Evaluating-the-RetrievalQA-Model’s-Legal-Context-Integration">
<h2>Evaluating the RetrievalQA Model’s Legal Context Integration<a class="headerlink" href="#Evaluating-the-RetrievalQA-Model’s-Legal-Context-Integration" title="Permalink to this headline"> </a></h2>
<p>This section of the tutorial showcases the RetrievalQA model’s sophisticated ability to integrate and interpret context from multiple legal documents. The model is challenged with a query that requires synthesizing information from distinct sources. This test is particularly interesting for its demonstration of the model’s proficiency in:</p>
<ol class="arabic simple">
<li><p><strong>Contextual Integration</strong>: The model adeptly pulls in relevant legal details from different documents, illustrating its capacity to navigate through multiple sources of information.</p></li>
<li><p><strong>Legal Interpretation</strong>: It interprets the legal implications related to the query, highlighting the model’s understanding of complex legal language and concepts.</p></li>
<li><p><strong>Cross-Document Inference</strong>: The model’s ability to discern and extract the most pertinent information from a pool of multiple documents is a testament to its advanced capabilities in multi-document scenarios.</p></li>
</ol>
<p>This evaluation provides a clear example of the model’s potential in handling intricate queries that necessitate a deep and nuanced understanding of diverse data sources.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">answer7</span> <span class="o">=</span> <span class="n">loaded_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="s2">&quot;Can I start a buffalo themed day spa outside of Yellowstone National Park and stifle any competition?&quot;</span>
        <span class="p">}</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">print_formatted_response</span><span class="p">(</span><span class="n">answer7</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
No, according to the context, any attempt to monopolize trade or commerce in
the Yellowstone area or in any territory of the United States is considered
illegal. Additionally, the park is under the exclusive control of the Secretary
of the Interior, who may grant leases for building purposes but is expected to
prevent the destruction of natural resources and the exploitation of fish and
game for profit. Therefore, it would not be possible to start a buffalo themed
day spa outside of Yellowstone National Park and stifle competition without
violating the law and risking consequences from the Secretary of the Interior.
</pre></div></div>
</div>
<p><strong>Cleanup: Removing Temporary Directory</strong>: - After we’re done asking our Retriever Model a bunch of silly questions, the temporary directory created earlier is cleaned up using <code class="docutils literal notranslate"><span class="pre">shutil.rmtree</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Clean up our temporary directory that we created with our FAISS instance</span>
<span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">temporary_directory</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Conclusion:-Mastering-RAG-with-MLflow">
<h2>Conclusion: Mastering RAG with MLflow<a class="headerlink" href="#Conclusion:-Mastering-RAG-with-MLflow" title="Permalink to this headline"> </a></h2>
<p>In this tutorial, we explored the depths of Retrieval Augmented Generation (RAG) applications, enabled and simplified by MLflow. Here’s a recap of our journey and the key takeaways:</p>
<ol class="arabic simple">
<li><p><strong>Ease of Developing RAG Applications</strong>: We learned how MLflow facilitates the development of RAG applications by streamlining the process of integrating large language models with external data sources. Our hands-on experience demonstrated the process of fetching, processing, and embedding documents into a FAISS database, all managed within the MLflow framework.</p></li>
<li><p><strong>Advanced Query Handling</strong>: Through our tests, we observed how the MLflow-wrapped LangChain RAG model adeptly handled complex queries, drawing from multiple documents to provide context-rich and accurate responses. This showcased the potential of RAG models in processing and understanding queries that require multi-source data integration.</p></li>
<li><p><strong>MLflow’s Role in Deployment and Management</strong>: MLflow’s robustness was evident in how it simplifies the logging, deployment, and management of complex models. Its ability to track experiments, manage artifacts, and ease the deployment process highlights its indispensability in the machine learning lifecycle.</p></li>
<li><p><strong>Practical Application Insights</strong>: Our queries, while humorous at times, served to illustrate the practical capabilities of RAG models. From legal interpretations to hypothetical scenarios, we saw how these models could be applied in real-world situations, providing insightful and contextually relevant responses.</p></li>
<li><p><strong>The Future of RAG and MLflow</strong>: This tutorial underscored the potential of combining RAG with MLflow’s streamlined management capabilities. As RAG continues to evolve, MLflow stands out as a crucial tool for harnessing its power, making advanced NLP applications more accessible and efficient.</p></li>
</ol>
<p>In summary, our journey through this tutorial has not only equipped us with the knowledge to develop and deploy RAG applications effectively but also opened our eyes to the vast possibilities that lie ahead in the realm of advanced NLP, all made more attainable through MLflow.</p>
</div>
<div class="section" id="What’s-next?">
<h2>What’s next?<a class="headerlink" href="#What’s-next?" title="Permalink to this headline"> </a></h2>
<p>If you’d like to learn more about how MLflow and LangChain integrate, see the other <a class="reference external" href="https://www.mlflow.org/docs/latest/llms/langchain/index.html#advanced-tutorials">advanced tutorials for MLflow’s LangChain flavor</a>.</p>
</div>
</div>


              </div>
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="langchain-quickstart.html" class="btn btn-neutral" title="Introduction to Using LangChain with MLflow" accesskey="p"><span class="db-icon db-icon-chevron-left"></span> Previous</a>
      
      
        <a href="../guide/index.html" class="btn btn-neutral" title="LangChain within MLflow (Experimental)" accesskey="n">Next <span class="db-icon db-icon-chevron-right"></span></a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; MLflow Project, a Series of LF Projects, LLC. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'../../../',
      VERSION:'2.17.1.dev0',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      LINK_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  

  <script type="text/javascript" src="../../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/jquery.waypoints.min.js"></script>

  
  
  
  <script type="text/javascript">var CLIPPY_SVG_PATH = "../../../_static/clippy.svg";</script>
  <script type="text/javascript" src="../../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  

  
  <script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        function copyToClipboard(text) {
            const textarea = document.createElement('textarea');
            textarea.value = text;
            document.body.appendChild(textarea);
            textarea.select();
            document.execCommand('copy');
            document.body.removeChild(textarea);
        }
        // Get the code block designator class entries
        const allHighlights = document.querySelectorAll('.highlight');
        // Disable copyable links for notebook cell numbering and for cell outputs
        const highlights = Array.from(allHighlights).filter(highlight => !highlight.closest('.highlight-none') && 
            !highlight.closest('.nboutput'));
    
        highlights.forEach(function(highlight) {
            const copyIcon = document.createElement('span');
            copyIcon.classList.add('copy-icon');
            copyIcon.innerHTML = '&#xf0ea;';

            copyIcon.addEventListener('click', function() {
                const code = highlight.querySelector('pre').textContent;
                copyToClipboard(code);

                // Flash effect on click
                this.style.color = '#0194E2';
                setTimeout(() => {
                    this.style.color = ''; 
                }, 100);

                // Display "Code copied to clipboard" near the clicked icon
                const message = document.createElement('span');
                message.textContent = "Copied!";
                message.classList.add('copy-message'); 

                // Append the message to the icon
                this.appendChild(message);

                setTimeout(() => {
                    this.removeChild(message);
                }, 500);
            });

            highlight.appendChild(copyIcon);
        });
    });
  </script>


<script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        // Force download for notebook-download-btn
        const downloadButtons = document.querySelectorAll('.notebook-download-btn');
        downloadButtons.forEach(function(button) {
            button.addEventListener('click', function(event) {
                event.preventDefault(); // Prevent default behavior

                // Fetch the raw content of the notebook from GitHub
                fetch(button.href)
                    .then(response => response.blob())
                    .then(blob => {
                        const url = window.URL.createObjectURL(blob);
                        const link = document.createElement('a');
                        link.style.display = 'none';
                        link.href = url;
                        const filename = button.href.split('/').pop();
                        link.download = filename; 

                        document.body.appendChild(link);
                        link.click();

                        window.URL.revokeObjectURL(url);
                        document.body.removeChild(link);
                    })
                    .catch(err => console.error('Error fetching the notebook:', err));
            });
        });
    });
</script> 
</body>
</html>