
  

<!DOCTYPE html>
<!-- source: docs/source/llms/sentence-transformers/tutorials/quickstart/sentence-transformers-quickstart.ipynb -->
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Introduction to Sentence Transformers and MLflow &mdash; MLflow 2.14.2.dev0 documentation</title>
  
   
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <link rel="canonical" href="https://mlflow.org/docs/latest/llms/sentence-transformers/tutorials/quickstart/sentence-transformers-quickstart.html">
  
  
    <link rel="shortcut icon" href="../../../../_static/favicon.ico"/>
    

    

  
    
        <!-- Google Tag Manager -->
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer',"GTM-N6WMTTJ");</script>
        <!-- End Google Tag Manager -->
    

  

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/cards.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/grids.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/mobile.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/simple-cards.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/tabs.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="../../../../genindex.html"/>
        <link rel="search" title="Search" href="../../../../search.html"/>
    <link rel="top" title="MLflow 2.14.2.dev0 documentation" href="../../../../index.html"/>
        <link rel="up" title="MLflow Sentence-Transformers Flavor" href="../../index.html"/>
        <link rel="next" title="Advanced Paraphrase Mining with Sentence Transformers and MLflow" href="/../paraphrase-mining/paraphrase-mining-sentence-transformers.html"/>
        <link rel="prev" title="MLflow Sentence-Transformers Flavor" href="/../../index.html"/> 

  
  <script src="../../../../_static/js/modernizr.min.js"></script>

</head>
<script type="text/javascript" src="../../../../_static/jquery.js"></script>
<script type="text/javascript" src="../../../../_static/underscore.js"></script>
<script type="text/javascript" src="../../../../_static/doctools.js"></script>
<script type="text/javascript" src="../../../../_static/languagesections.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/javascript" src="../../../../None"></script>

<body class="wy-body-for-nav" role="document">
  
    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->
  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <ul>
  <li class="menu-toggle">
    <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
    <a href="../../../../index.html" class="wy-nav-top-logo"
      ><img src="../../../../_static/MLflow-logo-final-black.png" alt="MLflow"
    /></a>
    <span class="version">2.14.2.dev0</span>
  </li>
</ul>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side relative">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
  </form>
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../../../index.html" class="main-navigation-home"><img src="../../../../_static/icons/nav-home.svg"> MLflow</a>
    

    
      

      
        <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../../introduction/index.html">What is MLflow?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../getting-started/index.html">Getting Started with MLflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../new-features/index.html">New Features</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../index.html">LLMs</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../../index.html#id1">MLflow Tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../index.html#id2">MLflow Deployments Server for LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../index.html#id3">LLM Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../index.html#id4">Prompt Engineering UI</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../../index.html#native-mlflow-flavors-for-llms">Native MLflow Flavors for LLMs</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../../../transformers/index.html">MLflow Transformers Flavor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../openai/index.html">MLflow OpenAI Flavor</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../../index.html">MLflow Sentence-Transformers Flavor</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../../index.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../index.html#what-makes-this-library-so-special">What makes this Library so Special?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../index.html#features">Features</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="../../index.html#getting-started-with-the-mlflow-sentence-transformers-flavor-tutorials-and-guides">Getting Started with the MLflow Sentence Transformers Flavor - Tutorials and Guides</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../index.html#id1">Detailed Documentation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../index.html#learning-more-about-sentence-transformers">Learning More About Sentence Transformers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../langchain/index.html">MLflow LangChain Flavor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../index.html#explore-the-native-llm-flavors">Explore the Native LLM Flavors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../index.html#id5">LLM Tracking in MLflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../index.html#tutorials-and-use-case-guides-for-llms-in-mlflow">Tutorials and Use Case Guides for LLMs in MLflow</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../model-evaluation/index.html">Model Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../deep-learning/index.html">Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../traditional-ml/index.html">Traditional ML</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../deployment/index.html">Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tracking.html">MLflow Tracking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../system-metrics/index.html">System Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../projects.html">MLflow Projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../models.html">MLflow Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../model-registry.html">MLflow Model Registry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../recipes.html">MLflow Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../plugins.html">MLflow Plugins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../auth/index.html">MLflow Authentication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../search-runs.html">Search Runs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../search-experiments.html">Search Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../R-api.html">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../java_api/index.html">Java API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../rest-api.html">REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../docker.html">Official MLflow Docker Image</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community-model-flavors.html">Community Model Flavors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorials-and-examples/index.html">Tutorials and Examples</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            










<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="../../../index.html">LLMs</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="../../index.html">MLflow Sentence-Transformers Flavor</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Introduction to Sentence Transformers and MLflow</li>
    
    
    <!-- <li class="wy-breadcrumbs-aside">
      <a href="https://github.com/mlflow/mlflow/blob/master/docs/source/llms/sentence-transformers/tutorials/quickstart/sentence-transformers-quickstart.ipynb" class="fa fa-github"> Edit on GitHub</a>
    </li> -->
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Introduction-to-Sentence-Transformers-and-MLflow">
<h1>Introduction to Sentence Transformers and MLflow<a class="headerlink" href="#Introduction-to-Sentence-Transformers-and-MLflow" title="Permalink to this headline"> </a></h1>
<p>Welcome to our tutorial on leveraging <strong>Sentence Transformers</strong> with <strong>MLflow</strong> for advanced natural language processing and model management.</p>
<a href="https://raw.githubusercontent.com/mlflow/mlflow/master/docs/source/llms/sentence-transformers/tutorials/quickstart/sentence-transformers-quickstart.ipynb" class="notebook-download-btn"><i class="fas fa-download"></i>Download this Notebook</a><br><div class="section" id="Learning-Objectives">
<h2>Learning Objectives<a class="headerlink" href="#Learning-Objectives" title="Permalink to this headline"> </a></h2>
<ul class="simple">
<li><p>Set up a pipeline for sentence embeddings with <code class="docutils literal notranslate"><span class="pre">sentence-transformers</span></code>.</p></li>
<li><p>Log models and configurations using MLflow.</p></li>
<li><p>Understand and apply model signatures in MLflow to <code class="docutils literal notranslate"><span class="pre">sentence-transformers</span></code>.</p></li>
<li><p>Deploy and use models for inference with MLflow’s features.</p></li>
</ul>
<div class="section" id="What-are-Sentence-Transformers?">
<h3>What are Sentence Transformers?<a class="headerlink" href="#What-are-Sentence-Transformers?" title="Permalink to this headline"> </a></h3>
<p>Sentence Transformers, an extension of the Hugging Face Transformers library, are designed for generating semantically rich sentence embeddings. They utilize models like BERT and RoBERTa, fine-tuned for tasks such as semantic search and text clustering, producing high-quality sentence-level embeddings.</p>
</div>
<div class="section" id="Benefits-of-Integrating-MLflow-with-Sentence-Transformers">
<h3>Benefits of Integrating MLflow with Sentence Transformers<a class="headerlink" href="#Benefits-of-Integrating-MLflow-with-Sentence-Transformers" title="Permalink to this headline"> </a></h3>
<p>Combining MLflow with Sentence Transformers enhances NLP projects by:</p>
<ul class="simple">
<li><p>Streamlining experiment management and logging.</p></li>
<li><p>Offering better control over model versions and configurations.</p></li>
<li><p>Ensuring reproducibility of results and model predictions.</p></li>
<li><p>Simplifying the deployment process in production environments.</p></li>
</ul>
<p>This integration empowers efficient tracking, management, and deployment of NLP applications.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Disable tokenizers warnings when constructing pipelines</span>
<span class="o">%</span><span class="k">env</span> TOKENIZERS_PARALLELISM=false

<span class="kn">import</span> <span class="nn">warnings</span>

<span class="c1"># Disable a few less-than-useful UserWarnings from setuptools and pydantic</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
env: TOKENIZERS_PARALLELISM=false
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Setting-Up-the-Environment-for-Sentence-Embedding">
<h2>Setting Up the Environment for Sentence Embedding<a class="headerlink" href="#Setting-Up-the-Environment-for-Sentence-Embedding" title="Permalink to this headline"> </a></h2>
<p>Begin your journey with Sentence Transformers and MLflow by establishing the core working environment.</p>
<div class="section" id="Key-Steps-for-Initialization">
<h3>Key Steps for Initialization<a class="headerlink" href="#Key-Steps-for-Initialization" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p>Import necessary libraries: <code class="docutils literal notranslate"><span class="pre">SentenceTransformer</span></code> and <code class="docutils literal notranslate"><span class="pre">mlflow</span></code>.</p></li>
<li><p>Initialize the <code class="docutils literal notranslate"><span class="pre">&quot;all-MiniLM-L6-v2&quot;</span></code> Sentence Transformer model.</p></li>
</ul>
</div>
<div class="section" id="Model-Initialization">
<h3>Model Initialization<a class="headerlink" href="#Model-Initialization" title="Permalink to this headline"> </a></h3>
<p>The compact and efficient <code class="docutils literal notranslate"><span class="pre">&quot;all-MiniLM-L6-v2&quot;</span></code> model is chosen for its effectiveness in generating meaningful sentence embeddings. Explore more models at the <a class="reference external" href="https://huggingface.co/models?pipeline_tag=sentence-similarity&amp;sort=trending">Hugging Face Hub</a>.</p>
</div>
<div class="section" id="Purpose-of-the-Model">
<h3>Purpose of the Model<a class="headerlink" href="#Purpose-of-the-Model" title="Permalink to this headline"> </a></h3>
<p>This model excels in transforming sentences into semantically rich embeddings, applicable in various NLP tasks like semantic search and clustering.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>

<span class="kn">import</span> <span class="nn">mlflow</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s2">&quot;all-MiniLM-L6-v2&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Defining-the-Model-Signature-with-MLflow">
<h2>Defining the Model Signature with MLflow<a class="headerlink" href="#Defining-the-Model-Signature-with-MLflow" title="Permalink to this headline"> </a></h2>
<p>Defining the model signature is a crucial step in setting up our Sentence Transformer model for consistent and expected behavior during inference.</p>
<div class="section" id="Steps-for-Signature-Definition">
<h3>Steps for Signature Definition<a class="headerlink" href="#Steps-for-Signature-Definition" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p><strong>Prepare Example Sentences</strong>: Define example sentences to demonstrate the model’s input and output formats.</p></li>
<li><p><strong>Generate Model Signature</strong>: Use the <code class="docutils literal notranslate"><span class="pre">mlflow.models.infer_signature</span></code> function with the model’s input and output to automatically define the signature.</p></li>
</ul>
</div>
<div class="section" id="Importance-of-the-Model-Signature">
<h3>Importance of the Model Signature<a class="headerlink" href="#Importance-of-the-Model-Signature" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p><strong>Clarity in Data Formats</strong>: Ensures clear documentation of the data types and structures the model expects and produces.</p></li>
<li><p><strong>Model Deployment and Usage</strong>: Crucial for deploying models to production, ensuring the model receives inputs in the correct format and produces expected outputs.</p></li>
<li><p><strong>Error Prevention</strong>: Helps in preventing errors during model inference by enforcing consistent data formats.</p></li>
</ul>
<p><strong>NOTE</strong>: The <code class="docutils literal notranslate"><span class="pre">List[str]</span></code> input type is equivalent at inference time to <code class="docutils literal notranslate"><span class="pre">str</span></code>. The MLflow flavor uses a <code class="docutils literal notranslate"><span class="pre">ColSpec[str]</span></code> definition for the input type.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">example_sentences</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;A sentence to encode.&quot;</span><span class="p">,</span> <span class="s2">&quot;Another sentence to encode.&quot;</span><span class="p">]</span>

<span class="c1"># Infer the signature of the custom model by providing an input example and the resultant prediction output.</span>
<span class="c1"># We&#39;re not including any custom inference parameters in this example, but you can include them as a third argument</span>
<span class="c1"># to infer_signature(), as you will see in the advanced tutorials for Sentence Transformers.</span>
<span class="n">signature</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">infer_signature</span><span class="p">(</span>
    <span class="n">model_input</span><span class="o">=</span><span class="n">example_sentences</span><span class="p">,</span>
    <span class="n">model_output</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">example_sentences</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># Visualize the signature</span>
<span class="n">signature</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
inputs:
  [string]
outputs:
  [Tensor(&#39;float32&#39;, (-1, 384))]
params:
  None
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Creating-an-experiment">
<h2>Creating an experiment<a class="headerlink" href="#Creating-an-experiment" title="Permalink to this headline"> </a></h2>
<p>We create a new MLflow Experiment so that the run we’re going to log our model to does not log to the default experiment and instead has its own contextually relevant entry.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># If you are running this tutorial in local mode, leave the next line commented out.</span>
<span class="c1"># Otherwise, uncomment the following line and set your tracking uri to your local or remote tracking server.</span>

<span class="c1"># mlflow.set_tracking_uri(&quot;http://127.0.0.1:8080&quot;)</span>

<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;Introduction to Sentence Transformers&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;Experiment: artifact_location=&#39;file:///Users/benjamin.wilson/repos/mlflow-fork/mlflow/docs/source/llms/sentence-transformers/tutorials/quickstart/mlruns/469990615226680434&#39;, creation_time=1701280211449, experiment_id=&#39;469990615226680434&#39;, last_update_time=1701280211449, lifecycle_stage=&#39;active&#39;, name=&#39;Introduction to Sentence Transformers&#39;, tags={}&gt;
</pre></div></div>
</div>
</div>
<div class="section" id="Logging-the-Sentence-Transformer-Model-with-MLflow">
<h2>Logging the Sentence Transformer Model with MLflow<a class="headerlink" href="#Logging-the-Sentence-Transformer-Model-with-MLflow" title="Permalink to this headline"> </a></h2>
<p>Logging the model in MLflow is essential for tracking, version control, and deployment, following the initialization and signature definition of our Sentence Transformer model.</p>
<div class="section" id="Steps-for-Logging-the-Model">
<h3>Steps for Logging the Model<a class="headerlink" href="#Steps-for-Logging-the-Model" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p><strong>Start an MLflow Run</strong>: Initiate a new run with <code class="docutils literal notranslate"><span class="pre">mlflow.start_run()</span></code>, grouping all logging operations.</p></li>
<li><p><strong>Log the Model</strong>: Use <code class="docutils literal notranslate"><span class="pre">mlflow.sentence_transformers.log_model</span></code> to log the model, providing the model object, artifact path, signature, and an input example.</p></li>
</ul>
</div>
<div class="section" id="Importance-of-Model-Logging">
<h3>Importance of Model Logging<a class="headerlink" href="#Importance-of-Model-Logging" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p><strong>Model Management</strong>: Facilitates the model’s lifecycle management from training to deployment.</p></li>
<li><p><strong>Reproducibility and Tracking</strong>: Enables tracking of model versions and ensures reproducibility.</p></li>
<li><p><strong>Ease of Deployment</strong>: Simplifies deployment by allowing models to be easily deployed for inference.</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>
    <span class="n">logged_model</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">sentence_transformers</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;sbert_model&quot;</span><span class="p">,</span>
        <span class="n">signature</span><span class="o">=</span><span class="n">signature</span><span class="p">,</span>
        <span class="n">input_example</span><span class="o">=</span><span class="n">example_sentences</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Loading-the-Model-and-Testing-Inference">
<h2>Loading the Model and Testing Inference<a class="headerlink" href="#Loading-the-Model-and-Testing-Inference" title="Permalink to this headline"> </a></h2>
<p>After logging the Sentence Transformer model in MLflow, we demonstrate how to load and test it for real-time inference.</p>
<div class="section" id="Loading-the-Model-as-a-PyFunc">
<h3>Loading the Model as a PyFunc<a class="headerlink" href="#Loading-the-Model-as-a-PyFunc" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p><strong>Why PyFunc</strong>: Load the logged model using <code class="docutils literal notranslate"><span class="pre">mlflow.pyfunc.load_model</span></code> for seamless integration into Python-based services or applications.</p></li>
<li><p><strong>Model URI</strong>: Use the <code class="docutils literal notranslate"><span class="pre">logged_model.model_uri</span></code> to accurately locate and load the model from MLflow.</p></li>
</ul>
</div>
<div class="section" id="Conducting-Inference-Tests">
<h3>Conducting Inference Tests<a class="headerlink" href="#Conducting-Inference-Tests" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p><strong>Test Sentences</strong>: Define sentences to test the model’s embedding generation capabilities.</p></li>
<li><p><strong>Performing Predictions</strong>: Use the model’s <code class="docutils literal notranslate"><span class="pre">predict</span></code> method with test sentences to obtain embeddings.</p></li>
<li><p><strong>Printing Embedding Lengths</strong>: Verify embedding generation by checking the length of embedding arrays, corresponding to the dimensionality of each sentence representation.</p></li>
</ul>
</div>
<div class="section" id="Importance-of-Inference-Testing">
<h3>Importance of Inference Testing<a class="headerlink" href="#Importance-of-Inference-Testing" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p><strong>Model Validation</strong>: Confirm the model’s expected behavior and data processing capability upon loading.</p></li>
<li><p><strong>Deployment Readiness</strong>: Validate the model’s readiness for real-time integration into application services.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inference_test</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;I enjoy pies of both apple and cherry.&quot;</span><span class="p">,</span> <span class="s2">&quot;I prefer cookies.&quot;</span><span class="p">]</span>

<span class="c1"># Load our custom model by providing the uri for where the model was logged.</span>
<span class="n">loaded_model_pyfunc</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">logged_model</span><span class="o">.</span><span class="n">model_uri</span><span class="p">)</span>

<span class="c1"># Perform a quick test to ensure that our loaded model generates the correct output</span>
<span class="n">embeddings_test</span> <span class="o">=</span> <span class="n">loaded_model_pyfunc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">inference_test</span><span class="p">)</span>

<span class="c1"># Verify that the output is a list of lists of floats (our expected output format)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The return structure length is: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">embeddings_test</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">embedding</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">embeddings_test</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The size of embedding </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> is: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">embeddings_test</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
The return structure length is: 2
The size of embedding 1 is: 384
The size of embedding 2 is: 384
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Displaying-Samples-of-Generated-Embeddings">
<h2>Displaying Samples of Generated Embeddings<a class="headerlink" href="#Displaying-Samples-of-Generated-Embeddings" title="Permalink to this headline"> </a></h2>
<p>Examine the content of embeddings to verify their quality and understand the model’s output.</p>
<div class="section" id="Inspecting-the-Embedding-Samples">
<h3>Inspecting the Embedding Samples<a class="headerlink" href="#Inspecting-the-Embedding-Samples" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p><strong>Purpose of Sampling</strong>: Inspect a sample of the entries in each embedding to understand the vector representations generated by the model.</p></li>
<li><p><strong>Printing Embedding Samples</strong>: Print the first 10 entries of each embedding vector using <code class="docutils literal notranslate"><span class="pre">embedding[:10]</span></code> to get a glimpse into the model’s output.</p></li>
</ul>
</div>
<div class="section" id="Why-Sampling-is-Important">
<h3>Why Sampling is Important<a class="headerlink" href="#Why-Sampling-is-Important" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p><strong>Quality Check</strong>: Sampling provides a quick way to verify the embeddings’ quality and ensures they are meaningful and non-degenerate.</p></li>
<li><p><strong>Understanding Model Output</strong>: Seeing parts of the embedding vectors offers an intuitive understanding of the model’s output, beneficial for debugging and development.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">embedding</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">embeddings_test</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The sample of the first 10 entries in embedding </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> is: </span><span class="si">{</span><span class="n">embedding</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
The sample of the first 10 entries in embedding 1 is: [ 0.04866192 -0.03687946  0.02408808  0.03534171 -0.12739632  0.00999414
  0.07135344 -0.01433522  0.04296691 -0.00654414]
The sample of the first 10 entries in embedding 2 is: [-0.03879027 -0.02373698  0.01314073  0.03589077 -0.01641303 -0.0857707
  0.08282158 -0.03173266  0.04507608  0.02777079]
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Native-Model-Loading-in-MLflow-for-Extended-Functionality">
<h2>Native Model Loading in MLflow for Extended Functionality<a class="headerlink" href="#Native-Model-Loading-in-MLflow-for-Extended-Functionality" title="Permalink to this headline"> </a></h2>
<p>Explore the full range of Sentence Transformer functionalities with MLflow’s support for native model loading.</p>
<div class="section" id="Why-Support-Native-Loading?">
<h3>Why Support Native Loading?<a class="headerlink" href="#Why-Support-Native-Loading?" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p><strong>Access to Native Functionalities</strong>: Native loading unlocks all the features of the Sentence Transformer model, essential for advanced NLP tasks.</p></li>
<li><p><strong>Loading the Model Natively</strong>: Use <code class="docutils literal notranslate"><span class="pre">mlflow.sentence_transformers.load_model</span></code> to load the model with its full capabilities, enhancing flexibility and efficiency.</p></li>
</ul>
</div>
<div class="section" id="Generating-Embeddings-Using-Native-Model">
<h3>Generating Embeddings Using Native Model<a class="headerlink" href="#Generating-Embeddings-Using-Native-Model" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p><strong>Model Encoding</strong>: Employ the model’s native <code class="docutils literal notranslate"><span class="pre">encode</span></code> method to generate embeddings, taking advantage of optimized functionality.</p></li>
<li><p><strong>Importance of Native Encoding</strong>: Native encoding ensures the utilization of the model’s full embedding generation capabilities, suitable for large-scale or complex NLP applications.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the saved model as a native Sentence Transformers model (unlike above, where we loaded as a generic python function)</span>
<span class="n">loaded_model_native</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">sentence_transformers</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">logged_model</span><span class="o">.</span><span class="n">model_uri</span><span class="p">)</span>

<span class="c1"># Use the native model to generate embeddings by calling encode() (unlike for the generic python function which uses the single entrypoint of `predict`)</span>
<span class="n">native_embeddings</span> <span class="o">=</span> <span class="n">loaded_model_native</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">inference_test</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">embedding</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">native_embeddings</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;The sample of the native library encoding call for embedding </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> is: </span><span class="si">{</span><span class="n">embedding</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2023/11/30 15:50:24 INFO mlflow.sentence_transformers: &#39;runs:/eeab3c1b13594fdea13e07585b1c0596/sbert_model&#39; resolved as &#39;file:///Users/benjamin.wilson/repos/mlflow-fork/mlflow/docs/source/llms/sentence-transformers/tutorials/quickstart/mlruns/469990615226680434/eeab3c1b13594fdea13e07585b1c0596/artifacts/sbert_model&#39;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
The sample of the native library encoding call for embedding 1 is: [ 0.04866192 -0.03687946  0.02408808  0.03534171 -0.12739632  0.00999414
  0.07135344 -0.01433522  0.04296691 -0.00654414]
The sample of the native library encoding call for embedding 2 is: [-0.03879027 -0.02373698  0.01314073  0.03589077 -0.01641303 -0.0857707
  0.08282158 -0.03173266  0.04507608  0.02777079]
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Conclusion:-Embracing-the-Power-of-Sentence-Transformers-with-MLflow">
<h2>Conclusion: Embracing the Power of Sentence Transformers with MLflow<a class="headerlink" href="#Conclusion:-Embracing-the-Power-of-Sentence-Transformers-with-MLflow" title="Permalink to this headline"> </a></h2>
<p>As we reach the end of our Introduction to Sentence Transformers tutorial, we have successfully navigated the basics of integrating the Sentence Transformers library with MLflow. This foundational knowledge sets the stage for more advanced and specialized applications in the field of Natural Language Processing (NLP).</p>
<div class="section" id="Recap-of-Key-Learnings">
<h3>Recap of Key Learnings<a class="headerlink" href="#Recap-of-Key-Learnings" title="Permalink to this headline"> </a></h3>
<ol class="arabic simple">
<li><p><strong>Integration Basics</strong>: We covered the essential steps of loading and logging a Sentence Transformer model using MLflow. This process demonstrated the simplicity and effectiveness of integrating cutting-edge NLP tools within MLflow’s ecosystem.</p></li>
<li><p><strong>Signature and Inference</strong>: Through the creation of a model signature and the execution of inference tasks, we showcased how to operationalize the Sentence Transformer model, ensuring that it’s ready for real-world applications.</p></li>
<li><p><strong>Model Loading and Prediction</strong>: We explored two ways of loading the model - as a PyFunc model and using the native Sentence Transformers loading mechanism. This dual approach highlighted the versatility of MLflow in accommodating different model interaction methods.</p></li>
<li><p><strong>Embeddings Exploration</strong>: By generating and examining sentence embeddings, we glimpsed the transformative potential of transformer models in capturing semantic information from text.</p></li>
</ol>
</div>
<div class="section" id="Looking-Ahead">
<h3>Looking Ahead<a class="headerlink" href="#Looking-Ahead" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p><strong>Expanding Horizons</strong>: While this tutorial focused on the foundational aspects of Sentence Transformers and MLflow, there’s a whole world of advanced applications waiting to be explored. From semantic similarity analysis to paraphrase mining, the potential use cases are vast and varied.</p></li>
<li><p><strong>Continued Learning</strong>: We strongly encourage you to delve into the other tutorials in this series, which dive deeper into more intriguing use cases like similarity analysis, semantic search, and paraphrase mining. These tutorials will provide you with a broader understanding and more practical applications of Sentence Transformers in various NLP tasks.</p></li>
</ul>
</div>
<div class="section" id="Final-Thoughts">
<h3>Final Thoughts<a class="headerlink" href="#Final-Thoughts" title="Permalink to this headline"> </a></h3>
<p>The journey into NLP with Sentence Transformers and MLflow is just beginning. With the skills and insights gained from this tutorial, you are well-equipped to explore more complex and exciting applications. The integration of advanced NLP models with MLflow’s robust management and deployment capabilities opens up new avenues for innovation and exploration in the field of language understanding and beyond.</p>
<p>Thank you for joining us on this introductory journey, and we look forward to seeing how you apply these tools and concepts in your NLP endeavors!</p>
</div>
</div>
</div>


              </div>
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../../index.html" class="btn btn-neutral" title="MLflow Sentence-Transformers Flavor" accesskey="p"><span class="db-icon db-icon-chevron-left"></span> Previous</a>
      
      
        <a href="../paraphrase-mining/paraphrase-mining-sentence-transformers.html" class="btn btn-neutral" title="Advanced Paraphrase Mining with Sentence Transformers and MLflow" accesskey="n">Next <span class="db-icon db-icon-chevron-right"></span></a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; MLflow Project, a Series of LF Projects, LLC. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'../../../../',
      VERSION:'2.14.2.dev0',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      LINK_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  

  <script type="text/javascript" src="../../../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/jquery.waypoints.min.js"></script>

  
  
  
  <script type="text/javascript">var CLIPPY_SVG_PATH = "../../../../_static/clippy.svg";</script>
  <script type="text/javascript" src="../../../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  

  
  <script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        function copyToClipboard(text) {
            const textarea = document.createElement('textarea');
            textarea.value = text;
            document.body.appendChild(textarea);
            textarea.select();
            document.execCommand('copy');
            document.body.removeChild(textarea);
        }
        // Get the code block designator class entries
        const allHighlights = document.querySelectorAll('.highlight');
        // Disable copyable links for notebook cell numbering and for cell outputs
        const highlights = Array.from(allHighlights).filter(highlight => !highlight.closest('.highlight-none') && 
            !highlight.closest('.nboutput'));
    
        highlights.forEach(function(highlight) {
            const copyIcon = document.createElement('span');
            copyIcon.classList.add('copy-icon');
            copyIcon.innerHTML = '&#xf0ea;';

            copyIcon.addEventListener('click', function() {
                const code = highlight.querySelector('pre').textContent;
                copyToClipboard(code);

                // Flash effect on click
                this.style.color = '#0194E2';
                setTimeout(() => {
                    this.style.color = ''; 
                }, 100);

                // Display "Code copied to clipboard" near the clicked icon
                const message = document.createElement('span');
                message.textContent = "Copied!";
                message.classList.add('copy-message'); 

                // Append the message to the icon
                this.appendChild(message);

                setTimeout(() => {
                    this.removeChild(message);
                }, 500);
            });

            highlight.appendChild(copyIcon);
        });
    });
  </script>


<script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        // Force download for notebook-download-btn
        const downloadButtons = document.querySelectorAll('.notebook-download-btn');
        downloadButtons.forEach(function(button) {
            button.addEventListener('click', function(event) {
                event.preventDefault(); // Prevent default behavior

                // Fetch the raw content of the notebook from GitHub
                fetch(button.href)
                    .then(response => response.blob())
                    .then(blob => {
                        const url = window.URL.createObjectURL(blob);
                        const link = document.createElement('a');
                        link.style.display = 'none';
                        link.href = url;
                        const filename = button.href.split('/').pop();
                        link.download = filename; 

                        document.body.appendChild(link);
                        link.click();

                        window.URL.revokeObjectURL(url);
                        document.body.removeChild(link);
                    })
                    .catch(err => console.error('Error fetching the notebook:', err));
            });
        });
    });
</script> 
</body>
</html>