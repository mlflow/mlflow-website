
  

<!DOCTYPE html>
<!-- source: docs/source/llms/transformers/index.rst -->
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>MLflow Transformers Flavor &mdash; MLflow 2.14.4.dev0 documentation</title>
  
   
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <link rel="canonical" href="https://mlflow.org/docs/latest/llms/transformers/index.html">
  
  
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    

    

  
    
        <!-- Google Tag Manager -->
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer',"GTM-N6WMTTJ");</script>
        <!-- End Google Tag Manager -->
    

  

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/cards.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/grids.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/mobile.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/simple-cards.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/tabs.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="../../genindex.html"/>
        <link rel="search" title="Search" href="../../search.html"/>
    <link rel="top" title="MLflow 2.14.4.dev0 documentation" href="../../index.html"/>
        <link rel="up" title="LLMs" href="../index.html"/>
        <link rel="next" title="Introduction to MLflow and Transformers" href="/tutorials/text-generation/text-generation.html"/>
        <link rel="prev" title="Prompt Engineering UI (Experimental)" href="/../prompt-engineering/index.html"/> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>
<script type="text/javascript" src="../../_static/jquery.js"></script>
<script type="text/javascript" src="../../_static/underscore.js"></script>
<script type="text/javascript" src="../../_static/doctools.js"></script>
<script type="text/javascript" src="../../_static/languagesections.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>

<body class="wy-body-for-nav" role="document">
  
    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->
  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <ul>
  <li class="menu-toggle">
    <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
    <a href="../../index.html" class="wy-nav-top-logo"
      ><img src="../../_static/MLflow-logo-final-black.png" alt="MLflow"
    /></a>
    <span class="version">2.14.4.dev0</span>
  </li>
</ul>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side relative">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
  </form>
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../index.html" class="main-navigation-home"><img src="../../_static/icons/nav-home.svg"> MLflow</a>
    

    
      

      
        <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../introduction/index.html">What is MLflow?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting-started/index.html">Getting Started with MLflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../new-features/index.html">New Features</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">LLMs</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../index.html#id1">MLflow Tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#id2">MLflow Deployments Server for LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#id3">LLM Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#id4">Prompt Engineering UI</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#native-mlflow-flavors-for-llms">Native MLflow Flavors for LLMs</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">MLflow Transformers Flavor</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#getting-started-with-the-mlflow-transformers-flavor-tutorials-and-guides">Getting Started with the MLflow Transformers Flavor - Tutorials and Guides</a></li>
<li class="toctree-l4"><a class="reference internal" href="#important-details-to-be-aware-of-with-the-transformers-flavor">Important Details to be aware of with the transformers flavor</a></li>
<li class="toctree-l4"><a class="reference internal" href="#working-with-tasks-for-transformer-pipelines">Working with <code class="docutils literal notranslate"><span class="pre">tasks</span></code> for Transformer Pipelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id1">Detailed Documentation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#learn-more-about-transformers">Learn more about Transformers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../openai/index.html">MLflow OpenAI Flavor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sentence-transformers/index.html">MLflow Sentence-Transformers Flavor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../langchain/index.html">MLflow LangChain Flavor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../llama-index/index.html">MLflow LlamaIndex Flavor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../index.html#explore-the-native-llm-flavors">Explore the Native LLM Flavors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#id5">LLM Tracking in MLflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#tutorials-and-use-case-guides-for-llms-in-mlflow">Tutorials and Use Case Guides for LLMs in MLflow</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../model-evaluation/index.html">Model Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deep-learning/index.html">Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../traditional-ml/index.html">Traditional ML</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deployment/index.html">Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tracking.html">MLflow Tracking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../system-metrics/index.html">System Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../projects.html">MLflow Projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../models.html">MLflow Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model-registry.html">MLflow Model Registry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../recipes.html">MLflow Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../plugins.html">MLflow Plugins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../auth/index.html">MLflow Authentication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../search-runs.html">Search Runs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../search-experiments.html">Search Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../R-api.html">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../java_api/index.html">Java API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rest-api.html">REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docker.html">Official MLflow Docker Image</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community-model-flavors.html">Community Model Flavors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials-and-examples/index.html">Tutorials and Examples</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            










<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="../index.html">LLMs</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>MLflow Transformers Flavor</li>
    
    
    <!-- <li class="wy-breadcrumbs-aside">
      <a href="https://github.com/mlflow/mlflow/blob/master/docs/source/llms/transformers/index.rst" class="fa fa-github"> Edit on GitHub</a>
    </li> -->
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  <div class="section" id="mlflow-transformers-flavor">
<h1>MLflow Transformers Flavor<a class="headerlink" href="#mlflow-transformers-flavor" title="Permalink to this headline"> </a></h1>
<div class="admonition attention">
<p class="admonition-title">Attention</p>
<p>The <code class="docutils literal notranslate"><span class="pre">transformers</span></code> flavor is in active development and is marked as Experimental. Public APIs may change and new features are
subject to be added as additional functionality is brought to the flavor.</p>
</div>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline"> </a></h2>
<p><strong>Transformers</strong> by 🤗 <a class="reference external" href="https://huggingface.co/docs/transformers/index">Hugging Face</a> represents a cornerstone in the realm of
machine learning, offering state-of-the-art capabilities for a multitude of frameworks including <a class="reference external" href="https://pytorch.org/">PyTorch</a>,
<a class="reference external" href="https://www.tensorflow.org/">TensorFlow</a>, and <a class="reference external" href="https://jax.readthedocs.io/en/latest/notebooks/quickstart.html">JAX</a>.
This library has become the de facto standard for natural language processing (NLP) and audio transcription processing.
It also provides a compelling and advanced set of options for computer vision and multimodal AI tasks.
Transformers achieves all of this by providing pre-trained models and accessible high-level APIs that are not only powerful
but also versatile and easy to implement.</p>
<p>For instance, one of the cornerstones of the simplicity of the transformers library is the <a class="reference external" href="https://huggingface.co/transformers/main_classes/pipelines.html">pipeline API</a>,
an encapsulation of the most common NLP tasks into a single API call. This API allows users to perform a variety of tasks based on the specified task without
having to worry about the underlying model or the preprocessing steps.</p>
<div class="figure align-center" id="id2">
<a class="reference internal image-reference" href="../../_images/transformers-pipeline-architecture.png"><img alt="Transformers Pipeline Architecture" src="../../_images/transformers-pipeline-architecture.png" style="width: 80%;" /></a>
<p class="caption"><span class="caption-text">Transformers Pipeline Architecture for the Whisper Model</span><a class="headerlink" href="#id2" title="Permalink to this image"> </a></p>
</div>
<p>The integration of the Transformers library with MLflow enhances the management of machine learning workflows, from experiment
tracking to model deployment. This combination offers a robust and efficient pathway for incorporating advanced NLP and AI capabilities
into your applications.</p>
<p><strong>Key Features of the Transformers Library</strong>:</p>
<ul class="simple">
<li><p><strong>Access to Pre-trained Models</strong>: A vast collection of <a class="reference external" href="https://huggingface.co/models">pre-trained models</a> for various tasks, minimizing training time and resources.</p></li>
<li><p><strong>Task Versatility</strong>: Support for multiple modalities including text, image, and speech processing tasks.</p></li>
<li><p><strong>Framework Interoperability</strong>: Compatibility with PyTorch, TensorFlow, JAX, ONNX, and TorchScript.</p></li>
<li><p><strong>Community Support</strong>: An active community for collaboration and support, accessible via forums and the Hugging Face Hub.</p></li>
</ul>
<p><strong>MLflow’s Transformers Flavor</strong>:</p>
<p>MLflow supports the use of the Transformers package by providing:</p>
<ul class="simple">
<li><p><strong>Simplified Experiment Tracking</strong>: Efficient logging of parameters, metrics, and models during the <a class="reference external" href="https://huggingface.co/docs/transformers/main_classes/trainer">fine-tuning process</a>.</p></li>
<li><p><strong>Effortless Model Deployment</strong>: Streamlined deployment to various production environments.</p></li>
<li><p><strong>Library Integration</strong>: Integration with HuggingFace libraries like <a class="reference external" href="https://huggingface.co/docs/accelerate/index">Accelerate</a>, <a class="reference external" href="https://huggingface.co/docs/peft/en/index">PEFT</a> for model optimization.</p></li>
<li><p><strong>Prompt Management</strong>: <a class="reference external" href="guide/index.html#saving-prompt-templates-with-transformer-pipelines">Save prompt templates</a> with transformers pipelines to optimize inference with less boilerplate.</p></li>
</ul>
<p><strong>Example Use Case:</strong></p>
<p>For an illustration of fine-tuning a model and logging the results with MLflow, refer to the <a class="reference internal" href="#transformers-finetuning-tutorials"><span class="std std-ref">fine-tuning tutorials</span></a>. These tutorial demonstrate the process of fine-tuning a pretrained foundational model into the application-specific model such as a spam classifier, SQL generator. MLflow plays a pivotal role in tracking the fine-tuning process, including datasets, hyperparameters, performance metrics, and the final model artifacts. The image below shows the result of the tutorial within the MLflow UI.</p>
<div class="figure align-center" id="id3">
<a class="reference internal image-reference" href="../../_images/transformers-fine-tuning.png"><img alt="Fine-tuning a Transformers Model with MLflow" src="../../_images/transformers-fine-tuning.png" style="width: 70%;" /></a>
<p class="caption"><span class="caption-text">Fine-tuning a Transformers Model with MLflow</span><a class="headerlink" href="#id3" title="Permalink to this image"> </a></p>
</div>
<div class="section" id="deployment-made-easy">
<h3>Deployment Made Easy<a class="headerlink" href="#deployment-made-easy" title="Permalink to this headline"> </a></h3>
<p>Once a model is trained, it needs to be <a class="reference external" href="guide/index.html#example-of-loading-a-transformers-model-as-a-python-function">deployed for inference</a>.
MLflow’s integration with Transformers simplifies this by providing functions such as <a class="reference internal" href="../../python_api/mlflow.transformers.html#mlflow.transformers.load_model" title="mlflow.transformers.load_model"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.transformers.load_model()</span></code></a> and
<a class="reference internal" href="../../python_api/mlflow.pyfunc.html#mlflow.pyfunc.load_model" title="mlflow.pyfunc.load_model"><code class="xref py py-func docutils literal notranslate"><span class="pre">mlflow.pyfunc.load_model()</span></code></a>, which allow for easy model serving.
As part of the feature support for enhanced inference with transformers, MLflow provides mechanisms to enable the use of <a class="reference external" href="guide/index.html#scalability-for-inference">inference
arguments</a> that can reduce the computational overhead and lower the memory requirements
for deployment.</p>
</div>
</div>
<div class="section" id="getting-started-with-the-mlflow-transformers-flavor-tutorials-and-guides">
<h2>Getting Started with the MLflow Transformers Flavor - Tutorials and Guides<a class="headerlink" href="#getting-started-with-the-mlflow-transformers-flavor-tutorials-and-guides" title="Permalink to this headline"> </a></h2>
<p>Below, you will find a number of guides that focus on different use cases using <cite>transformers</cite>  that leverage MLflow’s
APIs for tracking and inference capabilities.</p>
<div class="toctree-wrapper compound">
</div>
<div class="section" id="introductory-quickstart-to-using-transformers-with-mlflow">
<h3>Introductory Quickstart to using Transformers with MLflow<a class="headerlink" href="#introductory-quickstart-to-using-transformers-with-mlflow" title="Permalink to this headline"> </a></h3>
<p>If this is your first exposure to transformers or use transformers extensively but are new to MLflow, this is a great place to start.</p>
<section>
    <article class="simple-grid">
        <div class="simple-card">
            <a href="tutorials/text-generation/text-generation.html">
                <div class="header">
                    Quickstart: Text Generation with Transformers
                </div>
                <p>
                    Learn how to leverage the transformers integration with MLflow in this <strong>introductory quickstart</strong>.
                </p>
            </a>
        </div>
    </article>
</section></div>
<div class="section" id="transformers-fine-tuning-tutorials-with-mlflow">
<span id="transformers-finetuning-tutorials"></span><h3>Transformers Fine-Tuning Tutorials with MLflow<a class="headerlink" href="#transformers-fine-tuning-tutorials-with-mlflow" title="Permalink to this headline"> </a></h3>
<p>Fine-tuning a model is a common task in machine learning workflows. These tutorials are designed to showcase how to fine-tune a model using the transformers library with harnessing MLflow’s APIs for tracking experiment configurations and results.</p>
<section>
    <article class="simple-grid">
        <div class="simple-card">
            <a href="tutorials/fine-tuning/transformers-fine-tuning.html">
                <div class="header">
                    Fine tuning a transformers Foundation Model
                </div>
                <p>
                    Learn how to fine-tune a transformers model using MLflow to keep track of the training process and to log a use-case-specific tuned pipeline.
                </p>
            </a>
        </div>

        <div class="simple-card">
            <a href="tutorials/fine-tuning/transformers-peft.html">
                <div class="header">
                    Fine tuning LLMs efficiently using PEFT and MLflow
                </div>
                <p>
                    Learn how to fine-tune a large foundational models with significantly reduced memory usage using PEFT (QLoRA) and MLflow.
                </p>
            </a>
        </div>
</section></div>
<div class="section" id="use-case-tutorials-for-transformers-with-mlflow">
<h3>Use Case Tutorials for Transformers with MLflow<a class="headerlink" href="#use-case-tutorials-for-transformers-with-mlflow" title="Permalink to this headline"> </a></h3>
<p>Interested in learning about how to leverage transformers for tasks other than basic text generation? Want to learn more about the breadth of problems that you can solve with transformers and MLflow?</p>
<p>These more advanced tutorials are designed to showcase different applications of the transformers model architecture and how to leverage MLflow to track and deploy these models.</p>
<section>
    <article class="simple-grid">
        <div class="simple-card">
            <a href="tutorials/audio-transcription/whisper.html">
                <div class="header">
                    Audio Transcription with Transformers
                </div>
                <p>
                    Learn how to leverage the Whisper Model with MLflow to generate accurate audio transcriptions.
                </p>
            </a>
        </div>
        <div class="simple-card">
            <a href="tutorials/translation/component-translation.html">
                <div class="header">
                    Translation with Transformers
                </div>
                <p>
                    Learn about the options for saving and loading transformers models in MLflow for customization of your workflows with a fun translation example!
                </p>
            </a>
        </div>
        <div class="simple-card">
            <a href="tutorials/conversational/conversational-model.html">
                <div class="header">
                    Chat with Transformers
                </div>
                <p>
                    Learn the basics of stateful chat Conversational Pipelines with Transformers and MLflow.
                </p>
            </a>
        </div>
        <div class="simple-card">
            <a href="tutorials/conversational/pyfunc-chat-model.html">
                <div class="header">
                    Building and Serving an OpenAI-Compatible Chatbot
                </div>
                <p>
                    Learn how to build an OpenAI-compatible chatbot using a local Transformers
                    model and MLflow, and serve it with minimal configuration.
                </p>
            </a>
        </div>
        <div class="simple-card">
            <a href="tutorials/prompt-templating/prompt-templating.html">
                <div class="header">
                    Prompt templating with Transformers Pipelines
                </div>
                <p>
                    Learn how to set prompt templates on Transformers Pipelines to optimize your LLM's outputs, and simplify the end-user experience.
                </p>
            </a>
        </div>
        <div class="simple-card">
            <a href="../custom-pyfunc-for-llms/notebooks/custom-pyfunc-advanced-llm.html">
                <div class="header">
                    Custom PyFunc for Transformers
                </div>
                <p>
                    Learn how to define a custom PyFunc using transformers for advanced, state-of-the-art new models.
                </p>
            </a>
        </div>
    </article>
</section></div>
</div>
<div class="section" id="important-details-to-be-aware-of-with-the-transformers-flavor">
<h2>Important Details to be aware of with the transformers flavor<a class="headerlink" href="#important-details-to-be-aware-of-with-the-transformers-flavor" title="Permalink to this headline"> </a></h2>
<p>When working with the transformers flavor in MLflow, there are several important considerations to keep in mind:</p>
<ul class="simple">
<li><p><strong>Experimental Status</strong>: The Transformers flavor in MLflow is marked as experimental, which means that APIs are subject to change, and new features may be added over time with potentially breaking changes.</p></li>
<li><p><strong>PyFunc Limitations</strong>: Not all output from a Transformers pipeline may be captured when using the python_function flavor. For example, if additional references or scores are required from the output, the native implementation should be used instead. Also not all the pipeline types are supported for pyfunc. Please refer to <a class="reference external" href="guide/index.html#loading-a-transformers-model-as-a-python-function">Loading a Transformers Model as a Python Function</a> for the supported pipeline types and their input and output format.</p></li>
<li><p><strong>Supported Pipeline Types</strong>: Not all Transformers pipeline types are currently supported for use with the python_function flavor. In particular, new model architectures may not be supported until the transformers library has a designated pipeline type in its supported pipeline implementations.</p></li>
<li><p><strong>Input and Output Types</strong>: The input and output types for the python_function implementation may differ from those expected from the native pipeline. Users need to ensure compatibility with their data processing workflows.</p></li>
<li><p><strong>Model Configuration</strong>: When saving or logging models, the <cite>model_config</cite> can be used to set certain parameters. However, if both model_config and a <cite>ModelSignature</cite> with parameters are saved, the default parameters in ModelSignature will override those in <cite>model_config</cite>.</p></li>
<li><p><strong>Audio and Vision Models</strong>: Audio and text-based large language models are supported for use with pyfunc, while other types like computer vision and multi-modal models are only supported for native type loading.</p></li>
<li><p><strong>Prompt Templates</strong>: Prompt templating is currently supported for a few pipeline types. For a full list of supported pipelines, and more information about the feature, see <a class="reference external" href="guide/index.html#saving-prompt-templates-with-transformer-pipelines">this link</a>.</p></li>
</ul>
</div>
<div class="section" id="working-with-tasks-for-transformer-pipelines">
<h2>Working with <code class="docutils literal notranslate"><span class="pre">tasks</span></code> for Transformer Pipelines<a class="headerlink" href="#working-with-tasks-for-transformer-pipelines" title="Permalink to this headline"> </a></h2>
<p>In MLflow Transformers flavor, <code class="docutils literal notranslate"><span class="pre">task</span></code> plays a crucial role in determining the input and output format of the model. Please refer to the <a class="reference external" href="task.html">Tasks in MLflow Transformers</a> guide on how to use the native Transformers task types, and leverage the advanced tasks such as <code class="docutils literal notranslate"><span class="pre">llm/v1/chat</span></code> and <code class="docutils literal notranslate"><span class="pre">llm/v1/completions</span></code> for OpenAI-compatible inference.</p>
<div class="toctree-wrapper compound">
</div>
</div>
<div class="section" id="id1">
<h2><a class="reference external" href="guide/index.html">Detailed Documentation</a><a class="headerlink" href="#id1" title="Permalink to this headline"> </a></h2>
<p>To learn more about the nuances of the <cite>transformers</cite> flavor in MLflow, delve into <a class="reference external" href="guide/index.html">the comprehensive guide</a>, which covers:</p>
<ul class="simple">
<li><p><a class="reference external" href="guide/index.html#pipelines-vs-component-logging">Pipelines vs. Component Logging</a>: Explore the different approaches for saving model components or complete pipelines and understand the nuances of loading these models for various use cases.</p></li>
<li><p><a class="reference external" href="guide/index.html#loading-a-transformers-model-as-a-python-function">Transformers Model as a Python Function</a> : Familiarize yourself with the various <code class="docutils literal notranslate"><span class="pre">transformers</span></code> pipeline types compatible with the pyfunc model flavor. Understand the standardization of input and output formats in the pyfunc model implementation for the flavor, ensuring seamless integration with JSON and Pandas DataFrames.</p></li>
<li><p><a class="reference external" href="guide/index.html#saving-prompt-templates-with-transformer-pipelines">Prompt Template</a>: Learn how to save a prompt template with transformers pipelines to optimize inference with less boilerplate.</p></li>
<li><p><a class="reference external" href="guide/index.html#using-model-config-and-model-signature-params-for-inference">Model Config and Model Signature Params for Inference</a>: Learn how to leverage <code class="docutils literal notranslate"><span class="pre">model_config</span></code> and <code class="docutils literal notranslate"><span class="pre">ModelSignature</span></code> for flexible and customized model loading and inference.</p></li>
<li><p><a class="reference external" href="guide/index.html#automatic-metadata-and-modelcard-logging">Automatic Metadata and ModelCard Logging</a>: Discover the automatic logging features for model cards and other metadata, enhancing model documentation and transparency.</p></li>
<li><p><a class="reference external" href="guide/index.html#automatic-signature-inference">Model Signature Inference</a> : Learn about MLflow’s capability within the <code class="docutils literal notranslate"><span class="pre">transformers</span></code> flavor to automatically infer and attach model signatures, facilitating easier model deployment.</p></li>
<li><p><a class="reference external" href="guide/index.html#scale-inference-with-overriding-pytorch-dtype">Overriding Pytorch dtype</a> : Gain insights into optimizing <code class="docutils literal notranslate"><span class="pre">transformers</span></code> models for inference, focusing on memory optimization and data type configurations.</p></li>
<li><p><a class="reference external" href="guide/index.html#input-data-types-for-audio-pipelines">Input Data Types for Audio Pipelines</a>: Understand the specific requirements for handling audio data in transformers pipelines, including the handling of different input types like str, bytes, and np.ndarray.</p></li>
<li><p><a class="reference external" href="guide/index.html#storage-efficient-model-logging-with-save-pretrained-option">Storage-Efficient Model Logging with save_pretrained Option</a>: Learn how to leverage the new <code class="docutils literal notranslate"><span class="pre">save_pretrained</span></code> option to speed up model saving and loading for large foundational models without consuming excessive storage space.</p></li>
<li><p><a class="reference external" href="guide/index.html#peft-models-in-mlflow-transformers-flavor">PEFT Models in MLflow Transformers flavor</a>: PEFT (Parameter-Efficient Fine-Tuning) is natively supported in MLflow, enabling various optimization techniques like LoRA, QLoRA, and more for reducing fine-tuning cost significantly. Check out the guide and tutorials to learn more about how to leverage PEFT with MLflow.</p></li>
</ul>
<div class="toctree-wrapper compound">
</div>
</div>
<div class="section" id="learn-more-about-transformers">
<h2>Learn more about Transformers<a class="headerlink" href="#learn-more-about-transformers" title="Permalink to this headline"> </a></h2>
<p>Interested in learning more about how to leverage transformers for your machine learning workflows?</p>
<p>🤗 Hugging Face has a fantastic NLP course. Check it out and see how to leverage <a class="reference external" href="https://huggingface.co/learn/nlp-course/chapter1/1">Transformers, Datasets, Tokenizers, and Accelerate</a>.</p>
</div>
</div>


              </div>
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../prompt-engineering/index.html" class="btn btn-neutral" title="Prompt Engineering UI (Experimental)" accesskey="p"><span class="db-icon db-icon-chevron-left"></span> Previous</a>
      
      
        <a href="tutorials/text-generation/text-generation.html" class="btn btn-neutral" title="Introduction to MLflow and Transformers" accesskey="n">Next <span class="db-icon db-icon-chevron-right"></span></a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; MLflow Project, a Series of LF Projects, LLC. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'../../',
      VERSION:'2.14.4.dev0',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      LINK_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  

  <script type="text/javascript" src="../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../_static/js/jquery.waypoints.min.js"></script>

  
  
  
  <script type="text/javascript">var CLIPPY_SVG_PATH = "../../_static/clippy.svg";</script>
  <script type="text/javascript" src="../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  

  
  <script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        function copyToClipboard(text) {
            const textarea = document.createElement('textarea');
            textarea.value = text;
            document.body.appendChild(textarea);
            textarea.select();
            document.execCommand('copy');
            document.body.removeChild(textarea);
        }
        // Get the code block designator class entries
        const allHighlights = document.querySelectorAll('.highlight');
        // Disable copyable links for notebook cell numbering and for cell outputs
        const highlights = Array.from(allHighlights).filter(highlight => !highlight.closest('.highlight-none') && 
            !highlight.closest('.nboutput'));
    
        highlights.forEach(function(highlight) {
            const copyIcon = document.createElement('span');
            copyIcon.classList.add('copy-icon');
            copyIcon.innerHTML = '&#xf0ea;';

            copyIcon.addEventListener('click', function() {
                const code = highlight.querySelector('pre').textContent;
                copyToClipboard(code);

                // Flash effect on click
                this.style.color = '#0194E2';
                setTimeout(() => {
                    this.style.color = ''; 
                }, 100);

                // Display "Code copied to clipboard" near the clicked icon
                const message = document.createElement('span');
                message.textContent = "Copied!";
                message.classList.add('copy-message'); 

                // Append the message to the icon
                this.appendChild(message);

                setTimeout(() => {
                    this.removeChild(message);
                }, 500);
            });

            highlight.appendChild(copyIcon);
        });
    });
  </script>


<script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        // Force download for notebook-download-btn
        const downloadButtons = document.querySelectorAll('.notebook-download-btn');
        downloadButtons.forEach(function(button) {
            button.addEventListener('click', function(event) {
                event.preventDefault(); // Prevent default behavior

                // Fetch the raw content of the notebook from GitHub
                fetch(button.href)
                    .then(response => response.blob())
                    .then(blob => {
                        const url = window.URL.createObjectURL(blob);
                        const link = document.createElement('a');
                        link.style.display = 'none';
                        link.href = url;
                        const filename = button.href.split('/').pop();
                        link.download = filename; 

                        document.body.appendChild(link);
                        link.click();

                        window.URL.revokeObjectURL(url);
                        document.body.removeChild(link);
                    })
                    .catch(err => console.error('Error fetching the notebook:', err));
            });
        });
    });
</script> 
</body>
</html>