<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-llms/transformers/tutorials/conversational/pyfunc-chat-model-ipynb" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Deploying a Transformer model as an OpenAI-compatible Chatbot | MLflow</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://mlflow.org/docs/latest/llms/transformers/tutorials/conversational/pyfunc-chat-model"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Deploying a Transformer model as an OpenAI-compatible Chatbot | MLflow"><meta data-rh="true" name="description" content="Download this notebook"><meta data-rh="true" property="og:description" content="Download this notebook"><link data-rh="true" rel="icon" href="/docs/latest/images/favicon.ico"><link data-rh="true" rel="canonical" href="https://mlflow.org/docs/latest/llms/transformers/tutorials/conversational/pyfunc-chat-model"><link data-rh="true" rel="alternate" href="https://mlflow.org/docs/latest/llms/transformers/tutorials/conversational/pyfunc-chat-model" hreflang="en"><link data-rh="true" rel="alternate" href="https://mlflow.org/docs/latest/llms/transformers/tutorials/conversational/pyfunc-chat-model" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://XKVLO8P882-dsn.algolia.net" crossorigin="anonymous"><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=GTM-N6WMTTJ"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","GTM-N6WMTTJ",{anonymize_ip:!0}),gtag("config","AW-16857946923",{anonymize_ip:!0})</script>
<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var g=t.getElementsByTagName(a)[0],m=t.createElement(a);m.async=!0,m.src="https://www.googletagmanager.com/gtm.js?id=GTM-N6WMTTJ",g.parentNode.insertBefore(m,g)}(window,document,"script","dataLayer")</script>



<link rel="search" type="application/opensearchdescription+xml" title="MLflow" href="/docs/latest/opensearch.xml">

<script src="/docs/latest/js/runllm.js" defer="defer"></script><link rel="stylesheet" href="/docs/latest/assets/css/styles.504e3d8b.css">
<script src="/docs/latest/assets/js/runtime~main.5af5e8cd.js" defer="defer"></script>
<script src="/docs/latest/assets/js/main.ba39982f.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>


<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/docs/latest/"><div class="navbar__logo"><img src="/docs/latest/images/logo-light.svg" alt="MLflow Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/docs/latest/images/logo-dark.svg" alt="MLflow Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/latest/">Docs</a><a href="https://mlflow.org/docs/latest/api_reference/index.html" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">API Reference</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/mlflow/mlflow" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sidebar-top-level-category"><a class="menu__link" href="/docs/latest/">MLflow</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/mlflow-3/">MLflow 3.0</a><button aria-label="Expand sidebar category &#x27;MLflow 3.0&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/getting-started/">Getting Started</a><button aria-label="Expand sidebar category &#x27;Getting Started&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/latest/llms/">Machine Learning ðŸ§ </a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/docs/latest/llms/">LLM / GenAI</a><button aria-label="Collapse sidebar category &#x27;LLM / GenAI&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/llms/">Overview</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/latest/llms/openai/">Integrations</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/llms/openai/">OpenAI</a><button aria-label="Expand sidebar category &#x27;OpenAI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/llms/langchain/">LangChain</a><button aria-label="Expand sidebar category &#x27;LangChain&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/llms/dspy/">DSPy</a><button aria-label="Expand sidebar category &#x27;DSPy&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/llms/llama-index/">LlamaIndex</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/docs/latest/llms/transformers/">Transformers</a><button aria-label="Collapse sidebar category &#x27;Transformers&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/llms/transformers/">Overview</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-5 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/docs/latest/llms/transformers/tutorials/">Tutorials</a><button aria-label="Collapse sidebar category &#x27;Tutorials&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-6 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/llms/transformers/tutorials/audio-transcription/whisper">audio-transcription</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-6 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/latest/llms/transformers/tutorials/conversational/conversational-model">conversational</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-7 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/llms/transformers/tutorials/conversational/conversational-model">Introduction to Conversational AI with MLflow and DialoGPT</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-7 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/latest/llms/transformers/tutorials/conversational/pyfunc-chat-model">Deploying a Transformer model as an OpenAI-compatible Chatbot</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-6 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/llms/transformers/tutorials/fine-tuning/transformers-fine-tuning">fine-tuning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-6 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/llms/transformers/tutorials/prompt-templating/prompt-templating">prompt-templating</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-6 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/llms/transformers/tutorials/text-generation/text-generation">text-generation</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-6 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/llms/transformers/tutorials/translation/component-translation">translation</a></div></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/llms/transformers/guide/">Detailed Guide</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/llms/transformers/task/">Task</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/llms/transformers/large-models/">Storage Optimization</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/llms/sentence-transformers/">Sentence Transformers</a><button aria-label="Expand sidebar category &#x27;Sentence Transformers&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/tracing/integrations/">More</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/tracing/">Tracing (Observability)</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/llms/llm-evaluate/">Evaluation</a><button aria-label="Expand sidebar category &#x27;Evaluation&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/tracing/production">Production Monitoring</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/llms/responses-agent-intro/">ResponsesAgent</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/llms/chat-model-intro/">ChatModel</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/llms/rag/">RAG</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/prompts">Prompt Engineering</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/deep-learning/">Deep Learning</a><button aria-label="Expand sidebar category &#x27;Deep Learning&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/traditional-ml/">Traditional ML</a><button aria-label="Expand sidebar category &#x27;Traditional ML&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/docs/latest/tracking/">Build ðŸ”¨ </a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/tracking/">MLflow Tracking</a><button aria-label="Expand sidebar category &#x27;MLflow Tracking&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/model/">MLflow Model</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/prompts/">MLflow Prompts ðŸ†•</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/docs/latest/model-evaluation/">Evaluate &amp; Monitor ðŸ“Š</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/model-evaluation/">MLflow Evaluation</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/tracing/">MLflow Tracing (Observability)</a><button aria-label="Expand sidebar category &#x27;MLflow Tracing (Observability)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/dataset/">MLflow Dataset</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/docs/latest/model-registry/">Deploy ðŸš€</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/model-registry/">MLflow Model Registry</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/deployment/">MLflow Serving</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/llms/deployments/">MLflow AI Gateway</a><button aria-label="Expand sidebar category &#x27;MLflow AI Gateway&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/latest/tracking/#tracking-setup">Team Collaboration ðŸ‘¥</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a href="https://mlflow.org/docs/latest/api_reference/python_api/index.html" target="_blank" rel="noopener noreferrer" class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false">API References</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer" class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false">More</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/docs/latest/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Machine Learning ðŸ§ </span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/latest/llms/"><span itemprop="name">LLM / GenAI</span></a><meta itemprop="position" content="2"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Integrations</span><meta itemprop="position" content="3"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/latest/llms/transformers/"><span itemprop="name">Transformers</span></a><meta itemprop="position" content="4"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/latest/llms/transformers/tutorials/"><span itemprop="name">Tutorials</span></a><meta itemprop="position" content="5"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">conversational</span><meta itemprop="position" content="6"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Deploying a Transformer model as an OpenAI-compatible Chatbot</span><meta itemprop="position" content="7"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Deploying a Transformer model as an OpenAI-compatible Chatbot</h1></header>
<a class="button button--primary" style="margin-bottom:1rem;display:block;width:min-content" href="https://raw.githubusercontent.com/mlflow/mlflow/master/docs/docs/llms/transformers/tutorials/conversational/pyfunc-chat-model.ipynb" download="">Download this notebook</a>
<p>Welcome to our tutorial on using Transformers and MLflow to create an OpenAI-compatible chat model. In MLflow 2.11 and up, MLflow&#x27;s Transformers flavors support special task type <code>llm/v1/chat</code>, which turns thousands of <a href="https://huggingface.co/models?pipeline_tag=text-generation" target="_blank" rel="noopener noreferrer">text-generation</a> models on Hugging Face into conversational chat bots that are interoperable with OpenAI models. This enables you to seamlessly swap out your chat appâ€™s backing LLM or to easily evaluate different models without having to edit your client-side code.</p>
<p>If you haven&#x27;t already seen it, you may find it helpful to go through our <a href="https://mlflow.org/docs/latest/llms/transformers/tutorials/conversational/conversational-model.html" target="_blank" rel="noopener noreferrer">introductory notebook on chat and Transformers</a> before proceeding with this one, as this notebook is slightly higher-level and does not delve too deeply into the inner workings of Transformers or MLflow Tracking.</p>
<p><strong>Note</strong>: This page covers how to deploy a <strong>Transformers</strong> models as a chatbot. If you are using a different framework or a custom python model, use <a href="https://mlflow.org/docs/latest/llms/chat-model-intro/index.html" target="_blank" rel="noopener noreferrer">ChatModel</a> instead to build an OpenAI-compatible chat bot.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="learning-objectives">Learning objectives<a href="#learning-objectives" class="hash-link" aria-label="Direct link to Learning objectives" title="Direct link to Learning objectives">â€‹</a></h3>
<p>In this tutorial, you will:</p>
<ul>
<li>Create an OpenAI-compatible chat model using TinyLLama-1.1B-Chat</li>
<li>Log the model to MLflow and load it back for local inference.</li>
<li>Serve the model with MLflow Model Serving</li>
</ul>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token operator" style="color:#393A34">%</span><span class="token plain">pip install mlflow</span><span class="token operator" style="color:#393A34">&gt;=</span><span class="token number" style="color:#36acaa">2.11</span><span class="token number" style="color:#36acaa">.0</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token plain">q </span><span class="token operator" style="color:#393A34">-</span><span class="token plain">U</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># OpenAI-compatible chat model support is available for Transformers 4.34.0 and above</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">%</span><span class="token plain">pip install transformers</span><span class="token operator" style="color:#393A34">&gt;=</span><span class="token number" style="color:#36acaa">4.34</span><span class="token number" style="color:#36acaa">.0</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token plain">q </span><span class="token operator" style="color:#393A34">-</span><span class="token plain">U</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Disable tokenizers warnings when constructing pipelines</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">%</span><span class="token plain">env TOKENIZERS_PARALLELISM</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">false</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> warnings</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Disable a few less-than-useful UserWarnings from setuptools and pydantic</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">warnings</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">filterwarnings</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;ignore&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> category</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">UserWarning</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">env: TOKENIZERS_PARALLELISM=false</pre>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="building-a-chat-model">Building a Chat Model<a href="#building-a-chat-model" class="hash-link" aria-label="Direct link to Building a Chat Model" title="Direct link to Building a Chat Model">â€‹</a></h3>
<p>MLflow&#x27;s native Transformers integration allows you to specify the <code>task</code> param when saving or logging your pipelines. Originally, this param accepts any of the <a href="https://huggingface.co/tasks" target="_blank" rel="noopener noreferrer">Transformers pipeline task types</a>, but the <code>mlflow.transformers</code> flavor adds a few more MLflow-specific keys for <code>text-generation</code> pipeline types.</p>
<p>For <code>text-generation</code> pipelines, instead of specifying <code>text-generation</code> as the task type, you can provide one of two string literals conforming to the <a href="https://mlflow.org/docs/latest/llms/deployments/index.html#general-configuration-parameters" target="_blank" rel="noopener noreferrer">MLflow AI Gateway&#x27;s endpoint_type specification</a> (&quot;llm/v1/embeddings&quot; can be specified as a task on models saved with <code>mlflow.sentence_transformers</code>):</p>
<ul>
<li>&quot;llm/v1/chat&quot; for chat-style applications</li>
<li>&quot;llm/v1/completions&quot; for generic completions</li>
</ul>
<p>When one of these keys is specified, MLflow will automatically handle everything required to serve a chat or completions model. This includes:</p>
<ul>
<li>Setting a chat/completions compatible signature on the model</li>
<li>Performing data pre- and post-processing to ensure the inputs and outputs conform to the <a href="https://mlflow.org/docs/latest/llms/deployments/index.html#chat" target="_blank" rel="noopener noreferrer">Chat/Completions API spec</a>, which is compatible with OpenAI&#x27;s API spec.</li>
</ul>
<p>Note that these modifications only apply when the model is loaded with <code>mlflow.pyfunc.load_model()</code> (e.g. when serving the model with the <code>mlflow models serve</code> CLI tool). If you want to load just the base pipeline, you can always do so via <code>mlflow.transformers.load_model()</code>.</p>
<p>In the next few cells, we&#x27;ll learn how serve a chat model with a local Transformers pipeline and MLflow, using TinyLlama-1.1B-Chat as an example.</p>
<p>To begin, let&#x27;s go through the original flow of saving a text generation pipeline:</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> pipeline</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">generator </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> pipeline</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;text-generation&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  model</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;TinyLlama/TinyLlama-1.1B-Chat-v1.0&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># save the model using the vanilla `text-generation` task type</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">save_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  path</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;tinyllama-text-generation&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> transformers_model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">generator</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> task</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;text-generation&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">/var/folders/qd/9rwd0_gd0qs65g4sdqlm51hr0000gp/T/ipykernel_55429/4268198845.py:11: FutureWarning: The &#x27;transformers&#x27; MLflow Models integration is known to be compatible with the following package version ranges: ``4.25.1`` -  ``4.37.1``. MLflow Models integrations with transformers may not succeed when used with package versions outside of this range.
mlflow.transformers.save_model(</pre>
<p>Now, let&#x27;s load the model and use it for inference. Our loaded model is a <code>text-generation</code> pipeline, and let&#x27;s take a look at its signature to see its expected inputs and outputs.</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># load the model for inference</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pyfunc</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;tinyllama-text-generation&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">metadata</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">signature</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">Loading checkpoint shards:   0%|          | 0/5 [00:00&lt;?, ?it/s]</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">2024/02/26 21:06:51 WARNING mlflow.transformers: Could not specify device parameter for this pipeline type</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">Loading checkpoint shards:   0%|          | 0/5 [00:00&lt;?, ?it/s]</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">inputs: 
[string (required)]
outputs: 
[string (required)]
params: 
None</pre>
<p>Unfortunately, it only accepts <code>string</code> as input, which isn&#x27;t directly compatible with a chat interface. When interacting with OpenAI&#x27;s API, for example, we expect to simply be able to input a list of messages. In order to do this with our current model, we&#x27;ll have to write some additional boilerplate:</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># first, apply the tokenizer&#x27;s chat template, since the</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># model is tuned to accept prompts in a chat format. this</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># also converts the list of messages to a string.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">messages </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&quot;role&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;user&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;content&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Write me a hello world program in python&quot;</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">prompt </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> generator</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">tokenizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">apply_chat_template</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  messages</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> tokenize</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">False</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> add_generation_prompt</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">prompt</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">[&#x27;&lt;|user|&gt;
Write me a hello world program in python&lt;/s&gt;
&lt;|assistant|&gt;
Here&#x27;s a simple hello world program in Python:

```python
print(&quot;Hello, world!&quot;)
```

This program prints the string &quot;Hello, world!&quot; to the console. You can run this program by typing it into the Python interpreter or by running the command `python hello_world.py` in your terminal.&#x27;]</pre>
<p>Now we&#x27;re getting somewhere, but formatting our messages prior to inference is cumbersome.</p>
<p>Additionally, the output format isn&#x27;t compatible with the OpenAI API spec either--it&#x27;s just a list of strings. If we were looking to evaluate different model backends for our chat app, we&#x27;d have to rewrite some of our client-side code to both format the input, and to parse this new response.</p>
<p>To simplify all this, let&#x27;s just pass in <code>&quot;llm/v1/chat&quot;</code> as the task param when saving the model.</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># save the model using the `&quot;llm/v1/chat&quot;`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># task type instead of `text-generation`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">save_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  path</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;tinyllama-chat&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> transformers_model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">generator</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> task</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;llm/v1/chat&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">/var/folders/qd/9rwd0_gd0qs65g4sdqlm51hr0000gp/T/ipykernel_55429/609241782.py:3: FutureWarning: The &#x27;transformers&#x27; MLflow Models integration is known to be compatible with the following package version ranges: ``4.25.1`` -  ``4.37.1``. MLflow Models integrations with transformers may not succeed when used with package versions outside of this range.
mlflow.transformers.save_model(</pre>
<p>Once again, let&#x27;s load the model and inspect the signature:</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pyfunc</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;tinyllama-chat&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">metadata</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">signature</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">Loading checkpoint shards:   0%|          | 0/5 [00:00&lt;?, ?it/s]</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">2024/02/26 21:10:04 WARNING mlflow.transformers: Could not specify device parameter for this pipeline type</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">Loading checkpoint shards:   0%|          | 0/5 [00:00&lt;?, ?it/s]</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">inputs: 
[&#x27;messages&#x27;: Array({content: string (required), name: string (optional), role: string (required)}) (required), &#x27;temperature&#x27;: double (optional), &#x27;max_tokens&#x27;: long (optional), &#x27;stop&#x27;: Array(string) (optional), &#x27;n&#x27;: long (optional), &#x27;stream&#x27;: boolean (optional)]
outputs: 
[&#x27;id&#x27;: string (required), &#x27;object&#x27;: string (required), &#x27;created&#x27;: long (required), &#x27;model&#x27;: string (required), &#x27;choices&#x27;: Array({finish_reason: string (required), index: long (required), message: {content: string (required), name: string (optional), role: string (required)} (required)}) (required), &#x27;usage&#x27;: {completion_tokens: long (required), prompt_tokens: long (required), total_tokens: long (required)} (required)]
params: 
None</pre>
<p>Now when performing inference, we can pass our messages in a dict as we&#x27;d expect to do when interacting with the OpenAI API. Furthermore, the response we receive back from the model also conforms to the spec.</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">messages </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&quot;role&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;user&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;content&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Write me a hello world program in python&quot;</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&quot;messages&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> messages</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">[{&#x27;id&#x27;: &#x27;8435a57d-9895-485e-98d3-95b1cbe007c0&#x27;,
&#x27;object&#x27;: &#x27;chat.completion&#x27;,
&#x27;created&#x27;: 1708949437,
&#x27;model&#x27;: &#x27;TinyLlama/TinyLlama-1.1B-Chat-v1.0&#x27;,
&#x27;usage&#x27;: {&#x27;prompt_tokens&#x27;: 24, &#x27;completion_tokens&#x27;: 71, &#x27;total_tokens&#x27;: 95},
&#x27;choices&#x27;: [{&#x27;index&#x27;: 0,
  &#x27;finish_reason&#x27;: &#x27;stop&#x27;,
  &#x27;message&#x27;: {&#x27;role&#x27;: &#x27;assistant&#x27;,
   &#x27;content&#x27;: &#x27;Here&#x27;s a simple hello world program in Python:

```python
print(&quot;Hello, world!&quot;)
```

This program prints the string &quot;Hello, world!&quot; to the console. You can run this program by typing it into the Python interpreter or by running the command `python hello_world.py` in your terminal.&#x27;}}]}]</pre>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="serving-the-chat-model">Serving the Chat Model<a href="#serving-the-chat-model" class="hash-link" aria-label="Direct link to Serving the Chat Model" title="Direct link to Serving the Chat Model">â€‹</a></h3>
<p>To take this example further, let&#x27;s use MLflow to serve our chat model, so we can interact with it like a web API. To do this, we can use the <code>mlflow models serve</code> CLI tool.</p>
<p>In a terminal shell, run:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ mlflow models serve -m tinyllama-chat</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>When the server has finished initializing, you should be able to interact with the model via HTTP requests. The input format is almost identical to the format described in the <a href="https://mlflow.org/docs/latest/llms/deployments/index.html#chat" target="_blank" rel="noopener noreferrer">MLflow Deployments Server docs</a>, with the exception that <code>temperature</code> defaults to <code>1.0</code> instead of <code>0.0</code>.</p>
<p>Here&#x27;s a quick example:</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token operator" style="color:#393A34">%</span><span class="token operator" style="color:#393A34">%</span><span class="token plain">sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">curl http</span><span class="token punctuation" style="color:#393A34">:</span><span class="token operator" style="color:#393A34">//</span><span class="token number" style="color:#36acaa">127.0</span><span class="token number" style="color:#36acaa">.0</span><span class="token number" style="color:#36acaa">.1</span><span class="token punctuation" style="color:#393A34">:</span><span class="token number" style="color:#36acaa">5000</span><span class="token operator" style="color:#393A34">/</span><span class="token plain">invocations   </span><span class="token operator" style="color:#393A34">-</span><span class="token plain">H </span><span class="token string" style="color:#e3116c">&#x27;Content-Type: application/json&#x27;</span><span class="token plain">   </span><span class="token operator" style="color:#393A34">-</span><span class="token plain">d </span><span class="token string" style="color:#e3116c">&#x27;{ &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Write me a hello world program in python&quot;}] }&#x27;</span><span class="token plain">   </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> jq</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                               Dload  Upload   Total   Spent    Left  Speed
100   706  100   617  100    89     25      3  0:00:29  0:00:23  0:00:06   160</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">[
{
  &quot;id&quot;: &quot;fc3d08c3-d37d-420d-a754-50f77eb32a92&quot;,
  &quot;object&quot;: &quot;chat.completion&quot;,
  &quot;created&quot;: 1708949465,
  &quot;model&quot;: &quot;TinyLlama/TinyLlama-1.1B-Chat-v1.0&quot;,
  &quot;usage&quot;: {
    &quot;prompt_tokens&quot;: 24,
    &quot;completion_tokens&quot;: 71,
    &quot;total_tokens&quot;: 95
  },
  &quot;choices&quot;: [
    {
      &quot;index&quot;: 0,
      &quot;finish_reason&quot;: &quot;stop&quot;,
      &quot;message&quot;: {
        &quot;role&quot;: &quot;assistant&quot;,
        &quot;content&quot;: &quot;Here&#x27;s a simple hello world program in Python:

```python
print(&quot;Hello, world!&quot;)
```

This program prints the string &quot;Hello, world!&quot; to the console. You can run this program by typing it into the Python interpreter or by running the command `python hello_world.py` in your terminal.&quot;
      }
    }
  ]
}
]</pre>
<p>It&#x27;s that easy!</p>
<p>You can also call the API with a few optional inference params to adjust the model&#x27;s responses. These map to Transformers pipeline params, and are passed in directly at inference time.</p>
<ul>
<li><code>max_tokens</code> (maps to <code>max_new_tokens</code>): The maximum number of new tokens the model should generate.</li>
<li><code>temperature</code> (maps to <code>temperature</code>): Controls the creativity of the model&#x27;s response. Note that this is not guaranteed to be supported by all models, and in order for this param to have an effect, the pipeline must have been created with <code>do_sample=True</code>.</li>
<li><code>stop</code> (maps to <code>stopping_criteria</code>): A list of tokens at which to stop generation.</li>
</ul>
<p>Note: <code>n</code> does not have an equivalent Transformers pipeline param, and is not supported in queries. However, you can implement a model that consumes the <code>n</code> param using Custom Pyfunc (details below).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">â€‹</a></h2>
<p>In this tutorial, you learned how to create an OpenAI-compatible chat model by specifying &quot;llm/v1/chat&quot; as the task when saving Transformers pipelines.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="whats-next">What&#x27;s next?<a href="#whats-next" class="hash-link" aria-label="Direct link to What&#x27;s next?" title="Direct link to What&#x27;s next?">â€‹</a></h3>
<ul>
<li><a href="https://mlflow.org/docs/latest/llms/chat-model-intro/index.html" target="_blank" rel="noopener noreferrer">Learn about custom ChatModel</a>. If you&#x27;re looking for futrher customization or models outside Transformers, the linked page provides a hand-on guidance for how to build a chat bot with MLflow&#x27;s <code>ChatModel</code> class.</li>
<li><a href="https://mlflow.org/docs/latest/deployment/index.html" target="_blank" rel="noopener noreferrer">More on MLflow AI Gateway</a>. In this tutorial, we saw how to deploy a model using a local server, but MLflow provides many other ways to deploy your models to production. Check out this page to learn more about the different options.</li>
<li><a href="https://mlflow.org/docs/latest/llms/transformers/index.html" target="_blank" rel="noopener noreferrer">More on MLflow&#x27;s Transformers Integration</a>. This page provides a comprehensive overview on MLflow&#x27;s Transformers integrations, along with lots of hands-on guides and notebooks. Learn how to fine-tune models, use prompt templates, and more!</li>
<li><a href="https://mlflow.org/docs/latest/llms/index.html" target="_blank" rel="noopener noreferrer">Other LLM Integrations</a>. Aside from Transformers, MLflow has integrations with many other popular LLM libraries, such as Langchain and OpenAI.</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/mlflow/mlflow/edit/master/docs/docs/llms/transformers/tutorials/conversational/pyfunc-chat-model.ipynb" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/latest/llms/transformers/tutorials/conversational/conversational-model"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Introduction to Conversational AI with MLflow and DialoGPT</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/latest/llms/transformers/tutorials/fine-tuning/transformers-fine-tuning"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Fine-Tuning Transformers with MLflow for Enhanced Model Management</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#learning-objectives" class="table-of-contents__link toc-highlight">Learning objectives</a></li><li><a href="#building-a-chat-model" class="table-of-contents__link toc-highlight">Building a Chat Model</a></li><li><a href="#serving-the-chat-model" class="table-of-contents__link toc-highlight">Serving the Chat Model</a></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a><ul><li><a href="#whats-next" class="table-of-contents__link toc-highlight">What&#39;s next?</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/mlflow" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.linkedin.com/company/mlflow-org" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://x.com/mlflow" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Resources</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/latest/">Docs</a></li><li class="footer__item"><a href="https://mlflow.org/releases" target="_blank" rel="noopener noreferrer" class="footer__link-item">Releases</a></li><li class="footer__item"><a href="https://mlflow.org/blog" target="_blank" rel="noopener noreferrer" class="footer__link-item">Blog</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2025 MLflow Project, a Series of LF Projects, LLC.</div></div></div></footer></div>
</body>
</html>