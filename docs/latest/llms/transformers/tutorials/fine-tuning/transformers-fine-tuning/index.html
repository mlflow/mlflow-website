<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-llms/transformers/tutorials/fine-tuning/transformers-fine-tuning-ipynb" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Fine-Tuning Transformers with MLflow for Enhanced Model Management | MLflow</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://mlflow.org/docs/latest/llms/transformers/tutorials/fine-tuning/transformers-fine-tuning"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Fine-Tuning Transformers with MLflow for Enhanced Model Management | MLflow"><meta data-rh="true" name="description" content="Download this notebook"><meta data-rh="true" property="og:description" content="Download this notebook"><link data-rh="true" rel="icon" href="/docs/latest/images/favicon.ico"><link data-rh="true" rel="canonical" href="https://mlflow.org/docs/latest/llms/transformers/tutorials/fine-tuning/transformers-fine-tuning"><link data-rh="true" rel="alternate" href="https://mlflow.org/docs/latest/llms/transformers/tutorials/fine-tuning/transformers-fine-tuning" hreflang="en"><link data-rh="true" rel="alternate" href="https://mlflow.org/docs/latest/llms/transformers/tutorials/fine-tuning/transformers-fine-tuning" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://XKVLO8P882-dsn.algolia.net" crossorigin="anonymous"><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=GTM-N6WMTTJ"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","GTM-N6WMTTJ",{anonymize_ip:!0}),gtag("config","AW-16857946923",{anonymize_ip:!0})</script>
<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var g=t.getElementsByTagName(a)[0],m=t.createElement(a);m.async=!0,m.src="https://www.googletagmanager.com/gtm.js?id=GTM-N6WMTTJ",g.parentNode.insertBefore(m,g)}(window,document,"script","dataLayer")</script>



<link rel="search" type="application/opensearchdescription+xml" title="MLflow" href="/docs/latest/opensearch.xml">

<script src="/docs/latest/js/runllm.js" defer="defer"></script><link rel="stylesheet" href="/docs/latest/assets/css/styles.504e3d8b.css">
<script src="/docs/latest/assets/js/runtime~main.a746fe50.js" defer="defer"></script>
<script src="/docs/latest/assets/js/main.8cf08d89.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>


<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/docs/latest/"><div class="navbar__logo"><img src="/docs/latest/images/logo-light.svg" alt="MLflow Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/docs/latest/images/logo-dark.svg" alt="MLflow Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/latest/">Docs</a><a href="https://mlflow.org/docs/latest/api_reference/index.html" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">API Reference</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/mlflow/mlflow" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sidebar-top-level-category"><a class="menu__link" href="/docs/latest/">MLflow</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/mlflow-3/">MLflow 3.0</a><button aria-label="Expand sidebar category &#x27;MLflow 3.0&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/getting-started/">Getting Started</a><button aria-label="Expand sidebar category &#x27;Getting Started&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/latest/llms/">Machine Learning ðŸ§ </a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/docs/latest/llms/">LLM / GenAI</a><button aria-label="Collapse sidebar category &#x27;LLM / GenAI&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/llms/">Overview</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/latest/llms/openai/">Integrations</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/llms/openai/">OpenAI</a><button aria-label="Expand sidebar category &#x27;OpenAI&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/llms/langchain/">LangChain</a><button aria-label="Expand sidebar category &#x27;LangChain&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/llms/dspy/">DSPy</a><button aria-label="Expand sidebar category &#x27;DSPy&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/llms/llama-index/">LlamaIndex</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/docs/latest/llms/transformers/">Transformers</a><button aria-label="Collapse sidebar category &#x27;Transformers&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/llms/transformers/">Overview</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-5 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/docs/latest/llms/transformers/tutorials/">Tutorials</a><button aria-label="Collapse sidebar category &#x27;Tutorials&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-6 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/llms/transformers/tutorials/audio-transcription/whisper">audio-transcription</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-6 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/llms/transformers/tutorials/conversational/conversational-model">conversational</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-6 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/latest/llms/transformers/tutorials/fine-tuning/transformers-fine-tuning">fine-tuning</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-7 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/latest/llms/transformers/tutorials/fine-tuning/transformers-fine-tuning">Fine-Tuning Transformers with MLflow for Enhanced Model Management</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-7 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/llms/transformers/tutorials/fine-tuning/transformers-peft">Fine-Tuning Open-Source LLM using QLoRA with MLflow and PEFT</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-6 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/llms/transformers/tutorials/prompt-templating/prompt-templating">prompt-templating</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-6 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/llms/transformers/tutorials/text-generation/text-generation">text-generation</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-6 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/llms/transformers/tutorials/translation/component-translation">translation</a></div></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/llms/transformers/guide/">Detailed Guide</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/llms/transformers/task/">Task</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/llms/transformers/large-models/">Storage Optimization</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/llms/sentence-transformers/">Sentence Transformers</a><button aria-label="Expand sidebar category &#x27;Sentence Transformers&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/tracing/integrations/">More</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/tracing/">Tracing (Observability)</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/llms/llm-evaluate/">Evaluation</a><button aria-label="Expand sidebar category &#x27;Evaluation&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/tracing/production">Production Monitoring</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/llms/responses-agent-intro/">ResponsesAgent</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/llms/chat-model-intro/">ChatModel</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/llms/rag/">RAG</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/prompts">Prompt Engineering</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/deep-learning/">Deep Learning</a><button aria-label="Expand sidebar category &#x27;Deep Learning&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/traditional-ml/">Traditional ML</a><button aria-label="Expand sidebar category &#x27;Traditional ML&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/docs/latest/tracking/">Build ðŸ”¨ </a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/tracking/">MLflow Tracking</a><button aria-label="Expand sidebar category &#x27;MLflow Tracking&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/model/">MLflow Model</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/prompts/">MLflow Prompts ðŸ†•</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/docs/latest/model-evaluation/">Evaluate &amp; Monitor ðŸ“Š</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/model-evaluation/">MLflow Evaluation</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/tracing/">MLflow Tracing (Observability)</a><button aria-label="Expand sidebar category &#x27;MLflow Tracing (Observability)&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/dataset/">MLflow Dataset</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/docs/latest/model-registry/">Deploy ðŸš€</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/model-registry/">MLflow Model Registry</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/deployment/">MLflow Serving</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/llms/deployments/">MLflow AI Gateway</a><button aria-label="Expand sidebar category &#x27;MLflow AI Gateway&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/latest/tracking/#tracking-setup">Team Collaboration ðŸ‘¥</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a href="https://mlflow.org/docs/latest/api_reference/python_api/index.html" target="_blank" rel="noopener noreferrer" class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false">API References</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer" class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false">More</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/docs/latest/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Machine Learning ðŸ§ </span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/latest/llms/"><span itemprop="name">LLM / GenAI</span></a><meta itemprop="position" content="2"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Integrations</span><meta itemprop="position" content="3"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/latest/llms/transformers/"><span itemprop="name">Transformers</span></a><meta itemprop="position" content="4"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/latest/llms/transformers/tutorials/"><span itemprop="name">Tutorials</span></a><meta itemprop="position" content="5"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">fine-tuning</span><meta itemprop="position" content="6"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Fine-Tuning Transformers with MLflow for Enhanced Model Management</span><meta itemprop="position" content="7"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Fine-Tuning Transformers with MLflow for Enhanced Model Management</h1></header>
<a class="button button--primary" style="margin-bottom:1rem;display:block;width:min-content" href="https://raw.githubusercontent.com/mlflow/mlflow/master/docs/docs/llms/transformers/tutorials/fine-tuning/transformers-fine-tuning.ipynb" download="">Download this notebook</a>
<p>Welcome to our in-depth tutorial on fine-tuning Transformers models with enhanced management using MLflow.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-you-will-learn-in-this-tutorial">What You Will Learn in This Tutorial<a href="#what-you-will-learn-in-this-tutorial" class="hash-link" aria-label="Direct link to What You Will Learn in This Tutorial" title="Direct link to What You Will Learn in This Tutorial">â€‹</a></h3>
<ul>
<li>Understand the process of fine-tuning a Transformers model.</li>
<li>Learn to effectively log and manage the training cycle using MLflow.</li>
<li>Master logging the trained model separately in MLflow.</li>
<li>Gain insights into using the trained model for practical inference tasks.</li>
</ul>
<p>Our approach will provide a holistic understanding of model fine-tuning and management, ensuring that you&#x27;re well-equipped to handle similar tasks in your projects.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="emphasizing-fine-tuning">Emphasizing Fine-Tuning<a href="#emphasizing-fine-tuning" class="hash-link" aria-label="Direct link to Emphasizing Fine-Tuning" title="Direct link to Emphasizing Fine-Tuning">â€‹</a></h4>
<p>Fine-tuning pre-trained models is a common practice in machine learning, especially in the field of NLP. It involves adjusting a pre-trained model to make it more suitable for a specific task. This process is essential as it allows the leveraging of pre-existing knowledge in the model, significantly improving performance on specific datasets or tasks.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="role-of-mlflow-in-model-lifecycle">Role of MLflow in Model Lifecycle<a href="#role-of-mlflow-in-model-lifecycle" class="hash-link" aria-label="Direct link to Role of MLflow in Model Lifecycle" title="Direct link to Role of MLflow in Model Lifecycle">â€‹</a></h4>
<p>Integrating MLflow in this process is crucial for:</p>
<ul>
<li><strong>Training Cycle Logging</strong>: Keeping a detailed log of the training cycle, including parameters, metrics, and intermediate results.</li>
<li><strong>Model Logging and Management</strong>: Separately logging the trained model, tracking its versions, and managing its lifecycle post-training.</li>
<li><strong>Inference and Deployment</strong>: Using the logged model for inference, ensuring easy transition from training to deployment.</li>
</ul>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Disable tokenizers warnings when constructing pipelines</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token operator" style="color:#393A34">%</span><span class="token plain">env TOKENIZERS_PARALLELISM</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">false</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> warnings</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Disable a few less-than-useful UserWarnings from setuptools and pydantic</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">warnings</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">filterwarnings</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;ignore&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> category</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">UserWarning</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">env: TOKENIZERS_PARALLELISM=false</pre>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="preparing-the-dataset-and-environment-for-fine-tuning">Preparing the Dataset and Environment for Fine-Tuning<a href="#preparing-the-dataset-and-environment-for-fine-tuning" class="hash-link" aria-label="Direct link to Preparing the Dataset and Environment for Fine-Tuning" title="Direct link to Preparing the Dataset and Environment for Fine-Tuning">â€‹</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="key-steps-in-this-section">Key Steps in this Section<a href="#key-steps-in-this-section" class="hash-link" aria-label="Direct link to Key Steps in this Section" title="Direct link to Key Steps in this Section">â€‹</a></h4>
<ol>
<li><strong>Loading the Dataset</strong>: Utilizing the <code>sms_spam</code> dataset for spam detection.</li>
<li><strong>Splitting the Dataset</strong>: Dividing the dataset into training and test sets with an 80/20 distribution.</li>
<li><strong>Importing Necessary Libraries</strong>: Including libraries like <code>evaluate</code>, <code>mlflow</code>, <code>numpy</code>, and essential components from the <code>transformers</code> library.</li>
</ol>
<p>Before diving into the fine-tuning process, setting up our environment and preparing the dataset is crucial. This step involves loading the dataset, splitting it into training and testing sets, and initializing essential components of the Transformers library. These preparatory steps lay the groundwork for an efficient fine-tuning process.</p>
<p>This setup ensures that we have a solid foundation for fine-tuning our model, with all the necessary data and tools at our disposal. In the following Python code, we&#x27;ll execute these steps to kickstart our model fine-tuning journey.</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> evaluate</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> numpy </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> datasets </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> load_dataset</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  AutoModelForSequenceClassification</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  AutoTokenizer</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Trainer</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  TrainingArguments</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  pipeline</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Load the &quot;sms_spam&quot; dataset.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sms_dataset </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> load_dataset</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;sms_spam&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Split train/test by an 8/2 ratio.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sms_train_test </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> sms_dataset</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;train&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">train_test_split</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">test_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.2</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">train_dataset </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> sms_train_test</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;train&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">test_dataset </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> sms_train_test</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;test&quot;</span><span class="token punctuation" style="color:#393A34">]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">Found cached dataset sms_spam (/Users/benjamin.wilson/.cache/huggingface/datasets/sms_spam/plain_text/1.0.0/53f051d3b5f62d99d61792c91acefe4f1577ad3e4c216fb0ad39e30b9f20019c)</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">  0%|          | 0/1 [00:00&lt;?, ?it/s]</pre>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="tokenization-and-dataset-preparation">Tokenization and Dataset Preparation<a href="#tokenization-and-dataset-preparation" class="hash-link" aria-label="Direct link to Tokenization and Dataset Preparation" title="Direct link to Tokenization and Dataset Preparation">â€‹</a></h3>
<p>In the next code block, we tokenize our text data, preparing it for the fine-tuning process of our model.</p>
<p>With our dataset loaded and split, the next step is to prepare our text data for the model. This involves tokenizing the text, a crucial process in NLP where text is converted into a format that&#x27;s understandable and usable by our model.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="tokenization-process">Tokenization Process<a href="#tokenization-process" class="hash-link" aria-label="Direct link to Tokenization Process" title="Direct link to Tokenization Process">â€‹</a></h4>
<ul>
<li><strong>Loading the Tokenizer</strong>: Using the <code>AutoTokenizer</code> from the <code>transformers</code> library for the <code>distilbert-base-uncased</code> model&#x27;s tokenizer.</li>
<li><strong>Defining the Tokenization Function</strong>: Creating a function to tokenize text data, including padding and truncation.</li>
<li><strong>Applying Tokenization to the Dataset</strong>: Processing both the training and testing sets for model readiness.</li>
</ul>
<p>Tokenization is a critical step in preparing text data for NLP tasks. It ensures that the data is in a format that the model can process, and by handling aspects like padding and truncation, it ensures consistency across our dataset, which is vital for training stability and model performance.</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Load the tokenizer for &quot;distilbert-base-uncased&quot; model.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoTokenizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;distilbert-base-uncased&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">tokenize_function</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">examples</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Pad/truncate each text to 512 tokens. Enforcing the same shape</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># could make the training faster.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> tokenizer</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      examples</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;sms&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      padding</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;max_length&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      truncation</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      max_length</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">128</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">seed </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">22</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Tokenize the train and test datasets</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">train_tokenized </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> train_dataset</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">map</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">tokenize_function</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">train_tokenized </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> train_tokenized</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">remove_columns</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;sms&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">shuffle</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">seed</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">seed</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">test_tokenized </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> test_dataset</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">map</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">tokenize_function</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">test_tokenized </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> test_tokenized</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">remove_columns</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;sms&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">shuffle</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">seed</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">seed</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">Map:   0%|          | 0/4459 [00:00&lt;?, ? examples/s]</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">Map:   0%|          | 0/1115 [00:00&lt;?, ? examples/s]</pre>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="model-initialization-and-label-mapping">Model Initialization and Label Mapping<a href="#model-initialization-and-label-mapping" class="hash-link" aria-label="Direct link to Model Initialization and Label Mapping" title="Direct link to Model Initialization and Label Mapping">â€‹</a></h3>
<p>Next, we&#x27;ll set up label mappings and initialize the model for our text classification task.</p>
<p>Having prepared our data, the next crucial step is to initialize our model and set up label mappings. This involves defining a clear relationship between the labels in our dataset and their corresponding representations in the model.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="setting-up-label-mappings">Setting Up Label Mappings<a href="#setting-up-label-mappings" class="hash-link" aria-label="Direct link to Setting Up Label Mappings" title="Direct link to Setting Up Label Mappings">â€‹</a></h4>
<ul>
<li><strong>Defining Label Mappings</strong>: Creating bi-directional mappings between integer labels and textual representations (&quot;ham&quot; and &quot;spam&quot;).</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="initializing-the-model">Initializing the Model<a href="#initializing-the-model" class="hash-link" aria-label="Direct link to Initializing the Model" title="Direct link to Initializing the Model">â€‹</a></h4>
<ul>
<li><strong>Model Selection</strong>: Choosing the <code>distilbert-base-uncased</code> model for its balance of performance and efficiency.</li>
<li><strong>Model Configuration</strong>: Configuring the model for sequence classification with the defined label mappings.</li>
</ul>
<p>Proper model initialization and label mapping are key to ensuring that the model accurately understands and processes the task at hand. By explicitly defining these mappings and selecting an appropriate pre-trained model, we lay the groundwork for effective and efficient fine-tuning.</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Set the mapping between int label and its meaning.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">id2label </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;ham&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;spam&quot;</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">label2id </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&quot;ham&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;spam&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Acquire the model from the Hugging Face Hub, providing label and id mappings so that both we and the model can &#x27;speak&#x27; the same language.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoModelForSequenceClassification</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;distilbert-base-uncased&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  num_labels</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  label2id</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">label2id</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  id2label</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">id2label</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: [&#x27;classifier.weight&#x27;, &#x27;pre_classifier.bias&#x27;, &#x27;pre_classifier.weight&#x27;, &#x27;classifier.bias&#x27;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</pre>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="setting-up-evaluation-metrics">Setting Up Evaluation Metrics<a href="#setting-up-evaluation-metrics" class="hash-link" aria-label="Direct link to Setting Up Evaluation Metrics" title="Direct link to Setting Up Evaluation Metrics">â€‹</a></h3>
<p>Next, we focus on defining and computing evaluation metrics to measure our model&#x27;s performance accurately.</p>
<p>After initializing our model, the next critical step is to define how we&#x27;ll evaluate its performance. Accurate evaluation is key to understanding how well our model is learning and performing on the task.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="choosing-and-loading-the-metric">Choosing and Loading the Metric<a href="#choosing-and-loading-the-metric" class="hash-link" aria-label="Direct link to Choosing and Loading the Metric" title="Direct link to Choosing and Loading the Metric">â€‹</a></h4>
<ul>
<li><strong>Metric Selection</strong>: Opting for &#x27;accuracy&#x27; as the evaluation metric.</li>
<li><strong>Loading the Metric</strong>: Utilizing the <code>evaluate</code> library to load the &#x27;accuracy&#x27; metric.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="defining-the-metric-computation-function">Defining the Metric Computation Function<a href="#defining-the-metric-computation-function" class="hash-link" aria-label="Direct link to Defining the Metric Computation Function" title="Direct link to Defining the Metric Computation Function">â€‹</a></h4>
<ul>
<li><strong>Function for Metric Computation</strong>: Creating a function, <code>compute_metrics</code>, for calculating accuracy during model evaluation.</li>
<li><strong>Processing Predictions</strong>: Handling logits and labels from predictions to compute accuracy.</li>
</ul>
<p>Properly setting up evaluation metrics allows us to objectively measure the model&#x27;s performance. By using standardized metrics, we can compare our model&#x27;s performance against benchmarks or other models, ensuring that our fine-tuning process is effective and moving in the right direction.</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Define the target optimization metric</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">metric </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> evaluate</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;accuracy&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Define a function for calculating our defined target optimization metric during training</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">compute_metrics</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">eval_pred</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  logits</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> labels </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> eval_pred</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  predictions </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">argmax</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">logits</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> axis</span><span class="token operator" style="color:#393A34">=</span><span class="token operator" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> metric</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">compute</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">predictions</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">predictions</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> references</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">labels</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="configuring-the-training-environment">Configuring the Training Environment<a href="#configuring-the-training-environment" class="hash-link" aria-label="Direct link to Configuring the Training Environment" title="Direct link to Configuring the Training Environment">â€‹</a></h3>
<p>In this step, we&#x27;re going to configure our Trainer, supplying important training configurations via the use of the <code>TrainingArguments</code> API.</p>
<p>With our model and metrics ready, the next important step is to configure the training environment. This involves setting up the training arguments and initializing the Trainer, a component that orchestrates the model training process.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="training-arguments-configuration">Training Arguments Configuration<a href="#training-arguments-configuration" class="hash-link" aria-label="Direct link to Training Arguments Configuration" title="Direct link to Training Arguments Configuration">â€‹</a></h4>
<ul>
<li><strong>Defining the Output Directory</strong>: We specify the <code>training_output_dir</code> where our model checkpoints will be saved during training. This helps in managing and storing model states at different stages of training.</li>
<li><strong>Specifying Training Arguments</strong>: We create an instance of <code>TrainingArguments</code> to define various parameters for training, such as the output directory, evaluation strategy, batch sizes for training and evaluation, logging frequency, and the number of training epochs. These parameters are critical for controlling how the model is trained and evaluated.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="initializing-the-trainer">Initializing the Trainer<a href="#initializing-the-trainer" class="hash-link" aria-label="Direct link to Initializing the Trainer" title="Direct link to Initializing the Trainer">â€‹</a></h4>
<ul>
<li><strong>Creating the Trainer Instance</strong>: We use the Trainer class from the Transformers library, providing it with our model, the previously defined training arguments, datasets for training and evaluation, and the function to compute metrics.</li>
<li><strong>Role of the Trainer</strong>: The Trainer handles all aspects of training and evaluating the model, including the execution of training loops, handling of data batching, and calling the compute metrics function. It simplifies the training process, making it more streamlined and efficient.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="importance-of-proper-training-configuration">Importance of Proper Training Configuration<a href="#importance-of-proper-training-configuration" class="hash-link" aria-label="Direct link to Importance of Proper Training Configuration" title="Direct link to Importance of Proper Training Configuration">â€‹</a></h4>
<p>Setting up the training environment correctly is essential for effective model training. Proper configuration ensures that the model is trained under optimal conditions, leading to better performance and more reliable results.</p>
<p>In the following code block, we&#x27;ll configure our training environment and initialize the Trainer, setting the stage for the actual training process.</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Checkpoints will be output to this `training_output_dir`.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">training_output_dir </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;/tmp/sms_trainer&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">training_args </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> TrainingArguments</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  output_dir</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">training_output_dir</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  evaluation_strategy</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;epoch&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  per_device_train_batch_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">8</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  per_device_eval_batch_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">8</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  logging_steps</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">8</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  num_train_epochs</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">3</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Instantiate a `Trainer` instance that will be used to initiate a training run.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">trainer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> Trainer</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  args</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">training_args</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  train_dataset</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">train_tokenized</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  eval_dataset</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">test_tokenized</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  compute_metrics</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">compute_metrics</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># If you are running this tutorial in local mode, leave the next line commented out.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Otherwise, uncomment the following line and set your tracking uri to your local or remote tracking server.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># mlflow.set_tracking_uri(&quot;http://127.0.0.1:8080&quot;)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="integrating-mlflow-for-experiment-tracking">Integrating MLflow for Experiment Tracking<a href="#integrating-mlflow-for-experiment-tracking" class="hash-link" aria-label="Direct link to Integrating MLflow for Experiment Tracking" title="Direct link to Integrating MLflow for Experiment Tracking">â€‹</a></h3>
<p>The final preparatory step before beginning the training process is to integrate MLflow for experiment tracking.</p>
<p>MLflow is a critical tool in our workflow, enabling us to log, monitor, and compare different runs of our model training.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="setting-up-the-mlflow-experiment">Setting up the MLflow Experiment<a href="#setting-up-the-mlflow-experiment" class="hash-link" aria-label="Direct link to Setting up the MLflow Experiment" title="Direct link to Setting up the MLflow Experiment">â€‹</a></h4>
<ul>
<li><strong>Naming the Experiment</strong>: We use <code>mlflow.set_experiment</code> to create a new experiment or assign the current run to an existing experiment. In this case, we name our experiment &quot;Spam Classifier Training&quot;. This name should be descriptive and related to the task at hand, aiding in organizing and identifying experiments later.</li>
<li><strong>Role of MLflow in Training</strong>: By setting up an MLflow experiment, we can track various aspects of our model training, such as parameters, metrics, and outputs. This tracking is invaluable for comparing different models, tuning hyperparameters, and maintaining a record of our experiments.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="benefits-of-experiment-tracking">Benefits of Experiment Tracking<a href="#benefits-of-experiment-tracking" class="hash-link" aria-label="Direct link to Benefits of Experiment Tracking" title="Direct link to Benefits of Experiment Tracking">â€‹</a></h4>
<p>Utilizing MLflow for experiment tracking offers several advantages:</p>
<ul>
<li><strong>Organization</strong>: Keeps your training runs organized and easily accessible.</li>
<li><strong>Comparability</strong>: Allows for easy comparison of different training runs to understand the impact of changes in parameters or data.</li>
<li><strong>Reproducibility</strong>: Enhances the reproducibility of experiments by logging all necessary details.</li>
</ul>
<p>With MLflow set up, we&#x27;re now ready to begin the training process, keeping track of every important aspect along the way.</p>
<p>In the next code snippet, we&#x27;ll set up our MLflow experiment for tracking the training of our spam classification model.</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Pick a name that you like and reflects the nature of the runs that you will be recording to the experiment.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">set_experiment</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;Spam Classifier Training&quot;</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">&lt;Experiment: artifact_location=&#x27;file:///Users/benjamin.wilson/repos/mlflow-fork/mlflow/docs/source/llms/transformers/tutorials/fine-tuning/mlruns/258758267044147956&#x27;, creation_time=1701291176206, experiment_id=&#x27;258758267044147956&#x27;, last_update_time=1701291176206, lifecycle_stage=&#x27;active&#x27;, name=&#x27;Spam Classifier Training&#x27;, tags={}&gt;</pre>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="starting-the-training-process-with-mlflow">Starting the Training Process with MLflow<a href="#starting-the-training-process-with-mlflow" class="hash-link" aria-label="Direct link to Starting the Training Process with MLflow" title="Direct link to Starting the Training Process with MLflow">â€‹</a></h3>
<p>In this step, we initiate the fine-tuning training run, utilizing the native auto-logging functionality to record the parameters used and loss metrics calculated during the training process.</p>
<p>With our model, training arguments, and MLflow experiment set up, we are now ready to start the actual training process. This step involves initiating an MLflow run, which will encapsulate all the training activities and metrics.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="initiating-the-mlflow-run">Initiating the MLflow Run<a href="#initiating-the-mlflow-run" class="hash-link" aria-label="Direct link to Initiating the MLflow Run" title="Direct link to Initiating the MLflow Run">â€‹</a></h4>
<ul>
<li><strong>Starting an MLflow Run</strong>: We use <code>mlflow.start_run()</code> to begin a new MLflow run. This function creates a new run context, under which all the training operations and logging will occur.</li>
<li><strong>Training the Model</strong>: Inside the MLflow run context, we call <code>trainer.train()</code> to start training our model. This function will run the training loop, processing the data in batches, updating model parameters, and evaluating the model.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="monitoring-the-training-progress">Monitoring the Training Progress<a href="#monitoring-the-training-progress" class="hash-link" aria-label="Direct link to Monitoring the Training Progress" title="Direct link to Monitoring the Training Progress">â€‹</a></h4>
<p>During training, the <code>Trainer</code> object will output logs that provide valuable insights into the training progress:</p>
<ul>
<li><strong>Loss</strong>: Indicates the model&#x27;s performance, with lower values signifying better performance.</li>
<li><strong>Learning Rate</strong>: Shows the current learning rate used during training.</li>
<li><strong>Epoch Progress</strong>: Displays the progress through the current epoch.</li>
</ul>
<p>These logs are crucial for monitoring the model&#x27;s learning process and making any necessary adjustments. By tracking these metrics within an MLflow run, we can maintain a comprehensive record of the training process, enhancing reproducibility and analysis.</p>
<p>In the next code block, we will start our MLflow run and begin training our model, closely observing the output to gauge the training progress.</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">with</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">start_run</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> run</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  trainer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">train</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">  0%|          | 0/1674 [00:00&lt;?, ?it/s]</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">{&#x27;loss&#x27;: 0.4891, &#x27;learning_rate&#x27;: 4.9761051373954604e-05, &#x27;epoch&#x27;: 0.01}
{&#x27;loss&#x27;: 0.2662, &#x27;learning_rate&#x27;: 4.95221027479092e-05, &#x27;epoch&#x27;: 0.03}
{&#x27;loss&#x27;: 0.1756, &#x27;learning_rate&#x27;: 4.92831541218638e-05, &#x27;epoch&#x27;: 0.04}
{&#x27;loss&#x27;: 0.107, &#x27;learning_rate&#x27;: 4.90442054958184e-05, &#x27;epoch&#x27;: 0.06}
{&#x27;loss&#x27;: 0.0831, &#x27;learning_rate&#x27;: 4.8805256869773e-05, &#x27;epoch&#x27;: 0.07}
{&#x27;loss&#x27;: 0.0688, &#x27;learning_rate&#x27;: 4.8566308243727596e-05, &#x27;epoch&#x27;: 0.09}
{&#x27;loss&#x27;: 0.0959, &#x27;learning_rate&#x27;: 4.83273596176822e-05, &#x27;epoch&#x27;: 0.1}
{&#x27;loss&#x27;: 0.0831, &#x27;learning_rate&#x27;: 4.80884109916368e-05, &#x27;epoch&#x27;: 0.11}
{&#x27;loss&#x27;: 0.1653, &#x27;learning_rate&#x27;: 4.78494623655914e-05, &#x27;epoch&#x27;: 0.13}
{&#x27;loss&#x27;: 0.1865, &#x27;learning_rate&#x27;: 4.7610513739546e-05, &#x27;epoch&#x27;: 0.14}
{&#x27;loss&#x27;: 0.0887, &#x27;learning_rate&#x27;: 4.73715651135006e-05, &#x27;epoch&#x27;: 0.16}
{&#x27;loss&#x27;: 0.1009, &#x27;learning_rate&#x27;: 4.71326164874552e-05, &#x27;epoch&#x27;: 0.17}
{&#x27;loss&#x27;: 0.1017, &#x27;learning_rate&#x27;: 4.6893667861409805e-05, &#x27;epoch&#x27;: 0.19}
{&#x27;loss&#x27;: 0.0057, &#x27;learning_rate&#x27;: 4.66547192353644e-05, &#x27;epoch&#x27;: 0.2}
{&#x27;loss&#x27;: 0.0157, &#x27;learning_rate&#x27;: 4.6415770609319e-05, &#x27;epoch&#x27;: 0.22}
{&#x27;loss&#x27;: 0.0302, &#x27;learning_rate&#x27;: 4.61768219832736e-05, &#x27;epoch&#x27;: 0.23}
{&#x27;loss&#x27;: 0.0013, &#x27;learning_rate&#x27;: 4.59378733572282e-05, &#x27;epoch&#x27;: 0.24}
{&#x27;loss&#x27;: 0.0863, &#x27;learning_rate&#x27;: 4.56989247311828e-05, &#x27;epoch&#x27;: 0.26}
{&#x27;loss&#x27;: 0.1122, &#x27;learning_rate&#x27;: 4.54599761051374e-05, &#x27;epoch&#x27;: 0.27}
{&#x27;loss&#x27;: 0.1092, &#x27;learning_rate&#x27;: 4.5221027479092e-05, &#x27;epoch&#x27;: 0.29}
{&#x27;loss&#x27;: 0.0853, &#x27;learning_rate&#x27;: 4.49820788530466e-05, &#x27;epoch&#x27;: 0.3}
{&#x27;loss&#x27;: 0.1852, &#x27;learning_rate&#x27;: 4.4743130227001195e-05, &#x27;epoch&#x27;: 0.32}
{&#x27;loss&#x27;: 0.0913, &#x27;learning_rate&#x27;: 4.4504181600955796e-05, &#x27;epoch&#x27;: 0.33}
{&#x27;loss&#x27;: 0.0232, &#x27;learning_rate&#x27;: 4.42652329749104e-05, &#x27;epoch&#x27;: 0.34}
{&#x27;loss&#x27;: 0.0888, &#x27;learning_rate&#x27;: 4.402628434886499e-05, &#x27;epoch&#x27;: 0.36}
{&#x27;loss&#x27;: 0.195, &#x27;learning_rate&#x27;: 4.378733572281959e-05, &#x27;epoch&#x27;: 0.37}
{&#x27;loss&#x27;: 0.0198, &#x27;learning_rate&#x27;: 4.3548387096774194e-05, &#x27;epoch&#x27;: 0.39}
{&#x27;loss&#x27;: 0.056, &#x27;learning_rate&#x27;: 4.3309438470728796e-05, &#x27;epoch&#x27;: 0.4}
{&#x27;loss&#x27;: 0.1656, &#x27;learning_rate&#x27;: 4.307048984468339e-05, &#x27;epoch&#x27;: 0.42}
{&#x27;loss&#x27;: 0.0032, &#x27;learning_rate&#x27;: 4.283154121863799e-05, &#x27;epoch&#x27;: 0.43}
{&#x27;loss&#x27;: 0.1277, &#x27;learning_rate&#x27;: 4.259259259259259e-05, &#x27;epoch&#x27;: 0.44}
{&#x27;loss&#x27;: 0.0029, &#x27;learning_rate&#x27;: 4.2353643966547194e-05, &#x27;epoch&#x27;: 0.46}
{&#x27;loss&#x27;: 0.1007, &#x27;learning_rate&#x27;: 4.2114695340501795e-05, &#x27;epoch&#x27;: 0.47}
{&#x27;loss&#x27;: 0.0038, &#x27;learning_rate&#x27;: 4.1875746714456396e-05, &#x27;epoch&#x27;: 0.49}
{&#x27;loss&#x27;: 0.0035, &#x27;learning_rate&#x27;: 4.1636798088411e-05, &#x27;epoch&#x27;: 0.5}
{&#x27;loss&#x27;: 0.0015, &#x27;learning_rate&#x27;: 4.13978494623656e-05, &#x27;epoch&#x27;: 0.52}
{&#x27;loss&#x27;: 0.1423, &#x27;learning_rate&#x27;: 4.115890083632019e-05, &#x27;epoch&#x27;: 0.53}
{&#x27;loss&#x27;: 0.0316, &#x27;learning_rate&#x27;: 4.0919952210274794e-05, &#x27;epoch&#x27;: 0.54}
{&#x27;loss&#x27;: 0.0012, &#x27;learning_rate&#x27;: 4.0681003584229395e-05, &#x27;epoch&#x27;: 0.56}
{&#x27;loss&#x27;: 0.0009, &#x27;learning_rate&#x27;: 4.0442054958183996e-05, &#x27;epoch&#x27;: 0.57}
{&#x27;loss&#x27;: 0.1287, &#x27;learning_rate&#x27;: 4.020310633213859e-05, &#x27;epoch&#x27;: 0.59}
{&#x27;loss&#x27;: 0.0893, &#x27;learning_rate&#x27;: 3.996415770609319e-05, &#x27;epoch&#x27;: 0.6}
{&#x27;loss&#x27;: 0.0021, &#x27;learning_rate&#x27;: 3.972520908004779e-05, &#x27;epoch&#x27;: 0.62}
{&#x27;loss&#x27;: 0.0031, &#x27;learning_rate&#x27;: 3.9486260454002395e-05, &#x27;epoch&#x27;: 0.63}
{&#x27;loss&#x27;: 0.0022, &#x27;learning_rate&#x27;: 3.924731182795699e-05, &#x27;epoch&#x27;: 0.65}
{&#x27;loss&#x27;: 0.0008, &#x27;learning_rate&#x27;: 3.900836320191159e-05, &#x27;epoch&#x27;: 0.66}
{&#x27;loss&#x27;: 0.1119, &#x27;learning_rate&#x27;: 3.876941457586619e-05, &#x27;epoch&#x27;: 0.67}
{&#x27;loss&#x27;: 0.0012, &#x27;learning_rate&#x27;: 3.8530465949820786e-05, &#x27;epoch&#x27;: 0.69}
{&#x27;loss&#x27;: 0.2618, &#x27;learning_rate&#x27;: 3.829151732377539e-05, &#x27;epoch&#x27;: 0.7}
{&#x27;loss&#x27;: 0.0018, &#x27;learning_rate&#x27;: 3.805256869772999e-05, &#x27;epoch&#x27;: 0.72}
{&#x27;loss&#x27;: 0.0736, &#x27;learning_rate&#x27;: 3.781362007168459e-05, &#x27;epoch&#x27;: 0.73}
{&#x27;loss&#x27;: 0.0126, &#x27;learning_rate&#x27;: 3.7574671445639184e-05, &#x27;epoch&#x27;: 0.75}
{&#x27;loss&#x27;: 0.2125, &#x27;learning_rate&#x27;: 3.7335722819593785e-05, &#x27;epoch&#x27;: 0.76}
{&#x27;loss&#x27;: 0.0018, &#x27;learning_rate&#x27;: 3.7096774193548386e-05, &#x27;epoch&#x27;: 0.77}
{&#x27;loss&#x27;: 0.1386, &#x27;learning_rate&#x27;: 3.685782556750299e-05, &#x27;epoch&#x27;: 0.79}
{&#x27;loss&#x27;: 0.0024, &#x27;learning_rate&#x27;: 3.661887694145759e-05, &#x27;epoch&#x27;: 0.8}
{&#x27;loss&#x27;: 0.0016, &#x27;learning_rate&#x27;: 3.637992831541219e-05, &#x27;epoch&#x27;: 0.82}
{&#x27;loss&#x27;: 0.0011, &#x27;learning_rate&#x27;: 3.614097968936679e-05, &#x27;epoch&#x27;: 0.83}
{&#x27;loss&#x27;: 0.0307, &#x27;learning_rate&#x27;: 3.590203106332139e-05, &#x27;epoch&#x27;: 0.85}
{&#x27;loss&#x27;: 0.0007, &#x27;learning_rate&#x27;: 3.566308243727599e-05, &#x27;epoch&#x27;: 0.86}
{&#x27;loss&#x27;: 0.005, &#x27;learning_rate&#x27;: 3.542413381123059e-05, &#x27;epoch&#x27;: 0.87}
{&#x27;loss&#x27;: 0.0534, &#x27;learning_rate&#x27;: 3.518518518518519e-05, &#x27;epoch&#x27;: 0.89}
{&#x27;loss&#x27;: 0.0155, &#x27;learning_rate&#x27;: 3.494623655913979e-05, &#x27;epoch&#x27;: 0.9}
{&#x27;loss&#x27;: 0.0136, &#x27;learning_rate&#x27;: 3.4707287933094385e-05, &#x27;epoch&#x27;: 0.92}
{&#x27;loss&#x27;: 0.1108, &#x27;learning_rate&#x27;: 3.4468339307048986e-05, &#x27;epoch&#x27;: 0.93}
{&#x27;loss&#x27;: 0.0017, &#x27;learning_rate&#x27;: 3.422939068100359e-05, &#x27;epoch&#x27;: 0.95}
{&#x27;loss&#x27;: 0.0009, &#x27;learning_rate&#x27;: 3.399044205495819e-05, &#x27;epoch&#x27;: 0.96}
{&#x27;loss&#x27;: 0.0008, &#x27;learning_rate&#x27;: 3.375149342891278e-05, &#x27;epoch&#x27;: 0.97}
{&#x27;loss&#x27;: 0.0846, &#x27;learning_rate&#x27;: 3.3512544802867384e-05, &#x27;epoch&#x27;: 0.99}</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">  0%|          | 0/140 [00:00&lt;?, ?it/s]</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">{&#x27;eval_loss&#x27;: 0.03877367451786995, &#x27;eval_accuracy&#x27;: 0.9919282511210762, &#x27;eval_runtime&#x27;: 5.0257, &#x27;eval_samples_per_second&#x27;: 221.862, &#x27;eval_steps_per_second&#x27;: 27.857, &#x27;epoch&#x27;: 1.0}
{&#x27;loss&#x27;: 0.109, &#x27;learning_rate&#x27;: 3.3273596176821985e-05, &#x27;epoch&#x27;: 1.0}
{&#x27;loss&#x27;: 0.0084, &#x27;learning_rate&#x27;: 3.3034647550776586e-05, &#x27;epoch&#x27;: 1.02}
{&#x27;loss&#x27;: 0.0014, &#x27;learning_rate&#x27;: 3.279569892473118e-05, &#x27;epoch&#x27;: 1.03}
{&#x27;loss&#x27;: 0.0008, &#x27;learning_rate&#x27;: 3.255675029868578e-05, &#x27;epoch&#x27;: 1.05}
{&#x27;loss&#x27;: 0.0006, &#x27;learning_rate&#x27;: 3.231780167264038e-05, &#x27;epoch&#x27;: 1.06}
{&#x27;loss&#x27;: 0.0005, &#x27;learning_rate&#x27;: 3.207885304659498e-05, &#x27;epoch&#x27;: 1.08}
{&#x27;loss&#x27;: 0.0004, &#x27;learning_rate&#x27;: 3.183990442054958e-05, &#x27;epoch&#x27;: 1.09}
{&#x27;loss&#x27;: 0.0518, &#x27;learning_rate&#x27;: 3.160095579450418e-05, &#x27;epoch&#x27;: 1.1}
{&#x27;loss&#x27;: 0.0005, &#x27;learning_rate&#x27;: 3.136200716845878e-05, &#x27;epoch&#x27;: 1.12}
{&#x27;loss&#x27;: 0.149, &#x27;learning_rate&#x27;: 3.112305854241338e-05, &#x27;epoch&#x27;: 1.13}
{&#x27;loss&#x27;: 0.0022, &#x27;learning_rate&#x27;: 3.0884109916367984e-05, &#x27;epoch&#x27;: 1.15}
{&#x27;loss&#x27;: 0.0013, &#x27;learning_rate&#x27;: 3.0645161290322585e-05, &#x27;epoch&#x27;: 1.16}
{&#x27;loss&#x27;: 0.0051, &#x27;learning_rate&#x27;: 3.0406212664277183e-05, &#x27;epoch&#x27;: 1.18}
{&#x27;loss&#x27;: 0.0005, &#x27;learning_rate&#x27;: 3.016726403823178e-05, &#x27;epoch&#x27;: 1.19}
{&#x27;loss&#x27;: 0.0026, &#x27;learning_rate&#x27;: 2.9928315412186382e-05, &#x27;epoch&#x27;: 1.2}
{&#x27;loss&#x27;: 0.0005, &#x27;learning_rate&#x27;: 2.9689366786140983e-05, &#x27;epoch&#x27;: 1.22}
{&#x27;loss&#x27;: 0.0871, &#x27;learning_rate&#x27;: 2.9450418160095584e-05, &#x27;epoch&#x27;: 1.23}
{&#x27;loss&#x27;: 0.0004, &#x27;learning_rate&#x27;: 2.921146953405018e-05, &#x27;epoch&#x27;: 1.25}
{&#x27;loss&#x27;: 0.0004, &#x27;learning_rate&#x27;: 2.897252090800478e-05, &#x27;epoch&#x27;: 1.26}
{&#x27;loss&#x27;: 0.0003, &#x27;learning_rate&#x27;: 2.873357228195938e-05, &#x27;epoch&#x27;: 1.28}
{&#x27;loss&#x27;: 0.0003, &#x27;learning_rate&#x27;: 2.8494623655913982e-05, &#x27;epoch&#x27;: 1.29}
{&#x27;loss&#x27;: 0.0003, &#x27;learning_rate&#x27;: 2.8255675029868577e-05, &#x27;epoch&#x27;: 1.3}
{&#x27;loss&#x27;: 0.0478, &#x27;learning_rate&#x27;: 2.8016726403823178e-05, &#x27;epoch&#x27;: 1.32}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 2.777777777777778e-05, &#x27;epoch&#x27;: 1.33}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 2.753882915173238e-05, &#x27;epoch&#x27;: 1.35}
{&#x27;loss&#x27;: 0.0003, &#x27;learning_rate&#x27;: 2.7299880525686978e-05, &#x27;epoch&#x27;: 1.36}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 2.706093189964158e-05, &#x27;epoch&#x27;: 1.38}
{&#x27;loss&#x27;: 0.0005, &#x27;learning_rate&#x27;: 2.682198327359618e-05, &#x27;epoch&#x27;: 1.39}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 2.6583034647550775e-05, &#x27;epoch&#x27;: 1.41}
{&#x27;loss&#x27;: 0.0003, &#x27;learning_rate&#x27;: 2.6344086021505376e-05, &#x27;epoch&#x27;: 1.42}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 2.6105137395459977e-05, &#x27;epoch&#x27;: 1.43}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 2.586618876941458e-05, &#x27;epoch&#x27;: 1.45}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 2.5627240143369173e-05, &#x27;epoch&#x27;: 1.46}
{&#x27;loss&#x27;: 0.0007, &#x27;learning_rate&#x27;: 2.5388291517323774e-05, &#x27;epoch&#x27;: 1.48}
{&#x27;loss&#x27;: 0.1336, &#x27;learning_rate&#x27;: 2.5149342891278375e-05, &#x27;epoch&#x27;: 1.49}
{&#x27;loss&#x27;: 0.0004, &#x27;learning_rate&#x27;: 2.4910394265232977e-05, &#x27;epoch&#x27;: 1.51}
{&#x27;loss&#x27;: 0.0671, &#x27;learning_rate&#x27;: 2.4671445639187578e-05, &#x27;epoch&#x27;: 1.52}
{&#x27;loss&#x27;: 0.0004, &#x27;learning_rate&#x27;: 2.4432497013142176e-05, &#x27;epoch&#x27;: 1.53}
{&#x27;loss&#x27;: 0.1246, &#x27;learning_rate&#x27;: 2.4193548387096777e-05, &#x27;epoch&#x27;: 1.55}
{&#x27;loss&#x27;: 0.1142, &#x27;learning_rate&#x27;: 2.3954599761051375e-05, &#x27;epoch&#x27;: 1.56}
{&#x27;loss&#x27;: 0.002, &#x27;learning_rate&#x27;: 2.3715651135005976e-05, &#x27;epoch&#x27;: 1.58}
{&#x27;loss&#x27;: 0.002, &#x27;learning_rate&#x27;: 2.3476702508960574e-05, &#x27;epoch&#x27;: 1.59}
{&#x27;loss&#x27;: 0.0009, &#x27;learning_rate&#x27;: 2.3237753882915175e-05, &#x27;epoch&#x27;: 1.61}
{&#x27;loss&#x27;: 0.0778, &#x27;learning_rate&#x27;: 2.2998805256869773e-05, &#x27;epoch&#x27;: 1.62}
{&#x27;loss&#x27;: 0.0007, &#x27;learning_rate&#x27;: 2.2759856630824374e-05, &#x27;epoch&#x27;: 1.63}
{&#x27;loss&#x27;: 0.0008, &#x27;learning_rate&#x27;: 2.2520908004778972e-05, &#x27;epoch&#x27;: 1.65}
{&#x27;loss&#x27;: 0.0009, &#x27;learning_rate&#x27;: 2.2281959378733573e-05, &#x27;epoch&#x27;: 1.66}
{&#x27;loss&#x27;: 0.1032, &#x27;learning_rate&#x27;: 2.2043010752688174e-05, &#x27;epoch&#x27;: 1.68}
{&#x27;loss&#x27;: 0.0014, &#x27;learning_rate&#x27;: 2.1804062126642775e-05, &#x27;epoch&#x27;: 1.69}
{&#x27;loss&#x27;: 0.001, &#x27;learning_rate&#x27;: 2.1565113500597373e-05, &#x27;epoch&#x27;: 1.71}
{&#x27;loss&#x27;: 0.1199, &#x27;learning_rate&#x27;: 2.132616487455197e-05, &#x27;epoch&#x27;: 1.72}
{&#x27;loss&#x27;: 0.0009, &#x27;learning_rate&#x27;: 2.1087216248506572e-05, &#x27;epoch&#x27;: 1.73}
{&#x27;loss&#x27;: 0.0011, &#x27;learning_rate&#x27;: 2.084826762246117e-05, &#x27;epoch&#x27;: 1.75}
{&#x27;loss&#x27;: 0.0007, &#x27;learning_rate&#x27;: 2.060931899641577e-05, &#x27;epoch&#x27;: 1.76}
{&#x27;loss&#x27;: 0.0006, &#x27;learning_rate&#x27;: 2.037037037037037e-05, &#x27;epoch&#x27;: 1.78}
{&#x27;loss&#x27;: 0.0004, &#x27;learning_rate&#x27;: 2.013142174432497e-05, &#x27;epoch&#x27;: 1.79}
{&#x27;loss&#x27;: 0.0005, &#x27;learning_rate&#x27;: 1.989247311827957e-05, &#x27;epoch&#x27;: 1.81}
{&#x27;loss&#x27;: 0.1246, &#x27;learning_rate&#x27;: 1.9653524492234173e-05, &#x27;epoch&#x27;: 1.82}
{&#x27;loss&#x27;: 0.0974, &#x27;learning_rate&#x27;: 1.941457586618877e-05, &#x27;epoch&#x27;: 1.84}
{&#x27;loss&#x27;: 0.0003, &#x27;learning_rate&#x27;: 1.9175627240143372e-05, &#x27;epoch&#x27;: 1.85}
{&#x27;loss&#x27;: 0.0007, &#x27;learning_rate&#x27;: 1.893667861409797e-05, &#x27;epoch&#x27;: 1.86}
{&#x27;loss&#x27;: 0.1998, &#x27;learning_rate&#x27;: 1.869772998805257e-05, &#x27;epoch&#x27;: 1.88}
{&#x27;loss&#x27;: 0.0426, &#x27;learning_rate&#x27;: 1.845878136200717e-05, &#x27;epoch&#x27;: 1.89}
{&#x27;loss&#x27;: 0.002, &#x27;learning_rate&#x27;: 1.821983273596177e-05, &#x27;epoch&#x27;: 1.91}
{&#x27;loss&#x27;: 0.0009, &#x27;learning_rate&#x27;: 1.7980884109916368e-05, &#x27;epoch&#x27;: 1.92}
{&#x27;loss&#x27;: 0.0027, &#x27;learning_rate&#x27;: 1.774193548387097e-05, &#x27;epoch&#x27;: 1.94}
{&#x27;loss&#x27;: 0.0004, &#x27;learning_rate&#x27;: 1.7502986857825567e-05, &#x27;epoch&#x27;: 1.95}
{&#x27;loss&#x27;: 0.0003, &#x27;learning_rate&#x27;: 1.7264038231780168e-05, &#x27;epoch&#x27;: 1.96}
{&#x27;loss&#x27;: 0.1081, &#x27;learning_rate&#x27;: 1.702508960573477e-05, &#x27;epoch&#x27;: 1.98}
{&#x27;loss&#x27;: 0.0005, &#x27;learning_rate&#x27;: 1.678614097968937e-05, &#x27;epoch&#x27;: 1.99}</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">  0%|          | 0/140 [00:00&lt;?, ?it/s]</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">{&#x27;eval_loss&#x27;: 0.014878345653414726, &#x27;eval_accuracy&#x27;: 0.9973094170403587, &#x27;eval_runtime&#x27;: 4.0209, &#x27;eval_samples_per_second&#x27;: 277.3, &#x27;eval_steps_per_second&#x27;: 34.818, &#x27;epoch&#x27;: 2.0}
{&#x27;loss&#x27;: 0.0005, &#x27;learning_rate&#x27;: 1.6547192353643968e-05, &#x27;epoch&#x27;: 2.01}
{&#x27;loss&#x27;: 0.0005, &#x27;learning_rate&#x27;: 1.630824372759857e-05, &#x27;epoch&#x27;: 2.02}
{&#x27;loss&#x27;: 0.0004, &#x27;learning_rate&#x27;: 1.6069295101553167e-05, &#x27;epoch&#x27;: 2.04}
{&#x27;loss&#x27;: 0.0005, &#x27;learning_rate&#x27;: 1.5830346475507768e-05, &#x27;epoch&#x27;: 2.05}
{&#x27;loss&#x27;: 0.0004, &#x27;learning_rate&#x27;: 1.5591397849462366e-05, &#x27;epoch&#x27;: 2.06}
{&#x27;loss&#x27;: 0.0135, &#x27;learning_rate&#x27;: 1.5352449223416964e-05, &#x27;epoch&#x27;: 2.08}
{&#x27;loss&#x27;: 0.0014, &#x27;learning_rate&#x27;: 1.5113500597371565e-05, &#x27;epoch&#x27;: 2.09}
{&#x27;loss&#x27;: 0.0003, &#x27;learning_rate&#x27;: 1.4874551971326165e-05, &#x27;epoch&#x27;: 2.11}
{&#x27;loss&#x27;: 0.0003, &#x27;learning_rate&#x27;: 1.4635603345280766e-05, &#x27;epoch&#x27;: 2.12}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 1.4396654719235364e-05, &#x27;epoch&#x27;: 2.14}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 1.4157706093189965e-05, &#x27;epoch&#x27;: 2.15}
{&#x27;loss&#x27;: 0.0003, &#x27;learning_rate&#x27;: 1.3918757467144564e-05, &#x27;epoch&#x27;: 2.16}
{&#x27;loss&#x27;: 0.0008, &#x27;learning_rate&#x27;: 1.3679808841099166e-05, &#x27;epoch&#x27;: 2.18}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 1.3440860215053763e-05, &#x27;epoch&#x27;: 2.19}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 1.3201911589008365e-05, &#x27;epoch&#x27;: 2.21}
{&#x27;loss&#x27;: 0.0003, &#x27;learning_rate&#x27;: 1.2962962962962962e-05, &#x27;epoch&#x27;: 2.22}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 1.2724014336917564e-05, &#x27;epoch&#x27;: 2.24}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 1.2485065710872163e-05, &#x27;epoch&#x27;: 2.25}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 1.2246117084826763e-05, &#x27;epoch&#x27;: 2.27}
{&#x27;loss&#x27;: 0.0006, &#x27;learning_rate&#x27;: 1.2007168458781362e-05, &#x27;epoch&#x27;: 2.28}
{&#x27;loss&#x27;: 0.0875, &#x27;learning_rate&#x27;: 1.1768219832735962e-05, &#x27;epoch&#x27;: 2.29}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 1.1529271206690561e-05, &#x27;epoch&#x27;: 2.31}
{&#x27;loss&#x27;: 0.0003, &#x27;learning_rate&#x27;: 1.129032258064516e-05, &#x27;epoch&#x27;: 2.32}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 1.1051373954599762e-05, &#x27;epoch&#x27;: 2.34}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 1.0812425328554361e-05, &#x27;epoch&#x27;: 2.35}
{&#x27;loss&#x27;: 0.0003, &#x27;learning_rate&#x27;: 1.0573476702508961e-05, &#x27;epoch&#x27;: 2.37}
{&#x27;loss&#x27;: 0.0006, &#x27;learning_rate&#x27;: 1.033452807646356e-05, &#x27;epoch&#x27;: 2.38}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 1.009557945041816e-05, &#x27;epoch&#x27;: 2.39}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 9.856630824372761e-06, &#x27;epoch&#x27;: 2.41}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 9.61768219832736e-06, &#x27;epoch&#x27;: 2.42}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 9.37873357228196e-06, &#x27;epoch&#x27;: 2.44}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 9.13978494623656e-06, &#x27;epoch&#x27;: 2.45}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 8.90083632019116e-06, &#x27;epoch&#x27;: 2.47}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 8.661887694145759e-06, &#x27;epoch&#x27;: 2.48}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 8.42293906810036e-06, &#x27;epoch&#x27;: 2.49}
{&#x27;loss&#x27;: 0.0909, &#x27;learning_rate&#x27;: 8.18399044205496e-06, &#x27;epoch&#x27;: 2.51}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 7.945041816009559e-06, &#x27;epoch&#x27;: 2.52}
{&#x27;loss&#x27;: 0.0788, &#x27;learning_rate&#x27;: 7.706093189964159e-06, &#x27;epoch&#x27;: 2.54}
{&#x27;loss&#x27;: 0.0003, &#x27;learning_rate&#x27;: 7.467144563918758e-06, &#x27;epoch&#x27;: 2.55}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 7.228195937873358e-06, &#x27;epoch&#x27;: 2.57}
{&#x27;loss&#x27;: 0.0011, &#x27;learning_rate&#x27;: 6.989247311827957e-06, &#x27;epoch&#x27;: 2.58}
{&#x27;loss&#x27;: 0.0003, &#x27;learning_rate&#x27;: 6.7502986857825566e-06, &#x27;epoch&#x27;: 2.59}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 6.511350059737156e-06, &#x27;epoch&#x27;: 2.61}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 6.2724014336917564e-06, &#x27;epoch&#x27;: 2.62}
{&#x27;loss&#x27;: 0.0003, &#x27;learning_rate&#x27;: 6.033452807646357e-06, &#x27;epoch&#x27;: 2.64}
{&#x27;loss&#x27;: 0.0003, &#x27;learning_rate&#x27;: 5.794504181600956e-06, &#x27;epoch&#x27;: 2.65}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 5.555555555555556e-06, &#x27;epoch&#x27;: 2.67}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 5.316606929510155e-06, &#x27;epoch&#x27;: 2.68}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 5.077658303464755e-06, &#x27;epoch&#x27;: 2.7}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 4.838709677419355e-06, &#x27;epoch&#x27;: 2.71}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 4.599761051373955e-06, &#x27;epoch&#x27;: 2.72}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 4.360812425328554e-06, &#x27;epoch&#x27;: 2.74}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 4.121863799283155e-06, &#x27;epoch&#x27;: 2.75}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 3.882915173237754e-06, &#x27;epoch&#x27;: 2.77}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 3.643966547192354e-06, &#x27;epoch&#x27;: 2.78}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 3.405017921146954e-06, &#x27;epoch&#x27;: 2.8}
{&#x27;loss&#x27;: 0.0429, &#x27;learning_rate&#x27;: 3.1660692951015535e-06, &#x27;epoch&#x27;: 2.81}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 2.927120669056153e-06, &#x27;epoch&#x27;: 2.82}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 2.688172043010753e-06, &#x27;epoch&#x27;: 2.84}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 2.449223416965353e-06, &#x27;epoch&#x27;: 2.85}
{&#x27;loss&#x27;: 0.0761, &#x27;learning_rate&#x27;: 2.2102747909199524e-06, &#x27;epoch&#x27;: 2.87}
{&#x27;loss&#x27;: 0.0007, &#x27;learning_rate&#x27;: 1.971326164874552e-06, &#x27;epoch&#x27;: 2.88}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 1.7323775388291518e-06, &#x27;epoch&#x27;: 2.9}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 1.4934289127837516e-06, &#x27;epoch&#x27;: 2.91}
{&#x27;loss&#x27;: 0.0003, &#x27;learning_rate&#x27;: 1.2544802867383513e-06, &#x27;epoch&#x27;: 2.92}
{&#x27;loss&#x27;: 0.0003, &#x27;learning_rate&#x27;: 1.015531660692951e-06, &#x27;epoch&#x27;: 2.94}
{&#x27;loss&#x27;: 0.0144, &#x27;learning_rate&#x27;: 7.765830346475508e-07, &#x27;epoch&#x27;: 2.95}
{&#x27;loss&#x27;: 0.0568, &#x27;learning_rate&#x27;: 5.376344086021506e-07, &#x27;epoch&#x27;: 2.97}
{&#x27;loss&#x27;: 0.0001, &#x27;learning_rate&#x27;: 2.9868578255675034e-07, &#x27;epoch&#x27;: 2.98}
{&#x27;loss&#x27;: 0.0002, &#x27;learning_rate&#x27;: 5.973715651135006e-08, &#x27;epoch&#x27;: 3.0}</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">  0%|          | 0/140 [00:00&lt;?, ?it/s]</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">{&#x27;eval_loss&#x27;: 0.026208847761154175, &#x27;eval_accuracy&#x27;: 0.9937219730941704, &#x27;eval_runtime&#x27;: 4.0835, &#x27;eval_samples_per_second&#x27;: 273.052, &#x27;eval_steps_per_second&#x27;: 34.285, &#x27;epoch&#x27;: 3.0}
{&#x27;train_runtime&#x27;: 244.4781, &#x27;train_samples_per_second&#x27;: 54.717, &#x27;train_steps_per_second&#x27;: 6.847, &#x27;train_loss&#x27;: 0.0351541918909871, &#x27;epoch&#x27;: 3.0}</pre>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="creating-a-pipeline-with-the-fine-tuned-model">Creating a Pipeline with the Fine-Tuned Model<a href="#creating-a-pipeline-with-the-fine-tuned-model" class="hash-link" aria-label="Direct link to Creating a Pipeline with the Fine-Tuned Model" title="Direct link to Creating a Pipeline with the Fine-Tuned Model">â€‹</a></h3>
<p>In this section, we&#x27;re going to create a pipeline that contains our fine-tuned model.</p>
<p>After completing the training process, our next step is to create a pipeline for inference using our fine-tuned model. This pipeline will enable us to easily make predictions with the model.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="setting-up-the-inference-pipeline">Setting Up the Inference Pipeline<a href="#setting-up-the-inference-pipeline" class="hash-link" aria-label="Direct link to Setting Up the Inference Pipeline" title="Direct link to Setting Up the Inference Pipeline">â€‹</a></h4>
<ul>
<li><strong>Pipeline Creation</strong>: We use the <code>pipeline</code> function from the Transformers library to create an inference pipeline. This pipeline is configured for the task of text classification.</li>
<li><strong>Model Integration</strong>: We integrate our fine-tuned model (<code>trainer.model</code>) into the pipeline. This ensures that the pipeline uses our newly trained model for inference.</li>
<li><strong>Configuring the Pipeline</strong>: We set the batch size and tokenizer in the pipeline configuration. Additionally, we specify the device type, which is crucial for performance considerations.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="device-configuration-for-different-platforms">Device Configuration for Different Platforms<a href="#device-configuration-for-different-platforms" class="hash-link" aria-label="Direct link to Device Configuration for Different Platforms" title="Direct link to Device Configuration for Different Platforms">â€‹</a></h4>
<ul>
<li><strong>Apple Silicon (M1/M2) Devices</strong>: For those using Apple Silicon (e.g., M1 or M2 chips), we set the device type to <code>&quot;mps&quot;</code> in the pipeline. This leverages Apple&#x27;s Metal Performance Shaders for optimized performance on these devices.</li>
<li><strong>Other Devices</strong>: If you&#x27;re using a device other than a MacBook Pro with Apple Silicon, you&#x27;ll need to adjust the device setting to match your hardware (e.g., <code>&quot;cuda&quot;</code> for NVIDIA GPUs or <code>&quot;cpu&quot;</code> for CPU-only inference).</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="importance-of-a-customized-pipeline">Importance of a Customized Pipeline<a href="#importance-of-a-customized-pipeline" class="hash-link" aria-label="Direct link to Importance of a Customized Pipeline" title="Direct link to Importance of a Customized Pipeline">â€‹</a></h4>
<p>Creating a customized pipeline with our fine-tuned model allows for easy and efficient inference, tailored to our specific task and hardware. This step is vital in transitioning from model training to practical application.</p>
<p>In the following code block, we&#x27;ll set up our pipeline with the fine-tuned model and configure it for our device.</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># If you&#x27;re going to run this on something other than a Macbook Pro, change the device to the applicable type. &quot;mps&quot; is for Apple Silicon architecture in torch.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tuned_pipeline </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> pipeline</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  task</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;text-classification&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">trainer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  batch_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">8</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  tokenizer</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">tokenizer</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  device</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;mps&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="validating-the-fine-tuned-model">Validating the Fine-Tuned Model<a href="#validating-the-fine-tuned-model" class="hash-link" aria-label="Direct link to Validating the Fine-Tuned Model" title="Direct link to Validating the Fine-Tuned Model">â€‹</a></h3>
<p>In this next step, we&#x27;re going to validate that our fine-tuning training was effective prior to logging the tuned model to our run.</p>
<p>Before finalizing our model by logging it to MLflow, it&#x27;s crucial to validate its performance. This validation step ensures that the model meets our expectations and is ready for deployment.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="importance-of-model-validation">Importance of Model Validation<a href="#importance-of-model-validation" class="hash-link" aria-label="Direct link to Importance of Model Validation" title="Direct link to Importance of Model Validation">â€‹</a></h4>
<ul>
<li><strong>Assessing Model Performance</strong>: We need to evaluate the model&#x27;s performance on realistic scenarios to ensure it behaves as expected. This helps in identifying any issues or shortcomings in the model before it is logged and potentially deployed.</li>
<li><strong>Avoiding Costly Redo&#x27;s</strong>: Given the large size of Transformer models and the computational resources required for training, it&#x27;s essential to validate the model beforehand. If a model doesnâ€™t perform well, we wouldn&#x27;t want to log the model, only to have to later delete the run and the logged artifacts.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="evaluating-with-a-test-query">Evaluating with a Test Query<a href="#evaluating-with-a-test-query" class="hash-link" aria-label="Direct link to Evaluating with a Test Query" title="Direct link to Evaluating with a Test Query">â€‹</a></h4>
<ul>
<li><strong>Test Query</strong>: We will pass a realistic test query to our tuned pipeline to see how the model performs. This query should be representative of the kind of input the model is expected to handle in a real-world scenario.</li>
<li><strong>Observing the Output</strong>: By analyzing the output of the model for this query, we can gauge its understanding and response to complex situations. This provides a practical insight into the model&#x27;s capabilities post-fine-tuning.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="validating-before-logging-to-mlflow">Validating Before Logging to MLflow<a href="#validating-before-logging-to-mlflow" class="hash-link" aria-label="Direct link to Validating Before Logging to MLflow" title="Direct link to Validating Before Logging to MLflow">â€‹</a></h4>
<ul>
<li><strong>Rationale</strong>: The reason for this validation step is to ensure that the model we log to MLflow is of high quality and ready for further steps like deployment or sharing. Logging a poorly performing model would lead to unnecessary complications, especially considering the large size and complexity of these models.</li>
</ul>
<p>After validating the model and ensuring satisfactory performance, we can confidently proceed to log it in MLflow, knowing it&#x27;s ready for real-world applications.</p>
<p>In the next code block, we will run a test query through our fine-tuned model to evaluate its performance before proceeding to log it in MLflow.</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Perform a validation of our assembled pipeline that contains our fine-tuned model.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">quick_check </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;I have a question regarding the project development timeline and allocated resources; &quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;specifically, how certain are you that John and Ringo can work together on writing this next song? &quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;Do we need to get Paul involved here, or do you truly believe, as you said, &#x27;nah, they got this&#x27;?&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tuned_pipeline</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">quick_check</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">[{&#x27;label&#x27;: &#x27;ham&#x27;, &#x27;score&#x27;: 0.9985793828964233}]</pre>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="model-configuration-and-signature-inference">Model Configuration and Signature Inference<a href="#model-configuration-and-signature-inference" class="hash-link" aria-label="Direct link to Model Configuration and Signature Inference" title="Direct link to Model Configuration and Signature Inference">â€‹</a></h3>
<p>In this next step, we generate a signature for our pipeline in preparation for logging.</p>
<p>After validating our model&#x27;s performance, the next critical step is to prepare it for logging to MLflow. This involves setting up the model&#x27;s configuration and inferring its signature, which are essential aspects of the model management process.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="configuring-the-model-for-mlflow">Configuring the Model for MLflow<a href="#configuring-the-model-for-mlflow" class="hash-link" aria-label="Direct link to Configuring the Model for MLflow" title="Direct link to Configuring the Model for MLflow">â€‹</a></h4>
<ul>
<li><strong>Setting Model Configuration</strong>: We define a <code>model_config</code> dictionary to specify configuration parameters such as batch size and the device type (e.g., <code>&quot;mps&quot;</code> for Apple Silicon). This configuration is vital for ensuring that the model operates correctly in different environments.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="inferring-the-model-signature">Inferring the Model Signature<a href="#inferring-the-model-signature" class="hash-link" aria-label="Direct link to Inferring the Model Signature" title="Direct link to Inferring the Model Signature">â€‹</a></h4>
<ul>
<li><strong>Purpose of Signature Inference</strong>: The model signature defines the input and output schema of the model. Inferring this signature is crucial as it helps MLflow understand the data types and shapes that the model expects and produces.</li>
<li><strong>Using mlflow.models.infer_signature</strong>: We use this function to automatically infer the model signature. We provide sample input and output data to the function, which analyzes them to determine the appropriate schema.</li>
<li><strong>Including Model Parameters</strong>: Along with the input and output, we also include the <code>model_config</code> in the signature. This ensures that all relevant information about how the model should be run is captured.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="importance-of-signature-inference">Importance of Signature Inference<a href="#importance-of-signature-inference" class="hash-link" aria-label="Direct link to Importance of Signature Inference" title="Direct link to Importance of Signature Inference">â€‹</a></h4>
<p>Inferring the signature is a key step in preparing the model for logging and future deployment. It ensures that anyone who uses the model later, either for further development or in production, has clear information about the expected data format, making the model more robust and user-friendly.</p>
<p>With the model configuration set and its signature inferred, we are now ready to log the model into MLflow. This will be our next step, ensuring our model is properly managed and ready for deployment.</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Define a set of parameters that we would like to be able to flexibly override at inference time, along with their default values</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model_config </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&quot;batch_size&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">8</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Infer the model signature, including a representative input, the expected output, and the parameters that we would like to be able to override at inference time.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">signature </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">models</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">infer_signature</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;This is a test!&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;And this is also a test.&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">generate_signature_output</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      tuned_pipeline</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;This is a test response!&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;So is this.&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  params</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">model_config</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="logging-the-fine-tuned-model-to-mlflow">Logging the Fine-Tuned Model to MLflow<a href="#logging-the-fine-tuned-model-to-mlflow" class="hash-link" aria-label="Direct link to Logging the Fine-Tuned Model to MLflow" title="Direct link to Logging the Fine-Tuned Model to MLflow">â€‹</a></h3>
<p>In this next section, we&#x27;re going to log our validated pipeline to the training run.</p>
<p>With our model configuration and signature ready, the final step in our model training and validation process is to log the model to MLflow. This step is crucial for tracking and managing the model in a systematic way.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="accessing-the-existing-run-used-for-training">Accessing the existing Run used for training<a href="#accessing-the-existing-run-used-for-training" class="hash-link" aria-label="Direct link to Accessing the existing Run used for training" title="Direct link to Accessing the existing Run used for training">â€‹</a></h4>
<ul>
<li><strong>Initiating MLflow Run</strong>: We start a new run in MLflow using <code>mlflow.start_run()</code>. This new run is specifically for the purpose of logging the model, separate from the training run.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="logging-the-model-in-mlflow">Logging the Model in MLflow<a href="#logging-the-model-in-mlflow" class="hash-link" aria-label="Direct link to Logging the Model in MLflow" title="Direct link to Logging the Model in MLflow">â€‹</a></h4>
<ul>
<li>
<p><strong>Using mlflow.transformers.log_model</strong>: We log our fine-tuned model using this function. It&#x27;s specially designed for logging models from the Transformers library, making the process streamlined and efficient.</p>
</li>
<li>
<p><strong>Specifying Model Information</strong>: We provide several pieces of information to the logging function:</p>
<ul>
<li><strong>transformers_model</strong>: The fine-tuned model pipeline.</li>
<li><strong>artifact_path</strong>: The path where the model artifacts will be stored.</li>
<li><strong>signature</strong>: The inferred signature of the model, which includes input and output schemas.</li>
<li><strong>input_example</strong>: Sample inputs to give users an idea of what input the model expects.</li>
<li><strong>model_config</strong>: The configuration parameters of the model.</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="importance-of-model-logging">Importance of Model Logging<a href="#importance-of-model-logging" class="hash-link" aria-label="Direct link to Importance of Model Logging" title="Direct link to Importance of Model Logging">â€‹</a></h4>
<p>Logging the model in MLflow serves multiple purposes:</p>
<ul>
<li><strong>Version Control</strong>: It helps in keeping track of different versions of the model.</li>
<li><strong>Model Management</strong>: Facilitates the management of the model lifecycle, from training to deployment.</li>
<li><strong>Reproducibility and Sharing</strong>: Enhances reproducibility and makes it easier to share the model with others.</li>
</ul>
<p>By logging our model in MLflow, we ensure that it is well-documented, versioned, and ready for future use, whether for further development or deployment.</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Log the pipeline to the existing training run</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">with</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">start_run</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">run_id</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">run</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">info</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">run_id</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  model_info </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">log_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      transformers_model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">tuned_pipeline</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      name</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;fine_tuned&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      signature</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">signature</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      input_example</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;Pass in a string&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;And have it mark as spam or not.&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      model_config</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">model_config</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">2023/11/30 12:17:11 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /var/folders/cd/n8n0rm2x53l_s0xv_j_xklb00000gp/T/tmp77_imuy9/model, flavor: transformers), fall back to return [&#x27;transformers==4.34.1&#x27;, &#x27;torch==2.1.0&#x27;, &#x27;torchvision==0.16.0&#x27;, &#x27;accelerate==0.21.0&#x27;]. Set logging level to DEBUG to see the full traceback.</pre>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="loading-and-testing-the-model-from-mlflow">Loading and Testing the Model from MLflow<a href="#loading-and-testing-the-model-from-mlflow" class="hash-link" aria-label="Direct link to Loading and Testing the Model from MLflow" title="Direct link to Loading and Testing the Model from MLflow">â€‹</a></h3>
<p>After logging our fine-tuned model to MLflow, we&#x27;ll now load and test it.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="loading-the-model-from-mlflow">Loading the Model from MLflow<a href="#loading-the-model-from-mlflow" class="hash-link" aria-label="Direct link to Loading the Model from MLflow" title="Direct link to Loading the Model from MLflow">â€‹</a></h4>
<ul>
<li><strong>Using mlflow.transformers.load_model</strong>: We use this function to load the model stored in MLflow. This demonstrates how models can be retrieved and utilized post-training, ensuring they are accessible for future use.</li>
<li><strong>Retrieving Model URI</strong>: We use the <code>model_uri</code> obtained from logging the model to MLflow. This URI is the unique identifier for our logged model, allowing us to retrieve it accurately.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="testing-the-model-with-validation-text">Testing the Model with Validation Text<a href="#testing-the-model-with-validation-text" class="hash-link" aria-label="Direct link to Testing the Model with Validation Text" title="Direct link to Testing the Model with Validation Text">â€‹</a></h4>
<ul>
<li><strong>Preparing Validation Text</strong>: We use a creatively crafted text to test the model&#x27;s performance. This text is designed to mimic a typical spam message, which is relevant to our model&#x27;s training on spam classification.</li>
<li><strong>Evaluating Model Output</strong>: By passing this text through the loaded model, we can observe its performance and effectiveness in a practical scenario. This step is crucial to ensure that the model works as expected in real-world conditions.</li>
</ul>
<p>Testing the model after loading it from MLflow is essential for several reasons:</p>
<ul>
<li><strong>Validation of Logging Process</strong>: It confirms that the model was logged and loaded correctly.</li>
<li><strong>Practical Performance Assessment</strong>: Provides a real-world assessment of the model&#x27;s performance, which is critical for deployment decisions.</li>
<li><strong>Demonstrating End-to-End Workflow</strong>: Showcases a complete workflow from training, logging, loading, to using the model, which is vital for understanding the entire model lifecycle.</li>
</ul>
<p>In the next code block, we&#x27;ll load our model from MLflow and test it with a validation text to assess its real-world performance.</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Load our saved model in the native transformers format</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">loaded </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model_uri</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">model_info</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_uri</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Define a test example that we expect to be classified as spam</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">validation_text </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;Want to learn how to make MILLIONS with no effort? Click HERE now! See for yourself! Guaranteed to make you instantly rich! &quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&quot;Don&#x27;t miss out you could be a winner!&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># validate the performance of our fine-tuning</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">loaded</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">validation_text</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">2023/11/30 12:17:11 INFO mlflow.transformers: &#x27;runs:/e3260e8511c94c38aafb7124509240a4/fine_tuned&#x27; resolved as &#x27;file:///Users/benjamin.wilson/repos/mlflow-fork/mlflow/docs/source/llms/transformers/tutorials/fine-tuning/mlruns/258758267044147956/e3260e8511c94c38aafb7124509240a4/artifacts/fine_tuned&#x27;
2023/11/30 12:17:11 WARNING mlflow.transformers: Could not specify device parameter for this pipeline type</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">[{&#x27;label&#x27;: &#x27;spam&#x27;, &#x27;score&#x27;: 0.9873914122581482}]</pre>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion-mastering-fine-tuning-and-mlflow-integration">Conclusion: Mastering Fine-Tuning and MLflow Integration<a href="#conclusion-mastering-fine-tuning-and-mlflow-integration" class="hash-link" aria-label="Direct link to Conclusion: Mastering Fine-Tuning and MLflow Integration" title="Direct link to Conclusion: Mastering Fine-Tuning and MLflow Integration">â€‹</a></h3>
<p>Congratulations on completing this comprehensive tutorial on fine-tuning a Transformers model and integrating it with MLflow! Letâ€™s recap the essential skills and knowledge you&#x27;ve acquired through this journey.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="key-takeaways">Key Takeaways<a href="#key-takeaways" class="hash-link" aria-label="Direct link to Key Takeaways" title="Direct link to Key Takeaways">â€‹</a></h4>
<ol>
<li><strong>Fine-Tuning Transformers Models</strong>: Youâ€™ve learned how to fine-tune a foundational model from the Transformers library. This process demonstrates the power of adapting advanced pre-trained models to specific tasks, tailoring their performance to meet unique requirements.</li>
<li><strong>Ease of Fine-Tuning</strong>: We&#x27;ve seen firsthand how straightforward it is to fine-tune these advanced Large Language Models (LLMs). With the right tools and understanding, fine-tuning can significantly enhance a modelâ€™s performance on specific tasks.</li>
<li><strong>Specificity in Performance</strong>: The ability to fine-tune LLMs opens up a world of possibilities, allowing us to create models that excel in particular domains or tasks. This specificity in performance is crucial in deploying models in real-world scenarios where specialized understanding is required.</li>
</ol>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="integrating-mlflow-with-transformers">Integrating MLflow with Transformers<a href="#integrating-mlflow-with-transformers" class="hash-link" aria-label="Direct link to Integrating MLflow with Transformers" title="Direct link to Integrating MLflow with Transformers">â€‹</a></h4>
<ol>
<li><strong>Tracking and Managing the Fine-Tuning Process</strong>: A significant part of this tutorial was dedicated to using MLflow for experiment tracking, model logging, and management. Youâ€™ve learned how MLflow simplifies these aspects, making the machine learning workflow more manageable and efficient.</li>
<li><strong>Benefits of MLflow in Fine-Tuning</strong>: MLflow plays a crucial role in ensuring reproducibility, managing model versions, and streamlining the deployment process. Its integration with the Transformers fine-tuning process demonstrates the potential for synergy between advanced model training techniques and lifecycle management tools.</li>
</ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/mlflow/mlflow/edit/master/docs/docs/llms/transformers/tutorials/fine-tuning/transformers-fine-tuning.ipynb" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/latest/llms/transformers/tutorials/conversational/pyfunc-chat-model"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Deploying a Transformer model as an OpenAI-compatible Chatbot</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/latest/llms/transformers/tutorials/fine-tuning/transformers-peft"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Fine-Tuning Open-Source LLM using QLoRA with MLflow and PEFT</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#what-you-will-learn-in-this-tutorial" class="table-of-contents__link toc-highlight">What You Will Learn in This Tutorial</a></li><li><a href="#preparing-the-dataset-and-environment-for-fine-tuning" class="table-of-contents__link toc-highlight">Preparing the Dataset and Environment for Fine-Tuning</a></li><li><a href="#tokenization-and-dataset-preparation" class="table-of-contents__link toc-highlight">Tokenization and Dataset Preparation</a></li><li><a href="#model-initialization-and-label-mapping" class="table-of-contents__link toc-highlight">Model Initialization and Label Mapping</a></li><li><a href="#setting-up-evaluation-metrics" class="table-of-contents__link toc-highlight">Setting Up Evaluation Metrics</a></li><li><a href="#configuring-the-training-environment" class="table-of-contents__link toc-highlight">Configuring the Training Environment</a></li><li><a href="#integrating-mlflow-for-experiment-tracking" class="table-of-contents__link toc-highlight">Integrating MLflow for Experiment Tracking</a></li><li><a href="#starting-the-training-process-with-mlflow" class="table-of-contents__link toc-highlight">Starting the Training Process with MLflow</a></li><li><a href="#creating-a-pipeline-with-the-fine-tuned-model" class="table-of-contents__link toc-highlight">Creating a Pipeline with the Fine-Tuned Model</a></li><li><a href="#validating-the-fine-tuned-model" class="table-of-contents__link toc-highlight">Validating the Fine-Tuned Model</a></li><li><a href="#model-configuration-and-signature-inference" class="table-of-contents__link toc-highlight">Model Configuration and Signature Inference</a></li><li><a href="#logging-the-fine-tuned-model-to-mlflow" class="table-of-contents__link toc-highlight">Logging the Fine-Tuned Model to MLflow</a></li><li><a href="#loading-and-testing-the-model-from-mlflow" class="table-of-contents__link toc-highlight">Loading and Testing the Model from MLflow</a></li><li><a href="#conclusion-mastering-fine-tuning-and-mlflow-integration" class="table-of-contents__link toc-highlight">Conclusion: Mastering Fine-Tuning and MLflow Integration</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/mlflow" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.linkedin.com/company/mlflow-org" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://x.com/mlflow" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Resources</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/latest/">Docs</a></li><li class="footer__item"><a href="https://mlflow.org/releases" target="_blank" rel="noopener noreferrer" class="footer__link-item">Releases</a></li><li class="footer__item"><a href="https://mlflow.org/blog" target="_blank" rel="noopener noreferrer" class="footer__link-item">Blog</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2025 MLflow Project, a Series of LF Projects, LLC.</div></div></div></footer></div>
</body>
</html>