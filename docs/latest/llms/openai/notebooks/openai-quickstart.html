
  

<!DOCTYPE html>
<!-- source: docs/source/llms/openai/notebooks/openai-quickstart.ipynb -->
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Introduction to Using the OpenAI Flavor in MLflow &mdash; MLflow 2.14.2.dev0 documentation</title>
  
   
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <link rel="canonical" href="https://mlflow.org/docs/latest/llms/openai/notebooks/openai-quickstart.html">
  
  
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    

    

  
    
        <!-- Google Tag Manager -->
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer',"GTM-N6WMTTJ");</script>
        <!-- End Google Tag Manager -->
    

  

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/cards.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/grids.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/mobile.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/simple-cards.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/tabs.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="../../../genindex.html"/>
        <link rel="search" title="Search" href="../../../search.html"/>
    <link rel="top" title="MLflow 2.14.2.dev0 documentation" href="../../../index.html"/>
        <link rel="up" title="MLflow OpenAI Flavor" href="../index.html"/>
        <link rel="next" title="Introduction: Advancing Communication with GPT-4 and MLflow" href="/openai-chat-completions.html"/>
        <link rel="prev" title="MLflow OpenAI Flavor" href="/../index.html"/> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>
<script type="text/javascript" src="../../../_static/jquery.js"></script>
<script type="text/javascript" src="../../../_static/underscore.js"></script>
<script type="text/javascript" src="../../../_static/doctools.js"></script>
<script type="text/javascript" src="../../../_static/languagesections.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/javascript" src="../../../None"></script>

<body class="wy-body-for-nav" role="document">
  
    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->
  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <ul>
  <li class="menu-toggle">
    <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
    <a href="../../../index.html" class="wy-nav-top-logo"
      ><img src="../../../_static/MLflow-logo-final-black.png" alt="MLflow"
    /></a>
    <span class="version">2.14.2.dev0</span>
  </li>
</ul>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side relative">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
  </form>
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../../index.html" class="main-navigation-home"><img src="../../../_static/icons/nav-home.svg"> MLflow</a>
    

    
      

      
        <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../introduction/index.html">What is MLflow?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting-started/index.html">Getting Started with MLflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../new-features/index.html">New Features</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">LLMs</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../index.html#id1">MLflow Tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#id2">MLflow Deployments Server for LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#id3">LLM Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#id4">Prompt Engineering UI</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../index.html#native-mlflow-flavors-for-llms">Native MLflow Flavors for LLMs</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../../transformers/index.html">MLflow Transformers Flavor</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../index.html">MLflow OpenAI Flavor</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../index.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../index.html#what-makes-this-integration-so-special">What makes this Integration so Special?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../index.html#features">Features</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="../index.html#getting-started-with-the-mlflow-openai-flavor-tutorials-and-guides">Getting Started with the MLflow OpenAI Flavor - Tutorials and Guides</a></li>
<li class="toctree-l4"><a class="reference internal" href="../index.html#id1">Detailed Documentation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../sentence-transformers/index.html">MLflow Sentence-Transformers Flavor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../langchain/index.html">MLflow LangChain Flavor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../index.html#explore-the-native-llm-flavors">Explore the Native LLM Flavors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#id5">LLM Tracking in MLflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#tutorials-and-use-case-guides-for-llms-in-mlflow">Tutorials and Use Case Guides for LLMs in MLflow</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../model-evaluation/index.html">Model Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deep-learning/index.html">Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../traditional-ml/index.html">Traditional ML</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deployment/index.html">Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tracking.html">MLflow Tracking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../system-metrics/index.html">System Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects.html">MLflow Projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">MLflow Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../model-registry.html">MLflow Model Registry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../recipes.html">MLflow Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../plugins.html">MLflow Plugins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../auth/index.html">MLflow Authentication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../search-runs.html">Search Runs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../search-experiments.html">Search Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../R-api.html">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../java_api/index.html">Java API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../rest-api.html">REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docker.html">Official MLflow Docker Image</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../community-model-flavors.html">Community Model Flavors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials-and-examples/index.html">Tutorials and Examples</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            










<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="../../index.html">LLMs</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="../index.html">MLflow OpenAI Flavor</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Introduction to Using the OpenAI Flavor in MLflow</li>
    
    
    <!-- <li class="wy-breadcrumbs-aside">
      <a href="https://github.com/mlflow/mlflow/blob/master/docs/source/llms/openai/notebooks/openai-quickstart.ipynb" class="fa fa-github"> Edit on GitHub</a>
    </li> -->
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Introduction-to-Using-the-OpenAI-Flavor-in-MLflow">
<h1>Introduction to Using the OpenAI Flavor in MLflow<a class="headerlink" href="#Introduction-to-Using-the-OpenAI-Flavor-in-MLflow" title="Permalink to this headline"> </a></h1>
<p>Welcome to our tutorial on harnessing the power of OpenAI’s GPT models through the MLflow <code class="docutils literal notranslate"><span class="pre">openai</span></code> flavor. In this session, we embark on a journey to explore the intriguing world of AI-powered text analysis and modification. As we delve into the capabilities of GPT models, you’ll discover the nuances of their API and understand the evolution from the older Completions API to the more advanced ChatCompletions, which offers a conversational style interaction.</p>
<a href="https://raw.githubusercontent.com/mlflow/mlflow/master/docs/source/llms/openai/notebooks/openai-chat-completions.ipynb" class="notebook-download-btn"><i class="fas fa-download"></i>Download this Notebook</a><br><div class="section" id="What-You-Will-Learn:">
<h2>What You Will Learn:<a class="headerlink" href="#What-You-Will-Learn:" title="Permalink to this headline"> </a></h2>
<ul class="simple">
<li><p><strong>Interfacing with GPT Models</strong>: Understand how to interact with different model families like GPT-3.5 and GPT-4.</p></li>
<li><p><strong>MLflow Integration</strong>: Learn to seamlessly integrate these models within MLflow, allowing you to craft a purpose-built model instance that performs a single specific task in a predictable and repeatable way.</p></li>
<li><p><strong>Model Definition</strong>: You’ll learn how to define a simple single-purpose prompt with the <code class="docutils literal notranslate"><span class="pre">Completions</span></code> endpoint to define a function that you can interact with.</p></li>
</ul>
</div>
<div class="section" id="Backstory:-OpenAI-and-GPT-Models">
<h2>Backstory: OpenAI and GPT Models<a class="headerlink" href="#Backstory:-OpenAI-and-GPT-Models" title="Permalink to this headline"> </a></h2>
<p>OpenAI has revolutionized the field of natural language processing with their Generative Pre-trained Transformer (GPT) models. These models are trained on a diverse range of internet text and have an uncanny ability to generate human-like text, answer questions, summarize passages, and much more. The evolution from GPT-3 to GPT-4 marks significant improvements in understanding context and generating more accurate responses.</p>
</div>
<div class="section" id="The-Completions-API">
<h2>The Completions API<a class="headerlink" href="#The-Completions-API" title="Permalink to this headline"> </a></h2>
<p>This legacy API is used for generating text based on a prompt. It’s simple, straightforward, and doesn’t require a great deal of effort to implememnt apart from the creativity required to craft a useful prompt instruction set.</p>
</div>
<div class="section" id="Exploring-the-Tutorial">
<h2>Exploring the Tutorial<a class="headerlink" href="#Exploring-the-Tutorial" title="Permalink to this headline"> </a></h2>
<p>In this tutorial, we’ll use MLflow to deploy a model that interfaces with the <code class="docutils literal notranslate"><span class="pre">Completions</span></code> API, submitting a prompt that will be used for any call that is made to the model. Within this tutorial, you’ll learn the process of creating a prompt, how to save a model with callable parameters, and finally how to load the saved model to use for interactions.</p>
<p>Let’s dive into the world of AI-enhanced communication and explore the potential of GPT models in everyday scenarios.</p>
</div>
<div class="section" id="Prerequisites">
<h2>Prerequisites<a class="headerlink" href="#Prerequisites" title="Permalink to this headline"> </a></h2>
<p>In order to get started with the OpenAI flavor, we’re going to need a few things first.</p>
<ol class="arabic simple">
<li><p>An OpenAI API Account. You can <a class="reference external" href="https://platform.openai.com/login?launch">sign up here</a> to get access in order to start programatically accessing one of the leading highly sophisticated LLM services on the planet.</p></li>
<li><p>An OpenAI API Key. You can access this once you’ve created an account by navigating <a class="reference external" href="https://platform.openai.com/api-keys">to the API keys page</a>.</p></li>
<li><p>The OpenAI SDK. It’s <a class="reference external" href="https://pypi.org/project/openai/">available on PyPI</a> here. For this tutorial, we’re going to be using version 0.28.1 (the last release prior to the 1.0 release).</p></li>
</ol>
<p>To install the <code class="docutils literal notranslate"><span class="pre">openai</span></code> SDK library that is compatible with this notebook to try this out yourself, as well as the additional <code class="docutils literal notranslate"><span class="pre">tiktoken</span></code> dependency that is required for the MLflow integration with <code class="docutils literal notranslate"><span class="pre">openai</span></code>, simply run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span><span class="s1">&#39;openai&lt;1&#39;</span><span class="w"> </span>tiktoken
</pre></div>
</div>
</div>
<div class="section" id="API-Key-Security-Overview">
<h2>API Key Security Overview<a class="headerlink" href="#API-Key-Security-Overview" title="Permalink to this headline"> </a></h2>
<p>API keys, especially for SaaS Large Language Models (LLMs), are as sensitive as financial information due to their connection to billing.</p>
<p>If you’re interested in learning more about an alternative MLflow solution that securely manages your access keys, <a class="reference external" href="https://www.mlflow.org/docs/latest/llms/deployments/index.html">read about the deployments server here</a>.</p>
<div class="section" id="Essential-Practices:">
<h3>Essential Practices:<a class="headerlink" href="#Essential-Practices:" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p><strong>Confidentiality</strong>: Always keep API keys private.</p></li>
<li><p><strong>Secure Storage</strong>: Prefer environment variables or secure services.</p></li>
<li><p><strong>Frequent Rotation</strong>: Regularly update keys to avoid unauthorized access.</p></li>
</ul>
</div>
<div class="section" id="Configuring-API-Keys">
<h3>Configuring API Keys<a class="headerlink" href="#Configuring-API-Keys" title="Permalink to this headline"> </a></h3>
<p>For secure usage, set API keys as environment variables.</p>
<p><strong>macOS/Linux</strong>: Refer to <a class="reference external" href="https://support.apple.com/en-gb/guide/terminal/apd382cc5fa-4f58-4449-b20a-41c53c006f8f/mac">Apple’s guide on using environment variables in Terminal</a> for detailed instructions.</p>
<p><strong>Windows</strong>: Follow the steps outlined in <a class="reference external" href="https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_environment_variables?view=powershell-7.4">Microsoft’s documentation on environment variables</a>.</p>
</div>
</div>
<div class="section" id="Imports-and-a-quick-environment-verification-step">
<h2>Imports and a quick environment verification step<a class="headerlink" href="#Imports-and-a-quick-environment-verification-step" title="Permalink to this headline"> </a></h2>
<p>Along with the customary imports that we need to run this tutorial, we’re also going to verify that our API key has been set and is accessible.</p>
<p>After running the following cell, if an Exception is raised, please recheck the steps to ensure your API key is properly registered in your system’s environment variables.</p>
<div class="section" id="Troubleshooting-Tips">
<h3>Troubleshooting Tips<a class="headerlink" href="#Troubleshooting-Tips" title="Permalink to this headline"> </a></h3>
<p>If you encounter an Exception stating that the <code class="docutils literal notranslate"><span class="pre">OPENAI_API_KEY</span></code> environment variable must be set, consider the following common issues and remedies:</p>
<ul class="simple">
<li><p><strong>Kernel Restart</strong>: If you’re using a Jupyter notebook, make sure to restart the kernel after setting the environment variable. This is necessary for the kernel to recognize changes to environment variables.</p></li>
<li><p><strong>Correct Profile Script</strong>: On macOS and Linux, ensure you’ve edited the correct profile script (.bashrc for Bash, .zshrc for Zsh) and that you’ve used the correct syntax.</p></li>
<li><p><strong>System Restart</strong>: Sometimes, especially on Windows, you may need to restart your system for the changes to environment variables to take effect.</p></li>
<li><p><strong>Check Spelling and Syntax</strong>: Verify that the variable <code class="docutils literal notranslate"><span class="pre">OPENAI_API_KEY</span></code> is spelled correctly in both your environment settings and your script. Also, ensure that there are no extra spaces or syntax errors in your profile scripts or environment variable settings.</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>

<span class="c1"># Disable a few less-than-useful UserWarnings from setuptools and pydantic</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">openai</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>

<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">from</span> <span class="nn">mlflow.models.signature</span> <span class="kn">import</span> <span class="n">ModelSignature</span>
<span class="kn">from</span> <span class="nn">mlflow.types.schema</span> <span class="kn">import</span> <span class="n">ColSpec</span><span class="p">,</span> <span class="n">ParamSchema</span><span class="p">,</span> <span class="n">ParamSpec</span><span class="p">,</span> <span class="n">Schema</span>

<span class="c1"># Run a quick validation that we have an entry for the OPEN_API_KEY within environment variables</span>
<span class="k">assert</span> <span class="s2">&quot;OPENAI_API_KEY&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">,</span> <span class="s2">&quot;OPENAI_API_KEY environment variable must be set&quot;</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Understanding-Prompts-and-Their-Engineering">
<h2>Understanding Prompts and Their Engineering<a class="headerlink" href="#Understanding-Prompts-and-Their-Engineering" title="Permalink to this headline"> </a></h2>
<div class="section" id="What-is-a-Prompt?">
<h3>What is a Prompt?<a class="headerlink" href="#What-is-a-Prompt?" title="Permalink to this headline"> </a></h3>
<p>A prompt is a text input given to an AI model, particularly language models like GPT-3 and GPT-4, to elicit a specific type of response or output. It guides the model on the expected information or format of the response, setting the stage for the AI’s “thought process” and steering it toward the desired outcome.</p>
</div>
<div class="section" id="Prompt-Engineering">
<h3>Prompt Engineering<a class="headerlink" href="#Prompt-Engineering" title="Permalink to this headline"> </a></h3>
<p>Prompt engineering involves crafting these inputs to maximize the AI’s response effectiveness and accuracy. It’s about fine-tuning the language and structure of the prompt to align with the specific task, improving the quality and relevance of the AI’s output by reducing ambiguity and directing the model’s response towards the intended application.</p>
</div>
</div>
<div class="section" id="A-Fun-and-Simple-Example:-The-Lyrics-Corrector">
<h2>A Fun and Simple Example: The Lyrics Corrector<a class="headerlink" href="#A-Fun-and-Simple-Example:-The-Lyrics-Corrector" title="Permalink to this headline"> </a></h2>
<p>Imagine a scenario where a group of friends, who enjoy pop music, often end up in passionate, good-natured debates over misremembered song lyrics. To add more fun to these gatherings, we decide to create a game where an impartial judge – an AI model – adjudicates the correct lyrics after someone proposes and the group attempts to guess the correct song and lyrics from a creative interpretation.</p>
<div class="section" id="Why-not-a-Search-Engine?">
<h3>Why not a Search Engine?<a class="headerlink" href="#Why-not-a-Search-Engine?" title="Permalink to this headline"> </a></h3>
<p>Typically, one might turn to an internet search engine to settle these lyrical disputes. However, this method has its drawbacks. Depending on the input, search results can be imprecise, leading to time-consuming searches through various web pages to find the actual lyrics. The authenticity for the results found can be quite questionable due to the nature of the contents of some lyrics. Search engines are not designed with use cases like this in mind.</p>
</div>
<div class="section" id="Why-an-LLM-is-Perfect-for-This-Task">
<h3>Why an LLM is Perfect for This Task<a class="headerlink" href="#Why-an-LLM-is-Perfect-for-This-Task" title="Permalink to this headline"> </a></h3>
<p>This is where a powerful Language Model (LLM) like GPT-4 becomes a game-changer. LLMs, trained on extensive datasets, are adept at understanding and generating human-like text. Their ability to process natural language inputs and provide relevant, accurate responses makes them ideal for this lyrical challenge.</p>
</div>
<div class="section" id="Our-Solution:-The-Lyrics-Corrector-Prompt">
<h3>Our Solution: The Lyrics Corrector Prompt<a class="headerlink" href="#Our-Solution:-The-Lyrics-Corrector-Prompt" title="Permalink to this headline"> </a></h3>
<p>To leverage the LLM effectively, we craft a specialized prompt for our Lyrics Corrector application. This prompt is designed with two goals in mind:</p>
<ol class="arabic simple">
<li><p><strong>Correct Misheard Lyrics</strong>: It instructs the AI to identify the actual lyrics of a song, replacing commonly misheard versions.</p></li>
<li><p><strong>Add a Humorous Explanation</strong>: More than just correction, the AI also provides a funny explanation for why the misheard lyric is amusingly incorrect, adding an engaging, human-like element to the task.</p></li>
</ol>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>&quot;Here&#39;s a misheard lyric: {lyric}. What&#39;s the actual lyric, which song does it come from, which artist performed it, and can you give a funny explanation as to why the misheard version doesn&#39;t make sense? Also, rate the creativity of the lyric on a scale of 1 to 3, where 3 is good.&quot;
</pre></div>
</div>
<p>In this prompt, <code class="docutils literal notranslate"><span class="pre">{lyric}</span></code> is a placeholder for various misheard lyrics. This setup not only showcases the model’s ability to process and correct information but also to engage in a more creative, human-like manner.</p>
<p>Through this fun and simple example, we explore the potential of LLMs in real-world applications, demonstrating their capacity to enhance everyday experiences with a blend of accuracy and creativity.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lyrics_prompt</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">&quot;Here&#39;s a misheard lyric: </span><span class="si">{lyric}</span><span class="s2">. What&#39;s the actual lyric, which song does it come from, which artist performed it, and can you give a funny &quot;</span>
    <span class="s2">&quot;explanation as to why the misheard version doesn&#39;t make sense? Also, rate the creativity of the lyric on a scale of 1 to 3, where 3 is good.&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Setting-Up-and-Logging-the-Model-in-MLflow">
<h2>Setting Up and Logging the Model in MLflow<a class="headerlink" href="#Setting-Up-and-Logging-the-Model-in-MLflow" title="Permalink to this headline"> </a></h2>
<p>In this section, we define our model and <a class="reference external" href="https://www.mlflow.org/docs/latest/tracking/tracking-api.html">log it to MLflow</a>. This integrates our prompt that defines the characteristics of what we want the nature of the responses to be with the configuration parameters that dictate how MLflow will interact with the OpenAI SDK in order to select the right model with our desired parameters.</p>
<ul class="simple">
<li><p><strong>MLflow Experiments</strong>: Our first step involves creating or reusing an <a class="reference external" href="https://www.mlflow.org/docs/latest/tracking/tracking-api.html#organizing-runs-in-experiments">MLflow experiment</a> named “Lyrics Corrector”. Experiments in MLflow are crucial for organizing and tracking different model runs, along with their associated data and parameters.</p></li>
<li><p><strong>Model Logging</strong>: Within an <a class="reference external" href="https://www.mlflow.org/docs/latest/tracking.html#tracking-runs">MLflow run</a>, we log our model, specifying details such as the model type (<code class="docutils literal notranslate"><span class="pre">gpt-3.5-turbo-instruct</span></code>), the task it’s intended for (<code class="docutils literal notranslate"><span class="pre">openai.completions</span></code>), and the custom prompt we’ve designed. This action ensures that MLflow accurately captures the essence and operational context of our model.</p></li>
<li><p><strong>Model Signature</strong>: Here, we define the input and output schema for our model. We expect a string as input (the misheard lyric) and output a string (the corrected lyric with a humorous explanation). Additional parameters like <code class="docutils literal notranslate"><span class="pre">max_tokens</span></code>, <code class="docutils literal notranslate"><span class="pre">temperature</span></code>, and <code class="docutils literal notranslate"><span class="pre">best_of</span></code> are set to control the model’s text generation process.</p></li>
<li><p><strong>Model Loading</strong>: Finally, we load the logged model as a generic Python function within MLflow. This makes the model readily usable for predictions and further interactions, allowing us to invoke it like a regular Python function with the specified inputs.</p></li>
</ul>
<p>This setup not only establishes our Lyrics Corrector model but also demonstrates how MLflow can be effectively used to manage complex AI models, ensuring efficient tracking, management, and deployment in practical applications.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a new experiment (or reuse the existing one if we&#39;ve run this cell more than once)</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;Lyrics Corrector&quot;</span><span class="p">)</span>

<span class="c1"># Start our run and log our model</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>
    <span class="n">model_info</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">openai</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo-instruct&quot;</span><span class="p">,</span>
        <span class="n">task</span><span class="o">=</span><span class="n">openai</span><span class="o">.</span><span class="n">completions</span><span class="p">,</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
        <span class="n">prompt</span><span class="o">=</span><span class="n">lyrics_prompt</span><span class="p">,</span>
        <span class="n">signature</span><span class="o">=</span><span class="n">ModelSignature</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">)]),</span>
            <span class="n">outputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">)]),</span>
            <span class="n">params</span><span class="o">=</span><span class="n">ParamSchema</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">ParamSpec</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;max_tokens&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;long&quot;</span><span class="p">),</span>
                    <span class="n">ParamSpec</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;temperature&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">),</span>
                    <span class="n">ParamSpec</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;best_of&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;long&quot;</span><span class="p">),</span>
                <span class="p">]</span>
            <span class="p">),</span>
        <span class="p">),</span>
    <span class="p">)</span>

<span class="c1"># Load the model as a generic python function that can be used for completions</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">model_info</span><span class="o">.</span><span class="n">model_uri</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Generating-and-Correcting-Misheard-Lyrics">
<h2>Generating and Correcting Misheard Lyrics<a class="headerlink" href="#Generating-and-Correcting-Misheard-Lyrics" title="Permalink to this headline"> </a></h2>
<p>Let’s have some fun with our Lyrics Corrector model by testing it with a set of humorously misheard lyrics. These phrases are well-known for their amusing misinterpretations and will be a great way to see how the model performs with a touch of humor.</p>
<div class="section" id="Generating-Questionable-Lyrics">
<h3>Generating Questionable Lyrics<a class="headerlink" href="#Generating-Questionable-Lyrics" title="Permalink to this headline"> </a></h3>
<p>We’ve prepared a collection of iconic song lyrics that are often humorously misheard:</p>
<ul class="simple">
<li><p>“We built this city on sausage rolls” (a twist on “rock and roll”)</p></li>
<li><p>“Hold me closer, Tony Danza” (instead of “tiny dancer”)</p></li>
<li><p>“Sweet dreams are made of cheese. Who am I to dis a brie? I cheddar the world and a feta cheese” (a cheesy take on the original lyrics)</p></li>
<li><p>“Excuse me while I kiss this guy” (rather than “the sky”)</p></li>
<li><p>“I want to rock and roll all night and part of every day” (changing “every day” to a less committed schedule)</p></li>
<li><p>“Don’t roam out tonight, it’s bound to take your sight, there’s a bathroom on the right.” (a creative take on Bad Moon Rising)</p></li>
<li><p>“I think you’ll understand, when I say that somethin’, I want to take your land” (a dark take on a classic Beatles love song)</p></li>
</ul>
<p>These misheard versions add a layer of humor and quirkiness to the original lines, making them perfect candidates for our Lyrics Corrector.</p>
</div>
<div class="section" id="Submitting-Lyrics-to-the-Model">
<h3>Submitting Lyrics to the Model<a class="headerlink" href="#Submitting-Lyrics-to-the-Model" title="Permalink to this headline"> </a></h3>
<p>Now, it’s time to see how our model interprets these creative takes. We submit the misheard lyrics to the Lyrics Corrector, which will use its AI capabilities to determine the actual lyrics and provide a witty explanation for why the misheard version might be off-base.</p>
</div>
<div class="section" id="Viewing-the-Model’s-Responses">
<h3>Viewing the Model’s Responses<a class="headerlink" href="#Viewing-the-Model’s-Responses" title="Permalink to this headline"> </a></h3>
<p>After processing, the model’s responses are formatted and displayed in an easy-to-read manner. This step will highlight the model’s understanding of the lyrics and its ability to engage humorously with the content. It’s a showcase of blending AI’s linguistic accuracy with a sense of humor, making for an entertaining and insightful experience.</p>
<p>Let’s see what amusing corrections and explanations our Lyrics Corrector comes up with for these classic misheard lyrics!</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate some questionable lyrics</span>
<span class="n">bad_lyrics</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;lyric&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="s2">&quot;We built this city on sausage rolls&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Hold me closer, Tony Danza&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Sweet dreams are made of cheese. Who am I to dis a brie? I cheddar the world and a feta cheese&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Excuse me while I kiss this guy&quot;</span><span class="p">,</span>
            <span class="s2">&quot;I want to rock and roll all night and part of every day&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Don&#39;t roam out tonight, it&#39;s bound to take your sight, there&#39;s a bathroom on the right.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;I think you&#39;ll understand, when I say that somethin&#39;, I want to take your land&quot;</span><span class="p">,</span>
        <span class="p">]</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Submit our faulty lyrics to the model</span>
<span class="n">fix_my_lyrics</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">bad_lyrics</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;max_tokens&quot;</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span> <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>

<span class="c1"># See what the response is</span>
<span class="n">formatted_output</span> <span class="o">=</span> <span class="s2">&quot;&lt;br&gt;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
    <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;&lt;p&gt;&lt;strong&gt;</span><span class="si">{</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2">&lt;/strong&gt;&lt;/p&gt;&quot;</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">fix_my_lyrics</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="n">formatted_output</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<p><strong>The actual lyric is "We built this city on rock and roll" from the song "We Built This City" by Starship. The misheard version doesn't make sense because sausage rolls are a type of food, not a building material. Perhaps someone misheard the word "rock" as "roll" and their mind automatically went to food. The creativity of the misheard lyric is a 2, as it is a common mistake to mix up similar sounding words.</strong></p><br><p><strong>The actual lyric is "Hold me closer, tiny dancer" from the song "Tiny Dancer" by Elton John. The misheard version is a common one, with many people thinking the line is about the actor Tony Danza instead of a small dancer.

The artist, Elton John, is known for his flamboyant and over-the-top performances, so it's not too far-fetched to imagine him singing about being held by Tony Danza. However, it doesn't make much sense in the context of the song, which is about a young girl who dreams of becoming a famous dancer.

On a scale of 1 to 3, I would rate the creativity of the misheard lyric a 2. It's a common mistake and not particularly clever, but it does add a humorous twist to the song.</strong></p><br><p><strong>The actual lyric is "Sweet dreams are made of this. Who am I to disagree? I travel the world and the seven seas. Everybody's looking for something." It comes from the song "Sweet Dreams (Are Made of This)" by the Eurythmics.

The misheard version doesn't make sense because it replaces the word "this" with "cheese" and changes the rest of the lyrics to be about different types of cheese. It also changes the meaning of the song from a reflection on the search for fulfillment and purpose to a silly ode to cheese.

I would rate the creativity of the misheard lyric a 2. It's a clever play on words, but it doesn't quite fit with the original song or make much sense.</strong></p><br><p><strong>The actual lyric is "Excuse me while I kiss the sky" from the song "Purple Haze" by Jimi Hendrix. The misheard version doesn't make sense because it suggests the singer is going to kiss a random guy, which is not what the song is about. Perhaps the singer is feeling a bit confused and disoriented from the "purple haze" and mistakenly thinks there's a guy in front of them. I would rate the creativity of the misheard lyric a 2, as it plays off the similar sounding words but doesn't quite fit with the context of the song.</strong></p><br><p><strong>The actual lyric is "I want to rock and roll all night and party every day" from the song "Rock and Roll All Nite" by Kiss. The misheard version doesn't make sense because it suggests that the person only wants to rock and roll during the day and not at night, which goes against the spirit of the song. It also implies that they only want to party for part of the day, rather than all day and night.

I would rate the creativity of the misheard lyric a 2, as it still maintains the overall theme of the song but with a humorous twist.</strong></p><br><p><strong>The actual lyric is "Don't go 'round tonight, it's bound to take your life, there's a bad moon on the rise" from the song "Bad Moon Rising" by Creedence Clearwater Revival. The misheard version doesn't make sense because a bathroom on the right would not pose any danger to someone's sight or life. Perhaps the misheard version is a warning to not use the bathroom at night because it's haunted or cursed. I would rate the creativity of the misheard lyric a 2.</strong></p><br><p><strong>The actual lyric is "I think you'll understand, when I say that something, I want to hold your hand." It comes from the song "I Want to Hold Your Hand" by The Beatles.

The misheard version doesn't make sense because wanting to take someone's land is a very aggressive and strange thing to say in a love song. It also doesn't fit with the overall theme of the song, which is about wanting to be close to someone and hold their hand.

I would rate the creativity of the misheard lyric a 1, as it doesn't really make sense and doesn't add anything new or interesting to the original lyric.</strong></p></div>
</div>
</div>
</div>
<div class="section" id="Refining-Our-Approach-with-Prompt-Engineering">
<h2>Refining Our Approach with Prompt Engineering<a class="headerlink" href="#Refining-Our-Approach-with-Prompt-Engineering" title="Permalink to this headline"> </a></h2>
<p>After reviewing the initial results from our Lyrics Corrector model, we find that the responses, while amusing, don’t quite hit the mark in terms of creativity scoring. The ratings seem to cluster around the middle of the scale, lacking the differentiation we’re aiming for. This observation leads us to the iterative and nuanced process of prompt engineering, a critical step in fine-tuning AI model responses.</p>
<div class="section" id="The-Iterative-Process-of-Prompt-Engineering">
<h3>The Iterative Process of Prompt Engineering<a class="headerlink" href="#The-Iterative-Process-of-Prompt-Engineering" title="Permalink to this headline"> </a></h3>
<p>Prompt engineering is not a one-shot affair; it’s an iterative process. It involves refining the prompt based on the model’s responses and adjusting it to more precisely align with our objectives. This process is crucial when working with advanced language models like GPT-3 and GPT-4, which, while powerful, often require detailed guidance to produce specific types of outputs.</p>
</div>
<div class="section" id="Achieving-a-Refined-Response">
<h3>Achieving a Refined Response<a class="headerlink" href="#Achieving-a-Refined-Response" title="Permalink to this headline"> </a></h3>
<p>Our initial prompt provided a basic structure for the task but lacked detailed guidance on how to effectively rate the creativity of the misheard lyrics. To address this, we need to:</p>
<ol class="arabic simple">
<li><p><strong>Provide Clearer Instructions</strong>: Enhance the prompt with more explicit instructions on what constitutes different levels of creativity.</p></li>
<li><p><strong>Incorporate Examples</strong>: Include examples within the prompt that illustrate low, medium, and high creativity ratings.</p></li>
<li><p><strong>Clarify Expectations</strong>: Make it clear that the rating should consider not just the humor but also the originality and deviation from the original lyrics.</p></li>
</ol>
</div>
<div class="section" id="Our-Improved-Prompt">
<h3>Our Improved Prompt<a class="headerlink" href="#Our-Improved-Prompt" title="Permalink to this headline"> </a></h3>
<p>In the next cell, you’ll see an improved prompt that is designed to elicit more nuanced and varied responses from the model, providing a clearer framework for evaluating the creativity of misheard lyrics. By refining our approach through prompt engineering, we aim to achieve more accurate and diverse ratings that align better with our intended goal for the Lyrics Corrector.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define our prompt</span>
<span class="n">improved_lyrics_prompt</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">&quot;Here&#39;s a misheard lyric: </span><span class="si">{lyric}</span><span class="s2">. What&#39;s the actual lyric, which song does it come from, which artist performed it, and can &quot;</span>
    <span class="s2">&quot;you give a funny explanation as to why the misheard version doesn&#39;t make sense? Additionally, please provide an objective rating to the &quot;</span>
    <span class="s2">&quot;misheard lyric on a scale of 1 to 3, where 1 is &#39;not particularly creative&#39; (minimal humor, closely resembles the &quot;</span>
    <span class="s2">&quot;original lyrics and the intent of the song) and 3 is &#39;hilariously creative&#39; (highly original, very humorous, significantly different from &quot;</span>
    <span class="s2">&quot;the original). Explain your rating briefly. For example, &#39;I left my heart in San Francisco&#39; misheard as &#39;I left my hat in San Francisco&#39; &quot;</span>
    <span class="s2">&quot;might be a 1, as it’s a simple word swap with minimal humor. Conversely, &#39;I want to hold your hand&#39; misheard as &#39;I want to steal your land&#39; &quot;</span>
    <span class="s2">&quot;could be a 3, as it significantly changes the meaning in a humorous and unexpected way.&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a new experiment for the Improved Version (or reuse the existing one if we&#39;ve run this cell more than once)</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;Improved Lyrics Corrector&quot;</span><span class="p">)</span>

<span class="c1"># Start our run and log our model</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>
    <span class="n">model_info</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">openai</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo-instruct&quot;</span><span class="p">,</span>
        <span class="n">task</span><span class="o">=</span><span class="n">openai</span><span class="o">.</span><span class="n">completions</span><span class="p">,</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
        <span class="n">prompt</span><span class="o">=</span><span class="n">improved_lyrics_prompt</span><span class="p">,</span>
        <span class="n">signature</span><span class="o">=</span><span class="n">ModelSignature</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">)]),</span>
            <span class="n">outputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">)]),</span>
            <span class="n">params</span><span class="o">=</span><span class="n">ParamSchema</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">ParamSpec</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;max_tokens&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;long&quot;</span><span class="p">),</span>
                    <span class="n">ParamSpec</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;temperature&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">),</span>
                    <span class="n">ParamSpec</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;best_of&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;long&quot;</span><span class="p">),</span>
                <span class="p">]</span>
            <span class="p">),</span>
        <span class="p">),</span>
    <span class="p">)</span>

<span class="c1"># Load the model as a generic python function that can be used for completions</span>
<span class="n">improved_model</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">model_info</span><span class="o">.</span><span class="n">model_uri</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Submit our faulty lyrics to the model</span>
<span class="n">fix_my_lyrics_improved</span> <span class="o">=</span> <span class="n">improved_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
    <span class="n">bad_lyrics</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;max_tokens&quot;</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span> <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">}</span>
<span class="p">)</span>

<span class="c1"># See what the response is</span>
<span class="n">formatted_output</span> <span class="o">=</span> <span class="s2">&quot;&lt;br&gt;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
    <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;&lt;p&gt;&lt;strong&gt;</span><span class="si">{</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2">&lt;/strong&gt;&lt;/p&gt;&quot;</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">fix_my_lyrics_improved</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="n">formatted_output</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<p><strong>The actual lyric is "We built this city on rock and roll" from the song "We Built This City" by Starship. The misheard version is a 3 on the scale, as it completely changes the meaning of the song and adds a humorous twist. The misheard version doesn't make sense because it replaces the iconic rock and roll genre with a food item, sausage rolls. This could be interpreted as a commentary on the current state of the music industry, where popular songs are often criticized for being shallow and lacking substance. The misheard version could also be seen as a nod to the British culture, where sausage rolls are a popular snack. Overall, the misheard lyric adds a playful and unexpected element to the song.</strong></p><br><p><strong>The actual lyric is "Hold me closer, tiny dancer" from the song "Tiny Dancer" by Elton John. The misheard version is a common one, with many people thinking the lyric is about the actor Tony Danza instead of a dancer. This misheard version would be a 2 on the scale, as it is a humorous and unexpected interpretation of the original lyrics, but still closely resembles the original and the intent of the song. The misheard version doesn't make sense because Tony Danza is not known for his dancing skills, so it would be odd for someone to want to be held closer to him specifically for his dancing abilities. It also changes the meaning of the song, as the original lyrics are about a small and delicate dancer, while the misheard version is about a well-known actor.</strong></p><br><p><strong>The actual lyric is "Sweet dreams are made of this. Who am I to disagree? I travel the world and the seven seas. Everybody's looking for something." It comes from the song "Sweet Dreams (Are Made of This)" by the Eurythmics.

The misheard version is a play on words, replacing "this" with "cheese" and using different types of cheese in place of "seven seas." It doesn't make sense because cheese is not typically associated with dreams or traveling the world. It also changes the meaning of the song from a philosophical exploration of desires and purpose to a silly ode to cheese.

I would rate this misheard lyric a 2. It is fairly creative and humorous, but it still closely resembles the original lyrics and doesn't deviate too far from the intent of the song.</strong></p><br><p><strong>The actual lyric is "Excuse me while I kiss the sky" from the song "Purple Haze" by Jimi Hendrix. The misheard version is a common one, with many people thinking Hendrix was singing about kissing a guy instead of the sky.

Funny explanation: Maybe the misheard version came about because Hendrix was known for his wild and unpredictable performances, so people thought he might just randomly kiss a guy on stage. Or maybe they thought he was singing about a romantic moment with a male lover in the sky.

Objective rating: 2. While the misheard version is a common one and does have some humor to it, it's not particularly original or unexpected. It's a simple word swap that still somewhat makes sense in the context of the song.</strong></p><br><p><strong>The actual lyric is "I want to rock and roll all night and party every day" from the song "Rock and Roll All Nite" by Kiss.

The misheard lyric, "I want to rock and roll all night and part of every day," doesn't make sense because it implies that the person only wants to rock and roll for a portion of each day, rather than all night and every day. It also changes the meaning of the lyric from wanting to party all day and night to only wanting to party for part of the day.

I would rate this misheard lyric a 2. While it does have some humor and changes the meaning of the original lyric, it is still quite similar to the original and doesn't completely change the intent of the song.</strong></p><br><p><strong>The actual lyric is "There's a bad moon on the rise" from the song "Bad Moon Rising" by Creedence Clearwater Revival. The misheard lyric is a common one, with many people hearing "There's a bathroom on the right" instead of the correct lyrics. This misheard version doesn't make sense because it changes the tone and meaning of the song from a warning about a dangerous situation to a mundane reminder about bathroom locations.

Objective rating: 2. While the misheard lyric is not particularly creative, it does add a humorous twist to the song and is a common misinterpretation.</strong></p><br><p><strong>The actual lyric is "I think you'll understand, when I say that somethin', I want to hold your hand" from the song "I Want to Hold Your Hand" by The Beatles.

The misheard lyric is a 3 on the scale. The original lyric is a sweet and innocent expression of love, while the misheard version turns it into a bizarre and aggressive desire to take someone's land. It's a complete departure from the original meaning and adds a humorous twist to the song. It also plays on the idea of misheard lyrics often being nonsensical and out of context.</strong></p></div>
</div>
</div>
</div>
<div class="section" id="Conclusion:-The-Power-of-MLflow-in-Managing-AI-Model-Experiments">
<h2>Conclusion: The Power of MLflow in Managing AI Model Experiments<a class="headerlink" href="#Conclusion:-The-Power-of-MLflow-in-Managing-AI-Model-Experiments" title="Permalink to this headline"> </a></h2>
<p>As we wrap up our tutorial, let’s revisit the significant insights we’ve gained, particularly focusing on how MLflow enhances the experimentation and deployment of OpenAI’s advanced language models.</p>
<div class="section" id="Key-Takeaways">
<h3>Key Takeaways<a class="headerlink" href="#Key-Takeaways" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p><strong>Prompt Engineering and Experimentation</strong>: This tutorial highlighted the iterative nature of prompt engineering, showcasing how subtle changes in the prompt can lead to significantly different outcomes from an AI model. MLflow plays a pivotal role here, allowing us to track these variations effectively, compare results, and iterate towards the optimal prompt configuration.</p></li>
<li><p><strong>Simplifying AI Model Management with MLflow</strong>: MLflow’s capacity to log models, manage experiments, and handle the nuances of the machine learning lifecycle has been indispensable. It simplifies the complex process of managing and deploying AI models, making these tasks more accessible to both developers and data scientists.</p></li>
<li><p><strong>Leveraging OpenAI’s Advanced Models</strong>: The seamless integration of OpenAI’s GPT models within MLflow demonstrates how state-of-the-art AI technology can be applied in real-world scenarios. Our Lyrics Corrector example, built on the GPT-3.5-turbo model, illustrates just one of many potential applications that blend creativity, humor, and advanced language understanding.</p></li>
<li><p><strong>Advantages of MLflow’s pyfunc Implementation</strong>: The pyfunc implementation in MLflow allows for flexible and straightforward access to advanced models like OpenAI’s GPT. It enables users to deploy these models as generic Python functions, greatly enhancing their usability and integration into diverse applications.</p></li>
</ul>
</div>
<div class="section" id="Forward-Looking">
<h3>Forward-Looking<a class="headerlink" href="#Forward-Looking" title="Permalink to this headline"> </a></h3>
<p>The integration of MLflow with OpenAI’s GPT models opens up a world of possibilities for innovative applications. As AI technology evolves, the versatility and robustness of MLflow will be key in translating these advancements into practical and impactful solutions.</p>
</div>
<div class="section" id="Encouragement-for-Further-Exploration">
<h3>Encouragement for Further Exploration<a class="headerlink" href="#Encouragement-for-Further-Exploration" title="Permalink to this headline"> </a></h3>
<p>We invite you to continue exploring the vast potential of combining MLflow’s powerful model management capabilities with the advanced linguistic prowess of OpenAI’s models. Whether you’re enhancing communication, automating tasks, or creating new AI-driven services, this combination offers a rich platform for your creativity and technical expertise.</p>
<p>Thank you for joining us in this exploration of AI model experimentation and management. We are excited to see how you utilize these powerful tools in your upcoming projects and innovations!</p>
<p>To continue learning about the capabilities of MLflow and OpenAI as they work together, we encourage you to continue your learning with a more advanced example, <a class="reference external" href="https://www.mlflow.org/docs/latest/llms/openai/notebooks/openai-chat-completions.html">the Custom Python Model example for the MLflow OpenAI flavor</a>.</p>
</div>
</div>
</div>


              </div>
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../index.html" class="btn btn-neutral" title="MLflow OpenAI Flavor" accesskey="p"><span class="db-icon db-icon-chevron-left"></span> Previous</a>
      
      
        <a href="openai-chat-completions.html" class="btn btn-neutral" title="Introduction: Advancing Communication with GPT-4 and MLflow" accesskey="n">Next <span class="db-icon db-icon-chevron-right"></span></a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; MLflow Project, a Series of LF Projects, LLC. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'../../../',
      VERSION:'2.14.2.dev0',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      LINK_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  

  <script type="text/javascript" src="../../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/jquery.waypoints.min.js"></script>

  
  
  
  <script type="text/javascript">var CLIPPY_SVG_PATH = "../../../_static/clippy.svg";</script>
  <script type="text/javascript" src="../../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  

  
  <script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        function copyToClipboard(text) {
            const textarea = document.createElement('textarea');
            textarea.value = text;
            document.body.appendChild(textarea);
            textarea.select();
            document.execCommand('copy');
            document.body.removeChild(textarea);
        }
        // Get the code block designator class entries
        const allHighlights = document.querySelectorAll('.highlight');
        // Disable copyable links for notebook cell numbering and for cell outputs
        const highlights = Array.from(allHighlights).filter(highlight => !highlight.closest('.highlight-none') && 
            !highlight.closest('.nboutput'));
    
        highlights.forEach(function(highlight) {
            const copyIcon = document.createElement('span');
            copyIcon.classList.add('copy-icon');
            copyIcon.innerHTML = '&#xf0ea;';

            copyIcon.addEventListener('click', function() {
                const code = highlight.querySelector('pre').textContent;
                copyToClipboard(code);

                // Flash effect on click
                this.style.color = '#0194E2';
                setTimeout(() => {
                    this.style.color = ''; 
                }, 100);

                // Display "Code copied to clipboard" near the clicked icon
                const message = document.createElement('span');
                message.textContent = "Copied!";
                message.classList.add('copy-message'); 

                // Append the message to the icon
                this.appendChild(message);

                setTimeout(() => {
                    this.removeChild(message);
                }, 500);
            });

            highlight.appendChild(copyIcon);
        });
    });
  </script>


<script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        // Force download for notebook-download-btn
        const downloadButtons = document.querySelectorAll('.notebook-download-btn');
        downloadButtons.forEach(function(button) {
            button.addEventListener('click', function(event) {
                event.preventDefault(); // Prevent default behavior

                // Fetch the raw content of the notebook from GitHub
                fetch(button.href)
                    .then(response => response.blob())
                    .then(blob => {
                        const url = window.URL.createObjectURL(blob);
                        const link = document.createElement('a');
                        link.style.display = 'none';
                        link.href = url;
                        const filename = button.href.split('/').pop();
                        link.download = filename; 

                        document.body.appendChild(link);
                        link.click();

                        window.URL.revokeObjectURL(url);
                        document.body.removeChild(link);
                    })
                    .catch(err => console.error('Error fetching the notebook:', err));
            });
        });
    });
</script> 
</body>
</html>