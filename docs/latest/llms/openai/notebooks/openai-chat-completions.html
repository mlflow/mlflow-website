
  

<!DOCTYPE html>
<!-- source: docs/source/llms/openai/notebooks/openai-chat-completions.ipynb -->
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Introduction: Advancing Communication with GPT-4 and MLflow &mdash; MLflow 2.14.2.dev0 documentation</title>
  
   
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <link rel="canonical" href="https://mlflow.org/docs/latest/llms/openai/notebooks/openai-chat-completions.html">
  
  
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    

    

  
    
        <!-- Google Tag Manager -->
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer',"GTM-N6WMTTJ");</script>
        <!-- End Google Tag Manager -->
    

  

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/cards.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/grids.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/mobile.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/simple-cards.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/tabs.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="../../../genindex.html"/>
        <link rel="search" title="Search" href="../../../search.html"/>
    <link rel="top" title="MLflow 2.14.2.dev0 documentation" href="../../../index.html"/>
        <link rel="up" title="MLflow OpenAI Flavor" href="../index.html"/>
        <link rel="next" title="Building a Code Assistant with OpenAI &amp; MLflow" href="/openai-code-helper.html"/>
        <link rel="prev" title="Introduction to Using the OpenAI Flavor in MLflow" href="/openai-quickstart.html"/> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>
<script type="text/javascript" src="../../../_static/jquery.js"></script>
<script type="text/javascript" src="../../../_static/underscore.js"></script>
<script type="text/javascript" src="../../../_static/doctools.js"></script>
<script type="text/javascript" src="../../../_static/languagesections.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/javascript" src="../../../None"></script>

<body class="wy-body-for-nav" role="document">
  
    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->
  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <ul>
  <li class="menu-toggle">
    <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
    <a href="../../../index.html" class="wy-nav-top-logo"
      ><img src="../../../_static/MLflow-logo-final-black.png" alt="MLflow"
    /></a>
    <span class="version">2.14.2.dev0</span>
  </li>
</ul>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side relative">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
  </form>
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../../index.html" class="main-navigation-home"><img src="../../../_static/icons/nav-home.svg"> MLflow</a>
    

    
      

      
        <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../introduction/index.html">What is MLflow?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting-started/index.html">Getting Started with MLflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../new-features/index.html">New Features</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">LLMs</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../index.html#id1">MLflow Tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#id2">MLflow Deployments Server for LLMs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#id3">LLM Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#id4">Prompt Engineering UI</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../index.html#native-mlflow-flavors-for-llms">Native MLflow Flavors for LLMs</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../../transformers/index.html">MLflow Transformers Flavor</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../index.html">MLflow OpenAI Flavor</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../index.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../index.html#what-makes-this-integration-so-special">What makes this Integration so Special?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../index.html#features">Features</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="../index.html#getting-started-with-the-mlflow-openai-flavor-tutorials-and-guides">Getting Started with the MLflow OpenAI Flavor - Tutorials and Guides</a></li>
<li class="toctree-l4"><a class="reference internal" href="../index.html#id1">Detailed Documentation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../sentence-transformers/index.html">MLflow Sentence-Transformers Flavor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../langchain/index.html">MLflow LangChain Flavor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../index.html#explore-the-native-llm-flavors">Explore the Native LLM Flavors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#id5">LLM Tracking in MLflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#tutorials-and-use-case-guides-for-llms-in-mlflow">Tutorials and Use Case Guides for LLMs in MLflow</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../model-evaluation/index.html">Model Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deep-learning/index.html">Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../traditional-ml/index.html">Traditional ML</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deployment/index.html">Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tracking.html">MLflow Tracking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../system-metrics/index.html">System Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../projects.html">MLflow Projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../models.html">MLflow Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../model-registry.html">MLflow Model Registry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../recipes.html">MLflow Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../plugins.html">MLflow Plugins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../auth/index.html">MLflow Authentication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../search-runs.html">Search Runs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../search-experiments.html">Search Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../R-api.html">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../java_api/index.html">Java API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../rest-api.html">REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docker.html">Official MLflow Docker Image</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../community-model-flavors.html">Community Model Flavors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials-and-examples/index.html">Tutorials and Examples</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            










<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="../../index.html">LLMs</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="../index.html">MLflow OpenAI Flavor</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Introduction: Advancing Communication with GPT-4 and MLflow</li>
    
    
    <!-- <li class="wy-breadcrumbs-aside">
      <a href="https://github.com/mlflow/mlflow/blob/master/docs/source/llms/openai/notebooks/openai-chat-completions.ipynb" class="fa fa-github"> Edit on GitHub</a>
    </li> -->
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Introduction:-Advancing-Communication-with-GPT-4-and-MLflow">
<h1>Introduction: Advancing Communication with GPT-4 and MLflow<a class="headerlink" href="#Introduction:-Advancing-Communication-with-GPT-4-and-MLflow" title="Permalink to this headline"> </a></h1>
<p>Welcome to our advanced tutorial, where we delve into the cutting-edge capabilities of OpenAI’s GPT-4, particularly exploring its Chat Completions feature. In this session, we will combine the advanced linguistic prowess of GPT-4 with the robust experiment tracking and deployment framework of MLflow to create an innovative application: The Text Message Angel.</p>
<a href="https://raw.githubusercontent.com/mlflow/mlflow/master/docs/source/llms/openai/notebooks/openai-chat-completions.ipynb" class="notebook-download-btn"><i class="fas fa-download"></i>Download this Notebook</a><br><div class="section" id="Tutorial-Overview">
<h2>Tutorial Overview<a class="headerlink" href="#Tutorial-Overview" title="Permalink to this headline"> </a></h2>
<p>In this tutorial, we will:</p>
<ol class="arabic simple">
<li><p><strong>Set Up and Validate Environment</strong>: Ensure that all necessary configurations, including the <code class="docutils literal notranslate"><span class="pre">OPENAI_API_KEY</span></code>, are in place for our experiments.</p></li>
<li><p><strong>Initialize MLflow Experiment</strong>: Set up an MLflow experiment named “Text Message Angel” to track and manage our model’s performance and outcomes.</p></li>
<li><p><strong>Implement Chat Completions with GPT-4</strong>: Utilize the Chat Completions task of GPT-4 to develop an application that can analyze and respond to text messages. This feature of GPT-4 allows for context-aware, conversational AI applications that can understand and generate human-like text responses.</p></li>
<li><p><strong>Model Deployment and Prediction</strong>: Deploy our model using MLflow’s <code class="docutils literal notranslate"><span class="pre">pyfunc</span></code> implementation and make predictions on a set of sample text messages. This will demonstrate the practical application of our model in real-world scenarios.</p></li>
</ol>
</div>
<div class="section" id="The-Text-Message-Angel-Application">
<h2>The Text Message Angel Application<a class="headerlink" href="#The-Text-Message-Angel-Application" title="Permalink to this headline"> </a></h2>
<p>Our application, the Text Message Angel, aims to enhance everyday text communication. It will analyze SMS responses for tone, appropriateness, and relationship impact. The model will categorize responses as either appropriate (“Good to Go!”) or suggest caution (“You might want to read that again before pressing send”). For responses deemed inappropriate, it will also suggest alternative phrasing that maintains a friendly yet witty tone.</p>
</div>
<div class="section" id="Why-GPT-4-and-MLflow?">
<h2>Why GPT-4 and MLflow?<a class="headerlink" href="#Why-GPT-4-and-MLflow?" title="Permalink to this headline"> </a></h2>
<ul class="simple">
<li><p><strong>GPT-4’s Advanced AI</strong>: GPT-4 represents the latest in AI language model development, offering nuanced understanding and response generation capabilities that are ideal for a text-based application like the Text Message Angel.</p></li>
<li><p><strong>MLflow’s Seamless Management</strong>: MLflow simplifies the process of tracking experiments, managing different model versions, and deploying AI models. Its integration with GPT-4 allows us to focus on the creative aspect of our application while efficiently handling the technicalities of model management.</p></li>
</ul>
</div>
<div class="section" id="Engaging-with-the-Tutorial">
<h2>Engaging with the Tutorial<a class="headerlink" href="#Engaging-with-the-Tutorial" title="Permalink to this headline"> </a></h2>
<p>As we progress, we encourage you to actively engage with the code and concepts presented. This tutorial is not just about learning the functionalities but also understanding the potential of these technologies when combined creatively.</p>
<p>Let’s embark on this journey to harness the synergy of MLflow and GPT-4’s Chat Completions to enhance communication and interactions in our digital world.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>

<span class="c1"># Disable a few less-than-useful UserWarnings from setuptools and pydantic</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">openai</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>

<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">from</span> <span class="nn">mlflow.models.signature</span> <span class="kn">import</span> <span class="n">ModelSignature</span>
<span class="kn">from</span> <span class="nn">mlflow.types.schema</span> <span class="kn">import</span> <span class="n">ColSpec</span><span class="p">,</span> <span class="n">ParamSchema</span><span class="p">,</span> <span class="n">ParamSpec</span><span class="p">,</span> <span class="n">Schema</span>

<span class="c1"># Run a quick validation that we have an entry for the OPEN_API_KEY within environment variables</span>
<span class="k">assert</span> <span class="s2">&quot;OPENAI_API_KEY&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">,</span> <span class="s2">&quot;OPENAI_API_KEY environment variable must be set&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Implementing-the-Text-Message-Angel-with-GPT-4-and-Chat-Completions">
<h2>Implementing the Text Message Angel with GPT-4 and Chat Completions<a class="headerlink" href="#Implementing-the-Text-Message-Angel-with-GPT-4-and-Chat-Completions" title="Permalink to this headline"> </a></h2>
<p>After exploring the humorous world of misheard lyrics in the introductory tutorial to the <code class="docutils literal notranslate"><span class="pre">openai</span></code> flavor, we now shift our focus to a more sophisticated application involving GPT-4 and the Chat Completions feature. This tutorial introduces the “Text Message Angel”, an innovative application designed to pre-screen text messages, ensuring they are appropriate and relationship-friendly, especially for those inclined towards sarcasm.</p>
<div class="section" id="Setting-Up-the-Text-Message-Angel-Experiment">
<h3>Setting Up the Text Message Angel Experiment<a class="headerlink" href="#Setting-Up-the-Text-Message-Angel-Experiment" title="Permalink to this headline"> </a></h3>
<p>We begin by setting up a new MLflow experiment titled “Text Message Angel”. This experiment aims to create a service that analyzes text messages and provides guidance on their appropriateness before sending. The goal is to maintain positive communication while allowing for a playful tone.</p>
</div>
<div class="section" id="The-Role-of-GPT-4-and-Chat-Completions">
<h3>The Role of GPT-4 and Chat Completions<a class="headerlink" href="#The-Role-of-GPT-4-and-Chat-Completions" title="Permalink to this headline"> </a></h3>
<p>GPT-4 represents a massive leap in capability compared with the previous model we used in the introductory tutorial. It brings enhanced understanding and contextual awareness, making it ideal for interpreting and responding to natural language with a high degree of accuracy and nuance. The Chat Completions feature, specifically, enables a more conversational approach, which is perfect for our text message evaluation scenario.</p>
</div>
<div class="section" id="Crafting-the-Prompt-for-Text-Message-Evaluation">
<h3>Crafting the Prompt for Text Message Evaluation<a class="headerlink" href="#Crafting-the-Prompt-for-Text-Message-Evaluation" title="Permalink to this headline"> </a></h3>
<p>The core of our application is a well-crafted prompt that directs GPT-4 to evaluate text messages based on specific criteria:</p>
<ul class="simple">
<li><p><strong>Content Analysis</strong>: The model determines if a message contains inappropriate elements like humorless sarcasm, passive-aggressive tones, or anything that could harm a relationship.</p></li>
<li><p><strong>Response Categorization</strong>: Based on its analysis, the model categorizes the message as either “Good to Go!” or advises to “read that again before pressing send.”</p></li>
<li><p><strong>Suggested Corrections</strong>: If a message is deemed inappropriate, the model goes a step further to suggest an alternative version. This corrected message aims to preserve a fun and slightly snarky tone while ensuring it does not harm the relationship.</p></li>
</ul>
<p>This setup not only demonstrates the advanced capabilities of GPT-4 in understanding and generating human-like text but also highlights its potential for practical applications in everyday communication scenarios.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s2">&quot;Text Message Angel&quot;</span><span class="p">)</span>

<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
        <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="p">(</span>
            <span class="s2">&quot;Determine if this is an acceptable response to a friend through SMS. &quot;</span>
            <span class="s2">&quot;If the response contains humorless sarcasm, a passive aggressive tone, or could potentially &quot;</span>
            <span class="s2">&quot;damage my relationship with them, please respond with &#39;You might want to read that again before &quot;</span>
            <span class="s2">&quot;pressing send.&#39;, otherwise respond with &#39;Good to Go!&#39;. If the response classifies as inappropriate, &quot;</span>
            <span class="s2">&quot;please suggest a corrected version following the classification that will help to keep my &quot;</span>
            <span class="s2">&quot;relationship with this person intact, yet still maintains a fun and somewhat snarky tone: </span><span class="si">{text}</span><span class="s2">&quot;</span>
        <span class="p">),</span>
    <span class="p">}</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Integrating-GPT-4-with-MLflow-for-the-Text-Message-Angel">
<h2>Integrating GPT-4 with MLflow for the Text Message Angel<a class="headerlink" href="#Integrating-GPT-4-with-MLflow-for-the-Text-Message-Angel" title="Permalink to this headline"> </a></h2>
<p>In this crucial step, we’re integrating the advanced GPT-4 model with MLflow for our <code class="docutils literal notranslate"><span class="pre">Text</span> <span class="pre">Message</span> <span class="pre">Angel</span></code> application. This process involves setting up the model within an MLflow run, logging its configuration, and preparing it for practical use.</p>
<div class="section" id="Starting-the-MLflow-Run">
<h3>Starting the MLflow Run<a class="headerlink" href="#Starting-the-MLflow-Run" title="Permalink to this headline"> </a></h3>
<p>We initiate an MLflow run, a crucial step in tracking our model’s performance, parameters, and outputs. This run encapsulates all the details and metrics related to the GPT-4 model we are using.</p>
</div>
<div class="section" id="Logging-the-GPT-4-Model-in-MLflow">
<h3>Logging the GPT-4 Model in MLflow<a class="headerlink" href="#Logging-the-GPT-4-Model-in-MLflow" title="Permalink to this headline"> </a></h3>
<p>Within this run, we log our GPT-4 model using <code class="docutils literal notranslate"><span class="pre">mlflow.openai.log_model</span></code>. This function call is instrumental in registering our model’s specifics in MLflow’s tracking system. Here’s a breakdown of the parameters we’re logging:</p>
<ul class="simple">
<li><p><strong>Model Selection</strong>: We specify <code class="docutils literal notranslate"><span class="pre">gpt-4</span></code>, indicating we are utilizing a far more advanced version of OpenAI’s models than the previous example.</p></li>
<li><p><strong>Task Specification</strong>: The <code class="docutils literal notranslate"><span class="pre">openai.chat.completions</span></code> task is chosen, aligning with our objective of creating a conversational AI capable of analyzing and responding to text messages.</p></li>
<li><p><strong>Artifact Path</strong>: We define an artifact path where MLflow will store the model-related data.</p></li>
<li><p><strong>Messages</strong>: The <code class="docutils literal notranslate"><span class="pre">messages</span></code> variable, containing our pre-defined prompt and criteria for evaluating text messages, is passed to the model.</p></li>
<li><p><strong>Model Signature</strong>: The signature defines the input-output schema and parameters for our model, such as <code class="docutils literal notranslate"><span class="pre">max_tokens</span></code> and <code class="docutils literal notranslate"><span class="pre">temperature</span></code>. These settings are crucial in controlling how the model generates responses.</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>
    <span class="n">model_info</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">openai</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4&quot;</span><span class="p">,</span>
        <span class="n">task</span><span class="o">=</span><span class="n">openai</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="p">,</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="n">messages</span><span class="p">,</span>
        <span class="n">signature</span><span class="o">=</span><span class="n">ModelSignature</span><span class="p">(</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">)]),</span>
            <span class="n">outputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">)]),</span>
            <span class="n">params</span><span class="o">=</span><span class="n">ParamSchema</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">ParamSpec</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;max_tokens&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;long&quot;</span><span class="p">),</span>
                    <span class="n">ParamSpec</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;temperature&quot;</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">),</span>
                <span class="p">]</span>
            <span class="p">),</span>
        <span class="p">),</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Loading-the-Model-for-Use">
<h3>Loading the Model for Use<a class="headerlink" href="#Loading-the-Model-for-Use" title="Permalink to this headline"> </a></h3>
<p>After logging the model in MLflow, we load it as a generic Python function using <code class="docutils literal notranslate"><span class="pre">mlflow.pyfunc.load_model</span></code>. This step is vital as it transforms our GPT-4 model into a format that’s easily callable and usable within our application.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">model_info</span><span class="o">.</span><span class="n">model_uri</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Testing-the-Text-Message-Angel">
<h2>Testing the Text Message Angel<a class="headerlink" href="#Testing-the-Text-Message-Angel" title="Permalink to this headline"> </a></h2>
<p>With our Text Message Angel application powered by GPT-4 and integrated within MLflow, we are now ready to put it to the test. This section involves creating a set of sample text messages, some potentially containing sarcasm or passive-aggressive tones, and others being more straightforward and friendly.</p>
<div class="section" id="Creating-Validation-Data">
<h3>Creating Validation Data<a class="headerlink" href="#Creating-Validation-Data" title="Permalink to this headline"> </a></h3>
<p>We start by creating a DataFrame named <code class="docutils literal notranslate"><span class="pre">validation_data</span></code> with a variety of text messages. These messages are designed to test the model’s ability to discern tone and suggest corrections where necessary:</p>
<ol class="arabic simple">
<li><p>A message using humor to mask a critique of a dinner experience.</p></li>
<li><p>A sarcastic comment expressing reluctance to go to the movies.</p></li>
<li><p>A straightforward message expressing excitement for a road trip.</p></li>
<li><p>A simple thank-you message.</p></li>
<li><p>A sarcastic remark about enjoying someone’s singing.</p></li>
</ol>
</div>
<div class="section" id="Submitting-Messages-to-the-Model">
<h3>Submitting Messages to the Model<a class="headerlink" href="#Submitting-Messages-to-the-Model" title="Permalink to this headline"> </a></h3>
<p>Next, we submit these messages to our Text Message Angel model for evaluation. The model will analyze each message, determining whether it’s appropriate or needs a revision. For messages that might strain a relationship, the model will suggest a more suitable version.</p>
</div>
<div class="section" id="Displaying-the-Model’s-Responses">
<h3>Displaying the Model’s Responses<a class="headerlink" href="#Displaying-the-Model’s-Responses" title="Permalink to this headline"> </a></h3>
<p>The responses from the model are then formatted for clear and attractive display. This step is crucial for assessing the model’s performance in real-time and understanding how its corrections and suggestions align with the intended tone of the messages.</p>
</div>
<div class="section" id="Model’s-Output">
<h3>Model’s Output<a class="headerlink" href="#Model’s-Output" title="Permalink to this headline"> </a></h3>
<p>Let’s take a look at how the Text Message Angel responded:</p>
<ol class="arabic simple">
<li><p>Suggested a more tactful way to comment on the dinner.</p></li>
<li><p>Offered a humorous yet softer alternative for declining a movie invitation.</p></li>
<li><p>Confirmed that the road trip message is appropriate.</p></li>
<li><p>Validated the thank-you message as suitable.</p></li>
<li><p>Suggested a playful yet kinder remark about singing.</p></li>
</ol>
<p>These responses showcase the model’s nuanced understanding of social communication, its ability to maintain a friendly yet fun tone, and its potential in assisting users to communicate more effectively and harmoniously.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">validation_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="s2">&quot;Wow, what an interesting dinner last night! I had no idea that you could use canned &quot;</span>
            <span class="s2">&quot;cat food to make a meatloaf.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;I&#39;d rather book a 14th century surgical operation than go to the movies with you on Thursday.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Can&#39;t wait for the roadtrip this weekend! Love the playlist mixes that you choose!&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Thanks for helping out with the move this weekend. I really appreciate it.&quot;</span><span class="p">,</span>
            <span class="s2">&quot;You know what part I love most when you sing? The end. It means its over.&quot;</span><span class="p">,</span>
        <span class="p">]</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">chat_completions_response</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
    <span class="n">validation_data</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;max_tokens&quot;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span> <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">}</span>
<span class="p">)</span>

<span class="n">formatted_output</span> <span class="o">=</span> <span class="s2">&quot;&lt;br&gt;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
    <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;&lt;p&gt;&lt;strong&gt;</span><span class="si">{</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2">&lt;/strong&gt;&lt;/p&gt;&quot;</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">chat_completions_response</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="n">formatted_output</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<p><strong>You might want to read that again before pressing send.

Suggested response: "Wow, dinner last night was certainly unique! Who knew meatloaf could be so... adventurous?"</strong></p><br><p><strong>You might want to read that again before pressing send.

Suggested correction: "I'd rather watch a 14th century surgical operation documentary than miss out on the movies with you on Thursday. How's that for a plot twist?"</strong></p><br><p><strong>Good to Go!</strong></p><br><p><strong>Good to Go!</strong></p><br><p><strong>You might want to read that again before pressing send.

Suggested response: "You know what part I love most when you sing? The encore. It means I get to hear you again!"</strong></p></div>
</div>
</div>
</div>
<div class="section" id="Conclusion:-Advancing-AI-Interactions-with-MLflow-and-OpenAI’s-GPT-4">
<h2>Conclusion: Advancing AI Interactions with MLflow and OpenAI’s GPT-4<a class="headerlink" href="#Conclusion:-Advancing-AI-Interactions-with-MLflow-and-OpenAI’s-GPT-4" title="Permalink to this headline"> </a></h2>
<p>As we reach the end of this tutorial, it’s time to reflect on the insights we’ve gained, especially the remarkable capabilities of GPT-4 in the realm of conversational AI, and how MLflow facilitates the deployment and management of these advanced models.</p>
<div class="section" id="Key-Takeaways">
<h3>Key Takeaways<a class="headerlink" href="#Key-Takeaways" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p><strong>Deep Dive into ChatCompletions with GPT-4</strong>: This tutorial gave us a hands-on experience with GPT-4’s ChatCompletions feature, demonstrating its ability to understand context, maintain conversation flow, and generate human-like responses. The <code class="docutils literal notranslate"><span class="pre">Text</span> <span class="pre">Message</span> <span class="pre">Angel</span></code> application exemplified how such a model can be used to improve and refine everyday communication.</p></li>
<li><p><strong>MLflow’s Role in Managing Advanced AI</strong>: MLflow has shown its strength not just in handling model logistics, but also in simplifying the experimentation with complex AI models like GPT-4. Its robust tracking and logging capabilities make it easier to manage and iterate over conversational AI models.</p></li>
<li><p><strong>Real-World Application and Potential</strong>: The <code class="docutils literal notranslate"><span class="pre">Text</span> <span class="pre">Message</span> <span class="pre">Angel</span></code> illustrated a practical application of GPT-4’s advanced capabilities, demonstrating how AI can be leveraged to enhance and safeguard interpersonal communication. It’s a glimpse into how conversational AI can be used in customer service, mental health, education, and other domains.</p></li>
<li><p><strong>The Evolution of AI and MLflow’s Adaptability</strong>: The tutorial highlighted how MLflow’s flexible framework is well-suited to keep pace with the rapid advancements in AI, particularly in areas like natural language processing and conversational AI.</p></li>
</ul>
</div>
<div class="section" id="Moving-Forward-with-Conversational-AI">
<h3>Moving Forward with Conversational AI<a class="headerlink" href="#Moving-Forward-with-Conversational-AI" title="Permalink to this headline"> </a></h3>
<p>The combination of MLflow and OpenAI’s GPT-4 opens up exciting avenues for developing more intuitive and responsive AI-driven applications. As we continue to witness advancements in AI, MLflow’s ability to adapt and manage these complex models becomes increasingly vital.</p>
</div>
<div class="section" id="Embarking-on-Your-AI-Journey">
<h3>Embarking on Your AI Journey<a class="headerlink" href="#Embarking-on-Your-AI-Journey" title="Permalink to this headline"> </a></h3>
<p>We encourage you to build upon the foundations laid in this tutorial to explore the vast potential of conversational AI. With MLflow and OpenAI’s GPT-4, you are well-equipped to create innovative applications that can converse, understand, and interact in more human-like ways.</p>
<p>Thank you for joining us in exploring the cutting-edge of conversational AI and model management. Your journey into developing AI-enhanced communication tools is just beginning, and we are excited to see where your creativity and skills will lead you next!</p>
<p>To continue your learning journey, see the additional <a class="reference external" href="https://www.mlflow.org/docs/latest/llms/openai/index.html#advanced-tutorials">advanced tutorials for MLflow’s OpenAI flavor</a>.</p>
</div>
</div>
</div>


              </div>
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="openai-quickstart.html" class="btn btn-neutral" title="Introduction to Using the OpenAI Flavor in MLflow" accesskey="p"><span class="db-icon db-icon-chevron-left"></span> Previous</a>
      
      
        <a href="openai-code-helper.html" class="btn btn-neutral" title="Building a Code Assistant with OpenAI &amp; MLflow" accesskey="n">Next <span class="db-icon db-icon-chevron-right"></span></a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; MLflow Project, a Series of LF Projects, LLC. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'../../../',
      VERSION:'2.14.2.dev0',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      LINK_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  

  <script type="text/javascript" src="../../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/jquery.waypoints.min.js"></script>

  
  
  
  <script type="text/javascript">var CLIPPY_SVG_PATH = "../../../_static/clippy.svg";</script>
  <script type="text/javascript" src="../../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  

  
  <script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        function copyToClipboard(text) {
            const textarea = document.createElement('textarea');
            textarea.value = text;
            document.body.appendChild(textarea);
            textarea.select();
            document.execCommand('copy');
            document.body.removeChild(textarea);
        }
        // Get the code block designator class entries
        const allHighlights = document.querySelectorAll('.highlight');
        // Disable copyable links for notebook cell numbering and for cell outputs
        const highlights = Array.from(allHighlights).filter(highlight => !highlight.closest('.highlight-none') && 
            !highlight.closest('.nboutput'));
    
        highlights.forEach(function(highlight) {
            const copyIcon = document.createElement('span');
            copyIcon.classList.add('copy-icon');
            copyIcon.innerHTML = '&#xf0ea;';

            copyIcon.addEventListener('click', function() {
                const code = highlight.querySelector('pre').textContent;
                copyToClipboard(code);

                // Flash effect on click
                this.style.color = '#0194E2';
                setTimeout(() => {
                    this.style.color = ''; 
                }, 100);

                // Display "Code copied to clipboard" near the clicked icon
                const message = document.createElement('span');
                message.textContent = "Copied!";
                message.classList.add('copy-message'); 

                // Append the message to the icon
                this.appendChild(message);

                setTimeout(() => {
                    this.removeChild(message);
                }, 500);
            });

            highlight.appendChild(copyIcon);
        });
    });
  </script>


<script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        // Force download for notebook-download-btn
        const downloadButtons = document.querySelectorAll('.notebook-download-btn');
        downloadButtons.forEach(function(button) {
            button.addEventListener('click', function(event) {
                event.preventDefault(); // Prevent default behavior

                // Fetch the raw content of the notebook from GitHub
                fetch(button.href)
                    .then(response => response.blob())
                    .then(blob => {
                        const url = window.URL.createObjectURL(blob);
                        const link = document.createElement('a');
                        link.style.display = 'none';
                        link.href = url;
                        const filename = button.href.split('/').pop();
                        link.download = filename; 

                        document.body.appendChild(link);
                        link.click();

                        window.URL.revokeObjectURL(url);
                        document.body.removeChild(link);
                    })
                    .catch(err => console.error('Error fetching the notebook:', err));
            });
        });
    });
</script> 
</body>
</html>