
  

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mlflow.transformers &mdash; MLflow 2.9.3.dev0 documentation</title>
  
   
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
  <link rel="canonical" href="https://mlflow.org/docs/latest/_modules/mlflow/transformers.html">
  
  
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    

    

  
    

  

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/cards.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/grids.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/mobile.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/simple-cards.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/tabs.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="../../genindex.html"/>
        <link rel="search" title="Search" href="../../search.html"/>
    <link rel="top" title="MLflow 2.9.3.dev0 documentation" href="../../index.html"/>
        <link rel="up" title="Module code" href="../index.html"/> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>
<script type="text/javascript" src="../../_static/jquery.js"></script>
<script type="text/javascript" src="../../_static/underscore.js"></script>
<script type="text/javascript" src="../../_static/doctools.js"></script>
<script type="text/javascript" src="../../_static/tabs.js"></script>
<script type="text/javascript" src="../../_static/languagesections.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>

<body class="wy-body-for-nav" role="document">
  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <ul>
  <li class="menu-toggle">
    <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
    <a href="../../index.html" class="wy-nav-top-logo"
      ><img src="../../_static/MLflow-logo-final-black.png" alt="MLflow"
    /></a>
    <span class="version">2.9.3.dev0</span>
  </li>
</ul>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side relative">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
  </form>
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../index.html" class="main-navigation-home"><img src="../../_static/icons/nav-home.svg"> MLflow</a>
    

    
      

      
        <ul>
<li class="toctree-l1"><a class="reference internal" href="../../introduction/index.html">What is MLflow?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting-started/index.html">Getting Started with MLflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../new-features/index.html">New Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../llms/index.html">LLMs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model-evaluation/index.html">Model Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deep-learning/index.html">Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../traditional-ml/index.html">Traditional ML</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deployment/index.html">Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tracking.html">MLflow Tracking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../system-metrics/index.html">System Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../projects.html">MLflow Projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../models.html">MLflow Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model-registry.html">MLflow Model Registry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../recipes.html">MLflow Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../plugins.html">MLflow Plugins</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../auth/index.html">MLflow Authentication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../search-runs.html">Search Runs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../search-experiments.html">Search Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../R-api.html">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../java_api/index.html">Java API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rest-api.html">REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docker.html">Official MLflow Docker Image</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community-model-flavors.html">Community Model Flavors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials-and-examples/index.html">Tutorials and Examples</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            










<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="../index.html">Module code</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>mlflow.transformers</li>
    
    
    <!-- <li class="wy-breadcrumbs-aside">
      <a href="https://github.com/mlflow/mlflow/blob/master/docs/source/_modules/mlflow/transformers" class="fa fa-github"> Edit on GitHub</a>
    </li> -->
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  <h1>Source code for mlflow.transformers</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;MLflow module for HuggingFace/transformer support.&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">ast</span>
<span class="kn">import</span> <span class="nn">base64</span>
<span class="kn">import</span> <span class="nn">binascii</span>
<span class="kn">import</span> <span class="nn">contextlib</span>
<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pathlib</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">string</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">lru_cache</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">NamedTuple</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>
<span class="kn">from</span> <span class="nn">urllib.parse</span> <span class="kn">import</span> <span class="n">urlparse</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">yaml</span>
<span class="kn">from</span> <span class="nn">packaging.version</span> <span class="kn">import</span> <span class="n">Version</span>

<span class="kn">from</span> <span class="nn">mlflow</span> <span class="kn">import</span> <span class="n">pyfunc</span>
<span class="kn">from</span> <span class="nn">mlflow.environment_variables</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">MLFLOW_DEFAULT_PREDICTION_DEVICE</span><span class="p">,</span>
    <span class="n">MLFLOW_HUGGINGFACE_DEVICE_MAP_STRATEGY</span><span class="p">,</span>
    <span class="n">MLFLOW_HUGGINGFACE_DISABLE_ACCELERATE_FEATURES</span><span class="p">,</span>
    <span class="n">MLFLOW_HUGGINGFACE_MODEL_MAX_SHARD_SIZE</span><span class="p">,</span>
    <span class="n">MLFLOW_HUGGINGFACE_USE_DEVICE_MAP</span><span class="p">,</span>
    <span class="n">MLFLOW_HUGGINGFACE_USE_LOW_CPU_MEM_USAGE</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">mlflow.exceptions</span> <span class="kn">import</span> <span class="n">MlflowException</span>
<span class="kn">from</span> <span class="nn">mlflow.models</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Model</span><span class="p">,</span>
    <span class="n">ModelInputExample</span><span class="p">,</span>
    <span class="n">ModelSignature</span><span class="p">,</span>
    <span class="n">infer_pip_requirements</span><span class="p">,</span>
    <span class="n">infer_signature</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">mlflow.models.model</span> <span class="kn">import</span> <span class="n">MLMODEL_FILE_NAME</span>
<span class="kn">from</span> <span class="nn">mlflow.models.utils</span> <span class="kn">import</span> <span class="n">_contains_params</span><span class="p">,</span> <span class="n">_save_example</span>
<span class="kn">from</span> <span class="nn">mlflow.protos.databricks_pb2</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">BAD_REQUEST</span><span class="p">,</span>
    <span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
    <span class="n">RESOURCE_DOES_NOT_EXIST</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">mlflow.tracking._model_registry</span> <span class="kn">import</span> <span class="n">DEFAULT_AWAIT_MAX_SLEEP_SECONDS</span>
<span class="kn">from</span> <span class="nn">mlflow.types.schema</span> <span class="kn">import</span> <span class="n">ColSpec</span><span class="p">,</span> <span class="n">Schema</span><span class="p">,</span> <span class="n">TensorSpec</span>
<span class="kn">from</span> <span class="nn">mlflow.types.utils</span> <span class="kn">import</span> <span class="n">_validate_input_dictionary_contains_only_strings_and_lists_of_strings</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.annotations</span> <span class="kn">import</span> <span class="n">experimental</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.autologging_utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">autologging_integration</span><span class="p">,</span>
    <span class="n">disable_discrete_autologging</span><span class="p">,</span>
    <span class="n">safe_patch</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.docstring_utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">LOG_MODEL_PARAM_DOCS</span><span class="p">,</span>
    <span class="n">docstring_version_compatibility_warning</span><span class="p">,</span>
    <span class="n">format_docstring</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.environment</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_CONDA_ENV_FILE_NAME</span><span class="p">,</span>
    <span class="n">_CONSTRAINTS_FILE_NAME</span><span class="p">,</span>
    <span class="n">_PYTHON_ENV_FILE_NAME</span><span class="p">,</span>
    <span class="n">_REQUIREMENTS_FILE_NAME</span><span class="p">,</span>
    <span class="n">_mlflow_conda_env</span><span class="p">,</span>
    <span class="n">_process_conda_env</span><span class="p">,</span>
    <span class="n">_process_pip_requirements</span><span class="p">,</span>
    <span class="n">_PythonEnv</span><span class="p">,</span>
    <span class="n">_validate_env_arguments</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.file_utils</span> <span class="kn">import</span> <span class="n">get_total_file_size</span><span class="p">,</span> <span class="n">write_to</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.model_utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_add_code_from_conf_to_system_path</span><span class="p">,</span>
    <span class="n">_download_artifact_from_uri</span><span class="p">,</span>
    <span class="n">_get_flavor_configuration</span><span class="p">,</span>
    <span class="n">_get_flavor_configuration_from_uri</span><span class="p">,</span>
    <span class="n">_validate_and_copy_code_paths</span><span class="p">,</span>
    <span class="n">_validate_and_prepare_target_save_path</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">mlflow.utils.requirements_utils</span> <span class="kn">import</span> <span class="n">_get_pinned_requirement</span>

<span class="n">FLAVOR_NAME</span> <span class="o">=</span> <span class="s2">&quot;transformers&quot;</span>

<span class="n">_CARD_TEXT_FILE_NAME</span> <span class="o">=</span> <span class="s2">&quot;model_card.md&quot;</span>
<span class="n">_CARD_DATA_FILE_NAME</span> <span class="o">=</span> <span class="s2">&quot;model_card_data.yaml&quot;</span>
<span class="n">_COMPONENTS_BINARY_KEY</span> <span class="o">=</span> <span class="s2">&quot;components&quot;</span>
<span class="n">_FEATURE_EXTRACTOR_KEY</span> <span class="o">=</span> <span class="s2">&quot;feature_extractor&quot;</span>
<span class="n">_FEATURE_EXTRACTOR_TYPE_KEY</span> <span class="o">=</span> <span class="s2">&quot;feature_extractor_type&quot;</span>
<span class="n">_FRAMEWORK_KEY</span> <span class="o">=</span> <span class="s2">&quot;framework&quot;</span>
<span class="n">_IMAGE_PROCESSOR_KEY</span> <span class="o">=</span> <span class="s2">&quot;image_processor&quot;</span>
<span class="n">_IMAGE_PROCESSOR_TYPE_KEY</span> <span class="o">=</span> <span class="s2">&quot;image_processor_type&quot;</span>
<span class="n">_INFERENCE_CONFIG_BINARY_KEY</span> <span class="o">=</span> <span class="s2">&quot;inference_config.txt&quot;</span>
<span class="n">_INSTANCE_TYPE_KEY</span> <span class="o">=</span> <span class="s2">&quot;instance_type&quot;</span>
<span class="n">_MODEL_KEY</span> <span class="o">=</span> <span class="s2">&quot;model&quot;</span>
<span class="n">_MODEL_BINARY_KEY</span> <span class="o">=</span> <span class="s2">&quot;model_binary&quot;</span>
<span class="n">_MODEL_BINARY_FILE_NAME</span> <span class="o">=</span> <span class="s2">&quot;model&quot;</span>
<span class="n">_MODEL_PATH_OR_NAME_KEY</span> <span class="o">=</span> <span class="s2">&quot;source_model_name&quot;</span>
<span class="n">_PIPELINE_MODEL_TYPE_KEY</span> <span class="o">=</span> <span class="s2">&quot;pipeline_model_type&quot;</span>
<span class="n">_PROCESSOR_KEY</span> <span class="o">=</span> <span class="s2">&quot;processor&quot;</span>
<span class="n">_PROCESSOR_TYPE_KEY</span> <span class="o">=</span> <span class="s2">&quot;processor_type&quot;</span>
<span class="n">_PROMPT_TEMPLATE_KEY</span> <span class="o">=</span> <span class="s2">&quot;prompt_template&quot;</span>
<span class="n">_SUPPORTED_RETURN_TYPES</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;pipeline&quot;</span><span class="p">,</span> <span class="s2">&quot;components&quot;</span><span class="p">}</span>
<span class="c1"># The default device id for CPU is -1 and GPU IDs are ordinal starting at 0, as documented here:</span>
<span class="c1"># https://huggingface.co/transformers/v4.7.0/main_classes/pipelines.html</span>
<span class="n">_TRANSFORMERS_DEFAULT_CPU_DEVICE_ID</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">_TRANSFORMERS_DEFAULT_GPU_DEVICE_ID</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">_TASK_KEY</span> <span class="o">=</span> <span class="s2">&quot;task&quot;</span>
<span class="n">_TOKENIZER_KEY</span> <span class="o">=</span> <span class="s2">&quot;tokenizer&quot;</span>
<span class="n">_TOKENIZER_TYPE_KEY</span> <span class="o">=</span> <span class="s2">&quot;tokenizer_type&quot;</span>
<span class="n">_TORCH_DTYPE_KEY</span> <span class="o">=</span> <span class="s2">&quot;torch_dtype&quot;</span>
<span class="n">_METADATA_PIPELINE_SCALAR_CONFIG_KEYS</span> <span class="o">=</span> <span class="p">{</span><span class="n">_FRAMEWORK_KEY</span><span class="p">}</span>
<span class="n">_SUPPORTED_SAVE_KEYS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">_MODEL_KEY</span><span class="p">,</span>
    <span class="n">_TOKENIZER_KEY</span><span class="p">,</span>
    <span class="n">_FEATURE_EXTRACTOR_KEY</span><span class="p">,</span>
    <span class="n">_IMAGE_PROCESSOR_KEY</span><span class="p">,</span>
    <span class="n">_TORCH_DTYPE_KEY</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">_SUPPORTED_PROMPT_TEMPLATING_TASK_TYPES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;feature-extraction&quot;</span><span class="p">,</span>
    <span class="s2">&quot;fill-mask&quot;</span><span class="p">,</span>
    <span class="s2">&quot;summarization&quot;</span><span class="p">,</span>
    <span class="s2">&quot;text2text-generation&quot;</span><span class="p">,</span>
    <span class="s2">&quot;text-generation&quot;</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">_PROMPT_TEMPLATE_RETURN_FULL_TEXT_INFO</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">&quot;text-generation pipelines saved with prompt templates have the `return_full_text` &quot;</span>
    <span class="s2">&quot;pipeline kwarg set to False by default. To override this behavior, provide a &quot;</span>
    <span class="s2">&quot;`model_config` dict with `return_full_text` set to `True` when saving the model.&quot;</span>
<span class="p">)</span>

<span class="n">_logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_model_packages</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Determines which pip libraries should be included based on the base model engine type.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: The model instance to be saved in order to provide the required underlying</span>
<span class="sd">            deep learning execution framework dependency requirements.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A list of strings representing the underlying engine-specific dependencies</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">engine</span> <span class="o">=</span> <span class="n">_get_engine_type</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">engine</span> <span class="o">==</span> <span class="s2">&quot;torch&quot;</span><span class="p">:</span>
        <span class="n">packages</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="s2">&quot;torchvision&quot;</span><span class="p">]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">accelerate</span>  <span class="c1"># noqa: F401</span>

            <span class="n">packages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;accelerate&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">pass</span>
        <span class="k">return</span> <span class="n">packages</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">engine</span><span class="p">]</span>


<div class="viewcode-block" id="get_default_pip_requirements"><a class="viewcode-back" href="../../python_api/mlflow.transformers.html#mlflow.transformers.get_default_pip_requirements">[docs]</a><span class="nd">@experimental</span>
<span class="k">def</span> <span class="nf">get_default_pip_requirements</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">        model: The model instance to be saved in order to provide the required underlying</span>
<span class="sd">            deep learning execution framework dependency requirements. Note that this must</span>
<span class="sd">            be the actual model instance and not a Pipeline.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A list of default pip requirements for MLflow Models that have been produced with the</span>
<span class="sd">        ``transformers`` flavor. Calls to :py:func:`save_model()` and :py:func:`log_model()`</span>
<span class="sd">        produce a pip environment that contain these requirements at a minimum.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">FlaxPreTrainedModel</span><span class="p">,</span> <span class="n">PreTrainedModel</span><span class="p">,</span> <span class="n">TFPreTrainedModel</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">TFPreTrainedModel</span><span class="p">,</span> <span class="n">FlaxPreTrainedModel</span><span class="p">,</span> <span class="n">PreTrainedModel</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="s2">&quot;The supplied model type is unsupported. The model must be one of: &quot;</span>
            <span class="s2">&quot;PreTrainedModel, TFPreTrainedModel, or FlaxPreTrainedModel&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">base_reqs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;transformers&quot;</span><span class="p">,</span> <span class="o">*</span><span class="n">_model_packages</span><span class="p">(</span><span class="n">model</span><span class="p">)]</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">_get_pinned_requirement</span><span class="p">(</span><span class="n">module</span><span class="p">)</span> <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">base_reqs</span><span class="p">]</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">dependencies</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">_get_pinned_requirement</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;transformers&quot;</span><span class="p">,</span> <span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="s2">&quot;torchvision&quot;</span><span class="p">,</span> <span class="s2">&quot;tensorflow&quot;</span><span class="p">]</span>
        <span class="p">]</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;Could not infer model execution engine type due to huggingface_hub not &quot;</span>
            <span class="s2">&quot;being installed or unable to connect in online mode. Adding full &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;dependency chain: </span><span class="si">{</span><span class="n">dependencies</span><span class="si">}</span><span class="s2">. </span><span class="se">\n</span><span class="s2">Failure cause: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">dependencies</span></div>


<span class="k">def</span> <span class="nf">_validate_transformers_model_dict</span><span class="p">(</span><span class="n">transformers_model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Validator for a submitted save dictionary for the transformers model. If any additional keys</span>
<span class="sd">    are provided, raise to indicate which invalid keys were submitted.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">transformers_model</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">invalid_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">transformers_model</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_SUPPORTED_SAVE_KEYS</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">invalid_keys</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="s2">&quot;Invalid dictionary submitted for &#39;transformers_model&#39;. The &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;key(s) </span><span class="si">{</span><span class="n">invalid_keys</span><span class="si">}</span><span class="s2"> are not permitted. Must be one of: &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">_SUPPORTED_SAVE_KEYS</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">_MODEL_KEY</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">transformers_model</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The &#39;transformers_model&#39; dictionary must have an entry for </span><span class="si">{</span><span class="n">_MODEL_KEY</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">transformers_model</span><span class="p">[</span><span class="n">_MODEL_KEY</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">transformers_model</span><span class="o">.</span><span class="n">model</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;name_or_path&quot;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;The submitted model type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> does not inherit &quot;</span>
            <span class="s2">&quot;from a transformers pre-trained model. It is missing the attribute &quot;</span>
            <span class="s2">&quot;&#39;name_or_path&#39;. Please verify that the model is a supported &quot;</span>
            <span class="s2">&quot;transformers model.&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
        <span class="p">)</span>


<div class="viewcode-block" id="get_default_conda_env"><a class="viewcode-back" href="../../python_api/mlflow.transformers.html#mlflow.transformers.get_default_conda_env">[docs]</a><span class="nd">@experimental</span>
<span class="k">def</span> <span class="nf">get_default_conda_env</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns:</span>
<span class="sd">        The default Conda environment for MLflow Models produced with the ``transformers``</span>
<span class="sd">        flavor, based on the model instance framework type of the model to be logged.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_mlflow_conda_env</span><span class="p">(</span><span class="n">additional_pip_deps</span><span class="o">=</span><span class="n">get_default_pip_requirements</span><span class="p">(</span><span class="n">model</span><span class="p">))</span></div>


<div class="viewcode-block" id="save_model"><a class="viewcode-back" href="../../python_api/mlflow.transformers.html#mlflow.transformers.save_model">[docs]</a><span class="nd">@experimental</span>
<span class="nd">@docstring_version_compatibility_warning</span><span class="p">(</span><span class="n">integration_name</span><span class="o">=</span><span class="n">FLAVOR_NAME</span><span class="p">)</span>
<span class="nd">@format_docstring</span><span class="p">(</span><span class="n">LOG_MODEL_PARAM_DOCS</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">package_name</span><span class="o">=</span><span class="n">FLAVOR_NAME</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span>
    <span class="n">transformers_model</span><span class="p">,</span>
    <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">processor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">task</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">model_card</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">inference_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">code_paths</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">mlflow_model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Model</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">signature</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelSignature</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">input_example</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelInputExample</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">pip_requirements</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_pip_requirements</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">conda_env</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">model_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">example_no_conversion</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">prompt_template</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>  <span class="c1"># pylint: disable=unused-argument</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Save a trained transformers model to a path on the local file system.</span>

<span class="sd">    Args:</span>
<span class="sd">        transformers_model:</span>
<span class="sd">            A trained transformers `Pipeline` or a dictionary that maps required components of a</span>
<span class="sd">            pipeline to the named keys of [&quot;model&quot;, &quot;image_processor&quot;, &quot;tokenizer&quot;,</span>
<span class="sd">            &quot;feature_extractor&quot;]. The `model` key in the dictionary must map to a value that</span>
<span class="sd">            inherits from `PreTrainedModel`, `TFPreTrainedModel`, or `FlaxPreTrainedModel`.</span>
<span class="sd">            All other component entries in the dictionary must support the defined task type that is</span>
<span class="sd">            associated with the base model type configuration.</span>

<span class="sd">            An example of supplying component-level parts of a transformers model is shown below:</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                from transformers import MobileBertForQuestionAnswering, AutoTokenizer</span>

<span class="sd">                architecture = &quot;csarron/mobilebert-uncased-squad-v2&quot;</span>
<span class="sd">                tokenizer = AutoTokenizer.from_pretrained(architecture)</span>
<span class="sd">                model = MobileBertForQuestionAnswering.from_pretrained(architecture)</span>

<span class="sd">                with mlflow.start_run():</span>
<span class="sd">                    components = {</span>
<span class="sd">                        &quot;model&quot;: model,</span>
<span class="sd">                        &quot;tokenizer&quot;: tokenizer,</span>
<span class="sd">                    }</span>
<span class="sd">                    mlflow.transformers.save_model(</span>
<span class="sd">                        transformers_model=components,</span>
<span class="sd">                        path=&quot;path/to/save/model&quot;,</span>
<span class="sd">                    )</span>

<span class="sd">            An example of submitting a `Pipeline` from a default pipeline instantiation:</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                from transformers import pipeline</span>

<span class="sd">                qa_pipe = pipeline(&quot;question-answering&quot;, &quot;csarron/mobilebert-uncased-squad-v2&quot;)</span>

<span class="sd">                with mlflow.start_run():</span>
<span class="sd">                    mlflow.transformers.save_model(</span>
<span class="sd">                        transformers_model=qa_pipe,</span>
<span class="sd">                        path=&quot;path/to/save/model&quot;,</span>
<span class="sd">                    )</span>

<span class="sd">        path: Local path destination for the serialized model to be saved.</span>
<span class="sd">        processor: An optional ``Processor`` subclass object. Some model architectures,</span>
<span class="sd">            particularly multi-modal types, utilize Processors to combine text</span>
<span class="sd">            encoding and image or audio encoding in a single entrypoint.</span>

<span class="sd">            .. Note:: If a processor is supplied when saving a model, the</span>
<span class="sd">                        model will be unavailable for loading as a ``Pipeline`` or for</span>
<span class="sd">                        usage with pyfunc inference.</span>
<span class="sd">        task: The transformers-specific task type of the model. These strings are utilized so</span>
<span class="sd">            that a pipeline can be created with the appropriate internal call architecture</span>
<span class="sd">            to meet the needs of a given model. If this argument is not specified, the</span>
<span class="sd">            pipeline utilities within the transformers library will be used to infer the</span>
<span class="sd">            correct task type. If the value specified is not a supported type within the</span>
<span class="sd">            version of transformers that is currently installed, an Exception will be thrown.</span>
<span class="sd">        model_card: An Optional `ModelCard` instance from `huggingface-hub`. If provided, the</span>
<span class="sd">            contents of the model card will be saved along with the provided</span>
<span class="sd">            `transformers_model`. If not provided, an attempt will be made to fetch</span>
<span class="sd">            the card from the base pretrained model that is provided (or the one that is</span>
<span class="sd">            included within a provided `Pipeline`).</span>

<span class="sd">            .. Note:: In order for a ModelCard to be fetched (if not provided),</span>
<span class="sd">                        the huggingface_hub package must be installed and the version</span>
<span class="sd">                        must be &gt;=0.10.0</span>
<span class="sd">        inference_config:</span>

<span class="sd">            .. Warning:: Deprecated. `inference_config` is deprecated in favor of `model_config`.</span>

<span class="sd">        model_config:</span>
<span class="sd">            A dict of valid overrides that can be applied to a pipeline instance during inference.</span>
<span class="sd">            These arguments are used exclusively for the case of loading the model as a ``pyfunc``</span>
<span class="sd">            Model or for use in Spark.</span>
<span class="sd">            These values are not applied to a returned Pipeline from a call to</span>
<span class="sd">            ``mlflow.transformers.load_model()``</span>

<span class="sd">            .. Warning:: If the key provided is not compatible with either the</span>
<span class="sd">                    Pipeline instance for the task provided or is not a valid</span>
<span class="sd">                    override to any arguments available in the Model, an</span>
<span class="sd">                    Exception will be raised at runtime. It is very important</span>
<span class="sd">                    to validate the entries in this dictionary to ensure</span>
<span class="sd">                    that they are valid prior to saving or logging.</span>

<span class="sd">            An example of providing overrides for a question generation model:</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                from transformers import pipeline, AutoTokenizer</span>

<span class="sd">                task = &quot;text-generation&quot;</span>
<span class="sd">                architecture = &quot;gpt2&quot;</span>

<span class="sd">                sentence_pipeline = pipeline(</span>
<span class="sd">                    task=task,</span>
<span class="sd">                    tokenizer=AutoTokenizer.from_pretrained(architecture),</span>
<span class="sd">                    model=architecture,  # pylint: disable=line-too-long</span>
<span class="sd">                )</span>

<span class="sd">                # Validate that the overrides function</span>
<span class="sd">                prompts = [&quot;Generative models are&quot;, &quot;I&#39;d like a coconut so that I can&quot;]</span>

<span class="sd">                # validation of config prior to save or log</span>
<span class="sd">                model_config = {</span>
<span class="sd">                    &quot;top_k&quot;: 2,</span>
<span class="sd">                    &quot;num_beams&quot;: 5,</span>
<span class="sd">                    &quot;max_length&quot;: 30,</span>
<span class="sd">                    &quot;temperature&quot;: 0.62,</span>
<span class="sd">                    &quot;top_p&quot;: 0.85,</span>
<span class="sd">                    &quot;repetition_penalty&quot;: 1.15,</span>
<span class="sd">                }</span>

<span class="sd">                # Verify that no exceptions are thrown</span>
<span class="sd">                sentence_pipeline(prompts, **model_config)</span>

<span class="sd">                mlflow.transformers.save_model(</span>
<span class="sd">                    transformers_model=sentence_pipeline,</span>
<span class="sd">                    path=&quot;/path/for/model&quot;,</span>
<span class="sd">                    task=task,</span>
<span class="sd">                    model_config=model_config,</span>
<span class="sd">                )</span>

<span class="sd">        code_paths: A list of local filesystem paths to Python file dependencies (or directories</span>
<span class="sd">            containing file dependencies). These files are *prepended* to the system</span>
<span class="sd">            path when the model is loaded.</span>
<span class="sd">        mlflow_model: An MLflow model object that specifies the flavor that this model is being</span>
<span class="sd">            added to.</span>
<span class="sd">        signature: A Model Signature object that describes the input and output Schema of the</span>
<span class="sd">            model. The model signature can be inferred using `infer_signature` function</span>
<span class="sd">            of `mlflow.models.signature`.</span>
<span class="sd">            Example:</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                from mlflow.models import infer_signature</span>
<span class="sd">                from mlflow.transformers import generate_signature_output</span>
<span class="sd">                from transformers import pipeline</span>

<span class="sd">                en_to_de = pipeline(&quot;translation_en_to_de&quot;)</span>

<span class="sd">                data = &quot;MLflow is great!&quot;</span>
<span class="sd">                output = generate_signature_output(en_to_de, data)</span>
<span class="sd">                signature = infer_signature(data, output)</span>

<span class="sd">                mlflow.transformers.save_model(</span>
<span class="sd">                    transformers_model=en_to_de,</span>
<span class="sd">                    path=&quot;/path/to/save/model&quot;,</span>
<span class="sd">                    signature=signature,</span>
<span class="sd">                    input_example=data,</span>
<span class="sd">                )</span>

<span class="sd">                loaded = mlflow.pyfunc.load_model(&quot;/path/to/save/model&quot;)</span>
<span class="sd">                print(loaded.predict(data))</span>
<span class="sd">                # MLflow ist gro√üartig!</span>

<span class="sd">            If an input_example is provided and the signature is not, a signature will</span>
<span class="sd">            be inferred automatically and applied to the MLmodel file iff the</span>
<span class="sd">            pipeline type is a text-based model (NLP). If the pipeline type is not</span>
<span class="sd">            a supported type, this inference functionality will not function correctly</span>
<span class="sd">            and a warning will be issued. In order to ensure that a precise signature</span>
<span class="sd">            is logged, it is recommended to explicitly provide one.</span>
<span class="sd">        input_example: {{ input_example }}</span>
<span class="sd">        pip_requirements: {{ pip_requirements }}</span>
<span class="sd">        extra_pip_requirements: {{ extra_pip_requirements }}</span>
<span class="sd">        conda_env: {{ conda_env }}</span>
<span class="sd">        metadata: Custom metadata dictionary passed to the model and stored in the MLmodel file.</span>

<span class="sd">            .. Note:: Experimental: This parameter may change or be removed in a future</span>
<span class="sd">                                    release without warning.</span>
<span class="sd">        example_no_conversion: {{ example_no_conversion }}</span>
<span class="sd">        prompt_template: {{ prompt_template }}</span>
<span class="sd">        kwargs: Optional additional configurations for transformers serialization.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">transformers</span>

    <span class="n">_validate_transformers_model_dict</span><span class="p">(</span><span class="n">transformers_model</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">transformers_model</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">transformers_model</span> <span class="o">=</span> <span class="n">_TransformersModel</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="o">**</span><span class="n">transformers_model</span><span class="p">)</span>

    <span class="n">_validate_env_arguments</span><span class="p">(</span><span class="n">conda_env</span><span class="p">,</span> <span class="n">pip_requirements</span><span class="p">,</span> <span class="n">extra_pip_requirements</span><span class="p">)</span>

    <span class="n">path</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="o">.</span><span class="n">absolute</span><span class="p">()</span>

    <span class="n">_validate_and_prepare_target_save_path</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>

    <span class="n">code_dir_subpath</span> <span class="o">=</span> <span class="n">_validate_and_copy_code_paths</span><span class="p">(</span><span class="n">code_paths</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>

    <span class="n">resolved_task</span> <span class="o">=</span> <span class="n">_get_or_infer_task_type</span><span class="p">(</span><span class="n">transformers_model</span><span class="p">,</span> <span class="n">task</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">transformers_model</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">Pipeline</span><span class="p">):</span>
        <span class="n">built_pipeline</span> <span class="o">=</span> <span class="n">_build_pipeline_from_model_input</span><span class="p">(</span><span class="n">transformers_model</span><span class="p">,</span> <span class="n">resolved_task</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">built_pipeline</span> <span class="o">=</span> <span class="n">transformers_model</span>

    <span class="c1"># Verify that the model has not been loaded to distributed memory</span>
    <span class="c1"># NB: transformers does not correctly save a model whose weights have been loaded</span>
    <span class="c1"># using accelerate iff the model weights have been loaded using a device_map that is</span>
    <span class="c1"># heterogeneous. There is a distinct possibility for a partial write to occur, causing an</span>
    <span class="c1"># invalid state of the model&#39;s weights in this scenario. Hence, we raise.</span>
    <span class="k">if</span> <span class="n">_is_model_distributed_in_memory</span><span class="p">(</span><span class="n">built_pipeline</span><span class="o">.</span><span class="n">model</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="s2">&quot;The model that is attempting to be saved has been loaded into memory &quot;</span>
            <span class="s2">&quot;with an incompatible configuration. If you are using the accelerate &quot;</span>
            <span class="s2">&quot;library to load your model, please ensure that it is saved only after &quot;</span>
            <span class="s2">&quot;loading with the default device mapping. Do not specify `device_map` &quot;</span>
            <span class="s2">&quot;and please try again.&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">mlflow_model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mlflow_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">signature</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mlflow_model</span><span class="o">.</span><span class="n">signature</span> <span class="o">=</span> <span class="n">signature</span>
    <span class="k">if</span> <span class="n">input_example</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">input_example</span> <span class="o">=</span> <span class="n">_format_input_example_for_special_cases</span><span class="p">(</span><span class="n">input_example</span><span class="p">,</span> <span class="n">built_pipeline</span><span class="p">)</span>
        <span class="n">_save_example</span><span class="p">(</span><span class="n">mlflow_model</span><span class="p">,</span> <span class="n">input_example</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">path</span><span class="p">),</span> <span class="n">example_no_conversion</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">metadata</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mlflow_model</span><span class="o">.</span><span class="n">metadata</span> <span class="o">=</span> <span class="n">metadata</span>
    <span class="k">if</span> <span class="n">prompt_template</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># prevent saving prompt templates for unsupported pipeline types</span>
        <span class="k">if</span> <span class="n">built_pipeline</span><span class="o">.</span><span class="n">task</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_SUPPORTED_PROMPT_TEMPLATING_TASK_TYPES</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Prompt templating is not supported for the `</span><span class="si">{</span><span class="n">built_pipeline</span><span class="o">.</span><span class="n">task</span><span class="si">}</span><span class="s2">` task type. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Supported task types are: </span><span class="si">{</span><span class="n">_SUPPORTED_PROMPT_TEMPLATING_TASK_TYPES</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="n">_validate_prompt_template</span><span class="p">(</span><span class="n">prompt_template</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">mlflow_model</span><span class="o">.</span><span class="n">metadata</span><span class="p">:</span>
            <span class="n">mlflow_model</span><span class="o">.</span><span class="n">metadata</span><span class="p">[</span><span class="n">_PROMPT_TEMPLATE_KEY</span><span class="p">]</span> <span class="o">=</span> <span class="n">prompt_template</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mlflow_model</span><span class="o">.</span><span class="n">metadata</span> <span class="o">=</span> <span class="p">{</span><span class="n">_PROMPT_TEMPLATE_KEY</span><span class="p">:</span> <span class="n">prompt_template</span><span class="p">}</span>

    <span class="n">flavor_conf</span> <span class="o">=</span> <span class="n">_generate_base_flavor_configuration</span><span class="p">(</span><span class="n">built_pipeline</span><span class="p">,</span> <span class="n">resolved_task</span><span class="p">)</span>

    <span class="n">components</span> <span class="o">=</span> <span class="n">_record_pipeline_components</span><span class="p">(</span><span class="n">built_pipeline</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">components</span><span class="p">:</span>
        <span class="n">flavor_conf</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="o">**</span><span class="n">components</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">processor</span><span class="p">:</span>
        <span class="n">flavor_conf</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">_PROCESSOR_TYPE_KEY</span><span class="p">:</span> <span class="n">_get_instance_type</span><span class="p">(</span><span class="n">processor</span><span class="p">)})</span>

    <span class="c1"># Save the model object</span>
    <span class="n">built_pipeline</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span>
        <span class="n">save_directory</span><span class="o">=</span><span class="n">path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">_MODEL_BINARY_FILE_NAME</span><span class="p">),</span>
        <span class="n">max_shard_size</span><span class="o">=</span><span class="n">MLFLOW_HUGGINGFACE_MODEL_MAX_SHARD_SIZE</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">model_config</span> <span class="ow">and</span> <span class="n">inference_config</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="s2">&quot;Using both `model_config` and `inference_config` is not allowed. Use `model_config` &quot;</span>
            <span class="s2">&quot;to indicate any model configuration you need to use for inference.&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Save the components explicitly to the components directory</span>
    <span class="k">if</span> <span class="n">components</span><span class="p">:</span>
        <span class="n">_save_components</span><span class="p">(</span>
            <span class="n">root_path</span><span class="o">=</span><span class="n">path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">_COMPONENTS_BINARY_KEY</span><span class="p">),</span>
            <span class="n">component_config</span><span class="o">=</span><span class="n">components</span><span class="p">,</span>
            <span class="n">pipeline</span><span class="o">=</span><span class="n">built_pipeline</span><span class="p">,</span>
            <span class="n">processor</span><span class="o">=</span><span class="n">processor</span><span class="p">,</span>
            <span class="n">inference_config</span><span class="o">=</span><span class="n">inference_config</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># Get the model card from either the argument or the HuggingFace marketplace</span>
    <span class="n">card_data</span> <span class="o">=</span> <span class="n">model_card</span> <span class="k">if</span> <span class="n">model_card</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">_fetch_model_card</span><span class="p">(</span><span class="n">transformers_model</span><span class="p">)</span>

    <span class="c1"># If the card data can be acquired, save the text and the data separately</span>
    <span class="n">_write_card_data</span><span class="p">(</span><span class="n">card_data</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>

    <span class="n">model_bin_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="n">_MODEL_BINARY_KEY</span><span class="p">:</span> <span class="n">_MODEL_BINARY_FILE_NAME</span><span class="p">}</span>

    <span class="c1"># Only allow a subset of task types to have a pyfunc definition.</span>
    <span class="c1"># Currently supported types are NLP-based language tasks which have a pipeline definition</span>
    <span class="c1"># consisting exclusively of a Model and a Tokenizer.</span>
    <span class="k">if</span> <span class="n">_should_add_pyfunc_to_model</span><span class="p">(</span><span class="n">built_pipeline</span><span class="p">):</span>
        <span class="c1"># For pyfunc supported models, if a signature is not supplied, infer the signature</span>
        <span class="c1"># from the input_example if provided, otherwise, apply a generic signature.</span>
        <span class="k">if</span> <span class="n">mlflow_model</span><span class="o">.</span><span class="n">signature</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mlflow_model</span><span class="o">.</span><span class="n">signature</span> <span class="o">=</span> <span class="n">_get_default_pipeline_signature</span><span class="p">(</span>
                <span class="n">built_pipeline</span><span class="p">,</span> <span class="n">input_example</span><span class="p">,</span> <span class="n">model_config</span> <span class="ow">or</span> <span class="n">inference_config</span>
            <span class="p">)</span>

        <span class="c1"># if pipeline is text-generation and a prompt template is specified,</span>
        <span class="c1"># provide the return_full_text=False config by default to avoid confusing</span>
        <span class="c1"># extra text for end-users</span>
        <span class="k">if</span> <span class="n">prompt_template</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">built_pipeline</span><span class="o">.</span><span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;text-generation&quot;</span><span class="p">:</span>
            <span class="n">return_full_text_key</span> <span class="o">=</span> <span class="s2">&quot;return_full_text&quot;</span>
            <span class="n">model_config</span> <span class="o">=</span> <span class="n">model_config</span> <span class="ow">or</span> <span class="p">{}</span>
            <span class="k">if</span> <span class="n">return_full_text_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">model_config</span><span class="p">:</span>
                <span class="n">model_config</span><span class="p">[</span><span class="n">return_full_text_key</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">_logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">_PROMPT_TEMPLATE_RETURN_FULL_TEXT_INFO</span><span class="p">)</span>

        <span class="n">pyfunc</span><span class="o">.</span><span class="n">add_to_model</span><span class="p">(</span>
            <span class="n">mlflow_model</span><span class="p">,</span>
            <span class="n">loader_module</span><span class="o">=</span><span class="s2">&quot;mlflow.transformers&quot;</span><span class="p">,</span>
            <span class="n">conda_env</span><span class="o">=</span><span class="n">_CONDA_ENV_FILE_NAME</span><span class="p">,</span>
            <span class="n">python_env</span><span class="o">=</span><span class="n">_PYTHON_ENV_FILE_NAME</span><span class="p">,</span>
            <span class="n">code</span><span class="o">=</span><span class="n">code_dir_subpath</span><span class="p">,</span>
            <span class="n">model_config</span><span class="o">=</span><span class="n">model_config</span><span class="p">,</span>
            <span class="o">**</span><span class="n">model_bin_kwargs</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">processor</span><span class="p">:</span>
            <span class="n">reason</span> <span class="o">=</span> <span class="s2">&quot;the model has been saved with a &#39;processor&#39; argument supplied.&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">reason</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s2">&quot;the model is not a language-based model and requires a complex input type &quot;</span>
                <span class="s2">&quot;that is currently not supported.&quot;</span>
            <span class="p">)</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;This model is unable to be used for pyfunc prediction because </span><span class="si">{</span><span class="n">reason</span><span class="si">}</span><span class="s2"> &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;The pyfunc flavor will not be added to the Model.&quot;</span>
        <span class="p">)</span>
    <span class="n">flavor_conf</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="o">**</span><span class="n">model_bin_kwargs</span><span class="p">)</span>
    <span class="n">mlflow_model</span><span class="o">.</span><span class="n">add_flavor</span><span class="p">(</span>
        <span class="n">FLAVOR_NAME</span><span class="p">,</span>
        <span class="n">transformers_version</span><span class="o">=</span><span class="n">transformers</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
        <span class="n">code</span><span class="o">=</span><span class="n">code_dir_subpath</span><span class="p">,</span>
        <span class="o">**</span><span class="n">flavor_conf</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">size</span> <span class="o">:=</span> <span class="n">get_total_file_size</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
        <span class="n">mlflow_model</span><span class="o">.</span><span class="n">model_size_bytes</span> <span class="o">=</span> <span class="n">size</span>
    <span class="n">mlflow_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">MLMODEL_FILE_NAME</span><span class="p">)))</span>

    <span class="k">if</span> <span class="n">conda_env</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">pip_requirements</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">default_reqs</span> <span class="o">=</span> <span class="n">get_default_pip_requirements</span><span class="p">(</span><span class="n">transformers_model</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
            <span class="n">inferred_reqs</span> <span class="o">=</span> <span class="n">infer_pip_requirements</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">path</span><span class="p">),</span> <span class="n">FLAVOR_NAME</span><span class="p">,</span> <span class="n">fallback</span><span class="o">=</span><span class="n">default_reqs</span><span class="p">)</span>
            <span class="n">default_reqs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">inferred_reqs</span><span class="p">)</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">default_reqs</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">default_reqs</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conda_env</span><span class="p">,</span> <span class="n">pip_requirements</span><span class="p">,</span> <span class="n">pip_constraints</span> <span class="o">=</span> <span class="n">_process_pip_requirements</span><span class="p">(</span>
            <span class="n">default_reqs</span><span class="p">,</span> <span class="n">pip_requirements</span><span class="p">,</span> <span class="n">extra_pip_requirements</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">conda_env</span><span class="p">,</span> <span class="n">pip_requirements</span><span class="p">,</span> <span class="n">pip_constraints</span> <span class="o">=</span> <span class="n">_process_conda_env</span><span class="p">(</span><span class="n">conda_env</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">_CONDA_ENV_FILE_NAME</span><span class="p">)</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">yaml</span><span class="o">.</span><span class="n">safe_dump</span><span class="p">(</span><span class="n">conda_env</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">pip_constraints</span><span class="p">:</span>
        <span class="n">write_to</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">_CONSTRAINTS_FILE_NAME</span><span class="p">)),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pip_constraints</span><span class="p">))</span>

    <span class="n">write_to</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">_REQUIREMENTS_FILE_NAME</span><span class="p">)),</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pip_requirements</span><span class="p">))</span>

    <span class="n">_PythonEnv</span><span class="o">.</span><span class="n">current</span><span class="p">()</span><span class="o">.</span><span class="n">to_yaml</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">_PYTHON_ENV_FILE_NAME</span><span class="p">)))</span></div>


<div class="viewcode-block" id="log_model"><a class="viewcode-back" href="../../python_api/mlflow.transformers.html#mlflow.transformers.log_model">[docs]</a><span class="nd">@experimental</span>
<span class="nd">@docstring_version_compatibility_warning</span><span class="p">(</span><span class="n">integration_name</span><span class="o">=</span><span class="n">FLAVOR_NAME</span><span class="p">)</span>
<span class="nd">@format_docstring</span><span class="p">(</span><span class="n">LOG_MODEL_PARAM_DOCS</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">package_name</span><span class="o">=</span><span class="n">FLAVOR_NAME</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">log_model</span><span class="p">(</span>
    <span class="n">transformers_model</span><span class="p">,</span>
    <span class="n">artifact_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">processor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">task</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">model_card</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">inference_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">code_paths</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">registered_model_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">signature</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelSignature</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">input_example</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ModelInputExample</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">await_registration_for</span><span class="o">=</span><span class="n">DEFAULT_AWAIT_MAX_SLEEP_SECONDS</span><span class="p">,</span>
    <span class="n">pip_requirements</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">extra_pip_requirements</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">conda_env</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">metadata</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">model_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">example_no_conversion</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">prompt_template</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Log a ``transformers`` object as an MLflow artifact for the current run.</span>

<span class="sd">    Args:</span>
<span class="sd">        transformers_model:</span>
<span class="sd">            A trained transformers `Pipeline` or a dictionary that maps required components of a</span>
<span class="sd">            pipeline to the named keys of [&quot;model&quot;, &quot;image_processor&quot;, &quot;tokenizer&quot;,</span>
<span class="sd">            &quot;feature_extractor&quot;]. The `model` key in the dictionary must map to a value that</span>
<span class="sd">            inherits from `PreTrainedModel`, `TFPreTrainedModel`, or `FlaxPreTrainedModel`.</span>
<span class="sd">            All other component entries in the dictionary must support the defined task type that is</span>
<span class="sd">            associated with the base model type configuration.</span>

<span class="sd">            An example of supplying component-level parts of a transformers model is shown below:</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                from transformers import MobileBertForQuestionAnswering, AutoTokenizer</span>

<span class="sd">                architecture = &quot;csarron/mobilebert-uncased-squad-v2&quot;</span>
<span class="sd">                tokenizer = AutoTokenizer.from_pretrained(architecture)</span>
<span class="sd">                model = MobileBertForQuestionAnswering.from_pretrained(architecture)</span>

<span class="sd">                with mlflow.start_run():</span>
<span class="sd">                    components = {</span>
<span class="sd">                        &quot;model&quot;: model,</span>
<span class="sd">                        &quot;tokenizer&quot;: tokenizer,</span>
<span class="sd">                    }</span>
<span class="sd">                    mlflow.transformers.log_model(</span>
<span class="sd">                        transformers_model=components,</span>
<span class="sd">                        artifact_path=&quot;my_model&quot;,</span>
<span class="sd">                    )</span>

<span class="sd">            An example of submitting a `Pipeline` from a default pipeline instantiation:</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                from transformers import pipeline</span>

<span class="sd">                qa_pipe = pipeline(&quot;question-answering&quot;, &quot;csarron/mobilebert-uncased-squad-v2&quot;)</span>

<span class="sd">                with mlflow.start_run():</span>
<span class="sd">                    mlflow.transformers.log_model(</span>
<span class="sd">                        transformers_model=qa_pipe,</span>
<span class="sd">                        artifact_path=&quot;my_pipeline&quot;,</span>
<span class="sd">                    )</span>

<span class="sd">        artifact_path: Local path destination for the serialized model to be saved.</span>
<span class="sd">        processor: An optional ``Processor`` subclass object. Some model architectures,</span>
<span class="sd">            particularly multi-modal types, utilize Processors to combine text</span>
<span class="sd">            encoding and image or audio encoding in a single entrypoint.</span>

<span class="sd">                .. Note:: If a processor is supplied when logging a model, the</span>
<span class="sd">                    model will be unavailable for loading as a ``Pipeline`` or for usage</span>
<span class="sd">                    with pyfunc inference.</span>
<span class="sd">        task: The transformers-specific task type of the model. These strings are utilized so</span>
<span class="sd">            that a pipeline can be created with the appropriate internal call architecture</span>
<span class="sd">            to meet the needs of a given model. If this argument is not specified, the</span>
<span class="sd">            pipeline utilities within the transformers library will be used to infer the</span>
<span class="sd">            correct task type. If the value specified is not a supported type within the</span>
<span class="sd">            version of transformers that is currently installed, an Exception will be thrown.</span>
<span class="sd">        model_card: An Optional `ModelCard` instance from `huggingface-hub`. If provided, the</span>
<span class="sd">            contents of the model card will be saved along with the provided</span>
<span class="sd">            `transformers_model`. If not provided, an attempt will be made to fetch</span>
<span class="sd">            the card from the base pretrained model that is provided (or the one that is</span>
<span class="sd">            included within a provided `Pipeline`).</span>

<span class="sd">                .. Note:: In order for a ModelCard to be fetched (if not provided),</span>
<span class="sd">                    the huggingface_hub package must be installed and the version</span>
<span class="sd">                    must be &gt;=0.10.0</span>
<span class="sd">        inference_config:</span>

<span class="sd">            .. Warning:: Deprecated. `inference_config` is deprecated in favor of `model_config`.</span>
<span class="sd">        model_config:</span>
<span class="sd">            A dict of valid overrides that can be applied to a pipeline instance during inference.</span>
<span class="sd">            These arguments are used exclusively for the case of loading the model as a ``pyfunc``</span>
<span class="sd">            Model or for use in Spark. These values are not applied to a returned Pipeline from a</span>
<span class="sd">            call to ``mlflow.transformers.load_model()``</span>

<span class="sd">            .. Warning:: If the key provided is not compatible with either the</span>
<span class="sd">                         Pipeline instance for the task provided or is not a valid</span>
<span class="sd">                         override to any arguments available in the Model, an</span>
<span class="sd">                         Exception will be raised at runtime. It is very important</span>
<span class="sd">                         to validate the entries in this dictionary to ensure</span>
<span class="sd">                         that they are valid prior to saving or logging.</span>

<span class="sd">            An example of providing overrides for a question generation model:</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                from transformers import pipeline, AutoTokenizer</span>

<span class="sd">                task = &quot;text-generation&quot;</span>
<span class="sd">                architecture = &quot;gpt2&quot;</span>

<span class="sd">                sentence_pipeline = pipeline(</span>
<span class="sd">                    task=task,</span>
<span class="sd">                    tokenizer=AutoTokenizer.from_pretrained(architecture),</span>
<span class="sd">                    model=architecture,  # pylint: disable=line-too-long</span>
<span class="sd">                )</span>

<span class="sd">                # Validate that the overrides function</span>
<span class="sd">                prompts = [&quot;Generative models are&quot;, &quot;I&#39;d like a coconut so that I can&quot;]</span>

<span class="sd">                # validation of config prior to save or log</span>
<span class="sd">                model_config = {</span>
<span class="sd">                    &quot;top_k&quot;: 2,</span>
<span class="sd">                    &quot;num_beams&quot;: 5,</span>
<span class="sd">                    &quot;max_length&quot;: 30,</span>
<span class="sd">                    &quot;temperature&quot;: 0.62,</span>
<span class="sd">                    &quot;top_p&quot;: 0.85,</span>
<span class="sd">                    &quot;repetition_penalty&quot;: 1.15,</span>
<span class="sd">                }</span>

<span class="sd">                # Verify that no exceptions are thrown</span>
<span class="sd">                sentence_pipeline(prompts, **model_config)</span>

<span class="sd">                with mlflow.start_run():</span>
<span class="sd">                    mlflow.transformers.log_model(</span>
<span class="sd">                        transformers_model=sentence_pipeline,</span>
<span class="sd">                        artifact_path=&quot;my_sentence_generator&quot;,</span>
<span class="sd">                        task=task,</span>
<span class="sd">                        model_config=model_config,</span>
<span class="sd">                    )</span>

<span class="sd">        code_paths: A list of local filesystem paths to Python file dependencies (or directories</span>
<span class="sd">            containing file dependencies). These files are *prepended* to the system</span>
<span class="sd">            path when the model is loaded.</span>
<span class="sd">        registered_model_name: This argument may change or be removed in a</span>
<span class="sd">            future release without warning. If given, create a model</span>
<span class="sd">            version under ``registered_model_name``, also creating a</span>
<span class="sd">            registered model if one with the given name does not exist.</span>
<span class="sd">        signature: A Model Signature object that describes the input and output Schema of the</span>
<span class="sd">            model. The model signature can be inferred using `infer_signature` function</span>
<span class="sd">            of `mlflow.models.signature`.</span>
<span class="sd">            Example:</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                from mlflow.models import infer_signature</span>
<span class="sd">                from mlflow.transformers import generate_signature_output</span>
<span class="sd">                from transformers import pipeline</span>

<span class="sd">                en_to_de = pipeline(&quot;translation_en_to_de&quot;)</span>

<span class="sd">                data = &quot;MLflow is great!&quot;</span>
<span class="sd">                output = generate_signature_output(en_to_de, data)</span>
<span class="sd">                signature = infer_signature(data, output)</span>

<span class="sd">                with mlflow.start_run() as run:</span>
<span class="sd">                    mlflow.transformers.log_model(</span>
<span class="sd">                        transformers_model=en_to_de,</span>
<span class="sd">                        artifact_path=&quot;english_to_german_translator&quot;,</span>
<span class="sd">                        signature=signature,</span>
<span class="sd">                        input_example=data,</span>
<span class="sd">                    )</span>

<span class="sd">                model_uri = f&quot;runs:/{run.info.run_id}/english_to_german_translator&quot;</span>
<span class="sd">                loaded = mlflow.pyfunc.load_model(model_uri)</span>

<span class="sd">                print(loaded.predict(data))</span>
<span class="sd">                # MLflow ist gro√üartig!</span>

<span class="sd">            If an input_example is provided and the signature is not, a signature will</span>
<span class="sd">            be inferred automatically and applied to the MLmodel file iff the</span>
<span class="sd">            pipeline type is a text-based model (NLP). If the pipeline type is not</span>
<span class="sd">            a supported type, this inference functionality will not function correctly</span>
<span class="sd">            and a warning will be issued. In order to ensure that a precise signature</span>
<span class="sd">            is logged, it is recommended to explicitly provide one.</span>
<span class="sd">        input_example: {{ input_example }}</span>
<span class="sd">        await_registration_for: Number of seconds to wait for the model version</span>
<span class="sd">            to finish being created and is in ``READY`` status.</span>
<span class="sd">            By default, the function waits for five minutes.</span>
<span class="sd">            Specify 0 or None to skip waiting.</span>
<span class="sd">        pip_requirements: {{ pip_requirements }}</span>
<span class="sd">        extra_pip_requirements: {{ extra_pip_requirements }}</span>
<span class="sd">        conda_env: {{ conda_env }}</span>
<span class="sd">        metadata: Custom metadata dictionary passed to the model and stored in the MLmodel file.</span>

<span class="sd">            .. Note:: Experimental: This parameter may change or be removed in a future</span>
<span class="sd">                                    release without warning.</span>
<span class="sd">        example_no_conversion: {{ example_no_conversion }}</span>
<span class="sd">        prompt_template: {{ prompt_template }}</span>
<span class="sd">        kwargs: Additional arguments for :py:class:`mlflow.models.model.Model`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Model</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="n">artifact_path</span><span class="p">,</span>
        <span class="n">flavor</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="p">[</span><span class="vm">__name__</span><span class="p">],</span>  <span class="c1"># Get the current module.</span>
        <span class="n">registered_model_name</span><span class="o">=</span><span class="n">registered_model_name</span><span class="p">,</span>
        <span class="n">await_registration_for</span><span class="o">=</span><span class="n">await_registration_for</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="n">metadata</span><span class="p">,</span>
        <span class="n">transformers_model</span><span class="o">=</span><span class="n">transformers_model</span><span class="p">,</span>
        <span class="n">processor</span><span class="o">=</span><span class="n">processor</span><span class="p">,</span>
        <span class="n">task</span><span class="o">=</span><span class="n">task</span><span class="p">,</span>
        <span class="n">model_card</span><span class="o">=</span><span class="n">model_card</span><span class="p">,</span>
        <span class="n">inference_config</span><span class="o">=</span><span class="n">inference_config</span><span class="p">,</span>
        <span class="n">conda_env</span><span class="o">=</span><span class="n">conda_env</span><span class="p">,</span>
        <span class="n">code_paths</span><span class="o">=</span><span class="n">code_paths</span><span class="p">,</span>
        <span class="n">signature</span><span class="o">=</span><span class="n">signature</span><span class="p">,</span>
        <span class="n">input_example</span><span class="o">=</span><span class="n">input_example</span><span class="p">,</span>
        <span class="n">pip_requirements</span><span class="o">=</span><span class="n">pip_requirements</span><span class="p">,</span>
        <span class="n">extra_pip_requirements</span><span class="o">=</span><span class="n">extra_pip_requirements</span><span class="p">,</span>
        <span class="n">model_config</span><span class="o">=</span><span class="n">model_config</span><span class="p">,</span>
        <span class="n">example_no_conversion</span><span class="o">=</span><span class="n">example_no_conversion</span><span class="p">,</span>
        <span class="n">prompt_template</span><span class="o">=</span><span class="n">prompt_template</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="load_model"><a class="viewcode-back" href="../../python_api/mlflow.transformers.html#mlflow.transformers.load_model">[docs]</a><span class="nd">@experimental</span>
<span class="nd">@docstring_version_compatibility_warning</span><span class="p">(</span><span class="n">integration_name</span><span class="o">=</span><span class="n">FLAVOR_NAME</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span>
    <span class="n">model_uri</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">dst_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;pipeline&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load a ``transformers`` object from a local file or a run.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_uri: The location, in URI format, of the MLflow model. For example:</span>

<span class="sd">            - ``/Users/me/path/to/local/model``</span>
<span class="sd">            - ``relative/path/to/local/model``</span>
<span class="sd">            - ``s3://my_bucket/path/to/model``</span>
<span class="sd">            - ``runs:/&lt;mlflow_run_id&gt;/run-relative/path/to/model``</span>
<span class="sd">            - ``mlflow-artifacts:/path/to/model``</span>

<span class="sd">            For more information about supported URI schemes, see</span>
<span class="sd">            `Referencing Artifacts &lt;https://www.mlflow.org/docs/latest/tracking.html#</span>
<span class="sd">            artifact-locations&gt;`_.</span>
<span class="sd">        dst_path: The local filesystem path to utilize for downloading the model artifact.</span>
<span class="sd">            This directory must already exist if provided. If unspecified, a local output</span>
<span class="sd">            path will be created.</span>
<span class="sd">        return_type: A return type modifier for the stored ``transformers`` object.</span>
<span class="sd">            If set as &quot;components&quot;, the return type will be a dictionary of the saved</span>
<span class="sd">            individual components of either the ``Pipeline`` or the pre-trained model.</span>
<span class="sd">            The components for NLP-focused models will typically consist of a</span>
<span class="sd">            return representation as shown below with a text-classification example:</span>

<span class="sd">            .. code-block:: python</span>

<span class="sd">                {&quot;model&quot;: BertForSequenceClassification, &quot;tokenizer&quot;: BertTokenizerFast}</span>

<span class="sd">            Vision models will return an ``ImageProcessor`` instance of the appropriate</span>
<span class="sd">            type, while multi-modal models will return both a ``FeatureExtractor`` and</span>
<span class="sd">            a ``Tokenizer`` along with the model.</span>
<span class="sd">            Returning &quot;components&quot; can be useful for certain model types that do not</span>
<span class="sd">            have the desired pipeline return types for certain use cases.</span>
<span class="sd">            If set as &quot;pipeline&quot;, the model, along with any and all required</span>
<span class="sd">            ``Tokenizer``, ``FeatureExtractor``, ``Processor``, or ``ImageProcessor``</span>
<span class="sd">            objects will be returned within a ``Pipeline`` object of the appropriate</span>
<span class="sd">            type defined by the ``task`` set by the model instance type. To override</span>
<span class="sd">            this behavior, supply a valid ``task`` argument during model logging or</span>
<span class="sd">            saving. Default is &quot;pipeline&quot;.</span>
<span class="sd">        device: The device on which to load the model. Default is None. Use 0 to</span>
<span class="sd">            load to the default GPU.</span>
<span class="sd">        kwargs: Optional configuration options for loading of a ``transformers`` object.</span>
<span class="sd">            For information on parameters and their usage, see</span>
<span class="sd">            `transformers documentation &lt;https://huggingface.co/docs/transformers/index&gt;`_.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A ``transformers`` model instance or a dictionary of components</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">return_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_SUPPORTED_RETURN_TYPES</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;The specified return_type mode &#39;</span><span class="si">{</span><span class="n">return_type</span><span class="si">}</span><span class="s2">&#39; is unsupported. &quot;</span>
            <span class="s2">&quot;Please select one of: &#39;pipeline&#39; or &#39;components&#39;.&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">model_uri</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">model_uri</span><span class="p">)</span>

    <span class="n">local_model_path</span> <span class="o">=</span> <span class="n">_download_artifact_from_uri</span><span class="p">(</span><span class="n">artifact_uri</span><span class="o">=</span><span class="n">model_uri</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="n">dst_path</span><span class="p">)</span>

    <span class="n">flavor_config</span> <span class="o">=</span> <span class="n">_get_flavor_configuration_from_uri</span><span class="p">(</span><span class="n">model_uri</span><span class="p">,</span> <span class="n">FLAVOR_NAME</span><span class="p">,</span> <span class="n">_logger</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">return_type</span> <span class="o">==</span> <span class="s2">&quot;pipeline&quot;</span> <span class="ow">and</span> <span class="n">_PROCESSOR_TYPE_KEY</span> <span class="ow">in</span> <span class="n">flavor_config</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="s2">&quot;This model has been saved with a processor. Processor objects are &quot;</span>
            <span class="s2">&quot;not compatible with Pipelines. Please load this model by specifying &quot;</span>
            <span class="s2">&quot;the &#39;return_type&#39;=&#39;components&#39;.&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">BAD_REQUEST</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">_add_code_from_conf_to_system_path</span><span class="p">(</span><span class="n">local_model_path</span><span class="p">,</span> <span class="n">flavor_config</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">_load_model</span><span class="p">(</span><span class="n">local_model_path</span><span class="p">,</span> <span class="n">flavor_config</span><span class="p">,</span> <span class="n">return_type</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_is_model_distributed_in_memory</span><span class="p">(</span><span class="n">transformers_model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check if the model is distributed across multiple devices in memory.&quot;&quot;&quot;</span>

    <span class="c1"># Check if the model attribute exists. If not, accelerate was not used and the model can</span>
    <span class="c1"># be safely saved</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">transformers_model</span><span class="p">,</span> <span class="s2">&quot;hf_device_map&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="c1"># If the device map has more than one unique value entry, then the weights are not within</span>
    <span class="c1"># a contiguous memory system (VRAM, SYS, or DISK) and thus cannot be safely saved.</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">transformers_model</span><span class="o">.</span><span class="n">hf_device_map</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span> <span class="o">&gt;</span> <span class="mi">1</span>


<span class="c1"># This function attempts to determine if a GPU is available for the PyTorch and TensorFlow libraries</span>
<div class="viewcode-block" id="is_gpu_available"><a class="viewcode-back" href="../../python_api/mlflow.transformers.html#mlflow.transformers.is_gpu_available">[docs]</a><span class="k">def</span> <span class="nf">is_gpu_available</span><span class="p">():</span>
    <span class="c1"># try pytorch and if it fails, try tf</span>
    <span class="n">is_gpu</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span> <span class="nn">torch</span>

        <span class="n">is_gpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">pass</span>
    <span class="k">if</span> <span class="n">is_gpu</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

            <span class="n">is_gpu</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">is_gpu_available</span><span class="p">()</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="k">pass</span>
    <span class="k">if</span> <span class="n">is_gpu</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">is_gpu</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="n">is_gpu</span></div>


<span class="k">def</span> <span class="nf">_try_load_model_with_device</span><span class="p">(</span><span class="n">model_instance</span><span class="p">,</span> <span class="n">model_path</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">conf</span><span class="p">):</span>
    <span class="n">load_model_conf</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="c1"># Assume if torch_dtype was specified in the conf, then it must be with a</span>
    <span class="c1"># pipeline for which it&#39;s compatible.</span>
    <span class="k">if</span> <span class="n">_TORCH_DTYPE_KEY</span> <span class="ow">in</span> <span class="n">conf</span><span class="p">:</span>
        <span class="n">load_model_conf</span><span class="p">[</span><span class="n">_TORCH_DTYPE_KEY</span><span class="p">]</span> <span class="o">=</span> <span class="n">conf</span><span class="p">[</span><span class="n">_TORCH_DTYPE_KEY</span><span class="p">]</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">load_model_conf</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">device</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">model_instance</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="o">**</span><span class="n">load_model_conf</span><span class="p">)</span>
    <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">,</span> <span class="ne">NotImplementedError</span><span class="p">):</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Could not specify device parameter for this pipeline type&quot;</span><span class="p">)</span>
        <span class="n">load_model_conf</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;device&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">model_instance</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="o">**</span><span class="n">load_model_conf</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>


<span class="k">def</span> <span class="nf">_load_model</span><span class="p">(</span><span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">flavor_config</span><span class="p">,</span> <span class="n">return_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loads components from a locally serialized ``Pipeline`` object.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">transformers</span>

    <span class="n">model_instance</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">transformers</span><span class="p">,</span> <span class="n">flavor_config</span><span class="p">[</span><span class="n">_PIPELINE_MODEL_TYPE_KEY</span><span class="p">])</span>
    <span class="n">local_path</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="c1"># NB: Path resolution for models that were saved prior to 2.4.1 release when the pathing for</span>
    <span class="c1">#     the saved pipeline or component artifacts was handled by duplicate entries for components</span>
    <span class="c1">#     (artifacts/pipeline/* and artifacts/components/*) and pipelines were saved via the</span>
    <span class="c1">#     &quot;artifacts/pipeline/*&quot; path. In order to load the older formats after the change, the</span>
    <span class="c1">#     presence of the new path key is checked.</span>
    <span class="n">model_path</span> <span class="o">=</span> <span class="n">local_path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">flavor_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">_MODEL_BINARY_KEY</span><span class="p">,</span> <span class="s2">&quot;pipeline&quot;</span><span class="p">))</span>

    <span class="n">conf</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="n">flavor_config</span><span class="p">[</span><span class="n">_TASK_KEY</span><span class="p">],</span>
    <span class="p">}</span>

    <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">MLFLOW_DEFAULT_PREDICTION_DEVICE</span><span class="o">.</span><span class="n">get</span><span class="p">():</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">device</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">MLFLOW_DEFAULT_PREDICTION_DEVICE</span><span class="o">.</span><span class="n">get</span><span class="p">())</span>
            <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
                <span class="n">device</span> <span class="o">=</span> <span class="n">_TRANSFORMERS_DEFAULT_CPU_DEVICE_ID</span>
        <span class="k">elif</span> <span class="n">is_gpu_available</span><span class="p">():</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">_TRANSFORMERS_DEFAULT_GPU_DEVICE_ID</span>
    <span class="c1"># Note that we don&#39;t set the device in the conf yet because device is</span>
    <span class="c1"># incompatible with device_map.</span>
    <span class="n">accelerate_model_conf</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">MLFLOW_HUGGINGFACE_USE_DEVICE_MAP</span><span class="o">.</span><span class="n">get</span><span class="p">():</span>
        <span class="n">device_map_strategy</span> <span class="o">=</span> <span class="n">MLFLOW_HUGGINGFACE_DEVICE_MAP_STRATEGY</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
        <span class="n">conf</span><span class="p">[</span><span class="s2">&quot;device_map&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">device_map_strategy</span>
        <span class="n">accelerate_model_conf</span><span class="p">[</span><span class="s2">&quot;device_map&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">device_map_strategy</span>
        <span class="c1"># Cannot use device with device_map</span>
        <span class="n">device</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">conf</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">device</span>
        <span class="n">accelerate_model_conf</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">device</span>

    <span class="k">if</span> <span class="n">_TORCH_DTYPE_KEY</span> <span class="ow">in</span> <span class="n">flavor_config</span> <span class="ow">or</span> <span class="n">_TORCH_DTYPE_KEY</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">_TORCH_DTYPE_KEY</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">dtype_val</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">_TORCH_DTYPE_KEY</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dtype_val</span> <span class="o">=</span> <span class="n">_deserialize_torch_dtype_if_exists</span><span class="p">(</span><span class="n">flavor_config</span><span class="p">)</span>
        <span class="n">conf</span><span class="p">[</span><span class="n">_TORCH_DTYPE_KEY</span><span class="p">]</span> <span class="o">=</span> <span class="n">dtype_val</span>
        <span class="n">accelerate_model_conf</span><span class="p">[</span><span class="n">_TORCH_DTYPE_KEY</span><span class="p">]</span> <span class="o">=</span> <span class="n">dtype_val</span>

    <span class="n">accelerate_model_conf</span><span class="p">[</span><span class="s2">&quot;low_cpu_mem_usage&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">MLFLOW_HUGGINGFACE_USE_LOW_CPU_MEM_USAGE</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">MLFLOW_HUGGINGFACE_DISABLE_ACCELERATE_FEATURES</span><span class="o">.</span><span class="n">get</span><span class="p">():</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">model_instance</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="o">**</span><span class="n">accelerate_model_conf</span><span class="p">)</span>
        <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">,</span> <span class="ne">NotImplementedError</span><span class="p">,</span> <span class="ne">ImportError</span><span class="p">):</span>
            <span class="c1"># NB: ImportError is caught here in the event that `accelerate` is not installed</span>
            <span class="c1"># on the system, which will raise if `low_cpu_mem_usage` is set or the argument</span>
            <span class="c1"># `device_map` is set and accelerate is not installed.</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">_try_load_model_with_device</span><span class="p">(</span><span class="n">model_instance</span><span class="p">,</span> <span class="n">model_path</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">conf</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">_try_load_model_with_device</span><span class="p">(</span><span class="n">model_instance</span><span class="p">,</span> <span class="n">model_path</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">conf</span><span class="p">)</span>

    <span class="n">conf</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span>

    <span class="k">if</span> <span class="n">_PROCESSOR_TYPE_KEY</span> <span class="ow">in</span> <span class="n">flavor_config</span><span class="p">:</span>
        <span class="n">conf</span><span class="p">[</span><span class="n">_PROCESSOR_KEY</span><span class="p">]</span> <span class="o">=</span> <span class="n">_load_component</span><span class="p">(</span>
            <span class="n">local_path</span><span class="p">,</span> <span class="n">_PROCESSOR_KEY</span><span class="p">,</span> <span class="n">flavor_config</span><span class="p">[</span><span class="n">_PROCESSOR_TYPE_KEY</span><span class="p">]</span>
        <span class="p">)</span>

    <span class="k">for</span> <span class="n">component_key</span> <span class="ow">in</span> <span class="n">flavor_config</span><span class="p">[</span><span class="n">_COMPONENTS_BINARY_KEY</span><span class="p">]:</span>
        <span class="n">component_type_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">component_key</span><span class="si">}</span><span class="s2">_type&quot;</span>
        <span class="n">component_type</span> <span class="o">=</span> <span class="n">flavor_config</span><span class="p">[</span><span class="n">component_type_key</span><span class="p">]</span>
        <span class="n">conf</span><span class="p">[</span><span class="n">component_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">_load_component</span><span class="p">(</span><span class="n">local_path</span><span class="p">,</span> <span class="n">component_key</span><span class="p">,</span> <span class="n">component_type</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">_METADATA_PIPELINE_SCALAR_CONFIG_KEYS</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">flavor_config</span><span class="p">:</span>
            <span class="n">conf</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">flavor_config</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">return_type</span> <span class="o">==</span> <span class="s2">&quot;pipeline&quot;</span><span class="p">:</span>
        <span class="n">conf</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">transformers</span><span class="o">.</span><span class="n">pipeline</span><span class="p">(</span><span class="o">**</span><span class="n">conf</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">return_type</span> <span class="o">==</span> <span class="s2">&quot;components&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">conf</span>


<span class="nd">@lru_cache</span>
<span class="k">def</span> <span class="nf">_torch_dype_mapping</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Memoized torch data type mapping from the torch primary datatypes for use in deserializing the</span>
<span class="sd">    saved pipeline parameter `torch_dtype`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span> <span class="nn">torch</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="nb">str</span><span class="p">(</span><span class="n">dtype</span><span class="p">):</span> <span class="n">dtype</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">dtype</span> <span class="ow">in</span> <span class="n">torch</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dtype</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="s2">&quot;Unable to determine if the value supplied by the argument &quot;</span>
            <span class="s2">&quot;torch_dtype is valid since torch is not installed.&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
        <span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>


<span class="k">def</span> <span class="nf">_deserialize_torch_dtype_if_exists</span><span class="p">(</span><span class="n">flavor_config</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert the string-encoded `torch_dtype` pipeline argument back to the correct `torch.dtype`</span>
<span class="sd">    instance value for applying to a loaded pipeline instance.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">_torch_dype_mapping</span><span class="p">()[</span><span class="n">flavor_config</span><span class="p">[</span><span class="s2">&quot;torch_dtype&quot;</span><span class="p">]]</span>


<span class="k">def</span> <span class="nf">_fetch_model_card</span><span class="p">(</span><span class="n">model_or_pipeline</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Attempts to retrieve the model card for the specified model architecture iff the</span>
<span class="sd">    `huggingface_hub` library is installed. If a card cannot be found in the registry or</span>
<span class="sd">    the library is not installed, returns None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span> <span class="nn">huggingface_hub</span> <span class="k">as</span> <span class="nn">hub</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;Unable to store ModelCard data with the saved artifact. In order to &quot;</span>
            <span class="s2">&quot;preserve this information, please install the huggingface_hub package &quot;</span>
            <span class="s2">&quot;by running &#39;pip install huggingingface_hub&gt;0.10.0&#39;&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">model_or_pipeline</span><span class="o">.</span><span class="n">model</span>

    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">hub</span><span class="p">,</span> <span class="s2">&quot;ModelCard&quot;</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">hub</span><span class="o">.</span><span class="n">ModelCard</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The model card could not be retrieved from the hub due to </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;The version of huggingface_hub that is installed does not provide &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;ModelCard functionality. You have version </span><span class="si">{</span><span class="n">hub</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2"> installed. &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Update huggingface_hub to &gt;= &#39;0.10.0&#39; to retrieve the ModelCard data.&quot;</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">_write_card_data</span><span class="p">(</span><span class="n">card_data</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Writes the card data, if specified or available, to the provided path in two separate files</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">card_data</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">_CARD_TEXT_FILE_NAME</span><span class="p">)</span><span class="o">.</span><span class="n">write_text</span><span class="p">(</span><span class="n">card_data</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">UnicodeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unable to save the model card text due to: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">_CARD_DATA_FILE_NAME</span><span class="p">)</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
            <span class="n">yaml</span><span class="o">.</span><span class="n">safe_dump</span><span class="p">(</span>
                <span class="n">card_data</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(),</span> <span class="n">stream</span><span class="o">=</span><span class="n">file</span><span class="p">,</span> <span class="n">default_flow_style</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span>
            <span class="p">)</span>


<span class="k">def</span> <span class="nf">_build_pipeline_from_model_input</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">task</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Utility for generating a pipeline from component parts. If required components are not</span>
<span class="sd">    specified, use the transformers library pipeline component validation to force raising an</span>
<span class="sd">    exception. The underlying Exception thrown in transformers is verbose enough for diagnosis.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>

    <span class="n">pipeline_config</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
    <span class="n">pipeline_config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="n">task</span><span class="p">})</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">pipeline</span><span class="p">(</span><span class="o">**</span><span class="n">pipeline_config</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="s2">&quot;The provided model configuration cannot be created as a Pipeline. &quot;</span>
            <span class="s2">&quot;Please verify that all required and compatible components are &quot;</span>
            <span class="s2">&quot;specified with the correct keys.&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
        <span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>


<span class="k">def</span> <span class="nf">_record_pipeline_components</span><span class="p">(</span><span class="n">pipeline</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Utility for recording which components are present in either the generated pipeline iff the</span>
<span class="sd">    supplied save object is not a pipeline or the components of the supplied pipeline object.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">components_conf</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">components</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">attr</span><span class="p">,</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;feature_extractor&quot;</span><span class="p">,</span> <span class="n">_FEATURE_EXTRACTOR_TYPE_KEY</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;tokenizer&quot;</span><span class="p">,</span> <span class="n">_TOKENIZER_TYPE_KEY</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;image_processor&quot;</span><span class="p">,</span> <span class="n">_IMAGE_PROCESSOR_TYPE_KEY</span><span class="p">),</span>
    <span class="p">]:</span>
        <span class="n">component</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">component</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">components_conf</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">key</span><span class="p">:</span> <span class="n">_get_instance_type</span><span class="p">(</span><span class="n">component</span><span class="p">)})</span>
            <span class="n">components</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">components</span><span class="p">:</span>
        <span class="n">components_conf</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">_COMPONENTS_BINARY_KEY</span><span class="p">:</span> <span class="n">components</span><span class="p">})</span>
    <span class="k">return</span> <span class="n">components_conf</span>


<span class="k">def</span> <span class="nf">_save_components</span><span class="p">(</span>
    <span class="n">root_path</span><span class="p">:</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">,</span>
    <span class="n">component_config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
    <span class="n">pipeline</span><span class="p">,</span>
    <span class="n">processor</span><span class="p">,</span>
    <span class="n">inference_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Saves non-model pipeline components.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">component_types</span> <span class="o">=</span> <span class="n">component_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">_COMPONENTS_BINARY_KEY</span><span class="p">,</span> <span class="p">[])</span>
    <span class="k">for</span> <span class="n">component_name</span> <span class="ow">in</span> <span class="n">component_types</span><span class="p">:</span>
        <span class="n">component</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">component_name</span><span class="p">)</span>
        <span class="n">component</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">root_path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">component_name</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">processor</span><span class="p">:</span>
        <span class="n">processor</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="n">root_path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">_PROCESSOR_KEY</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">inference_config</span><span class="p">:</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;Indicating `inference_config` is deprecated and will be removed in a future version &quot;</span>
            <span class="s2">&quot;of MLflow. Use `model_config` instead.&quot;</span>
        <span class="p">)</span>
        <span class="n">root_path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">_INFERENCE_CONFIG_BINARY_KEY</span><span class="p">)</span><span class="o">.</span><span class="n">write_text</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">inference_config</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_load_component</span><span class="p">(</span><span class="n">root_path</span><span class="p">:</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">,</span> <span class="n">component_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">component_type</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loads an individual component object from local disk.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">transformers</span>

    <span class="n">components_dir</span> <span class="o">=</span> <span class="n">root_path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">_COMPONENTS_BINARY_KEY</span><span class="p">)</span>
    <span class="n">component_path</span> <span class="o">=</span> <span class="n">components_dir</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">component_key</span><span class="p">)</span>
    <span class="n">component_instance</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">transformers</span><span class="p">,</span> <span class="n">component_type</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">component_instance</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">component_path</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_generate_base_flavor_configuration</span><span class="p">(</span>
    <span class="n">pipeline</span><span class="p">,</span>
    <span class="n">task</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generates the base flavor metadata needed for reconstructing a pipeline from saved</span>
<span class="sd">    components. This is important because the ``Pipeline`` class does not have a loader</span>
<span class="sd">    functionality. The serialization of a Pipeline saves the model, configurations, and</span>
<span class="sd">    metadata for ``FeatureExtractor``s, ``Processor``s, and ``Tokenizer``s exclusively.</span>
<span class="sd">    This function extracts key information from the submitted model object so that the precise</span>
<span class="sd">    instance types can be loaded correctly.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_validate_transformers_task_type</span><span class="p">(</span><span class="n">task</span><span class="p">)</span>

    <span class="n">flavor_configuration</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">_TASK_KEY</span><span class="p">:</span> <span class="n">task</span><span class="p">,</span>
        <span class="n">_INSTANCE_TYPE_KEY</span><span class="p">:</span> <span class="n">_get_instance_type</span><span class="p">(</span><span class="n">pipeline</span><span class="p">),</span>
        <span class="n">_MODEL_PATH_OR_NAME_KEY</span><span class="p">:</span> <span class="n">_get_base_model_architecture</span><span class="p">(</span><span class="n">pipeline</span><span class="p">),</span>
        <span class="n">_PIPELINE_MODEL_TYPE_KEY</span><span class="p">:</span> <span class="n">_get_instance_type</span><span class="p">(</span><span class="n">pipeline</span><span class="o">.</span><span class="n">model</span><span class="p">),</span>
    <span class="p">}</span>

    <span class="c1"># Extract and add to the configuration the scalar serializable arguments for pipeline args</span>
    <span class="k">for</span> <span class="n">arg_key</span> <span class="ow">in</span> <span class="n">_METADATA_PIPELINE_SCALAR_CONFIG_KEYS</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">entry</span> <span class="o">:=</span> <span class="n">_get_scalar_argument_from_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">arg_key</span><span class="p">):</span>
            <span class="n">flavor_configuration</span><span class="p">[</span><span class="n">arg_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">entry</span>

    <span class="c1"># Extract a serialized representation of torch_dtype if provided</span>
    <span class="k">if</span> <span class="n">torch_dtype</span> <span class="o">:=</span> <span class="n">_extract_torch_dtype_if_set</span><span class="p">(</span><span class="n">pipeline</span><span class="p">):</span>
        <span class="n">flavor_configuration</span><span class="p">[</span><span class="n">_TORCH_DTYPE_KEY</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch_dtype</span>

    <span class="k">return</span> <span class="n">flavor_configuration</span>


<span class="k">def</span> <span class="nf">_get_scalar_argument_from_pipeline</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">arg_key</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Retrieve provided pipeline arguments for the purposes of instantiating a pipeline object upon</span>
<span class="sd">    loading.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">arg_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_extract_torch_dtype_if_set</span><span class="p">(</span><span class="n">pipeline</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extract the torch datatype argument if set and return as a string encoded value.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">torch_dtype</span> <span class="o">:=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">_TORCH_DTYPE_KEY</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">torch_dtype</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_get_or_infer_task_type</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">task</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Validates that a supplied task type is supported by the ``transformers`` library if supplied,</span>
<span class="sd">    else, if not supplied, infers the appropriate task type based on the model type.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">task</span><span class="p">:</span>
        <span class="n">_validate_transformers_task_type</span><span class="p">(</span><span class="n">task</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">task</span> <span class="o">=</span> <span class="n">_infer_transformers_task_type</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">task</span>


<span class="k">def</span> <span class="nf">_infer_transformers_task_type</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs inference of the task type, used in generating a pipeline object based on the</span>
<span class="sd">    underlying model&#39;s intended use case. This utility relies on the definitions within the</span>
<span class="sd">    transformers pipeline construction utility functions.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: Either the model or the Pipeline object that the task will be extracted or</span>
<span class="sd">            inferred from</span>

<span class="sd">    Returns:</span>
<span class="sd">        The task type string</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Pipeline</span>
    <span class="kn">from</span> <span class="nn">transformers.pipelines</span> <span class="kn">import</span> <span class="n">get_task</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">task</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">_TransformersModel</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">get_task</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="s2">&quot;The task type cannot be inferred from the submitted Pipeline or dictionary of &quot;</span>
                <span class="s2">&quot;model components. Please provide the task type explicitly when saving or logging &quot;</span>
                <span class="s2">&quot;this submitted Pipeline or dictionary of components.&quot;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">BAD_REQUEST</span><span class="p">,</span>
            <span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;The provided model type: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="si">}</span><span class="s2"> is not supported. &quot;</span>
            <span class="s2">&quot;Supported model types are: Pipeline or a dictionary with specific named keys. &quot;</span>
            <span class="s2">&quot;Run `help(mlflow.transformers.save_model)` to see details of supported types.&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">BAD_REQUEST</span><span class="p">,</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">_validate_transformers_task_type</span><span class="p">(</span><span class="n">task</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Validates that a given ``task`` type is supported by the ``transformers`` library and has been</span>
<span class="sd">    registered in the hub.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">transformers.pipelines</span> <span class="kn">import</span> <span class="n">get_supported_tasks</span>

    <span class="n">valid_tasks</span> <span class="o">=</span> <span class="n">get_supported_tasks</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">task</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_tasks</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">task</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;translation&quot;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;The task provided is invalid. &#39;</span><span class="si">{</span><span class="n">task</span><span class="si">}</span><span class="s2">&#39; is not a supported task. &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Must be one of the registered tasks: </span><span class="si">{</span><span class="n">valid_tasks</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">BAD_REQUEST</span><span class="p">,</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">_get_engine_type</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Determines the underlying execution engine for the model based on the 3 currently supported</span>
<span class="sd">    deep learning framework backends: ``tensorflow``, ``torch``, or ``flax``.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">FlaxPreTrainedModel</span><span class="p">,</span> <span class="n">PreTrainedModel</span><span class="p">,</span> <span class="n">TFPreTrainedModel</span>

    <span class="k">for</span> <span class="bp">cls</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__mro__</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">issubclass</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">TFPreTrainedModel</span><span class="p">):</span>
            <span class="k">return</span> <span class="s2">&quot;tensorflow&quot;</span>
        <span class="k">elif</span> <span class="nb">issubclass</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">PreTrainedModel</span><span class="p">):</span>
            <span class="k">return</span> <span class="s2">&quot;torch&quot;</span>
        <span class="k">elif</span> <span class="nb">issubclass</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">FlaxPreTrainedModel</span><span class="p">):</span>
            <span class="k">return</span> <span class="s2">&quot;flax&quot;</span>


<span class="k">def</span> <span class="nf">_get_base_model_architecture</span><span class="p">(</span><span class="n">model_or_pipeline</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extracts the base model architecture type from a submitted model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Pipeline</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model_or_pipeline</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">model_or_pipeline</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">name_or_path</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">model_or_pipeline</span><span class="p">[</span><span class="n">_MODEL_KEY</span><span class="p">]</span><span class="o">.</span><span class="n">name_or_path</span>


<span class="k">def</span> <span class="nf">_get_instance_type</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Utility for extracting the saved object type or, if the `base` argument is set to `True`,</span>
<span class="sd">    the base ABC type of the model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">obj</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>


<span class="k">def</span> <span class="nf">_should_add_pyfunc_to_model</span><span class="p">(</span><span class="n">pipeline</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Discriminator for determining whether a particular task type and model instance from within</span>
<span class="sd">    a ``Pipeline`` is currently supported for the pyfunc flavor.</span>

<span class="sd">    Image and Video pipelines can still be logged and used, but are not available for</span>
<span class="sd">    loading as pyfunc.</span>
<span class="sd">    Similarly, esoteric model types (Graph Models, Timeseries Models, and Reinforcement Learning</span>
<span class="sd">    Models) are not permitted for loading as pyfunc due to the complex input types that, in</span>
<span class="sd">    order to support, will require significant modifications (breaking changes) to the pyfunc</span>
<span class="sd">    contract.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">transformers</span>

    <span class="n">exclusion_model_types</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;GraphormerPreTrainedModel&quot;</span><span class="p">,</span>
        <span class="s2">&quot;InformerPreTrainedModel&quot;</span><span class="p">,</span>
        <span class="s2">&quot;TimeSeriesTransformerPreTrainedModel&quot;</span><span class="p">,</span>
        <span class="s2">&quot;DecisionTransformerPreTrainedModel&quot;</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="c1"># NB: When pyfunc functionality is added for these pipeline types over time, remove the</span>
    <span class="c1"># entries from the following list.</span>
    <span class="n">exclusion_pipeline_types</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;DocumentQuestionAnsweringPipeline&quot;</span><span class="p">,</span>
        <span class="s2">&quot;ImageToTextPipeline&quot;</span><span class="p">,</span>
        <span class="s2">&quot;VisualQuestionAnsweringPipeline&quot;</span><span class="p">,</span>
        <span class="s2">&quot;ImageSegmentationPipeline&quot;</span><span class="p">,</span>
        <span class="s2">&quot;DepthEstimationPipeline&quot;</span><span class="p">,</span>
        <span class="s2">&quot;ObjectDetectionPipeline&quot;</span><span class="p">,</span>
        <span class="s2">&quot;VideoClassificationPipeline&quot;</span><span class="p">,</span>
        <span class="s2">&quot;ZeroShotImageClassificationPipeline&quot;</span><span class="p">,</span>
        <span class="s2">&quot;ZeroShotObjectDetectionPipeline&quot;</span><span class="p">,</span>
        <span class="s2">&quot;ZeroShotAudioClassificationPipeline&quot;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">for</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="n">exclusion_model_types</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">transformers</span><span class="p">,</span> <span class="n">model_type</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pipeline</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">transformers</span><span class="p">,</span> <span class="n">model_type</span><span class="p">)):</span>
                <span class="k">return</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">pipeline</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="ow">in</span> <span class="n">exclusion_pipeline_types</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="kc">True</span>


<span class="k">def</span> <span class="nf">_format_input_example_for_special_cases</span><span class="p">(</span><span class="n">input_example</span><span class="p">,</span> <span class="n">pipeline</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Handles special formatting for specific types of Pipelines so that the displayed example</span>
<span class="sd">    reflects the correct example input structure that mirrors the behavior of the input parsing</span>
<span class="sd">    for pyfunc.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">transformers</span>

    <span class="n">input_data</span> <span class="o">=</span> <span class="n">input_example</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_example</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="n">input_example</span>

    <span class="k">if</span> <span class="p">(</span>
        <span class="nb">isinstance</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">ZeroShotClassificationPipeline</span><span class="p">)</span>
        <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
        <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_data</span><span class="p">[</span><span class="s2">&quot;candidate_labels&quot;</span><span class="p">],</span> <span class="nb">list</span><span class="p">)</span>
    <span class="p">):</span>
        <span class="n">input_data</span><span class="p">[</span><span class="s2">&quot;candidate_labels&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">input_data</span><span class="p">[</span><span class="s2">&quot;candidate_labels&quot;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">input_data</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_example</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">input_example</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">_get_default_pipeline_signature</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">example</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">model_config</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelSignature</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Assigns a default ModelSignature for a given Pipeline type that has pyfunc support. These</span>
<span class="sd">    default signatures should only be generated and assigned when saving a model iff the user</span>
<span class="sd">    has not supplied a signature.</span>
<span class="sd">    For signature inference in some Pipelines that support complex input types, an input example</span>
<span class="sd">    is needed.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">import</span> <span class="nn">transformers</span>

    <span class="k">if</span> <span class="n">example</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">params</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">_contains_params</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
                <span class="n">example</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">example</span>
            <span class="n">example</span> <span class="o">=</span> <span class="n">_format_input_example_for_special_cases</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">pipeline</span><span class="p">)</span>
            <span class="n">prediction</span> <span class="o">=</span> <span class="n">generate_signature_output</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">example</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">infer_signature</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">prediction</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Attempted to generate a signature for the saved model or pipeline &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but encountered an error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="k">raise</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">pipeline</span><span class="p">,</span>
            <span class="p">(</span>
                <span class="n">transformers</span><span class="o">.</span><span class="n">TokenClassificationPipeline</span><span class="p">,</span>
                <span class="n">transformers</span><span class="o">.</span><span class="n">ConversationalPipeline</span><span class="p">,</span>
                <span class="n">transformers</span><span class="o">.</span><span class="n">TranslationPipeline</span><span class="p">,</span>
                <span class="n">transformers</span><span class="o">.</span><span class="n">FillMaskPipeline</span><span class="p">,</span>
                <span class="n">transformers</span><span class="o">.</span><span class="n">TextGenerationPipeline</span><span class="p">,</span>
                <span class="n">transformers</span><span class="o">.</span><span class="n">Text2TextGenerationPipeline</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="n">ModelSignature</span><span class="p">(</span>
                <span class="n">inputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">)]),</span> <span class="n">outputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">)])</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">pipeline</span><span class="p">,</span>
            <span class="p">(</span>
                <span class="n">transformers</span><span class="o">.</span><span class="n">TextClassificationPipeline</span><span class="p">,</span>
                <span class="n">transformers</span><span class="o">.</span><span class="n">ImageClassificationPipeline</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="n">ModelSignature</span><span class="p">(</span>
                <span class="n">inputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">)]),</span>
                <span class="n">outputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">),</span> <span class="n">ColSpec</span><span class="p">(</span><span class="s2">&quot;double&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;score&quot;</span><span class="p">)]),</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">ZeroShotClassificationPipeline</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">ModelSignature</span><span class="p">(</span>
                <span class="n">inputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">ColSpec</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;sequences&quot;</span><span class="p">),</span>
                        <span class="n">ColSpec</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;candidate_labels&quot;</span><span class="p">),</span>
                        <span class="n">ColSpec</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;hypothesis_template&quot;</span><span class="p">),</span>
                    <span class="p">]</span>
                <span class="p">),</span>
                <span class="n">outputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">ColSpec</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;sequence&quot;</span><span class="p">),</span>
                        <span class="n">ColSpec</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;labels&quot;</span><span class="p">),</span>
                        <span class="n">ColSpec</span><span class="p">(</span><span class="s2">&quot;double&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;scores&quot;</span><span class="p">),</span>
                    <span class="p">]</span>
                <span class="p">),</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AutomaticSpeechRecognitionPipeline</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">ModelSignature</span><span class="p">(</span>
                <span class="n">inputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">)]),</span>
                <span class="n">outputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">)]),</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AudioClassificationPipeline</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">ModelSignature</span><span class="p">(</span>
                <span class="n">inputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="s2">&quot;binary&quot;</span><span class="p">)]),</span>
                <span class="n">outputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="s2">&quot;double&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;score&quot;</span><span class="p">),</span> <span class="n">ColSpec</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">)]),</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">pipeline</span><span class="p">,</span>
            <span class="p">(</span>
                <span class="n">transformers</span><span class="o">.</span><span class="n">TableQuestionAnsweringPipeline</span><span class="p">,</span>
                <span class="n">transformers</span><span class="o">.</span><span class="n">QuestionAnsweringPipeline</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">):</span>
            <span class="n">column_1</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">column_2</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">TableQuestionAnsweringPipeline</span><span class="p">):</span>
                <span class="n">column_1</span> <span class="o">=</span> <span class="s2">&quot;query&quot;</span>
                <span class="n">column_2</span> <span class="o">=</span> <span class="s2">&quot;table&quot;</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">QuestionAnsweringPipeline</span><span class="p">):</span>
                <span class="n">column_1</span> <span class="o">=</span> <span class="s2">&quot;question&quot;</span>
                <span class="n">column_2</span> <span class="o">=</span> <span class="s2">&quot;context&quot;</span>
            <span class="k">return</span> <span class="n">ModelSignature</span><span class="p">(</span>
                <span class="n">inputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">ColSpec</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">column_1</span><span class="p">),</span>
                        <span class="n">ColSpec</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">column_2</span><span class="p">),</span>
                    <span class="p">]</span>
                <span class="p">),</span>
                <span class="n">outputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">)]),</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">FeatureExtractionPipeline</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">ModelSignature</span><span class="p">(</span>
                <span class="n">inputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">ColSpec</span><span class="p">(</span><span class="s2">&quot;string&quot;</span><span class="p">)]),</span>
                <span class="n">outputs</span><span class="o">=</span><span class="n">Schema</span><span class="p">([</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="s2">&quot;float64&quot;</span><span class="p">),</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;double&quot;</span><span class="p">)]),</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;An unsupported Pipeline type was supplied for signature inference. &quot;</span>
                <span class="s2">&quot;Either provide an `input_example` or generate a signature manually &quot;</span>
                <span class="s2">&quot;via `infer_signature` if you would like to have a signature recorded &quot;</span>
                <span class="s2">&quot;in the MLmodel file.&quot;</span>
            <span class="p">)</span>


<span class="k">class</span> <span class="nc">_TransformersModel</span><span class="p">(</span><span class="n">NamedTuple</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Type validator class for models that are submitted as a dictionary for saving and logging.</span>
<span class="sd">    Usage of this class should always leverage the type-checking from the class method</span>
<span class="sd">    &#39;from_dict()&#39; instead of the instance-based configuration that is utilized with instantiating</span>
<span class="sd">    a NamedTuple instance (it uses &#39;__new__()&#39; instead of an &#39;__init__()&#39;  dunder method, making</span>
<span class="sd">    type validation on instantiation overly complex if we were to support that approach).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># NB: Assigning Any type here to eliminate local imports. Type validation is performed when</span>
    <span class="c1"># calling the `from_dict` class method.</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">Any</span>
    <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">feature_extractor</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">image_processor</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">processor</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">torch_dtype</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">dict_repr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_asdict</span><span class="p">()</span>
        <span class="c1"># NB: due to breaking changes in APIs, newer pipeline-supported argument keys are not</span>
        <span class="c1"># backwards compatible. If there isn&#39;t an instance present, do not return an empty</span>
        <span class="c1"># key to value mapping.</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">obj</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">dict_repr</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">obj</span><span class="p">}</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_build_exception_msg</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">obj_name</span><span class="p">,</span> <span class="n">valid_types</span><span class="p">):</span>
        <span class="n">type_msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">&quot;one of: &quot;</span> <span class="o">+</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">valid_type</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">valid_type</span> <span class="ow">in</span> <span class="n">valid_types</span><span class="p">])</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">valid_types</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">valid_types</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;The </span><span class="si">{</span><span class="n">obj_name</span><span class="si">}</span><span class="s2"> type submitted is not compatible with the transformers flavor: &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;&#39;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&#39;. &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;The allowed types must inherit from </span><span class="si">{</span><span class="n">type_msg</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_validate_submitted_types</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">feature_extractor</span><span class="p">,</span> <span class="n">image_processor</span><span class="p">,</span> <span class="n">processor</span><span class="p">,</span> <span class="n">torch_dtype</span>
    <span class="p">):</span>
        <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="p">(</span>
            <span class="n">FeatureExtractionMixin</span><span class="p">,</span>
            <span class="n">FlaxPreTrainedModel</span><span class="p">,</span>
            <span class="n">ImageFeatureExtractionMixin</span><span class="p">,</span>
            <span class="n">ImageProcessingMixin</span><span class="p">,</span>
            <span class="n">PreTrainedModel</span><span class="p">,</span>
            <span class="n">PreTrainedTokenizerBase</span><span class="p">,</span>
            <span class="n">ProcessorMixin</span><span class="p">,</span>
            <span class="n">TFPreTrainedModel</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">validation</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">PreTrainedModel</span><span class="p">,</span> <span class="n">TFPreTrainedModel</span><span class="p">,</span> <span class="n">FlaxPreTrainedModel</span><span class="p">)),</span>
            <span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="s2">&quot;tokenizer&quot;</span><span class="p">,</span> <span class="n">PreTrainedTokenizerBase</span><span class="p">),</span>
            <span class="p">(</span>
                <span class="n">feature_extractor</span><span class="p">,</span>
                <span class="s2">&quot;feature_extractor&quot;</span><span class="p">,</span>
                <span class="p">(</span>
                    <span class="n">FeatureExtractionMixin</span><span class="p">,</span>
                    <span class="n">ImageFeatureExtractionMixin</span><span class="p">,</span>
                    <span class="n">ProcessorMixin</span><span class="p">,</span>
                    <span class="n">ImageProcessingMixin</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">),</span>
            <span class="p">(</span><span class="n">image_processor</span><span class="p">,</span> <span class="s2">&quot;image_processor&quot;</span><span class="p">,</span> <span class="n">ImageProcessingMixin</span><span class="p">),</span>
            <span class="p">(</span><span class="n">processor</span><span class="p">,</span> <span class="s2">&quot;processor&quot;</span><span class="p">,</span> <span class="n">ProcessorMixin</span><span class="p">),</span>
        <span class="p">]</span>
        <span class="n">invalid_types</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">arg</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">types</span> <span class="ow">in</span> <span class="n">validation</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">arg</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">arg</span><span class="p">,</span> <span class="n">types</span><span class="p">):</span>
                <span class="n">invalid_types</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">_build_exception_msg</span><span class="p">(</span><span class="n">arg</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">types</span><span class="p">))</span>
        <span class="c1"># only import torch when torch_dtype is not None</span>
        <span class="k">if</span> <span class="n">torch_dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">dtype</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">torch_dtype</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
                <span class="n">invalid_types</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">_build_exception_msg</span><span class="p">(</span><span class="n">torch_dtype</span><span class="p">,</span> <span class="s2">&quot;torch_dtype&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">invalid_types</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">invalid_types</span><span class="p">),</span> <span class="n">error_code</span><span class="o">=</span><span class="n">BAD_REQUEST</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_dict</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">feature_extractor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">image_processor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">processor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">torch_dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>  <span class="c1"># pylint: disable=unused-argument</span>
    <span class="p">):</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">_validate_submitted_types</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">feature_extractor</span><span class="p">,</span> <span class="n">image_processor</span><span class="p">,</span> <span class="n">processor</span><span class="p">,</span> <span class="n">torch_dtype</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">_TransformersModel</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">feature_extractor</span><span class="p">,</span> <span class="n">image_processor</span><span class="p">,</span> <span class="n">processor</span><span class="p">,</span> <span class="n">torch_dtype</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">_get_model_config</span><span class="p">(</span><span class="n">local_path</span><span class="p">,</span> <span class="n">pyfunc_config</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load the model configuration if it was provided for use in the `_TransformersWrapper` pyfunc</span>
<span class="sd">    Model wrapper.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">config_path</span> <span class="o">=</span> <span class="n">local_path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="s2">&quot;inference_config.txt&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">config_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
        <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;Inference config stored in file ``inference_config.txt`` is deprecated. New logged &quot;</span>
            <span class="s2">&quot;models will store the model configuration in the ``pyfunc`` flavor configuration.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">config_path</span><span class="o">.</span><span class="n">read_text</span><span class="p">())</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">pyfunc_config</span> <span class="ow">or</span> <span class="p">{}</span>


<span class="k">def</span> <span class="nf">_load_pyfunc</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">model_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loads the model as pyfunc model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">local_path</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">flavor_configuration</span> <span class="o">=</span> <span class="n">_get_flavor_configuration</span><span class="p">(</span><span class="n">local_path</span><span class="p">,</span> <span class="n">FLAVOR_NAME</span><span class="p">)</span>
    <span class="n">model_config</span> <span class="o">=</span> <span class="n">_get_model_config</span><span class="p">(</span><span class="n">local_path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="n">_COMPONENTS_BINARY_KEY</span><span class="p">),</span> <span class="n">model_config</span><span class="p">)</span>
    <span class="n">prompt_template</span> <span class="o">=</span> <span class="n">_get_prompt_template</span><span class="p">(</span><span class="n">local_path</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">_TransformersWrapper</span><span class="p">(</span>
        <span class="n">_load_model</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">local_path</span><span class="p">),</span> <span class="n">flavor_configuration</span><span class="p">,</span> <span class="s2">&quot;pipeline&quot;</span><span class="p">),</span>
        <span class="n">flavor_configuration</span><span class="p">,</span>
        <span class="n">model_config</span><span class="p">,</span>
        <span class="n">prompt_template</span><span class="p">,</span>
    <span class="p">)</span>


<div class="viewcode-block" id="generate_signature_output"><a class="viewcode-back" href="../../python_api/mlflow.transformers.html#mlflow.transformers.generate_signature_output">[docs]</a><span class="nd">@experimental</span>
<span class="k">def</span> <span class="nf">generate_signature_output</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">model_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Utility for generating the response output for the purposes of extracting an output signature</span>
<span class="sd">    for model saving and logging. This function simulates loading of a saved model or pipeline</span>
<span class="sd">    as a ``pyfunc`` model without having to incur a write to disk.</span>

<span class="sd">    Args:</span>
<span class="sd">        pipeline: A ``transformers`` pipeline object. Note that component-level or model-level</span>
<span class="sd">            inputs are not permitted for extracting an output example.</span>
<span class="sd">        data: An example input that is compatible with the given pipeline</span>
<span class="sd">        model_config: Any additional model configuration, provided as kwargs, to inform</span>
<span class="sd">            the format of the output type from a pipeline inference call.</span>
<span class="sd">        params: A dictionary of additional parameters to pass to the pipeline for inference.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The output from the ``pyfunc`` pipeline wrapper&#39;s ``predict`` method</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">transformers</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">Pipeline</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;The pipeline type submitted is not a valid transformers Pipeline. &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;The type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">pipeline</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> is not supported.&quot;</span><span class="p">,</span>
            <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">_TransformersWrapper</span><span class="p">(</span><span class="n">pipeline</span><span class="o">=</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">model_config</span><span class="o">=</span><span class="n">model_config</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span>
    <span class="p">)</span></div>


<span class="k">class</span> <span class="nc">_TransformersWrapper</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pipeline</span><span class="p">,</span> <span class="n">flavor_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">model_config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prompt_template</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">pipeline</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flavor_config</span> <span class="o">=</span> <span class="n">flavor_config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span> <span class="o">=</span> <span class="n">model_config</span> <span class="ow">or</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">prompt_template</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_conversation</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># NB: Current special-case custom pipeline types that have not been added to</span>
        <span class="c1"># the native-supported transformers package but require custom parsing:</span>
        <span class="c1"># InstructionTextGenerationPipeline [Dolly] https://huggingface.co/databricks/dolly-v2-12b</span>
        <span class="c1">#   (and all variants)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_supported_custom_generator_types</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;InstructionTextGenerationPipeline&quot;</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">_convert_pandas_to_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">transformers</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">ZeroShotClassificationPipeline</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">data</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(</span><span class="n">orient</span><span class="o">=</span><span class="s2">&quot;records&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># NB: The ZeroShotClassificationPipeline requires an input in the form of</span>
            <span class="c1"># Dict[str, Union[str, List[str]]] and will throw if an additional nested</span>
            <span class="c1"># List is present within the List value (which is what the duplicated values</span>
            <span class="c1"># within the orient=&quot;list&quot; conversion in Pandas will do. This parser will</span>
            <span class="c1"># deduplicate label lists to a single list.</span>
            <span class="n">unpacked</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(</span><span class="n">orient</span><span class="o">=</span><span class="s2">&quot;list&quot;</span><span class="p">)</span>
            <span class="n">parsed</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">unpacked</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="n">contents</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">value</span><span class="p">:</span>
                        <span class="c1"># Deduplication logic</span>
                        <span class="k">if</span> <span class="n">item</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">contents</span><span class="p">:</span>
                            <span class="n">contents</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
                    <span class="c1"># Collapse nested lists to return the correct data structure for the</span>
                    <span class="c1"># ZeroShotClassificationPipeline input structure</span>
                    <span class="n">parsed</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">contents</span>
                        <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">contents</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">contents</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>
                        <span class="k">else</span> <span class="n">contents</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="p">)</span>
            <span class="k">return</span> <span class="n">parsed</span>

    <span class="k">def</span> <span class="nf">_override_model_config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">_logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;params provided to the `predict` method will override the inference &quot;</span>
                <span class="s2">&quot;configuration saved with the model. If the params provided are not &quot;</span>
                <span class="s2">&quot;valid for the pipeline, MlflowException will be raised.&quot;</span>
            <span class="p">)</span>

            <span class="c1"># Override the inference configuration with any additional kwargs provided by the user.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_validate_model_config_and_return_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">transformers</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">(</span><span class="o">**</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;The following `model_kwargs` are not used by the model&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">):</span>
                <span class="k">raise</span> <span class="n">MlflowException</span><span class="o">.</span><span class="n">invalid_parameter_value</span><span class="p">(</span>
                    <span class="s2">&quot;The params provided to the `predict` method are not valid &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;for pipeline </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">,</span>
                <span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span>
                <span class="p">(</span>
                    <span class="n">transformers</span><span class="o">.</span><span class="n">AutomaticSpeechRecognitionPipeline</span><span class="p">,</span>
                    <span class="n">transformers</span><span class="o">.</span><span class="n">AudioClassificationPipeline</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">)</span> <span class="ow">and</span> <span class="p">(</span>
                <span class="c1"># transformers &lt;= 4.33.3</span>
                <span class="s2">&quot;Malformed soundfile&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
                <span class="c1"># transformers &gt; 4.33.3</span>
                <span class="ow">or</span> <span class="s2">&quot;Soundfile is either not in the correct format or is malformed&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="n">MlflowException</span><span class="o">.</span><span class="n">invalid_parameter_value</span><span class="p">(</span>
                    <span class="s2">&quot;Failed to process the input audio data. Either the audio file is &quot;</span>
                    <span class="s2">&quot;corrupted or a uri was passed in without overriding the default model &quot;</span>
                    <span class="s2">&quot;signature. If submitting a string uri, please ensure that the model has &quot;</span>
                    <span class="s2">&quot;been saved with a signature that defines a string input type.&quot;</span><span class="p">,</span>
                <span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>
            <span class="k">raise</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            data: Model input data.</span>
<span class="sd">            params: Additional parameters to pass to the model for inference.</span>

<span class="sd">                .. Note:: Experimental: This parameter may change or be removed in a future</span>
<span class="sd">                                        release without warning.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Model predictions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_override_model_config</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
            <span class="n">input_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_convert_pandas_to_dict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="nb">dict</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)):</span>
            <span class="n">input_data</span> <span class="o">=</span> <span class="n">data</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">entry</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">dict</span><span class="p">))</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">data</span><span class="p">):</span>
                <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                    <span class="s2">&quot;Invalid data submission. Ensure all elements in the list are strings &quot;</span>
                    <span class="s2">&quot;or dictionaries. If dictionaries are supplied, all keys in the &quot;</span>
                    <span class="s2">&quot;dictionaries must be strings and values must be either str or List[str].&quot;</span><span class="p">,</span>
                    <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="n">input_data</span> <span class="o">=</span> <span class="n">data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="s2">&quot;Input data must be either a pandas.DataFrame, a string, bytes, List[str], &quot;</span>
                <span class="s2">&quot;List[Dict[str, str]], List[Dict[str, Union[str, List[str]]]], &quot;</span>
                <span class="s2">&quot;or Dict[str, Union[str, List[str]]].&quot;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="n">input_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parse_raw_pipeline_input</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
        <span class="c1"># Validate resolved or input dict types</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">_validate_input_dictionary_contains_only_strings_and_lists_of_strings</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">entry</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">input_data</span><span class="p">):</span>
            <span class="c1"># Validate each dict inside an input List[Dict]</span>
            <span class="nb">all</span><span class="p">(</span>
                <span class="n">_validate_input_dictionary_contains_only_strings_and_lists_of_strings</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">input_data</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">transformers</span>

        <span class="c1"># NB: the ordering of these conditional statements matters. TranslationPipeline and</span>
        <span class="c1"># SummarizationPipeline both inherit from TextGenerationPipeline (they are subclasses)</span>
        <span class="c1"># in which the return data structure from their __call__ implementation is modified.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">TranslationPipeline</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validate_str_or_list_str</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">output_key</span> <span class="o">=</span> <span class="s2">&quot;translation_text&quot;</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">SummarizationPipeline</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validate_str_or_list_str</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_prompt_template</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">output_key</span> <span class="o">=</span> <span class="s2">&quot;summary_text&quot;</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">Text2TextGenerationPipeline</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parse_text2text_input</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_prompt_template</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">output_key</span> <span class="o">=</span> <span class="s2">&quot;generated_text&quot;</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">TextGenerationPipeline</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validate_str_or_list_str</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_prompt_template</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">output_key</span> <span class="o">=</span> <span class="s2">&quot;generated_text&quot;</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">QuestionAnsweringPipeline</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parse_question_answer_input</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">output_key</span> <span class="o">=</span> <span class="s2">&quot;answer&quot;</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">FillMaskPipeline</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validate_str_or_list_str</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_prompt_template</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">output_key</span> <span class="o">=</span> <span class="s2">&quot;token_str&quot;</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">TextClassificationPipeline</span><span class="p">):</span>
            <span class="n">output_key</span> <span class="o">=</span> <span class="s2">&quot;label&quot;</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">ImageClassificationPipeline</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_convert_image_input</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">output_key</span> <span class="o">=</span> <span class="s2">&quot;label&quot;</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">ZeroShotClassificationPipeline</span><span class="p">):</span>
            <span class="n">output_key</span> <span class="o">=</span> <span class="s2">&quot;labels&quot;</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parse_json_encoded_list</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s2">&quot;candidate_labels&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">TableQuestionAnsweringPipeline</span><span class="p">):</span>
            <span class="n">output_key</span> <span class="o">=</span> <span class="s2">&quot;answer&quot;</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parse_json_encoded_dict_payload_to_dict</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s2">&quot;table&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">TokenClassificationPipeline</span><span class="p">):</span>
            <span class="n">output_key</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;entity_group&quot;</span><span class="p">,</span> <span class="s2">&quot;entity&quot;</span><span class="p">}</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">FeatureExtractionPipeline</span><span class="p">):</span>
            <span class="n">output_key</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parse_feature_extraction_input</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_format_prompt_template</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">ConversationalPipeline</span><span class="p">):</span>
            <span class="n">output_key</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_conversation</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_conversation</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">Conversation</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_conversation</span><span class="o">.</span><span class="n">add_user_input</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_supported_custom_generator_types</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validate_str_or_list_str</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">output_key</span> <span class="o">=</span> <span class="s2">&quot;generated_text&quot;</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AutomaticSpeechRecognitionPipeline</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;return_timestamps&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;word&quot;</span><span class="p">,</span> <span class="s2">&quot;char&quot;</span><span class="p">]:</span>
                <span class="n">output_key</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">output_key</span> <span class="o">=</span> <span class="s2">&quot;text&quot;</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_convert_audio_input</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AudioClassificationPipeline</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_convert_audio_input</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">output_key</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The loaded pipeline type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> is &quot;</span>
                <span class="s2">&quot;not enabled for pyfunc predict functionality.&quot;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">BAD_REQUEST</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># Optional input preservation for specific pipeline types. This is True (include raw</span>
        <span class="c1"># formatting output), but if `include_prompt` is set to False in the `model_config`</span>
        <span class="c1"># option during model saving, excess newline characters and the fed-in prompt will be</span>
        <span class="c1"># trimmed out from the start of the response.</span>
        <span class="n">include_prompt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;include_prompt&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="c1"># Optional stripping out of `\n` for specific generator pipelines.</span>
        <span class="n">collapse_whitespace</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;collapse_whitespace&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_convert_cast_lists_from_np_back_to_list</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># Generate inference data with the pipeline object</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">ConversationalPipeline</span><span class="p">):</span>
            <span class="n">conversation_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_conversation</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">conversation_output</span><span class="o">.</span><span class="n">generated_responses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">raw_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_model_config_and_return_output</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># Handle the pipeline outputs</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_supported_custom_generator_types</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">TextGenerationPipeline</span>
        <span class="p">):</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_strip_input_from_response_in_instruction_pipelines</span><span class="p">(</span>
                <span class="n">data</span><span class="p">,</span>
                <span class="n">raw_output</span><span class="p">,</span>
                <span class="n">output_key</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">flavor_config</span><span class="p">,</span>
                <span class="n">include_prompt</span><span class="p">,</span>
                <span class="n">collapse_whitespace</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">FeatureExtractionPipeline</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parse_feature_extraction_output</span><span class="p">(</span><span class="n">raw_output</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">FillMaskPipeline</span><span class="p">):</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parse_list_of_multiple_dicts</span><span class="p">(</span><span class="n">raw_output</span><span class="p">,</span> <span class="n">output_key</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">ZeroShotClassificationPipeline</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_zero_shot_text_classifier_output_to_df</span><span class="p">(</span><span class="n">raw_output</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">TokenClassificationPipeline</span><span class="p">):</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parse_tokenizer_output</span><span class="p">(</span><span class="n">raw_output</span><span class="p">,</span> <span class="n">output_key</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AutomaticSpeechRecognitionPipeline</span>
        <span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;return_timestamps&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;word&quot;</span><span class="p">,</span> <span class="s2">&quot;char&quot;</span><span class="p">]:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">raw_output</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span>
            <span class="p">(</span>
                <span class="n">transformers</span><span class="o">.</span><span class="n">AudioClassificationPipeline</span><span class="p">,</span>
                <span class="n">transformers</span><span class="o">.</span><span class="n">TextClassificationPipeline</span><span class="p">,</span>
                <span class="n">transformers</span><span class="o">.</span><span class="n">ImageClassificationPipeline</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">raw_output</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parse_lists_of_dict_to_list_of_str</span><span class="p">(</span><span class="n">raw_output</span><span class="p">,</span> <span class="n">output_key</span><span class="p">)</span>

        <span class="n">sanitized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sanitize_output</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_wrap_strings_as_list_if_scalar</span><span class="p">(</span><span class="n">sanitized</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_parse_raw_pipeline_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Converts inputs to the expected types for specific Pipeline types.</span>
<span class="sd">        Specific logic for individual pipeline types are called via their respective methods if</span>
<span class="sd">        the input isn&#39;t a basic str or List[str] input type of Pipeline.</span>
<span class="sd">        These parsers are required due to the conversion that occurs within schema validation to</span>
<span class="sd">        a Pandas DataFrame encapsulation, a format which is unsupported for the `transformers`</span>
<span class="sd">        library.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">transformers</span>

        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coerce_exploded_dict_to_single_dict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parse_input_for_table_question_answering</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parse_conversation_input</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span>
                <span class="p">(</span>
                    <span class="n">transformers</span><span class="o">.</span><span class="n">FillMaskPipeline</span><span class="p">,</span>
                    <span class="n">transformers</span><span class="o">.</span><span class="n">TextGenerationPipeline</span><span class="p">,</span>
                    <span class="n">transformers</span><span class="o">.</span><span class="n">TranslationPipeline</span><span class="p">,</span>
                    <span class="n">transformers</span><span class="o">.</span><span class="n">SummarizationPipeline</span><span class="p">,</span>
                    <span class="n">transformers</span><span class="o">.</span><span class="n">TokenClassificationPipeline</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">)</span>
            <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
            <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">entry</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">data</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">entry</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">TextClassificationPipeline</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_text_classification_input</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">data</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_validate_text_classification_input</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform input type validation for TextClassification pipelines and casting of data</span>
<span class="sd">        that is manipulated internally by the MLflow model server back to a structure that</span>
<span class="sd">        can be used for pipeline inference.</span>

<span class="sd">        To illustrate the input and outputs of this function, for the following inputs to</span>
<span class="sd">        the pyfunc.predict() call for this pipeline type:</span>

<span class="sd">        &quot;text to classify&quot;</span>
<span class="sd">        [&quot;text to classify&quot;, &quot;other text to classify&quot;]</span>
<span class="sd">        {&quot;text&quot;: &quot;text to classify&quot;, &quot;text_pair&quot;: &quot;pair text&quot;}</span>
<span class="sd">        [{&quot;text&quot;: &quot;text&quot;, &quot;text_pair&quot;: &quot;pair&quot;}, {&quot;text&quot;: &quot;t&quot;, &quot;text_pair&quot;: &quot;tp&quot; }]</span>

<span class="sd">        Pyfunc processing will convert these to the following structures:</span>

<span class="sd">        [{0: &quot;text to classify&quot;}]</span>
<span class="sd">        [{0: &quot;text to classify&quot;}, {0: &quot;other text to classify&quot;}]</span>
<span class="sd">        [{&quot;text&quot;: &quot;text to classify&quot;, &quot;text_pair&quot;: &quot;pair text&quot;}]</span>
<span class="sd">        [{&quot;text&quot;: &quot;text&quot;, &quot;text_pair&quot;: &quot;pair&quot;}, {&quot;text&quot;: &quot;t&quot;, &quot;text_pair&quot;: &quot;tp&quot; }]</span>

<span class="sd">        The purpose of this function is to convert them into the correct format for input</span>
<span class="sd">        to the pipeline (wrapping as a list has no bearing on the correctness of the</span>
<span class="sd">        inferred classifications):</span>

<span class="sd">        [&quot;text to classify&quot;]</span>
<span class="sd">        [&quot;text to classify&quot;, &quot;other text to classify&quot;]</span>
<span class="sd">        [{&quot;text&quot;: &quot;text to classify&quot;, &quot;text_pair&quot;: &quot;pair text&quot;}]</span>
<span class="sd">        [{&quot;text&quot;: &quot;text&quot;, &quot;text_pair&quot;: &quot;pair&quot;}, {&quot;text&quot;: &quot;t&quot;, &quot;text_pair&quot;: &quot;tp&quot; }]</span>

<span class="sd">        Additionally, for dict input types (the &#39;text&#39; &amp; &#39;text_pair&#39; input example), the dict</span>
<span class="sd">        input will be JSON stringified within MLflow model serving. In order to reconvert this</span>
<span class="sd">        structure back into the appropriate type, we use ast.literal_eval() to convert back</span>
<span class="sd">        to a dict. We avoid using JSON.loads() due to pandas DataFrame conversions that invert</span>
<span class="sd">        single and double quotes with escape sequences that are not consistent if the string</span>
<span class="sd">        contains escaped quotes.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">_check_keys</span><span class="p">(</span><span class="n">payload</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Check if a dictionary contains only allowable keys.&quot;&quot;&quot;</span>
            <span class="n">allowable_str_keys</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;text_pair&quot;</span><span class="p">}</span>
            <span class="k">if</span> <span class="nb">set</span><span class="p">(</span><span class="n">payload</span><span class="p">)</span> <span class="o">-</span> <span class="n">allowable_str_keys</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">payload</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                    <span class="s2">&quot;Text Classification pipelines may only define dictionary inputs with keys &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;defined as </span><span class="si">{</span><span class="n">allowable_str_keys</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">data</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">_check_keys</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">data</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">data</span>
            <span class="k">elif</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">payload</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
                    <span class="n">_check_keys</span><span class="p">(</span><span class="n">payload</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="c1"># NB: To support MLflow serving signature validation, the value within dict</span>
                    <span class="c1"># inputs is JSON encoded. In order for the proper data structure input support</span>
                    <span class="c1"># for a {&quot;text&quot;: &quot;a&quot;, &quot;text_pair&quot;: &quot;b&quot;} (or the list of such a structure) as</span>
                    <span class="c1"># an input, we have to convert the string encoded dict back to a dict.</span>
                    <span class="c1"># Due to how unescaped characters (such as &quot;&#39;&quot;) are encoded, using an explicit</span>
                    <span class="c1"># json.loads() attempted cast can result in invalid input data to the pipeline.</span>
                    <span class="c1"># ast.literal_eval() shows correct conversion, as validated in unit tests.</span>
                    <span class="k">return</span> <span class="p">[</span><span class="n">ast</span><span class="o">.</span><span class="n">literal_eval</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
                <span class="k">except</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">,</span> <span class="ne">SyntaxError</span><span class="p">):</span>
                    <span class="k">return</span> <span class="n">data</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                    <span class="s2">&quot;An unsupported data type has been passed for Text Classification inference. &quot;</span>
                    <span class="s2">&quot;Only str, list of str, dict, and list of dict are supported.&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="s2">&quot;An unsupported data type has been passed for Text Classification inference. &quot;</span>
                <span class="s2">&quot;Only str, list of str, dict, and list of dict are supported.&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_parse_conversation_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">transformers</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">ConversationalPipeline</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span> <span class="nb">str</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="n">data</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">elem</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">data</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="c1"># The conversation pipeline can only accept a single string at a time</span>
            <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>

    <span class="k">def</span> <span class="nf">_parse_input_for_table_question_answering</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">transformers</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">TableQuestionAnsweringPipeline</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">data</span>

        <span class="k">if</span> <span class="s2">&quot;table&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="s2">&quot;The input dictionary must have the &#39;table&#39; key.&quot;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;table&quot;</span><span class="p">],</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">data</span><span class="p">[</span><span class="s2">&quot;table&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;table&quot;</span><span class="p">])</span>
            <span class="k">return</span> <span class="n">data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">data</span>

    <span class="k">def</span> <span class="nf">_coerce_exploded_dict_to_single_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parses the result of Pandas DataFrame.to_dict(orient=&quot;records&quot;) from pyfunc</span>
<span class="sd">        signature validation to coerce the output to the required format for a</span>
<span class="sd">        Pipeline that requires a single dict with list elements such as</span>
<span class="sd">        TableQuestionAnsweringPipeline.</span>
<span class="sd">        Example input:</span>

<span class="sd">        [</span>
<span class="sd">          {&quot;answer&quot;: &quot;We should order more pizzas to meet the demand.&quot;},</span>
<span class="sd">          {&quot;answer&quot;: &quot;The venue size should be updated to handle the number of guests.&quot;},</span>
<span class="sd">        ]</span>

<span class="sd">        Output:</span>

<span class="sd">        [</span>
<span class="sd">          &quot;We should order more pizzas to meet the demand.&quot;,</span>
<span class="sd">          &quot;The venue size should be updated to handle the number of guests.&quot;,</span>
<span class="sd">        ]</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">transformers</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span>
            <span class="n">transformers</span><span class="o">.</span><span class="n">TableQuestionAnsweringPipeline</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="n">data</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="p">):</span>
            <span class="n">collection</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">parsed</span> <span class="o">=</span> <span class="n">collection</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">coll</span> <span class="ow">in</span> <span class="n">collection</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">coll</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">parsed</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                            <span class="s2">&quot;Unable to parse the input. The keys within each &quot;</span>
                            <span class="s2">&quot;dictionary of the parsed input are not consistent&quot;</span>
                            <span class="s2">&quot;among the dictionaries.&quot;</span><span class="p">,</span>
                            <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="k">if</span> <span class="n">value</span> <span class="o">!=</span> <span class="n">parsed</span><span class="p">[</span><span class="n">key</span><span class="p">]:</span>
                        <span class="n">value_type</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">parsed</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>
                        <span class="k">if</span> <span class="n">value_type</span> <span class="o">==</span> <span class="nb">str</span><span class="p">:</span>
                            <span class="n">parsed</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">parsed</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">value</span><span class="p">]</span>
                        <span class="k">elif</span> <span class="n">value_type</span> <span class="o">==</span> <span class="nb">list</span><span class="p">:</span>
                            <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">entry</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">value</span><span class="p">):</span>
                                <span class="c1"># This conversion is required solely for model serving.</span>
                                <span class="c1"># In the parsing logic that occurs internally, strings that</span>
                                <span class="c1"># contain single quotes `&#39;` result in casting to a List[char]</span>
                                <span class="c1"># instead of a str type. Attempting to append a List[char]</span>
                                <span class="c1"># to a List[str] as would happen in the `else` block here</span>
                                <span class="c1"># results in the entire List being overwritten as `None` without</span>
                                <span class="c1"># an Exception being raised. By checking for single value entries</span>
                                <span class="c1"># and subsequently converting to list and extracting the first</span>
                                <span class="c1"># element reconstructs the original input string.</span>
                                <span class="n">parsed</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">value</span><span class="p">)][</span><span class="mi">0</span><span class="p">])</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="n">parsed</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">parsed</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">parsed</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="k">return</span> <span class="n">parsed</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">data</span>

    <span class="k">def</span> <span class="nf">_flatten_zero_shot_text_classifier_output_to_df</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Converts the output of sequences, labels, and scores to a Pandas DataFrame output.</span>

<span class="sd">        Example input:</span>

<span class="sd">        [{&#39;sequence&#39;: &#39;My dog loves to eat spaghetti&#39;,</span>
<span class="sd">          &#39;labels&#39;: [&#39;happy&#39;, &#39;sad&#39;],</span>
<span class="sd">          &#39;scores&#39;: [0.9896970987319946, 0.010302911512553692]},</span>
<span class="sd">         {&#39;sequence&#39;: &#39;My dog hates going to the vet&#39;,</span>
<span class="sd">          &#39;labels&#39;: [&#39;sad&#39;, &#39;happy&#39;],</span>
<span class="sd">          &#39;scores&#39;: [0.957074761390686, 0.042925238609313965]}]</span>

<span class="sd">        Output:</span>

<span class="sd">        pd.DataFrame in a fully normalized (flattened) format with each sequence, label, and score</span>
<span class="sd">        having a row entry.</span>
<span class="sd">        For example, here is the DataFrame output:</span>

<span class="sd">                                sequence labels    scores</span>
<span class="sd">        0  My dog loves to eat spaghetti  happy  0.989697</span>
<span class="sd">        1  My dog loves to eat spaghetti    sad  0.010303</span>
<span class="sd">        2  My dog hates going to the vet    sad  0.957075</span>
<span class="sd">        3  My dog hates going to the vet  happy  0.042925</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="s2">&quot;Encountered an unknown return type from the pipeline type &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">. Expecting a List[Dict]&quot;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">BAD_REQUEST</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">]</span>

        <span class="n">flattened_data</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">entry</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">],</span> <span class="n">entry</span><span class="p">[</span><span class="s2">&quot;scores&quot;</span><span class="p">]):</span>
                <span class="n">flattened_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="p">{</span><span class="s2">&quot;sequence&quot;</span><span class="p">:</span> <span class="n">entry</span><span class="p">[</span><span class="s2">&quot;sequence&quot;</span><span class="p">],</span> <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="n">label</span><span class="p">,</span> <span class="s2">&quot;scores&quot;</span><span class="p">:</span> <span class="n">score</span><span class="p">}</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">flattened_data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_strip_input_from_response_in_instruction_pipelines</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_data</span><span class="p">,</span>
        <span class="n">output</span><span class="p">,</span>
        <span class="n">output_key</span><span class="p">,</span>
        <span class="n">flavor_config</span><span class="p">,</span>
        <span class="n">include_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">collapse_whitespace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parse the output from instruction pipelines to conform with other text generator</span>
<span class="sd">        pipeline types and remove line feed characters and other confusing outputs</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">extract_response_data</span><span class="p">(</span><span class="n">data_out</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data_out</span><span class="p">):</span>
                <span class="k">return</span> <span class="p">[</span><span class="n">elem</span><span class="p">[</span><span class="n">output_key</span><span class="p">]</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">data_out</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">elif</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data_out</span><span class="p">):</span>
                <span class="k">return</span> <span class="p">[</span><span class="n">elem</span><span class="p">[</span><span class="n">output_key</span><span class="p">]</span> <span class="k">for</span> <span class="n">coll</span> <span class="ow">in</span> <span class="n">data_out</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">coll</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                    <span class="s2">&quot;Unable to parse the pipeline output. Expected List[Dict[str,str]] or &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;List[List[Dict[str,str]]] but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">data_out</span><span class="p">)</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
                <span class="p">)</span>

        <span class="n">output</span> <span class="o">=</span> <span class="n">extract_response_data</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">trim_input</span><span class="p">(</span><span class="n">data_in</span><span class="p">,</span> <span class="n">data_out</span><span class="p">):</span>
            <span class="c1"># NB: the &#39;\n\n&#39; pattern is exclusive to specific InstructionalTextGenerationPipeline</span>
            <span class="c1"># types that have been loaded as a plain TextGenerator. The structure of these</span>
            <span class="c1"># pipelines will precisely repeat the input question immediately followed by 2 carriage</span>
            <span class="c1"># return statements, followed by the start of the response to the prompt. We only</span>
            <span class="c1"># want to left-trim these types of pipelines output values if the user has indicated</span>
            <span class="c1"># the removal action of the input prompt in the returned str or List[str] by applying</span>
            <span class="c1"># the optional model_config entry of `{&quot;include_prompt&quot;: False}`.</span>
            <span class="c1"># By default, the prompt is included in the response.</span>
            <span class="c1"># Stripping out additional carriage returns (\n) is another additional optional flag</span>
            <span class="c1"># that can be set for these generator pipelines. It is off by default (False).</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="ow">not</span> <span class="n">include_prompt</span>
                <span class="ow">and</span> <span class="n">flavor_config</span><span class="p">[</span><span class="n">_INSTANCE_TYPE_KEY</span><span class="p">]</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_supported_custom_generator_types</span>
                <span class="ow">and</span> <span class="n">data_out</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">data_in</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="c1"># If the user has indicated to not preserve the prompt input in the response,</span>
                <span class="c1"># split the response output and trim the input prompt from the response.</span>
                <span class="n">data_out</span> <span class="o">=</span> <span class="n">data_out</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">data_in</span><span class="p">)</span> <span class="p">:]</span><span class="o">.</span><span class="n">lstrip</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">data_out</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;A:&quot;</span><span class="p">):</span>
                    <span class="n">data_out</span> <span class="o">=</span> <span class="n">data_out</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span><span class="o">.</span><span class="n">lstrip</span><span class="p">()</span>

            <span class="c1"># If the user has indicated to remove newlines and extra spaces from the generated</span>
            <span class="c1"># text, replace them with a single space.</span>
            <span class="k">if</span> <span class="n">collapse_whitespace</span><span class="p">:</span>
                <span class="n">data_out</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\s+&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">data_out</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">data_out</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">trim_input</span><span class="p">(</span><span class="n">data_in</span><span class="p">,</span> <span class="n">data_out</span><span class="p">)</span> <span class="k">for</span> <span class="n">data_in</span><span class="p">,</span> <span class="n">data_out</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">output</span><span class="p">)]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">trim_input</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="s2">&quot;Unknown data structure after parsing output. Expected str or List[str]. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_sanitize_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">input_data</span><span class="p">):</span>
        <span class="c1"># Some pipelines and their underlying models leave leading or trailing whitespace.</span>
        <span class="c1"># This method removes that whitespace.</span>
        <span class="kn">import</span> <span class="nn">transformers</span>

        <span class="k">if</span> <span class="p">(</span>
            <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">TokenClassificationPipeline</span><span class="p">)</span>
            <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
            <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="c1"># Retrieve the first output for return types that are List[str] of only a single</span>
            <span class="c1"># element.</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">output</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">elem</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">output</span><span class="p">):</span>
                <span class="n">cleaned</span> <span class="o">=</span> <span class="p">[</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">output</span><span class="p">]</span>
                <span class="c1"># If the list has only a single string, return as string.</span>
                <span class="k">return</span> <span class="n">cleaned</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cleaned</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">cleaned</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_sanitize_output</span><span class="p">(</span><span class="n">coll</span><span class="p">,</span> <span class="n">input_data</span><span class="p">)</span> <span class="k">for</span> <span class="n">coll</span> <span class="ow">in</span> <span class="n">output</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">output</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">output</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">output</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_wrap_strings_as_list_if_scalar</span><span class="p">(</span><span class="n">output_data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Wraps single string outputs in a list to support batch processing logic in serving.</span>
<span class="sd">        Scalar values are not supported for processing in batch logic as they cannot be coerced</span>
<span class="sd">        to DataFrame representations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_data</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">output_data</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">output_data</span>

    <span class="k">def</span> <span class="nf">_parse_lists_of_dict_to_list_of_str</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_data</span><span class="p">,</span> <span class="n">target_dict_key</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parses the output results from select Pipeline types to extract specific values from a</span>
<span class="sd">        target key.</span>
<span class="sd">        Examples (with &quot;a&quot; as the `target_dict_key`):</span>

<span class="sd">        Input: [{&quot;a&quot;: &quot;valid&quot;, &quot;b&quot;: &quot;invalid&quot;}, {&quot;a&quot;: &quot;another valid&quot;, &quot;c&quot;: invalid&quot;}]</span>
<span class="sd">        Output: [&quot;valid&quot;, &quot;another_valid&quot;]</span>

<span class="sd">        Input: [{&quot;a&quot;: &quot;valid&quot;, &quot;b&quot;: [{&quot;a&quot;: &quot;another valid&quot;}, {&quot;b&quot;: &quot;invalid&quot;}]},</span>
<span class="sd">                {&quot;a&quot;: &quot;valid 2&quot;, &quot;b&quot;: [{&quot;a&quot;: &quot;another valid 2&quot;}, {&quot;c&quot;: &quot;invalid&quot;}]}]</span>
<span class="sd">        Output: [&quot;valid&quot;, &quot;another valid&quot;, &quot;valid 2&quot;, &quot;another valid 2&quot;]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_data</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">output_coll</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">output_data</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">output</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="n">target_dict_key</span><span class="p">:</span>
                            <span class="n">output_coll</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="n">target_dict_key</span><span class="p">])</span>
                        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span>
                            <span class="nb">isinstance</span><span class="p">(</span><span class="n">elem</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">value</span>
                        <span class="p">):</span>
                            <span class="n">output_coll</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">_parse_lists_of_dict_to_list_of_str</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">target_dict_key</span><span class="p">)</span>
                            <span class="p">)</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="n">output_coll</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_parse_lists_of_dict_to_list_of_str</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target_dict_key</span><span class="p">)</span>
                    <span class="p">)</span>
            <span class="k">return</span> <span class="n">output_coll</span>
        <span class="k">elif</span> <span class="n">target_dict_key</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">output_data</span><span class="p">[</span><span class="n">target_dict_key</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">output_data</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_parse_feature_extraction_input</span><span class="p">(</span><span class="n">input_data</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">input_data</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">input_data</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_parse_feature_extraction_output</span><span class="p">(</span><span class="n">output_data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parse the return type from a FeatureExtractionPipeline output. The mixed types for</span>
<span class="sd">        input are present depending on how the pyfunc is instantiated. For model serving usage,</span>
<span class="sd">        the returned type from MLServer will be a numpy.ndarray type, otherwise, the return</span>
<span class="sd">        within a manually executed pyfunc (i.e., for udf usage), the return will be a collection</span>
<span class="sd">        of nested lists.</span>

<span class="sd">        Examples:</span>

<span class="sd">        Input: [[[0.11, 0.98, 0.76]]] or np.array([0.11, 0.98, 0.76])</span>
<span class="sd">        Output: np.array([0.11, 0.98, 0.76])</span>

<span class="sd">        Input: [[[[0.1, 0.2], [0.3, 0.4]]]] or</span>
<span class="sd">            np.array([np.array([0.1, 0.2]), np.array([0.3, 0.4])])</span>
<span class="sd">        Output: np.array([np.array([0.1, 0.2]), np.array([0.3, 0.4])])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_data</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">output_data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">output_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_parse_tokenizer_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_data</span><span class="p">,</span> <span class="n">target_set</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parses the tokenizer pipeline output.</span>

<span class="sd">        Examples:</span>

<span class="sd">        Input: [{&quot;entity&quot;: &quot;PRON&quot;, &quot;score&quot;: 0.95}, {&quot;entity&quot;: &quot;NOUN&quot;, &quot;score&quot;: 0.998}]</span>
<span class="sd">        Output: &quot;PRON,NOUN&quot;</span>

<span class="sd">        Input: [[{&quot;entity&quot;: &quot;PRON&quot;, &quot;score&quot;: 0.95}, {&quot;entity&quot;: &quot;NOUN&quot;, &quot;score&quot;: 0.998}],</span>
<span class="sd">                [{&quot;entity&quot;: &quot;PRON&quot;, &quot;score&quot;: 0.95}, {&quot;entity&quot;: &quot;NOUN&quot;, &quot;score&quot;: 0.998}]]</span>
<span class="sd">        Output: [&quot;PRON,NOUN&quot;, &quot;PRON,NOUN&quot;]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># NB: We&#39;re collapsing the results here to a comma separated string for each inference</span>
        <span class="c1"># input string. This is to simplify having to otherwise make extensive changes to</span>
        <span class="c1"># ColSpec in order to support schema enforcement of List[List[str]]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_parse_tokenizer_output</span><span class="p">(</span><span class="n">coll</span><span class="p">,</span> <span class="n">target_set</span><span class="p">)</span> <span class="k">for</span> <span class="n">coll</span> <span class="ow">in</span> <span class="n">output_data</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># NB: Since there are no attributes accessible from the pipeline object that determine</span>
            <span class="c1"># what the characteristics of the return structure names are within the dictionaries,</span>
            <span class="c1"># Determine which one is present in the output to extract the correct entries.</span>
            <span class="n">target</span> <span class="o">=</span> <span class="n">target_set</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="n">output_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
            <span class="k">return</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">coll</span><span class="p">[</span><span class="n">target</span><span class="p">]</span> <span class="k">for</span> <span class="n">coll</span> <span class="ow">in</span> <span class="n">output_data</span><span class="p">])</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_parse_list_of_multiple_dicts</span><span class="p">(</span><span class="n">output_data</span><span class="p">,</span> <span class="n">target_dict_key</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the first value of the `target_dict_key` that matches in the first dictionary in a</span>
<span class="sd">        list of dictionaries.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">fetch_target_key_value</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">key</span><span class="p">]</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span>
                <span class="n">fetch_target_key_value</span><span class="p">(</span><span class="n">collection</span><span class="p">,</span> <span class="n">target_dict_key</span><span class="p">)</span> <span class="k">for</span> <span class="n">collection</span> <span class="ow">in</span> <span class="n">output_data</span>
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">output_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">target_dict_key</span><span class="p">]]</span>

    <span class="k">def</span> <span class="nf">_parse_list_output_for_multiple_candidate_pipelines</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_data</span><span class="p">):</span>
        <span class="c1"># NB: This will not continue to parse nested lists. Pipelines do not output complex</span>
        <span class="c1"># types that are greater than 2 levels deep so there is no need for more complex</span>
        <span class="c1"># traversal for outputs.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_data</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_data</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="s2">&quot;The output of the pipeline contains no data.&quot;</span><span class="p">,</span> <span class="n">error_code</span><span class="o">=</span><span class="n">BAD_REQUEST</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_parse_list_output_for_multiple_candidate_pipelines</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">output_data</span>
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">output_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_parse_question_answer_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parses the single string input representation for a question answer pipeline into the</span>
<span class="sd">        required dict format for a `question-answering` pipeline.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_parse_question_answer_input</span><span class="p">(</span><span class="n">entry</span><span class="p">)</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">expected_keys</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;question&quot;</span><span class="p">,</span> <span class="s2">&quot;context&quot;</span><span class="p">}</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">expected_keys</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span> <span class="o">==</span> <span class="n">expected_keys</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Invalid keys were submitted. Keys must be exclusively </span><span class="si">{</span><span class="n">expected_keys</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="s2">&quot;An invalid type has been supplied. Must be either List[Dict[str, str]] or &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Dict[str, str]. </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s2"> is not supported.&quot;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_parse_text2text_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parses the mixed input types that can be submitted into a text2text Pipeline.</span>
<span class="sd">        Valid examples:</span>

<span class="sd">        Input:</span>
<span class="sd">            {&quot;context&quot;: &quot;abc&quot;, &quot;answer&quot;: &quot;def&quot;}</span>
<span class="sd">        Output:</span>
<span class="sd">            &quot;context: abc answer: def&quot;</span>
<span class="sd">        Input:</span>
<span class="sd">            [{&quot;context&quot;: &quot;abc&quot;, &quot;answer&quot;: &quot;def&quot;}, {&quot;context&quot;: &quot;ghi&quot;, &quot;answer&quot;: &quot;jkl&quot;}]</span>
<span class="sd">        Output:</span>
<span class="sd">            [&quot;context: abc answer: def&quot;, &quot;context: ghi answer: jkl&quot;]</span>
<span class="sd">        Input:</span>
<span class="sd">            &quot;abc&quot;</span>
<span class="sd">        Output:</span>
<span class="sd">            &quot;abc&quot;</span>
<span class="sd">        Input:</span>
<span class="sd">            [&quot;abc&quot;, &quot;def&quot;]</span>
<span class="sd">        Output:</span>
<span class="sd">            [&quot;abc&quot;, &quot;def&quot;]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
            <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">data</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;inputs&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
                <span class="c1"># NB: Text2Text Pipelines require submission of text in a pseudo-string based dict</span>
                <span class="c1"># formatting.</span>
                <span class="c1"># As an example, for the input of:</span>
                <span class="c1"># data = {&quot;context&quot;: &quot;The sky is blue&quot;, &quot;answer&quot;: &quot;blue&quot;}</span>
                <span class="c1"># This method will return the Pipeline-required format of:</span>
                <span class="c1"># &quot;context: The sky is blue. answer: blue&quot;</span>
                <span class="k">return</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_parse_text2text_input</span><span class="p">(</span><span class="n">entry</span><span class="p">)</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="n">data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="s2">&quot;An invalid type has been supplied. Please supply a Dict[str, str], str, &quot;</span>
                <span class="s2">&quot;List[str], or a List[Dict[str, str]] for a Text2Text Pipeline.&quot;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_parse_json_encoded_list</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">key_to_unpack</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parses the complex input types for pipelines such as ZeroShotClassification in which</span>
<span class="sd">        the required input type is Dict[str, Union[str, List[str]]] wherein the list</span>
<span class="sd">        provided is encoded as JSON. This method unpacks that string to the required</span>
<span class="sd">        elements.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_parse_json_encoded_list</span><span class="p">(</span><span class="n">entry</span><span class="p">,</span> <span class="n">key_to_unpack</span><span class="p">)</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">key_to_unpack</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                    <span class="s2">&quot;Invalid key in inference payload. The expected inference data key &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;is: </span><span class="si">{</span><span class="n">key_to_unpack</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">key_to_unpack</span><span class="p">],</span> <span class="nb">str</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">return</span> <span class="p">{</span>
                        <span class="n">k</span><span class="p">:</span> <span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="n">key_to_unpack</span> <span class="k">else</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                    <span class="p">}</span>
                <span class="k">except</span> <span class="n">json</span><span class="o">.</span><span class="n">JSONDecodeError</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">data</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">key_to_unpack</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">data</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_parse_json_encoded_dict_payload_to_dict</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">key_to_unpack</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parses complex dict input types that have been json encoded. Pipelines like</span>
<span class="sd">        TableQuestionAnswering require such input types.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">[</span>
                <span class="p">{</span>
                    <span class="n">key</span><span class="p">:</span> <span class="p">(</span>
                        <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="n">key_to_unpack</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
                        <span class="k">else</span> <span class="n">value</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">entry</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                <span class="p">}</span>
                <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">data</span>
            <span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="c1"># This is to handle serving use cases as the DataFrame encapsulation converts</span>
            <span class="c1"># collections within rows to np.array type. In order to process this data through</span>
            <span class="c1"># the transformers.Pipeline API, we need to cast these arrays back to lists</span>
            <span class="c1"># and replace the single quotes with double quotes after extracting the</span>
            <span class="c1"># json-encoded `table` (a pandas DF) in order to convert it to a dict that</span>
            <span class="c1"># the TableQuestionAnsweringPipeline can accept and cast to a Pandas DataFrame.</span>
            <span class="c1">#</span>
            <span class="c1"># An example casting that occurs for this case when input to model serving is the</span>
            <span class="c1"># conversion of a user input of:</span>
            <span class="c1">#   &#39;{&quot;inputs&quot;: {&quot;query&quot;: &quot;What is the longest distance?&quot;,</span>
            <span class="c1">#                &quot;table&quot;: {&quot;Distance&quot;: [&quot;1000&quot;, &quot;10&quot;, &quot;1&quot;]}}}&#39;</span>
            <span class="c1"># is converted to:</span>
            <span class="c1">#   [{&#39;query&#39;: array(&#39;What is the longest distance?&#39;, dtype=&#39;&lt;U29&#39;),</span>
            <span class="c1">#     &#39;table&#39;: array(&#39;{\&#39;Distance\&#39;: [\&#39;1000\&#39;, \&#39;10\&#39;, \&#39;1\&#39;]}&#39;, dtype=&#39;U&lt;204&#39;)}]</span>
            <span class="c1"># which is an invalid input to the pipeline.</span>
            <span class="c1"># this method converts the input to:</span>
            <span class="c1">#   {&#39;query&#39;: &#39;What is the longest distance?&#39;,</span>
            <span class="c1">#    &#39;table&#39;: {&#39;Distance&#39;: [&#39;1000&#39;, &#39;10&#39;, &#39;1&#39;]}}</span>
            <span class="c1"># which is a valid input to the TableQuestionAnsweringPipeline.</span>
            <span class="n">output</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="n">key_to_unpack</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                        <span class="n">output</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">ast</span><span class="o">.</span><span class="n">literal_eval</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">output</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">ast</span><span class="o">.</span><span class="n">literal_eval</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
                        <span class="c1"># This cast to np.ndarray occurs when more than one question is asked.</span>
                        <span class="n">output</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># Otherwise, the entry does not need casting from a np.ndarray type to</span>
                        <span class="c1"># list as it is already a scalar string.</span>
                        <span class="n">output</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="k">return</span> <span class="n">output</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="n">key</span><span class="p">:</span> <span class="p">(</span>
                    <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="n">key_to_unpack</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">value</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_validate_str_or_list_str</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The input data is of an incorrect type. </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s2"> is invalid. &quot;</span>
                <span class="s2">&quot;Must be either string or List[str]&quot;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">entry</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">data</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="s2">&quot;If supplying a list, all values must be of string type.&quot;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_convert_cast_lists_from_np_back_to_list</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This handles the casting of dicts within lists from Pandas DF conversion within model</span>
<span class="sd">        serving back into the required Dict[str, List[str]] if this type matching occurs.</span>
<span class="sd">        Otherwise, it&#39;s a noop.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="c1"># NB: applying a short-circuit return here to not incur runtime overhead with</span>
            <span class="c1"># type validation if the input is not a list</span>
            <span class="k">return</span> <span class="n">data</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">parsed_data</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">entry</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
                    <span class="n">parsed_data</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">entry</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">parsed_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">entry</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">parsed_data</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">is_base64_image</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check whether input image is a base64 encoded&quot;&quot;&quot;</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64encode</span><span class="p">(</span><span class="n">base64</span><span class="o">.</span><span class="n">b64decode</span><span class="p">(</span><span class="n">image</span><span class="p">))</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="n">image</span>
        <span class="k">except</span> <span class="n">binascii</span><span class="o">.</span><span class="n">Error</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">_convert_image_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Conversion utility for decoding the base64 encoded bytes data of a raw image file when</span>
<span class="sd">        parsed through model serving, if applicable. Direct usage of the pyfunc implementation</span>
<span class="sd">        outside of model serving will treat this utility as a noop.</span>

<span class="sd">        For reference, the expected encoding for input to Model Serving will be:</span>

<span class="sd">        import requests</span>
<span class="sd">        import base64</span>

<span class="sd">        response = requests.get(&quot;https://www.my.images/a/sound/file.jpg&quot;)</span>
<span class="sd">        encoded_image = base64.b64encode(response.content).decode(&quot;utf-8&quot;)</span>

<span class="sd">        inference_data = json.dumps({&quot;inputs&quot;: [encoded_image]})</span>

<span class="sd">        or</span>

<span class="sd">        inference_df = pd.DataFrame(</span>
<span class="sd">        pd.Series([encoded_image], name=&quot;image_file&quot;)</span>
<span class="sd">        )</span>
<span class="sd">        split_dict = {&quot;dataframe_split&quot;: inference_df.to_dict(orient=&quot;split&quot;)}</span>
<span class="sd">        split_json = json.dumps(split_dict)</span>

<span class="sd">        or</span>

<span class="sd">        records_dict = {&quot;dataframe_records&quot;: inference_df.to_dict(orient=&quot;records&quot;)}</span>
<span class="sd">        records_json = json.dumps(records_dict)</span>

<span class="sd">        This utility will convert this JSON encoded, base64 encoded text back into bytes for</span>
<span class="sd">        input into the Image pipelines for inference.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">process_input_element</span><span class="p">(</span><span class="n">input_element</span><span class="p">):</span>
            <span class="n">input_value</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">input_element</span><span class="o">.</span><span class="n">values</span><span class="p">()))</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_value</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_base64_image</span><span class="p">(</span><span class="n">input_value</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_validate_str_input_uri_or_file</span><span class="p">(</span><span class="n">input_value</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">input_value</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">element</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">input_data</span>
        <span class="p">):</span>
            <span class="c1"># Use a list comprehension for readability</span>
            <span class="c1"># the elimination of empty collection declarations</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">process_input_element</span><span class="p">(</span><span class="n">element</span><span class="p">)</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">input_data</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_base64_image</span><span class="p">(</span><span class="n">input_data</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validate_str_input_uri_or_file</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">input_data</span>

    <span class="k">def</span> <span class="nf">_convert_audio_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Conversion utility for decoding the base64 encoded bytes data of a raw soundfile when</span>
<span class="sd">        parsed through model serving, if applicable. Direct usage of the pyfunc implementation</span>
<span class="sd">        outside of model serving will treat this utility as a noop.</span>

<span class="sd">        For reference, the expected encoding for input to Model Serving will be:</span>

<span class="sd">        import requests</span>
<span class="sd">        import base64</span>

<span class="sd">        response = requests.get(&quot;https://www.my.sound/a/sound/file.wav&quot;)</span>
<span class="sd">        encoded_audio = base64.b64encode(response.content).decode(&quot;ascii&quot;)</span>

<span class="sd">        inference_data = json.dumps({&quot;inputs&quot;: [encoded_audio]})</span>

<span class="sd">        or</span>

<span class="sd">        inference_df = pd.DataFrame(</span>
<span class="sd">        pd.Series([encoded_audio], name=&quot;audio_file&quot;)</span>
<span class="sd">        )</span>
<span class="sd">        split_dict = {&quot;dataframe_split&quot;: inference_df.to_dict(orient=&quot;split&quot;)}</span>
<span class="sd">        split_json = json.dumps(split_dict)</span>

<span class="sd">        or</span>

<span class="sd">        records_dict = {&quot;dataframe_records&quot;: inference_df.to_dict(orient=&quot;records&quot;)}</span>
<span class="sd">        records_json = json.dumps(records_dict)</span>

<span class="sd">        This utility will convert this JSON encoded, base64 encoded text back into bytes for</span>
<span class="sd">        input into the AutomaticSpeechRecognitionPipeline for inference.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">is_base64</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64encode</span><span class="p">(</span><span class="n">base64</span><span class="o">.</span><span class="n">b64decode</span><span class="p">(</span><span class="n">s</span><span class="p">))</span> <span class="o">==</span> <span class="n">s</span>
            <span class="k">except</span> <span class="n">binascii</span><span class="o">.</span><span class="n">Error</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>

        <span class="k">def</span> <span class="nf">decode_audio</span><span class="p">(</span><span class="n">encoded</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">encoded</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="c1"># This is to support blob style passing of uri locations to process audio files</span>
                <span class="c1"># on disk or object store. Note that if a uri is passed, a signature *must be*</span>
                <span class="c1"># provided for serving to function as the default signature uses bytes.</span>
                <span class="k">return</span> <span class="n">encoded</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">encoded</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">):</span>
                <span class="c1"># For input types &#39;dataframe_split&#39; and &#39;dataframe_records&#39;, the encoding</span>
                <span class="c1"># conversion to bytes is handled.</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">is_base64</span><span class="p">(</span><span class="n">encoded</span><span class="p">):</span>
                    <span class="k">return</span> <span class="n">encoded</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># For input type &#39;inputs&#39;, explicit decoding of the b64encoded audio is needed.</span>
                    <span class="k">return</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64decode</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64decode</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span>
                <span class="k">except</span> <span class="n">binascii</span><span class="o">.</span><span class="n">Error</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                        <span class="s2">&quot;The encoded soundfile that was passed has not been properly base64 &quot;</span>
                        <span class="s2">&quot;encoded. Please ensure that the raw sound bytes have been processed with &quot;</span>
                        <span class="s2">&quot;`base64.b64encode(&lt;audio data bytes&gt;).decode(&#39;ascii&#39;)`&quot;</span>
                    <span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>

        <span class="c1"># The example input data that is processed by this logic is from the pd.DataFrame</span>
        <span class="c1"># conversion that happens within serving wherein the bytes input data is cast to</span>
        <span class="c1"># a pd.DataFrame(pd.Series([raw_bytes])) and then cast to JSON serializable data in the</span>
        <span class="c1"># format:</span>
        <span class="c1"># {[0]: [{[0]: &lt;audio data&gt;}]}</span>
        <span class="c1"># In the inputs format, due to the modification of how types are not enforced, the</span>
        <span class="c1"># logic that is present in processing `records` and `split` format orientation when casting</span>
        <span class="c1"># back to dictionary does not do the automatic decoding of the data from base64 encoded</span>
        <span class="c1"># back to bytes. This is the reason for the conditional logic within `decode_audio` based</span>
        <span class="c1"># on whether the bytes data is base64 encoded or standard bytes format.</span>
        <span class="c1"># The output of the conversion present in the conditional structural validation below is</span>
        <span class="c1"># to return the only input format that the audio transcription pipeline permits:</span>
        <span class="c1"># a bytes input of a single element.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">element</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">data</span><span class="p">):</span>
            <span class="n">encoded_audio</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">encoded_audio</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_validate_str_input_uri_or_file</span><span class="p">(</span><span class="n">encoded_audio</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">decode_audio</span><span class="p">(</span><span class="n">encoded_audio</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validate_str_input_uri_or_file</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="c1"># For new schema, we extract the data field out when converting</span>
        <span class="c1"># pandas DataFrame to dictionary.</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">decode_audio</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">data</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_validate_str_input_uri_or_file</span><span class="p">(</span><span class="n">input_str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Validation of blob references to either audio or image files,</span>
<span class="sd">        if a string is input to the ``predict``</span>
<span class="sd">        method, perform validation of the string contents by checking for a valid uri or</span>
<span class="sd">        filesystem reference instead of surfacing the cryptic stack trace that is otherwise raised</span>
<span class="sd">        for an invalid uri input.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">is_uri</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">urlparse</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
                <span class="k">return</span> <span class="nb">all</span><span class="p">([</span><span class="n">result</span><span class="o">.</span><span class="n">scheme</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">netloc</span><span class="p">])</span>
            <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>

        <span class="n">valid_uri</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">input_str</span><span class="p">)</span> <span class="ow">or</span> <span class="n">is_uri</span><span class="p">(</span><span class="n">input_str</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">valid_uri</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_str</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">20</span><span class="p">:</span>
                <span class="n">data_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Received: </span><span class="si">{</span><span class="n">input_str</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">data_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Received (truncated): </span><span class="si">{</span><span class="n">input_str</span><span class="p">[:</span><span class="mi">20</span><span class="p">]</span><span class="si">}</span><span class="s2">...&quot;</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="s2">&quot;An invalid string input was provided. String inputs to &quot;</span>
                <span class="s2">&quot;audio or image files must be either a file location or a uri.&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;audio files must be either a file location or a uri. </span><span class="si">{</span><span class="n">data_str</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">error_code</span><span class="o">=</span><span class="n">BAD_REQUEST</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_format_prompt_template</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Wraps the input data in the specified prompt template. If no template is</span>
<span class="sd">        specified, or if the pipeline is an unsupported type, or if the input type</span>
<span class="sd">        is not a string or list of strings, then the input data is returned unchanged.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">input_data</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">task</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_SUPPORTED_PROMPT_TEMPLATING_TASK_TYPES</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;_format_prompt_template called on an unexpected pipeline type. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Expected one of: </span><span class="si">{</span><span class="n">_SUPPORTED_PROMPT_TEMPLATING_TASK_TYPES</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Received: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">task</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">prompt</span><span class="o">=</span><span class="n">input_data</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="c1"># if every item is a string, then apply formatting to every item</span>
            <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">input_data</span><span class="p">):</span>
                <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">prompt_template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">prompt</span><span class="o">=</span><span class="n">data</span><span class="p">)</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">input_data</span><span class="p">]</span>

        <span class="c1"># throw for unsupported types</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="o">.</span><span class="n">invalid_parameter_value</span><span class="p">(</span>
            <span class="s2">&quot;Prompt templating is only supported for data of type str or List[str]. &quot;</span>
        <span class="p">)</span>


<div class="viewcode-block" id="autolog"><a class="viewcode-back" href="../../python_api/mlflow.transformers.html#mlflow.transformers.autolog">[docs]</a><span class="nd">@experimental</span>
<span class="nd">@autologging_integration</span><span class="p">(</span><span class="n">FLAVOR_NAME</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">autolog</span><span class="p">(</span>
    <span class="n">log_input_examples</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">log_model_signatures</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">log_models</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">log_datasets</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">disable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">exclusive</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">disable_for_unsupported_versions</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">silent</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">extra_tags</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>  <span class="c1"># pylint: disable=unused-argument</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This autologging integration is solely used for disabling spurious autologging of irrelevant</span>
<span class="sd">    sub-models that are created during the training and evaluation of transformers-based models.</span>
<span class="sd">    Autologging functionality is not implemented fully for the transformers flavor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># A list of other flavors whose base autologging config would be automatically logged due to</span>
    <span class="c1"># training a model that would otherwise create a run and be logged internally within the</span>
    <span class="c1"># transformers-supported trainer calls.</span>
    <span class="n">DISABLED_ANCILLARY_FLAVOR_AUTOLOGGING</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;sklearn&quot;</span><span class="p">,</span> <span class="s2">&quot;tensorflow&quot;</span><span class="p">,</span> <span class="s2">&quot;pytorch&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">disable_discrete_autologging</span><span class="p">(</span><span class="n">DISABLED_ANCILLARY_FLAVOR_AUTOLOGGING</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">original</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">suppress</span><span class="p">(</span><span class="ne">ImportError</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">setfit</span>

        <span class="n">safe_patch</span><span class="p">(</span>
            <span class="n">FLAVOR_NAME</span><span class="p">,</span>
            <span class="p">(</span>
                <span class="n">setfit</span><span class="o">.</span><span class="n">SetFitTrainer</span>
                <span class="k">if</span> <span class="n">Version</span><span class="p">(</span><span class="n">setfit</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">Version</span><span class="p">(</span><span class="s2">&quot;1.0.0&quot;</span><span class="p">)</span>
                <span class="k">else</span> <span class="n">setfit</span><span class="o">.</span><span class="n">Trainer</span>
            <span class="p">),</span>
            <span class="s2">&quot;train&quot;</span><span class="p">,</span>
            <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">train</span><span class="p">),</span>
            <span class="n">manage_run</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">with</span> <span class="n">contextlib</span><span class="o">.</span><span class="n">suppress</span><span class="p">(</span><span class="ne">ImportError</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">transformers</span>

        <span class="n">classes</span> <span class="o">=</span> <span class="p">[</span><span class="n">transformers</span><span class="o">.</span><span class="n">Trainer</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">Seq2SeqTrainer</span><span class="p">]</span>
        <span class="n">methods</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">clazz</span> <span class="ow">in</span> <span class="n">classes</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">method</span> <span class="ow">in</span> <span class="n">methods</span><span class="p">:</span>
                <span class="n">safe_patch</span><span class="p">(</span><span class="n">FLAVOR_NAME</span><span class="p">,</span> <span class="n">clazz</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">train</span><span class="p">),</span> <span class="n">manage_run</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_get_prompt_template</span><span class="p">(</span><span class="n">model_path</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">model_path</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="sa">f</span><span class="s1">&#39;Could not find an &quot;</span><span class="si">{</span><span class="n">MLMODEL_FILE_NAME</span><span class="si">}</span><span class="s1">&quot; configuration file at &quot;</span><span class="si">{</span><span class="n">model_path</span><span class="si">}</span><span class="s1">&quot;&#39;</span><span class="p">,</span>
            <span class="n">RESOURCE_DOES_NOT_EXIST</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">model_conf</span> <span class="o">=</span> <span class="n">Model</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">model_conf</span><span class="o">.</span><span class="n">metadata</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">model_conf</span><span class="o">.</span><span class="n">metadata</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">_PROMPT_TEMPLATE_KEY</span><span class="p">)</span>

    <span class="k">return</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">_validate_prompt_template</span><span class="p">(</span><span class="n">prompt_template</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">prompt_template</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt_template</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Argument `prompt_template` must be a string, received </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">prompt_template</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">INVALID_PARAMETER_VALUE</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">format_args</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">tup</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">tup</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">Formatter</span><span class="p">()</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">prompt_template</span><span class="p">)</span> <span class="k">if</span> <span class="n">tup</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="p">]</span>

    <span class="c1"># expect there to only be one format arg, and for that arg to be &quot;prompt&quot;</span>
    <span class="k">if</span> <span class="n">format_args</span> <span class="o">!=</span> <span class="p">[</span><span class="s2">&quot;prompt&quot;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="n">MlflowException</span><span class="o">.</span><span class="n">invalid_parameter_value</span><span class="p">(</span>
            <span class="s2">&quot;Argument `prompt_template` must be a string with a single format arg, &#39;prompt&#39;. &quot;</span>
            <span class="s2">&quot;For example: &#39;Answer the following question in a friendly tone. Q: </span><span class="si">{prompt}</span><span class="s2">. A:&#39;</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Received </span><span class="si">{</span><span class="n">prompt_template</span><span class="si">}</span><span class="s2">. &quot;</span>
        <span class="p">)</span>
</pre></div>

              </div>
            </div>
            <footer>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; MLflow Project, a Series of LF Projects, LLC. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'../../',
      VERSION:'2.9.3.dev0',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      LINK_SUFFIX: '.html',
      HAS_SOURCE:  true
    };
  </script>

  

  <script type="text/javascript" src="../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../_static/js/jquery.waypoints.min.js"></script>

  
  
  
  <script type="text/javascript">var CLIPPY_SVG_PATH = "../../_static/clippy.svg";</script>
  <script type="text/javascript" src="../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  

  
  <script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        function copyToClipboard(text) {
            const textarea = document.createElement('textarea');
            textarea.value = text;
            document.body.appendChild(textarea);
            textarea.select();
            document.execCommand('copy');
            document.body.removeChild(textarea);
        }
        // Get the code block designator class entries
        const allHighlights = document.querySelectorAll('.highlight');
        // Disable copyable links for notebook cell numbering and for cell outputs
        const highlights = Array.from(allHighlights).filter(highlight => !highlight.closest('.highlight-none') && 
            !highlight.closest('.nboutput'));
    
        highlights.forEach(function(highlight) {
            const copyIcon = document.createElement('span');
            copyIcon.classList.add('copy-icon');
            copyIcon.innerHTML = '&#xf0ea;';

            copyIcon.addEventListener('click', function() {
                const code = highlight.querySelector('pre').textContent;
                copyToClipboard(code);

                // Flash effect on click
                this.style.color = '#0194E2';
                setTimeout(() => {
                    this.style.color = ''; 
                }, 100);

                // Display "Code copied to clipboard" near the clicked icon
                const message = document.createElement('span');
                message.textContent = "Copied!";
                message.classList.add('copy-message'); 

                // Append the message to the icon
                this.appendChild(message);

                setTimeout(() => {
                    this.removeChild(message);
                }, 500);
            });

            highlight.appendChild(copyIcon);
        });
    });
  </script>


<script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
        // Force download for notebook-download-btn
        const downloadButtons = document.querySelectorAll('.notebook-download-btn');
        downloadButtons.forEach(function(button) {
            button.addEventListener('click', function(event) {
                event.preventDefault(); // Prevent default behavior

                // Fetch the raw content of the notebook from GitHub
                fetch(button.href)
                    .then(response => response.blob())
                    .then(blob => {
                        const url = window.URL.createObjectURL(blob);
                        const link = document.createElement('a');
                        link.style.display = 'none';
                        link.href = url;
                        const filename = button.href.split('/').pop();
                        link.download = filename; 

                        document.body.appendChild(link);
                        link.click();

                        window.URL.revokeObjectURL(url);
                        document.body.removeChild(link);
                    })
                    .catch(err => console.error('Error fetching the notebook:', err));
            });
        });
    });
</script> 
</body>
</html>