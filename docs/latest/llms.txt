# MLflow


## Mlflow Website

- [Community](/mlflow-website/docs/latest/community.md): Welcome to the MLflow community! Connect with thousands of data scientists, ML engineers, and practitioners who are building the future of machine learning together.
- [Usage Tracking](/mlflow-website/docs/latest/community/usage-tracking.md): Starting with version 3.2.0, MLflow collects anonymized usage data by default. This data contains no sensitive or personally identifiable information.
- [Build with MLflow GenAI](/mlflow-website/docs/latest/genai.md): Build with MLflow GenAI
- [Ground Truth Expectations](/mlflow-website/docs/latest/genai/assessments/expectations.md): MLflow Expectations provide a systematic way to capture ground truth - the correct or desired outputs that your AI should produce. By establishing these reference points, you create the foundation for meaningful evaluation and continuous improvement of your GenAI applications.
- [Feedback Collection](/mlflow-website/docs/latest/genai/assessments/feedback.md): MLflow Feedback provides a comprehensive system for capturing quality evaluations from multiple sources - whether automated AI judges, programmatic rules, or human reviewers. This systematic approach to feedback collection enables you to understand and improve your GenAI application's performance at scale.
- [Evaluation Dataset Concepts](/mlflow-website/docs/latest/genai/concepts/evaluation-datasets.md): Evaluation Datasets require an MLflow Tracking Server with a SQL backend (PostgreSQL, MySQL, SQLite, or MSSQL).
- [Expectation Concepts](/mlflow-website/docs/latest/genai/concepts/expectations.md): What are Expectations?
- [Feedback Concepts](/mlflow-website/docs/latest/genai/concepts/feedback.md): What is Feedback?
- [Scorer Concepts](/mlflow-website/docs/latest/genai/concepts/scorers.md): What are Scorers?
- [Spans](/mlflow-website/docs/latest/genai/concepts/span.md): What is a Span?
- [Trace Concepts](/mlflow-website/docs/latest/genai/concepts/trace.md): What is Tracing?
- [Feedback Concepts](/mlflow-website/docs/latest/genai/concepts/trace/feedback.md): This guide introduces the core concepts of feedback and assessment in MLflow's GenAI evaluation framework. Understanding these concepts is essential for effectively measuring and improving the quality of your GenAI applications.
- [Evaluation Datasets](/mlflow-website/docs/latest/genai/datasets.md): Transform Your GenAI Testing with Structured Evaluation Data
- [End-to-End Workflow: Evaluation-Driven Development](/mlflow-website/docs/latest/genai/datasets/end-to-end-workflow.md): This guide demonstrates the complete workflow for building and evaluating GenAI applications using MLflow's evaluation-driven development approach.
- [Evaluation Datasets SDK Guide](/mlflow-website/docs/latest/genai/datasets/sdk-guide.md): Master the APIs for creating, evolving, and managing evaluation datasets through practical workflows and real-world patterns.
- [Evaluating LLMs/Agents with MLflow](/mlflow-website/docs/latest/genai/eval-monitor.md): This documentation covers MLflow's GenAI evaluation system which uses:
- [AI Issue Discovery](/mlflow-website/docs/latest/genai/eval-monitor/ai-insights/ai-issue-discovery.md): Automatically analyze traces in your MLflow experiments to find operational issues, quality problems, and performance patterns. The Analyze Experiment tool uses hypothesis-driven analysis to systematically examine your GenAI application's behavior, identify the most important problems, and create a plan for addressing them in the form of a comprehensive markdown report.
- [Evaluate & Monitor FAQ](/mlflow-website/docs/latest/genai/eval-monitor/faq.md): This page addresses frequently asked questions about MLflow's GenAI evaluation.
- [Migrating from Legacy LLM Evaluation](/mlflow-website/docs/latest/genai/eval-monitor/legacy-llm-evaluation.md): LLM evaluation involves assessing how well a model performs on a task. MLflow provides a simple API to evaluate your LLMs with popular metrics.
- [GenAI Evaluation Quickstart](/mlflow-website/docs/latest/genai/eval-monitor/quickstart.md): This quickstart guide will walk you through evaluating your GenAI applications with MLflow's comprehensive evaluation framework. In less than 5 minutes, you'll learn how to evaluate LLM outputs, use built-in and custom evaluation criteria, and analyze results in the MLflow UI.
- [Evaluating Agents](/mlflow-website/docs/latest/genai/eval-monitor/running-evaluation/agents.md): AI Agents are an emerging pattern of GenAI applications that can use tools, make decisions, and execute multi-step workflows. However, evaluating the performance of those complex agents is challenging. MLflow provides a powerful toolkit to systematically evaluate the agent behavior precisely using traces and scorers.
- [Evaluating Prompts](/mlflow-website/docs/latest/genai/eval-monitor/running-evaluation/prompts.md): Prompts are the core components of GenAI applications. However, iterating over prompts can be challenging because it is hard to know if the new prompt is better than the old one. MLflow provides a framework to systematically evaluate prompt templates and track performance over time.
- [Evaluating (Production) Traces](/mlflow-website/docs/latest/genai/eval-monitor/running-evaluation/traces.md): Traces are the core data of MLflow. They capture the complete execution flow of your LLM applications. Evaluating traces is a powerful way to understand the performance of your LLM applications and get insights for quality improvement.
- [What are Scorers?](/mlflow-website/docs/latest/genai/eval-monitor/scorers.md): Scorers are key components of the MLflow GenAI evaluation framework. They provide a unified interface to define evaluation criteria for your models, agents, and applications.
- [Custom Code-based Scorers](/mlflow-website/docs/latest/genai/eval-monitor/scorers/custom.md): Custom scorers offer the ultimate flexibility to define precisely how your GenAI application's quality is measured. They provide the flexibility to define evaluation metrics tailored to your specific business use case, whether based on simple heuristics, advanced logic, or programmatic evaluations.
- [LLM-based Scorers (LLM-as-a-Judge)](/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge.md): LLM-as-a-Judge is an evaluation approach that uses Large Language Models to assess the quality of AI-generated responses. LLM judges can evaluate subjective qualities like helpfulness and safety, which are hard to measure with heuristic metrics. On the other hand, LLM-as-a-Judge scorers are more scalable and cost-effective than human evaluation.
- [Agent-based Scorer (aka. Agent-as-a-Judge)](/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/agentic-overview.md): Understanding how judges become autonomous agents for deep trace analysis
- [Judge Alignment: Teaching AI to Match Human Preferences](/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/alignment.md): Transform Generic Judges into Domain Experts
- [Guidelines-based LLM Scorers](/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/guidelines.md): Guidelines is a powerful scorer class designed to let you quickly and easily customize evaluation by defining natural language criteria that are framed as pass/fail conditions. It is ideal for checking compliance with rules, style guides, or information inclusion/exclusion.
- [Template-based LLM Scorers](/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/make-judge.md): The make_judge API is the recommended way to create custom LLM judges in MLflow. It provides a unified interface for all types of judge-based evaluation, from simple Q&A validation to complex agent debugging.
- [Predefined LLM Scorers](/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/predefined.md): MLflow provides several pre-configured LLM judge scorers optimized for common evaluation scenarios.
- [Bring Your Own Prompts](/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/prompt.md): The custompromptjudge API is being phased out. We strongly recommend using the make_judge API instead, which provides:
- [End-to-End Judge Workflow](/mlflow-website/docs/latest/genai/eval-monitor/scorers/llm-judge/workflow.md): Complete workflow for developing, testing, and deploying custom LLM judges
- [Registering and Versioning Scorers](/mlflow-website/docs/latest/genai/eval-monitor/scorers/versioning.md): Scorers can be registered to MLflow experiments for version control and team collaboration.
- [MLflow GenAI Packaging Integrations](/mlflow-website/docs/latest/genai/flavors.md): MLflow 3 delivers built-in support for packaging and deploying applications written with the GenAI frameworks you depend on. Whether you're calling OpenAI directly, orchestrating chains with LangChain or LangGraph, indexing documents in LlamaIndex, wiring up agent patterns via ChatModel and ResponseAgent, or rolling your own with a PythonModel, MLflow provides native packaging and deployment APIs ("flavors") to streamline your path to production.
- [Tutorial: Custom GenAI Models using ChatModel](/mlflow-website/docs/latest/genai/flavors/chat-model-guide.md): Starting in MLflow 3.0.0, we recommend ResponsesAgent instead of ChatModel. See more details in the ResponsesAgent Introduction.
- [Build a tool-calling model with mlflow.pyfunc.ChatModel](/mlflow-website/docs/latest/genai/flavors/chat-model-guide/chat-model-tool-calling.md): Download this notebook
- [Tutorial: Getting Started with ChatModel](/mlflow-website/docs/latest/genai/flavors/chat-model-intro.md): Starting in MLflow 3.0.0, we recommend ResponsesAgent instead of ChatModel. See more details in the ResponsesAgent Introduction.
- [Deploying Advanced LLMs with Custom PyFuncs in MLflow](/mlflow-website/docs/latest/genai/flavors/custom-pyfunc-for-llms.md): Starting in MLflow 3.0.0, we recommend ResponsesAgent instead of ChatModel. See more details in the ResponsesAgent Introduction.
- [Serving LLMs with MLflow: Leveraging Custom PyFunc](/mlflow-website/docs/latest/genai/flavors/custom-pyfunc-for-llms/notebooks/custom-pyfunc-advanced-llm.md): Download this notebook
- [MLflow DSPy Flavor](/mlflow-website/docs/latest/genai/flavors/dspy.md): The dspy flavor is under active development and is marked as Experimental. Public APIs are
- [DSPy Quickstart](/mlflow-website/docs/latest/genai/flavors/dspy/notebooks/dspy_quickstart.md): Download this notebook
- [DSPy Optimizer Autologging](/mlflow-website/docs/latest/genai/flavors/dspy/optimizer.md): A DSPy optimizer is an algorithm that tunes the parameters of a DSPy program (i.e., the prompts and/or the LM weights) to maximize the metrics you specify.
- [MLflow LangChain Flavor](/mlflow-website/docs/latest/genai/flavors/langchain.md): The langchain flavor is under active development and is marked as Experimental. Public APIs are
- [MLflow Langchain Autologging](/mlflow-website/docs/latest/genai/flavors/langchain/autologging.md): MLflow LangChain flavor supports autologging, a powerful feature that allows you to log crucial details about the LangChain model and execution without the need for explicit logging statements. MLflow LangChain autologging covers various aspects of the model, including traces, models, signatures and more.
- [LangChain within MLflow (Experimental)](/mlflow-website/docs/latest/genai/flavors/langchain/guide.md): The langchain flavor is currently under active development and is marked as Experimental. Public APIs are evolving, and new features are being added to enhance its functionality.
- [Introduction to Using LangChain with MLflow](/mlflow-website/docs/latest/genai/flavors/langchain/notebooks/langchain-quickstart.md): Download this notebook
- [Introduction to RAG with MLflow and LangChain](/mlflow-website/docs/latest/genai/flavors/langchain/notebooks/langchain-retriever.md): Download this notebook
- [MLflow LlamaIndex Flavor](/mlflow-website/docs/latest/genai/flavors/llama-index.md): Introduction
- [Introduction to Using LlamaIndex with MLflow](/mlflow-website/docs/latest/genai/flavors/llama-index/notebooks/llama_index_quickstart.md): Download this notebook
- [Building a Tool-calling Agent with LlamaIndex Workflow and MLflow](/mlflow-website/docs/latest/genai/flavors/llama-index/notebooks/llama_index_workflow_tutorial.md): Download this notebook
- [MLflow OpenAI Flavor](/mlflow-website/docs/latest/genai/flavors/openai.md): Introduction
- [MLflow OpenAI Autologging](/mlflow-website/docs/latest/genai/flavors/openai/autologging.md): The OpenAI flavor for MLflow supports autologging to ensure that experimentation, testing, and validation of your ideas can be captured dynamically without
- [OpenAI within MLflow](/mlflow-website/docs/latest/genai/flavors/openai/guide.md): The openai flavor is under active development and is marked as Experimental. Public APIs may change and new features are
- [MLflow OpenAI Flavor - Tutorials and Guides](/mlflow-website/docs/latest/genai/flavors/openai/notebooks.md): Below, you will find a number of guides that focus on different ways that you can leverage the power of the openai library, leveraging MLflow's
- [Introduction: Advancing Communication with GPT-4 and MLflow](/mlflow-website/docs/latest/genai/flavors/openai/notebooks/openai-chat-completions.md): Download this notebook
- [Building a Code Assistant with OpenAI & MLflow](/mlflow-website/docs/latest/genai/flavors/openai/notebooks/openai-code-helper.md): Download this notebook
- [Advanced Tutorial: Embeddings Support with OpenAI in MLflow](/mlflow-website/docs/latest/genai/flavors/openai/notebooks/openai-embeddings-generation.md): Download this notebook
- [Introduction to Using the OpenAI Flavor in MLflow](/mlflow-website/docs/latest/genai/flavors/openai/notebooks/openai-quickstart.md): Download this notebook
- [ResponsesAgent Introduction](/mlflow-website/docs/latest/genai/flavors/responses-agent-intro.md): What is a ResponsesAgent?
- [Getting Started with MLflow for GenAI](/mlflow-website/docs/latest/genai/getting-started.md): Build, evaluate, and deploy production-ready GenAI applications with MLflow's comprehensive LLMOps platform
- [Connect Your Development Environment to MLflow](/mlflow-website/docs/latest/genai/getting-started/connect-environment.md): Learn how to connect your development environment to MLflow for GenAI application development, whether using OSS MLflow or a managed offering.
- [Try Managed MLflow](/mlflow-website/docs/latest/genai/getting-started/databricks-trial.md): The Databricks Free Trial offers an opportunity to experience the Databricks platform without prior cloud provider access.
- [MLflow AI Gateway](/mlflow-website/docs/latest/genai/governance/ai-gateway.md): MLflow AI Gateway does not support Windows.
- [AI Gateway Configuration](/mlflow-website/docs/latest/genai/governance/ai-gateway/configuration.md): Configure providers, endpoints, and advanced settings for your MLflow AI Gateway.
- [Getting Started with MLflow AI Gateway](/mlflow-website/docs/latest/genai/governance/ai-gateway/guides.md): MLflow AI Gateway provides a unified interface for deploying and managing LLM providers, offering centralized API key management and seamless integration with multiple language model services.
- [Configuring and Starting the Gateway Server](/mlflow-website/docs/latest/genai/governance/ai-gateway/guides/step1-create-deployments.md): Step 1: Install
- [Querying Endpoints in the MLflow Deployment Server](/mlflow-website/docs/latest/genai/governance/ai-gateway/guides/step2-query-deployments.md): Now that the deployment server is operational, it's time to send it some data. You can interact with the
- [AI Gateway Integration](/mlflow-website/docs/latest/genai/governance/ai-gateway/integration.md): Learn how to integrate the MLflow AI Gateway with applications, frameworks, and production systems.
- [AI Gateway Setup](/mlflow-website/docs/latest/genai/governance/ai-gateway/setup.md): Get your MLflow AI Gateway up and running quickly with this step-by-step setup guide.
- [AI Gateway Usage](/mlflow-website/docs/latest/genai/governance/ai-gateway/usage.md): Learn how to query your AI Gateway endpoints, integrate with applications, and leverage different APIs and tools.
- [Unity Catalog Integration](/mlflow-website/docs/latest/genai/governance/unity-catalog.md): This example illustrates the use of the Unity Catalog (UC) integration with the MLflow AI Gateway.
- [MLflow MCP Server](/mlflow-website/docs/latest/genai/mcp.md): - This feature is experimental and may change in future releases.
- [MLflow 3](/mlflow-website/docs/latest/genai/mlflow-3.md): MLflow 3 Landing Page
- [Breaking Changes in MLflow 3](/mlflow-website/docs/latest/genai/mlflow-3/breaking-changes.md): This document outlines all breaking changes introduced in MLflow 3 to help you migrate your existing code.
- [Deep Learning with MLflow 3](/mlflow-website/docs/latest/genai/mlflow-3/deep-learning.md): In this example, we demonstrate how to use MLflow 3 to track and evaluate deep learning models with a PyTorch-based Iris classifier.
- [FAQs](/mlflow-website/docs/latest/genai/mlflow-3/faqs.md): Can MLflow 3.x load resources (runs, models, traces, etc.) created with MLflow 2.x?
- [GenAI Agent with MLflow 3](/mlflow-website/docs/latest/genai/mlflow-3/genai-agent.md): Prerequisites
- [Prompt Registry](/mlflow-website/docs/latest/genai/prompt-registry.md): MLflow Prompt Registry
- [Create and Edit Prompts](/mlflow-website/docs/latest/genai/prompt-registry/create-and-edit-prompts.md): Learn how to create new prompts and edit existing ones in the MLflow Prompt Registry using both the UI and Python APIs.
- [Evaluating Prompts](/mlflow-website/docs/latest/genai/prompt-registry/evaluate-prompts.md): Combining MLflow Prompt Registry with MLflow LLM Evaluation enables you to evaluate prompt performance across different models and datasets, and track the evaluation results in a centralized registry. You can also inspect model outputs from the traces logged during evaluation to understand how the model responds to different prompts.
- [Log Prompts with Models](/mlflow-website/docs/latest/genai/prompt-registry/log-with-model.md): Prompts are often used as a part of GenAI applications. Managing the association between prompts and models is crucial for tracking the evolution of models and ensuring consistency across different environments. MLflow Prompt Registry is integrated with MLflow's model tracking capability, allowing you to track which prompts (and versions) are used by your models and applications.
- [Manage Prompt Lifecycles](/mlflow-website/docs/latest/genai/prompt-registry/manage-prompt-lifecycles-with-aliases.md): Discover how to use aliases in the MLflow Prompt Registry to manage the lifecycle of your prompts, from development to production, and for implementing governance.
- [Optimize Prompts (Experimental)](/mlflow-website/docs/latest/genai/prompt-registry/optimize-prompts.md): The simple way to continuously improve your AI agents and prompts.
- [Prompt Engineering UI (Experimental)](/mlflow-website/docs/latest/genai/prompt-registry/prompt-engineering.md): Starting in MLflow 2.7, the MLflow Tracking UI provides a best-in-class experience for prompt
- [Auto-rewrite Prompts for New Models (Experimental)](/mlflow-website/docs/latest/genai/prompt-registry/rewrite-prompts.md): When migrating to a new language model, you often discover that your carefully crafted prompts don't work as well with the new model. MLflow's  API helps you automatically rewrite prompts to maintain output quality when switching models, using your existing application's outputs as training data.
- [Structured Output](/mlflow-website/docs/latest/genai/prompt-registry/structured-output.md): Learn how to define structured output schemas for your prompts to ensure consistent and validated responses from language models.
- [Use Prompts in Apps](/mlflow-website/docs/latest/genai/prompt-registry/use-prompts-in-apps.md): Learn how to integrate prompts from the MLflow Prompt Registry into your applications and link them to MLflow Models for end-to-end lineage.
- [MLflow Model Serving](/mlflow-website/docs/latest/genai/serving.md): Transform your trained models into production-ready inference servers with MLflow's comprehensive serving capabilities. Deploy locally, in the cloud, or through managed endpoints with standardized REST APIs.
- [MLflow Agent Server](/mlflow-website/docs/latest/genai/serving/agent-server.md): Agent Server Features
- [Custom Serving Applications](/mlflow-website/docs/latest/genai/serving/custom-apps.md): MLflow's custom serving applications allow you to build sophisticated model serving solutions that go beyond simple prediction endpoints. Using the PyFunc framework, you can create custom applications with complex preprocessing, postprocessing, multi-model inference, and business logic integration.
- [ResponsesAgent for Model Serving](/mlflow-website/docs/latest/genai/serving/responses-agent.md): The ResponsesAgent class in MLflow provides a specialized interface for serving generative AI models that handle structured responses with tool calling capabilities. This agent is designed to work seamlessly with MLflow's serving infrastructure while providing compatibility with OpenAI-style APIs.
- [MLflow Tracing for LLM Observability](/mlflow-website/docs/latest/genai/tracing.md): MLflow Tracing is a fully OpenTelemetry-compatible LLM observability solution for your applications. It captures the inputs, outputs, and metadata associated with each intermediate step of a request, enabling you to easily pinpoint the source of bugs and unexpected behaviors.
- [Instrument Your App with MLflow Tracing](/mlflow-website/docs/latest/genai/tracing/app-instrumentation.md): New to MLflow Tracing? Checkout the Quick Start Guide to get started.
- [Automatic Tracing](/mlflow-website/docs/latest/genai/tracing/app-instrumentation/automatic.md): MLflow Tracing is integrated with various GenAI libraries and provides one-line automatic tracing experience for each library (and the combination of them!). This page shows detailed examples to integrate MLflow with popular GenAI libraries.
- [Manual Tracing](/mlflow-website/docs/latest/genai/tracing/app-instrumentation/manual-tracing.md): In addition to the Auto Tracing integrations, you can instrument your Python code using MLflow's manual tracing APIs. This is especially useful when you need to instrument your custom Python code.
- [Tracing with OpenTelemetry](/mlflow-website/docs/latest/genai/tracing/app-instrumentation/opentelemetry.md): OpenTelemetry is a CNCF-backed project that provides vendor-neutral observability APIs and SDKs to collect telemetry data from your applications. MLflow Tracing is fully compatible with OpenTelemetry, making it free from vendor lock-in.
- [MLflow Typescript SDK for Tracing](/mlflow-website/docs/latest/genai/tracing/app-instrumentation/typescript-sdk.md): Lean how to use MLflow Typescript SDK to debug, evaluate, and monitor your applications with MLflow's powerful observability capabilities.
- [Setting Trace Tags](/mlflow-website/docs/latest/genai/tracing/attach-tags.md): Tags are mutable key-value pairs that you can attach to traces to add valuable metadata and context. This metadata is useful for organizing, searching, and filtering your traces. For example, you might tag your traces based on the topic of the user's input, the environment they're running in, or the model version being used.
- [Collect User Feedback](/mlflow-website/docs/latest/genai/tracing/collect-user-feedback.md): Capturing user feedback is critical for understanding the real-world quality of your GenAI application. MLflow's Feedback API provides a structured, standardized approach to collecting, storing, and analyzing user feedback directly within your traces.
- [Tracing FAQ](/mlflow-website/docs/latest/genai/tracing/faq.md): Getting Started and Basic Usage
- [Auto Tracing Integrations](/mlflow-website/docs/latest/genai/tracing/integrations.md): MLflow Tracing is integrated with 20+ popular Generative AI libraries and frameworks, offering one-line automatic tracing experience. This allows you to gain immediate observability into your GenAI applications with minimal setup.
- [Contributing to MLflow Tracing](/mlflow-website/docs/latest/genai/tracing/integrations/contribute.md): Welcome to the MLflow Tracing contribution guide! This step-by-step resource will assist you in implementing additional GenAI library integrations for tracing into MLflow.
- [Tracing AG2ü§ñ](/mlflow-website/docs/latest/genai/tracing/integrations/listing/ag2.md): AG2 Tracing via autolog
- [Tracing Agno](/mlflow-website/docs/latest/genai/tracing/integrations/listing/agno.md): Agno is a flexible agent framework for orchestrating LLMs, reasoning steps, tools, and memory into a unified pipeline.
- [Tracing Anthropic](/mlflow-website/docs/latest/genai/tracing/integrations/listing/anthropic.md): Anthropic Tracing via autolog
- [Tracing AutoGen](/mlflow-website/docs/latest/genai/tracing/integrations/listing/autogen.md): AutoGen tracing via autolog
- [Tracing Amazon Bedrock with MLflow](/mlflow-website/docs/latest/genai/tracing/integrations/listing/bedrock.md): MLflow supports automatic tracing for Amazon Bedrock, a fully managed service on AWS that provides high-performing
- [Tracing Claude Code](/mlflow-website/docs/latest/genai/tracing/integrations/listing/claude_code.md): Claude Code Tracing via CLI autolog
- [Tracing CrewAI](/mlflow-website/docs/latest/genai/tracing/integrations/listing/crewai.md): CrewAI Tracing via autolog
- [Tracing DeepSeek](/mlflow-website/docs/latest/genai/tracing/integrations/listing/deepseek.md): Deepseek Tracing via autolog
- [Tracing DSPyüß©](/mlflow-website/docs/latest/genai/tracing/integrations/listing/dspy.md): DSPy Tracing via autolog
- [Tracing Gemini](/mlflow-website/docs/latest/genai/tracing/integrations/listing/gemini.md): OpenAI Tracing via autolog
- [Tracing Google Agent Development Kit (ADK)](/mlflow-website/docs/latest/genai/tracing/integrations/listing/google-adk.md): MLflow Tracing provides automatic tracing capability for Google ADK, a flexible and modular AI agents framework developed by Google. MLflow supports tracing for Google ADK through the OpenTelemetry integration.
- [Tracing Groq](/mlflow-website/docs/latest/genai/tracing/integrations/listing/groq.md): Groq tracing via autolog
- [Tracing Haystack](/mlflow-website/docs/latest/genai/tracing/integrations/listing/haystack.md): Haystack is an open-source AI orchestration framework developed by deepset, designed to help Python developers build production-ready LLM-powered applications.
- [Tracing Instructor](/mlflow-website/docs/latest/genai/tracing/integrations/listing/instructor.md): Instructor Tracing via autolog
- [Tracing LangChainü¶ú‚õìÔ∏è](/mlflow-website/docs/latest/genai/tracing/integrations/listing/langchain.md): LangChain Tracing via autolog
- [Tracing LangGraphü¶úüï∏Ô∏è](/mlflow-website/docs/latest/genai/tracing/integrations/listing/langgraph.md): LangChain Tracing via autolog
- [Tracing LiteLLMüöÑ](/mlflow-website/docs/latest/genai/tracing/integrations/listing/litellm.md): LiteLLM Tracing via autolog
- [Tracing LlamaIndexü¶ô](/mlflow-website/docs/latest/genai/tracing/integrations/listing/llama_index.md): LlamaIndex Tracing via autolog
- [Tracing Mastra](/mlflow-website/docs/latest/genai/tracing/integrations/listing/mastra.md): MLflow Tracing provides automatic tracing capability for Mastra, a flexible and modular AI agents framework developed by Mastra. MLflow supports tracing for Mastra through the OpenTelemetry integration.
- [Tracing Microsoft Agent Framework](/mlflow-website/docs/latest/genai/tracing/integrations/listing/microsoft-agent-framework.md): MLflow Tracing provides automatic tracing capability for Microsoft Agent Framework, a flexible and modular AI agents framework developed by Microsoft. MLflow supports tracing for Microsoft Agent Framework through the OpenTelemetry integration.
- [Tracing Mistral](/mlflow-website/docs/latest/genai/tracing/integrations/listing/mistral.md): Mistral tracing via autolog
- [Tracing Ollama](/mlflow-website/docs/latest/genai/tracing/integrations/listing/ollama.md): Ollama Tracing via autolog
- [Tracing OpenAI](/mlflow-website/docs/latest/genai/tracing/integrations/listing/openai.md): MLflow Tracing provides automatic tracing capability for OpenAI. By enabling auto tracing
- [Tracing OpenAI Agentü§ñ](/mlflow-website/docs/latest/genai/tracing/integrations/listing/openai-agent.md): OpenAI Tracing via autolog
- [Tracing PydanticAI](/mlflow-website/docs/latest/genai/tracing/integrations/listing/pydantic_ai.md): PydanticAI Tracing via autolog
- [Tracing Semantic Kernel](/mlflow-website/docs/latest/genai/tracing/integrations/listing/semantic_kernel.md): Semantic Kernel is a lightweight, open-source SDK that functions as AI middleware, enabling you to integrate AI models into your C#, Python, or Java codebase via a uniform API layer. By abstracting model interactions, it lets you swap in new models without rewriting your application logic.
- [Tracing Smolagents](/mlflow-website/docs/latest/genai/tracing/integrations/listing/smolagents.md): Smolagents tracing via autolog
- [Tracing Strands Agents SDK](/mlflow-website/docs/latest/genai/tracing/integrations/listing/strands.md): Strands Agents SDK is an open‚Äësource, model‚Äëdriven SDK developed by AWS that enables developers to create autonomous AI agents
- [Tracing txtai](/mlflow-website/docs/latest/genai/tracing/integrations/listing/txtai.md): txtai Tracing via autolog
- [Tracing Vercel AI SDK](/mlflow-website/docs/latest/genai/tracing/integrations/listing/vercelai.md): MLflow Tracing provides automatic tracing for applications built with the Vercel AI SDK (the ai package), unlocking powerful observability capabilities for TypeScript and Javascript application developers.
- [Lightweight Tracing SDK Optimized for Production Usage](/mlflow-website/docs/latest/genai/tracing/lightweight-sdk.md): MLflow offers a lightweight tracing SDK package called mlflow-tracing that includes only the essential functionality for tracing and monitoring of your GenAI applications. This package is designed for production environments where minimizing dependencies and deployment size is critical.
- [Delete Traces](/mlflow-website/docs/latest/genai/tracing/observe-with-traces/delete-traces.md): You can delete traces based on specific criteria using the  method. This method allows you to delete traces by experiment ID, maximum timestamp, or trace IDs.
- [Redacting Sensitive Data from Traces](/mlflow-website/docs/latest/genai/tracing/observe-with-traces/masking.md): Traces capture powerful insights for debugging and monitoring your application, however, they may contain sensitive data, such as Personal Identifiable Information (PII), that you don't want to share with others. MLflow provides a fully configurable way to mask sensitive data from traces before they are saved to the backend.
- [MLflow Tracing UI](/mlflow-website/docs/latest/genai/tracing/observe-with-traces/ui.md): Traces within MLflow Experiments
- [OpenTelemetry Integration](/mlflow-website/docs/latest/genai/tracing/opentelemetry.md): OpenTelemetry is a CNCF-backed project that provides vendor-neutral observability APIs and SDKs to instrument your applications and collect telemetry data in a consistent way. MLflow Tracing is fully compatible with OpenTelemetry, making it free from vendor lock-in.
- [Export MLflow Traces/Metrics via OTLP](/mlflow-website/docs/latest/genai/tracing/opentelemetry/export.md): Set Up OTLP Exporter
- [Collect OpenTelemetry Traces into MLflow](/mlflow-website/docs/latest/genai/tracing/opentelemetry/ingest.md): OpenTelemetry trace ingestion is supported in MLflow 3.6.0 and above.
- [Production Monitoring for GenAI Applications](/mlflow-website/docs/latest/genai/tracing/prod-tracing.md): Machine learning projects don't conclude with their initial launch. Ongoing monitoring and incremental enhancements are critical for long-term success. MLflow Tracing offers comprehensive observability for your production applications, supporting the iterative process of continuous improvement while ensuring quality delivery to users.
- [Tracing Quickstart](/mlflow-website/docs/latest/genai/tracing/quickstart.md): This quickstart guide will walk you through setting up a simple GenAI application with MLflow Tracing. In less than 10 minutes, you'll enable tracing, run a basic application, and explore the generated traces in the MLflow UI.
- [Tracing Quickstart (Python)](/mlflow-website/docs/latest/genai/tracing/quickstart/python-openai.md): The TypeScript/JavaScript quickstart is available here.
- [Tracing Quickstart (TS/JS)](/mlflow-website/docs/latest/genai/tracing/quickstart/typescript-openai.md): The Python quickstart is available here.
- [Search Traces](/mlflow-website/docs/latest/genai/tracing/search-traces.md): This guide will walk you through how to search for traces in MLflow using both the MLflow UI and Python API. This resource will be valuable if you're interested in querying specific traces based on their metadata, tags, execution time, status, or other trace attributes.
- [Track Versions & Environments](/mlflow-website/docs/latest/genai/tracing/track-environments-context.md): Tracking environments, application versions, and custom contextual information in your GenAI application enables comprehensive observability across different deployment stages, versions, and business-specific dimensions. MLflow provides flexible mechanisms to attach rich metadata to your traces using tags.
- [Track Users & Sessions](/mlflow-website/docs/latest/genai/tracing/track-users-sessions.md): Traces with session IDs
- [Version Tracking for GenAI Applications](/mlflow-website/docs/latest/genai/version-tracking.md): Understand how MLflow enables version tracking for your complete GenAI applications using LoggedModels, linking code, configurations, evaluations, and traces.
- [Compare Application Versions with Traces](/mlflow-website/docs/latest/genai/version-tracking/compare-app-versions.md): Compare different application versions using traces to track improvements and identify the best performing iteration.
- [Version Tracking Quickstart](/mlflow-website/docs/latest/genai/version-tracking/quickstart.md): Build and track a LangChain-based chatbot with MLflow's version management capabilities. This quickstart demonstrates prompt versioning, application tracking, trace generation, and performance evaluation using MLflow's GenAI features.
- [Track versions of Git-based applications with MLflow](/mlflow-website/docs/latest/genai/version-tracking/track-application-versions-with-mlflow.md): Learn how to track versions of your GenAI application when your app's code resides in Git, using MLflow's automatic Git versioning capabilities.
- [MLflow: A Tool for Managing the Machine Learning Lifecycle](/mlflow-website/docs/latest/ml.md): MLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in
- [Community Model Flavors](/mlflow-website/docs/latest/ml/community-model-flavors.md): MLflow's vibrant community has developed flavors for specialized ML frameworks and use cases, extending MLflow's capabilities beyond the built-in flavors. These community-maintained packages enable seamless integration with domain-specific tools for time series forecasting, anomaly detection, visualization, and more.
- [MLflow Dataset Tracking](/mlflow-website/docs/latest/ml/dataset.md): The mlflow.data module is a comprehensive solution for dataset management throughout the machine learning lifecycle. It enables you to track, version, and manage datasets used in training, validation, and evaluation, providing complete lineage from raw data to model predictions.
- [MLflow for Deep Learning](/mlflow-website/docs/latest/ml/deep-learning.md): Deep learning has revolutionized artificial intelligence, enabling breakthrough capabilities in computer vision, natural language processing, generative AI, and countless other domains. As models grow more sophisticated, managing the complexity of deep learning experiments becomes increasingly challenging.
- [MLflow Keras 3.0 Integration](/mlflow-website/docs/latest/ml/deep-learning/keras.md): Keras 3.0 represents a revolutionary leap in deep learning accessibility and flexibility. As a high-level neural networks API, Keras empowers everyone from machine learning beginners to seasoned researchers to build, train, and deploy sophisticated models with unprecedented ease.
- [Keras within MLflow](/mlflow-website/docs/latest/ml/deep-learning/keras/guide.md): In this guide we will walk you through how to use Keras with MLflow. We will demonstrate how to track your Keras experiments and log your Keras models to MLflow using both autologging and manual logging approaches.
- [Get Started with Keras 3.0 + MLflow](/mlflow-website/docs/latest/ml/deep-learning/keras/quickstart/quickstart-keras.md): Download this notebook
- [MLflow PyTorch Integration](/mlflow-website/docs/latest/ml/deep-learning/pytorch.md): PyTorch has revolutionized deep learning with its dynamic computation graphs and intuitive, Pythonic approach to building neural networks.
- [PyTorch within MLflow](/mlflow-website/docs/latest/ml/deep-learning/pytorch/guide.md): PyTorch has emerged as one of the leading deep learning frameworks, renowned for its intuitive design, dynamic computation graphs, and seamless debugging capabilities. By combining PyTorch's flexibility with MLflow's experiment tracking, you gain a powerful workflow for developing, monitoring, and deploying machine learning models.
- [Quickstart with MLflow PyTorch Flavor](/mlflow-website/docs/latest/ml/deep-learning/pytorch/quickstart/quickstart-pytorch.md): Download this notebook
- [MLflow Sentence Transformers Integration](/mlflow-website/docs/latest/ml/deep-learning/sentence-transformers.md): Sentence Transformers have revolutionized how we understand and work with text at the semantic level, transforming sentences, paragraphs, and documents into meaningful vector representations that capture their true meaning. Developed by UKP Lab, sentence transformers bridge the gap between human language understanding and machine computation, enabling applications that go far beyond simple keyword matching.
- [Sentence Transformers within MLflow](/mlflow-website/docs/latest/ml/deep-learning/sentence-transformers/guide.md): Sentence Transformers have become the go-to solution for converting text into meaningful vector representations that capture semantic meaning. By combining the power of sentence transformers with MLflow's comprehensive experiment tracking, you create a robust workflow for developing, monitoring, and deploying semantic understanding applications.
- [MLflow Sentence Transformers Flavor - Tutorials and Guides](/mlflow-website/docs/latest/ml/deep-learning/sentence-transformers/tutorials.md): Below, you will find a number of guides that focus on different ways that you can leverage the power of the sentence-transformers library, leveraging MLflow's
- [Advanced Paraphrase Mining with Sentence Transformers and MLflow](/mlflow-website/docs/latest/ml/deep-learning/sentence-transformers/tutorials/paraphrase-mining/paraphrase-mining-sentence-transformers.md): Download this notebook
- [Introduction to Sentence Transformers and MLflow](/mlflow-website/docs/latest/ml/deep-learning/sentence-transformers/tutorials/quickstart/sentence-transformers-quickstart.md): Download this notebook
- [Advanced Semantic Search with Sentence Transformers and MLflow](/mlflow-website/docs/latest/ml/deep-learning/sentence-transformers/tutorials/semantic-search/semantic-search-sentence-transformers.md): Download this notebook
- [Introduction to Advanced Semantic Similarity Analysis with Sentence Transformers and MLflow](/mlflow-website/docs/latest/ml/deep-learning/sentence-transformers/tutorials/semantic-similarity/semantic-similarity-sentence-transformers.md): Download this notebook
- [MLflow spaCy Integration](/mlflow-website/docs/latest/ml/deep-learning/spacy.md): spaCy is the leading industrial-strength natural language processing library, designed from the ground up for production use.
- [spaCy within MLflow](/mlflow-website/docs/latest/ml/deep-learning/spacy/guide.md): spaCy is the leading industrial-strength natural language processing library, designed from the ground up for production use. Created by Explosion AI, spaCy combines cutting-edge research with practical engineering to deliver fast, accurate, and scalable NLP solutions that power everything from chatbots and content analysis to document processing and knowledge extraction systems.
- [MLflow TensorFlow Integration](/mlflow-website/docs/latest/ml/deep-learning/tensorflow.md): TensorFlow is an end-to-end open source platform for machine learning that has revolutionized how developers build and deploy ML solutions. With its comprehensive ecosystem of tools, libraries, and community resources, TensorFlow enables researchers to push the boundaries of ML while giving developers a robust framework for production-ready applications.
- [TensorFlow within MLflow](/mlflow-website/docs/latest/ml/deep-learning/tensorflow/guide.md): TensorFlow is a powerful end-to-end open source platform for machine learning that has revolutionized how developers build and deploy ML solutions. With its comprehensive ecosystem of tools and libraries, TensorFlow empowers everyone from beginners to experts to create sophisticated models for diverse applications.
- [Get Started with MLflow + Tensorflow](/mlflow-website/docs/latest/ml/deep-learning/tensorflow/quickstart/quickstart-tensorflow.md): Download this notebook
- [MLflow Transformers Flavor](/mlflow-website/docs/latest/ml/deep-learning/transformers.md): Introduction
- [ü§ó Transformers within MLflow](/mlflow-website/docs/latest/ml/deep-learning/transformers/guide.md): The transformers model flavor enables logging of transformers models, components, and pipelines
- [Working with Large Models in MLflow Transformers flavor](/mlflow-website/docs/latest/ml/deep-learning/transformers/large-models.md): The features described in this guide are intended for advanced users familiar with Transformers and MLflow. Please understand the limitations and potential risks associated with these features before use.
- [Tasks in MLflow Transformers Flavor](/mlflow-website/docs/latest/ml/deep-learning/transformers/task.md): This page provides an overview of how to use the task parameter in the MLflow Transformers flavor to control
- [MLflow Transformers Flavor - Tutorials and Guides](/mlflow-website/docs/latest/ml/deep-learning/transformers/tutorials.md): Below, you will find a number of guides that focus on different use cases using transformers that leverage MLflow's
- [Introduction to MLflow and OpenAI's Whisper](/mlflow-website/docs/latest/ml/deep-learning/transformers/tutorials/audio-transcription/whisper.md): Download this notebook
- [Introduction to Conversational AI with MLflow and DialoGPT](/mlflow-website/docs/latest/ml/deep-learning/transformers/tutorials/conversational/conversational-model.md): Download this notebook
- [Deploying a Transformer model as an OpenAI-compatible Chatbot](/mlflow-website/docs/latest/ml/deep-learning/transformers/tutorials/conversational/pyfunc-chat-model.md): Download this notebook
- [Fine-Tuning Transformers with MLflow for Enhanced Model Management](/mlflow-website/docs/latest/ml/deep-learning/transformers/tutorials/fine-tuning/transformers-fine-tuning.md): Download this notebook
- [Fine-Tuning Open-Source LLM using QLoRA with MLflow and PEFT](/mlflow-website/docs/latest/ml/deep-learning/transformers/tutorials/fine-tuning/transformers-peft.md): Download this notebook
- [Prompt Templating with MLflow and Transformers](/mlflow-website/docs/latest/ml/deep-learning/transformers/tutorials/prompt-templating/prompt-templating.md): Download this notebook
- [Introduction to MLflow and Transformers](/mlflow-website/docs/latest/ml/deep-learning/transformers/tutorials/text-generation/text-generation.md): Download this notebook
- [Introduction to Translation with Transformers and MLflow](/mlflow-website/docs/latest/ml/deep-learning/transformers/tutorials/translation/component-translation.md): Download this notebook
- [MLflow Serving](/mlflow-website/docs/latest/ml/deployment.md): After training your machine learning model and ensuring its performance, the next step is deploying it to a production environment.
- [Deploy MLflow Model as a Local Inference Server](/mlflow-website/docs/latest/ml/deployment/deploy-model-locally.md): MLflow allows you to deploy your model locally using just a single command.
- [Deploy MLflow Model to Kubernetes](/mlflow-website/docs/latest/ml/deployment/deploy-model-to-kubernetes.md): Using MLServer as the Inference Server
- [Develop ML model with MLflow and deploy to Kubernetes](/mlflow-website/docs/latest/ml/deployment/deploy-model-to-kubernetes/tutorial.md): This tutorial assumes that you have access to a Kubernetes cluster. However, you can also complete this tutorial on your local machine
- [Deploy MLflow Model to Amazon SageMaker](/mlflow-website/docs/latest/ml/deployment/deploy-model-to-sagemaker.md): Amazon SageMaker is a fully managed service designed for scaling ML inference containers.
- [Official MLflow Docker image](/mlflow-website/docs/latest/ml/docker.md): The official MLflow Docker image is available on GitHub Container Registry at https://ghcr.io/mlflow/mlflow.
- [MLflow Evaluation](/mlflow-website/docs/latest/ml/evaluation.md): This documentation covers MLflow's classic evaluation system (mlflow.evaluate) which uses EvaluationMetric and make_metric for custom metrics.
- [Dataset Evaluation](/mlflow-website/docs/latest/ml/evaluation/dataset-eval.md): Dataset evaluation allows you to assess model performance on pre-computed predictions without re-running the model. This is particularly useful for evaluating large-scale batch inference results, historical predictions, or when you want to separate the prediction and evaluation phases.
- [Function Evaluation](/mlflow-website/docs/latest/ml/evaluation/function-eval.md): Function evaluation allows you to assess Python functions directly without the overhead of logging models to MLflow. This lightweight approach is perfect for rapid prototyping, testing custom prediction logic, and evaluating complex business rules that may not fit the traditional model paradigm.
- [Custom Metrics & Visualizations](/mlflow-website/docs/latest/ml/evaluation/metrics-visualizations.md): MLflow's evaluation framework allows you to define custom metrics and create specialized visualizations tailored to your specific business requirements. This capability is essential when standard metrics don't capture your domain's unique success criteria or when you need custom visual analysis for stakeholder communication.
- [Model Evaluation](/mlflow-website/docs/latest/ml/evaluation/model-eval.md): This guide covers MLflow's core model evaluation capabilities for classification and regression tasks, showing how to comprehensively assess model performance with automated metrics, visualizations, and diagnostic tools.
- [Plugin Evaluators](/mlflow-website/docs/latest/ml/evaluation/plugin-evaluators.md): MLflow's evaluation framework is designed for extensibility, allowing specialized evaluation plugins to seamlessly integrate with the core evaluation workflow. These plugins extend MLflow's capabilities with domain-specific validation, advanced vulnerability scanning, and specialized testing frameworks developed by the broader ML community.
- [SHAP Integration](/mlflow-website/docs/latest/ml/evaluation/shap.md): MLflow's built-in SHAP integration provides automatic model explanations and feature importance analysis during evaluation. SHAP (SHapley Additive exPlanations) values help you understand what drives your model's predictions, making your ML models more interpretable and trustworthy.
- [Getting Started with MLflow](/mlflow-website/docs/latest/ml/getting-started.md): If you're new to MLflow or seeking a refresher on its core functionalities, these
- [Deep Learning Quickstart](/mlflow-website/docs/latest/ml/getting-started/deep-learning.md): In this tutorial, we demonstrate how to use MLflow to track deep learning experiments with Pytorch. By combining MLflow
- [Tracking Hyperparameter Tuning with MLflow](/mlflow-website/docs/latest/ml/getting-started/hyperparameter-tuning.md): Hyperparameter tuning is an important process for improving the performance of a machine learning model, however, it can be cumbersome to manually track and compare the different trials. MLflow provides a powerful framework for hyperparameter tuning that allows you to systematically explore the hyperparameter space and find the best model.
- [MLflow Tracking Quickstart](/mlflow-website/docs/latest/ml/getting-started/quickstart.md): Looking for using MLflow for LLMs/Agent development? Checkout the MLflow for GenAI documentation instead. This guide is intended for data scientists who train traditional machine learning models, such as decision trees.
- [Connect Your Development Environment to MLflow](/mlflow-website/docs/latest/ml/getting-started/running-notebooks.md): Learn how to connect your development environment to MLflow, whether using OSS MLflow or a managed offering.
- [MLflow Models](/mlflow-website/docs/latest/ml/model.md): An MLflow Model is a standard format for packaging machine learning models that can be used in a
- [Managing Dependencies in MLflow Models](/mlflow-website/docs/latest/ml/model/dependencies.md): MLflow Model is a standard format that packages a machine learning model with its dependencies and other metadata.
- [Models From Code](/mlflow-website/docs/latest/ml/model/models-from-code.md): Models from Code is available in MLflow 2.12.2 and above. For earlier versions, use the legacy serialization methods outlined in the Custom Python Model documentation.
- [MLflow Signature Playground Notebook](/mlflow-website/docs/latest/ml/model/notebooks/signature_examples.md): Download this notebook
- [MLflow PythonModel Guide](/mlflow-website/docs/latest/ml/model/python_model.md): Introduction to MLflow PythonModel
- [Model Signatures and Input Examples](/mlflow-website/docs/latest/ml/model/signatures.md): Model signatures and input examples are foundational components that define how your models should be used, ensuring consistent and reliable interactions across MLflow's ecosystem.
- [MLflow Model Registry](/mlflow-website/docs/latest/ml/model-registry.md): The MLflow Model Registry is a centralized model store, set of APIs and a UI designed to
- [Model Registry Tutorials](/mlflow-website/docs/latest/ml/model-registry/tutorial.md): Explore the full functionality of the Model Registry in this tutorial ‚Äî from registering a model and inspecting its structure, to loading a specific model version for further use.
- [Model Registry Workflows](/mlflow-website/docs/latest/ml/model-registry/workflow.md): This guide walks you through using the MLflow Model Registry via both the UI and API. Learn how to register models, manage versions, apply aliases and tags, and organize your models for deployment.
- [MLflow Plugins](/mlflow-website/docs/latest/ml/plugins.md): MLflow's plugin architecture enables seamless integration with third-party tools and custom infrastructure. As a framework-agnostic platform, MLflow provides developer APIs for extending functionality across storage, authentication, execution backends, and model evaluation.
- [MLflow Projects](/mlflow-website/docs/latest/ml/projects.md): MLflow Projects provide a standard format for packaging and sharing reproducible data science code. Based on simple conventions, Projects enable seamless collaboration and automated execution across different environments and platforms.
- [Search Experiments](/mlflow-website/docs/latest/ml/search/search-experiments.md): and MlflowClient.search_experiments()
- [Search Logged Models](/mlflow-website/docs/latest/ml/search/search-models.md): This guide will walk you through how to search for logged models in MLflow using both the MLflow UI and Python API. This resource will be valuable if you're interested in querying specific models based on their metrics, params, tags, or model metadata.
- [Search Runs](/mlflow-website/docs/latest/ml/search/search-runs.md): This guide will walk you through how to search your MLflow runs through the MLflow UI and Python API.
- [MLflow Tracking](/mlflow-website/docs/latest/ml/tracking.md): The MLflow Tracking is an API and UI for logging parameters, code versions, metrics, and output files
- [Automatic Logging with MLflow Tracking](/mlflow-website/docs/latest/ml/tracking/autolog.md): Auto logging is a powerful feature that allows you to log metrics, parameters, and models without the need for explicit log statements. All you need to do is to
- [MLflow Tracking Quickstart](/mlflow-website/docs/latest/ml/tracking/quickstart.md): The purpose of this quickstart is to provide a quick guide to the most essential core APIs of MLflow Tracking. In just a few minutes of following along with this quickstart, you will learn:
- [System Metrics](/mlflow-website/docs/latest/ml/tracking/system-metrics.md): MLflow allows users to log system metrics including CPU stats, GPU stats, memory usage, network traffic, and
- [MLflow Tracking APIs](/mlflow-website/docs/latest/ml/tracking/tracking-api.md): MLflow Tracking provides comprehensive APIs across multiple programming languages to capture your machine learning experiments. Whether you prefer automatic instrumentation or granular control, MLflow adapts to your workflow.
- [Tracking Experiments with Local Database](/mlflow-website/docs/latest/ml/tracking/tutorials/local-database.md): In this tutorial, you will learn how to use a local database to track your experiment metadata with MLflow.
- [Remote Experiment Tracking with MLflow Tracking Server](/mlflow-website/docs/latest/ml/tracking/tutorials/remote-server.md): In this tutorial, you will learn how to set up MLflow Tracking environment for team development using the MLflow Tracking Server.
- [MLflow for Traditional Machine Learning](/mlflow-website/docs/latest/ml/traditional-ml.md): Traditional machine learning forms the backbone of data science, powering critical applications across every industry. From fraud detection in banking to demand forecasting in retail, these proven algorithms deliver reliable, interpretable results that businesses depend on every day.
- [MLflow Prophet Integration](/mlflow-website/docs/latest/ml/traditional-ml/prophet.md): Introduction
- [Prophet with MLflow](/mlflow-website/docs/latest/ml/traditional-ml/prophet/guide.md): In this comprehensive guide, we'll explore how to use Prophet with MLflow for time series forecasting, experiment tracking, and model deployment. We'll cover everything from basic forecasting workflows to advanced business scenario modeling and production deployment patterns.
- [MLflow Scikit-learn Integration](/mlflow-website/docs/latest/ml/traditional-ml/sklearn.md): Introduction
- [Scikit-learn with MLflow](/mlflow-website/docs/latest/ml/traditional-ml/sklearn/guide.md): In this comprehensive guide, we'll walk you through how to use scikit-learn with MLflow for experiment tracking, model management, and production deployment. We'll cover both autologging and manual logging approaches, from basic usage to advanced production patterns.
- [Get Started with MLflow + Scikit-learn](/mlflow-website/docs/latest/ml/traditional-ml/sklearn/quickstart/quickstart-sklearn.md): Download this notebook
- [MLflow Spark MLlib Integration](/mlflow-website/docs/latest/ml/traditional-ml/sparkml.md): Introduction
- [Spark MLlib with MLflow](/mlflow-website/docs/latest/ml/traditional-ml/sparkml/guide.md): In this comprehensive guide, we'll walk you through how to use Spark MLlib with MLflow for experiment tracking, model management, and production deployment. We'll cover basic model logging, pipeline tracking, and deployment patterns that will get you productive quickly with distributed machine learning.
- [Building Custom Python Function Models with MLflow](/mlflow-website/docs/latest/ml/traditional-ml/tutorials/creating-custom-pyfunc.md): MLflow offers a wide range of pre-defined model flavors, but there are instances where you'd want to go
- [Custom PyFuncs with MLflow - Notebooks](/mlflow-website/docs/latest/ml/traditional-ml/tutorials/creating-custom-pyfunc/notebooks.md): If you would like to view the notebooks in this guide in their entirety, each notebook can viewed or downloaded directly below.
- [Introduction to MLflow Custom Pyfunc](/mlflow-website/docs/latest/ml/traditional-ml/tutorials/creating-custom-pyfunc/notebooks/basic-pyfunc.md): Download this notebook
- [Creating a Custom Model: "Add N" Model](/mlflow-website/docs/latest/ml/traditional-ml/tutorials/creating-custom-pyfunc/notebooks/introduction.md): Download this notebook
- [Customizing a Model's predict method](/mlflow-website/docs/latest/ml/traditional-ml/tutorials/creating-custom-pyfunc/notebooks/override-predict.md): Download this notebook
- [Models, Flavors, and PyFuncs in MLflow](/mlflow-website/docs/latest/ml/traditional-ml/tutorials/creating-custom-pyfunc/part1-named-flavors.md): In the MLflow ecosystem, "flavors" play a pivotal role in model management. Essentially, a "flavor" is a designated wrapper for specific machine
- [Understanding PyFunc in MLflow](/mlflow-website/docs/latest/ml/traditional-ml/tutorials/creating-custom-pyfunc/part2-pyfunc-components.md): In the realm of MLflow, while named flavors offer specific functionalities tailored to popular frameworks, there are situations and
- [Hyperparameter Tuning with MLflow and Optuna](/mlflow-website/docs/latest/ml/traditional-ml/tutorials/hyperparameter-tuning.md): In this guide, we venture into a frequent use case of MLflow Tracking: hyperparameter tuning.
- [Hyperparameter tuning with MLflow and child runs - Notebooks](/mlflow-website/docs/latest/ml/traditional-ml/tutorials/hyperparameter-tuning/notebooks.md): If you would like to view the notebooks in this guide in their entirety, each notebook can be either viewed or downloaded below.
- [MLflow with Optuna: Hyperparameter Optimization and Tracking](/mlflow-website/docs/latest/ml/traditional-ml/tutorials/hyperparameter-tuning/notebooks/hyperparameter-tuning-with-child-runs.md): Download this notebook
- [Logging Visualizations with MLflow](/mlflow-website/docs/latest/ml/traditional-ml/tutorials/hyperparameter-tuning/notebooks/logging-plots-in-mlflow.md): Download this notebook
- [Leveraging Child Runs in MLflow for Hyperparameter Tuning](/mlflow-website/docs/latest/ml/traditional-ml/tutorials/hyperparameter-tuning/notebooks/parent-child-runs.md): Download this notebook
- [Understanding Parent and Child Runs in MLflow](/mlflow-website/docs/latest/ml/traditional-ml/tutorials/hyperparameter-tuning/part1-child-runs.md): Introduction
- [Leveraging Visualizations and MLflow for In-depth Model Analysis](/mlflow-website/docs/latest/ml/traditional-ml/tutorials/hyperparameter-tuning/part2-logging-plots.md): Introduction
- [Serving Multiple Models on a Single Endpoint with a Custom PyFunc Model](/mlflow-website/docs/latest/ml/traditional-ml/tutorials/serving-multiple-models-with-pyfunc.md): This tutorial addresses a common scenario in machine learning: serving multiple models through a
- [Deploy an MLflow PyFunc model with Model Serving](/mlflow-website/docs/latest/ml/traditional-ml/tutorials/serving-multiple-models-with-pyfunc/notebooks/MME_Tutorial.md): Download this notebook
- [MLflow XGBoost Integration](/mlflow-website/docs/latest/ml/traditional-ml/xgboost.md): Introduction
- [XGBoost with MLflow](/mlflow-website/docs/latest/ml/traditional-ml/xgboost/guide.md): In this comprehensive guide, we'll explore how to use XGBoost with MLflow for experiment tracking, model management, and production deployment. We'll cover both the native XGBoost API and scikit-learn compatible interface, from basic autologging to advanced distributed training patterns.
- [Get Started with MLflow + XGBoost](/mlflow-website/docs/latest/ml/traditional-ml/xgboost/quickstart/quickstart-xgboost.md): Download this notebook
- [Tutorials and Examples](/mlflow-website/docs/latest/ml/tutorials-and-examples.md): Welcome to our Tutorials and Examples hub! Here you'll find a curated set of resources to help you get started and deepen your knowledge of MLflow. Whether you're fine-tuning hyperparameters, orchestrating complex workflows, or integrating MLflow into your training code, these examples will guide you step by step.
- [Webhooks](/mlflow-website/docs/latest/ml/webhooks.md): - This feature is still experimental and may change in future releases.
- [Search the documentation](/mlflow-website/docs/latest/search.md)
- [Self-Hosting MLflow](/mlflow-website/docs/latest/self-hosting.md): #### _The most vendor-neutral MLOps/LLMOps platform in the world._
- [Artifact Stores](/mlflow-website/docs/latest/self-hosting/architecture/artifact-store.md): The artifact store is a core component in MLflow Tracking where MLflow stores (typically large) artifacts
- [Backend Stores](/mlflow-website/docs/latest/self-hosting/architecture/backend-store.md): The backend store is a core component in MLflow that stores metadata for
- [Architecture Overview](/mlflow-website/docs/latest/self-hosting/architecture/overview.md): MLflow's architecture is simple yet flexible. Whether your needs are for local solo development or production-scale deployment, you can choose the right components and backend options to fit your needs.
- [MLflow Tracking Server](/mlflow-website/docs/latest/self-hosting/architecture/tracking-server.md): MLflow tracking server is a stand-alone HTTP server that serves multiple REST API endpoints for tracking runs/experiments.
- [How to Upgrade MLflow](/mlflow-website/docs/latest/self-hosting/migration.md): MLflow evolves rapidly to provide new features and improve the framework. This document outlines the steps to upgrade self-hosted MLflow servers to the latest version.
- [Authentication with Username and Password](/mlflow-website/docs/latest/self-hosting/security/basic-http-auth.md): MLflow supports basic HTTP authentication to enable access control over experiments and registered models.
- [Custom Authentication](/mlflow-website/docs/latest/self-hosting/security/custom.md): MLflow's authentication system is designed to be extensible. You can use custom authentication methods through plugins or pluggable functions.
- [Protect Your Tracking Server from Network Exposure](/mlflow-website/docs/latest/self-hosting/security/network.md): MLflow 3.5.0+ includes security middleware to protect against DNS rebinding, CORS attacks, and clickjacking. These features are available with the default FastAPI-based tracking server (uvicorn).
- [SSO (Single Sign-On)](/mlflow-website/docs/latest/self-hosting/security/sso.md): You can use SSO (Single Sign-On) to authenticate users to your MLflow instance, by installing a custom plugin or using a reverse proxy.
- [Troubleshooting & FAQs](/mlflow-website/docs/latest/self-hosting/troubleshooting.md): This page aggregates common production issues for self-hosted MLflow deployments and how to resolve them.
