<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-classic-ml docs-version-current docs-doc-page docs-doc-id-deep-learning/transformers/guide/index" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">ü§ó Transformers within MLflow | MLflow</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://mlflow.org/docs/latest/ml/deep-learning/transformers/guide/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-classic-ml-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-classic-ml-current"><meta data-rh="true" property="og:title" content="ü§ó Transformers within MLflow | MLflow"><meta data-rh="true" name="description" content="The transformers model flavor enables logging of transformers models, components, and pipelines"><meta data-rh="true" property="og:description" content="The transformers model flavor enables logging of transformers models, components, and pipelines"><link data-rh="true" rel="icon" href="/docs/latest/images/favicon.ico"><link data-rh="true" rel="canonical" href="https://mlflow.org/docs/latest/ml/deep-learning/transformers/guide/"><link data-rh="true" rel="alternate" href="https://mlflow.org/docs/latest/ml/deep-learning/transformers/guide/" hreflang="en"><link data-rh="true" rel="alternate" href="https://mlflow.org/docs/latest/ml/deep-learning/transformers/guide/" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://XKVLO8P882-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Deep Learning üï∏Ô∏è","item":"https://mlflow.org/docs/latest/ml/deep-learning/"},{"@type":"ListItem","position":2,"name":"Transformers","item":"https://mlflow.org/docs/latest/ml/deep-learning/transformers/"},{"@type":"ListItem","position":3,"name":"ü§ó Transformers within MLflow","item":"https://mlflow.org/docs/latest/ml/deep-learning/transformers/guide/"}]}</script><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=GTM-N6WMTTJ"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","GTM-N6WMTTJ",{anonymize_ip:!0}),gtag("config","AW-16857946923",{anonymize_ip:!0})</script>
<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var g=t.getElementsByTagName(a)[0],m=t.createElement(a);m.async=!0,m.src="https://www.googletagmanager.com/gtm.js?id=GTM-N6WMTTJ",g.parentNode.insertBefore(m,g)}(window,document,"script","dataLayer")</script>



<link rel="search" type="application/opensearchdescription+xml" title="MLflow" href="/docs/latest/opensearch.xml">





<script src="/docs/latest/js/runllm.js" defer="defer"></script><link rel="stylesheet" href="/docs/latest/assets/css/styles.d8f6f8a6.css">
<script src="/docs/latest/assets/js/runtime~main.90112150.js" defer="defer"></script>
<script src="/docs/latest/assets/js/main.faa53f1b.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>


<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/docs/latest/"><div class="navbar__logo"><img src="/docs/latest/images/logo-light.svg" alt="MLflow Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/docs/latest/images/logo-dark.svg" alt="MLflow Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Documentation</a><ul class="dropdown__menu"><li><a aria-current="page" class="dropdown__link ml-docs-link dropdown__link--active" href="/docs/latest/ml/">ML Docs</a></li><li><a class="dropdown__link genai-docs-link" href="/docs/latest/genai/">GenAI Docs</a></li></ul></div><a href="https://mlflow.org/docs/latest/api_reference/index.html" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">API Reference</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/mlflow/mlflow" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link github-link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sidebar-top-level-category"><a class="menu__link" href="/docs/latest/ml/">MLflow</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/ml/mlflow-3/">MLflow 3.0</a><button aria-label="Expand sidebar category &#x27;MLflow 3.0&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/ml/getting-started/">Getting Started üöÄ</a><button aria-label="Expand sidebar category &#x27;Getting Started üöÄ&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/latest/ml/traditional-ml/">Machine Learning ü§ñ</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/ml/traditional-ml/">Traditional ML</a><button aria-label="Expand sidebar category &#x27;Traditional ML&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/docs/latest/ml/deep-learning/">Deep Learning üï∏Ô∏è</a><button aria-label="Collapse sidebar category &#x27;Deep Learning üï∏Ô∏è&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/ml/deep-learning/keras/">Keras</a><button aria-label="Expand sidebar category &#x27;Keras&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/ml/deep-learning/pytorch/">PyTorch</a><button aria-label="Expand sidebar category &#x27;PyTorch&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/ml/deep-learning/tensorflow/">TensorFlow</a><button aria-label="Expand sidebar category &#x27;TensorFlow&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/docs/latest/ml/deep-learning/transformers/">Transformers</a><button aria-label="Collapse sidebar category &#x27;Transformers&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/latest/ml/deep-learning/transformers/guide/">ü§ó Transformers within MLflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/ml/deep-learning/transformers/large-models/">Working with Large Transformers Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/ml/deep-learning/transformers/task/">Transformers Task Types</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/ml/deep-learning/transformers/tutorials/">Tutorials</a><button aria-label="Expand sidebar category &#x27;Tutorials&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/ml/deep-learning/sentence-transformers/">Sentence Transformers</a><button aria-label="Expand sidebar category &#x27;Sentence Transformers&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/ml/deep-learning/spacy/">spaCy</a><button aria-label="Expand sidebar category &#x27;spaCy&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/docs/latest/ml/tracking/">Build üî® </a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/ml/tracking/">MLflow Tracking üìà</a><button aria-label="Expand sidebar category &#x27;MLflow Tracking üìà&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/ml/model/">MLflow Model üß†</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/ml/dataset/">MLflow Datasets üóÉÔ∏è</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/ml/evaluation/">Evaluate üéØ</a><button aria-label="Expand sidebar category &#x27;Evaluate üéØ&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/latest/ml/model-registry/">Deploy üö¢</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/latest/ml/tracking/#tracking-setup">Team Collaboration üë•</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a href="https://mlflow.org/docs/latest/api_reference/python_api/index.html" target="_blank" rel="noopener noreferrer" class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false">API References</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer" class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false">More</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/docs/latest/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Machine Learning ü§ñ</span></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/docs/latest/ml/deep-learning/"><span>Deep Learning üï∏Ô∏è</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/docs/latest/ml/deep-learning/transformers/"><span>Transformers</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">ü§ó Transformers within MLflow</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>ü§ó Transformers within MLflow</h1></header>
<p>The <code>transformers</code> model flavor enables logging of <a href="https://huggingface.co/docs/transformers/index" target="_blank" rel="noopener noreferrer">transformers models, components, and pipelines</a>
in MLflow format via the <a href="/docs/latest/api_reference/python_api/mlflow.transformers.html#mlflow.transformers.save_model" target="_blank"><code>mlflow.transformers.save_model<!-- -->()</code></a> and <a href="/docs/latest/api_reference/python_api/mlflow.transformers.html#mlflow.transformers.log_model" target="_blank"><code>mlflow.transformers.log_model<!-- -->()</code></a> functions. Use of these
functions also adds the <code>python_function</code> flavor to the MLflow Models that they produce, allowing the model to be
interpreted as a generic Python function for inference via <a href="/docs/latest/api_reference/python_api/mlflow.pyfunc.html#mlflow.pyfunc.load_model" target="_blank"><code>mlflow.pyfunc.load_model<!-- -->()</code></a>.
You can also use the <a href="/docs/latest/api_reference/python_api/mlflow.transformers.html#mlflow.transformers.load_model" target="_blank"><code>mlflow.transformers.load_model<!-- -->()</code></a> function to load a saved or logged MLflow
Model with the <code>transformers</code> flavor in the native transformers formats.</p>
<p>This page explains the detailed features and configurations of the MLflow <code>transformers</code> flavor. For the general introduction about the MLflow&#x27;s Transformer integration,
please refer to the <a href="/docs/latest/ml/deep-learning/transformers">MLflow Transformers Flavor</a> page.</p>
<div class="tableOfContentsInline_prmo"><ul class="table-of-contents"><li><a href="#loading-a-transformers-model-as-a-python-function">Loading a Transformers Model as a Python Function</a></li><li><a href="#saving-prompt-templates-with-transformer-pipelines">Saving Prompt Templates with Transformer Pipelines</a></li><li><a href="#using-model-config-and-model-signature-params-for-inference">Using model_config and Model Signature Params for Inference</a></li><li><a href="#pipelines-vs-component-logging">Pipelines vs. Component Logging</a></li><li><a href="#automatic-metadata-and-modelcard-logging">Automatic Metadata and ModelCard logging</a></li><li><a href="#automatic-signature-inference">Automatic Signature inference</a></li><li><a href="#scalability-for-inference">Scale Inference with Overriding Pytorch dtype</a></li><li><a href="#input-data-types-for-audio-pipelines">Input Data Types for Audio Pipelines</a></li><li><a href="#peft-models-in-mlflow-transformers-flavor">PEFT Models in MLflow Transformers flavor</a></li></ul></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="loading-a-transformers-model-as-a-python-function">Loading a Transformers Model as a Python Function<a href="#loading-a-transformers-model-as-a-python-function" class="hash-link" aria-label="Direct link to Loading a Transformers Model as a Python Function" title="Direct link to Loading a Transformers Model as a Python Function">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="supported-transformers-pipeline-types">Supported Transformers Pipeline types<a href="#supported-transformers-pipeline-types" class="hash-link" aria-label="Direct link to Supported Transformers Pipeline types" title="Direct link to Supported Transformers Pipeline types">‚Äã</a></h3>
<p>The <code>transformers</code> <a href="/docs/latest/ml/model#pyfunc-model-flavor">python_function (pyfunc) model flavor</a> simplifies
and standardizes both the inputs and outputs of pipeline inference. This conformity allows for serving
and batch inference by coercing the data structures that are required for <code>transformers</code> inference pipelines
to formats that are compatible with json serialization and casting to Pandas DataFrames.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>Certain <em>TextGenerationPipeline</em> types, particularly instructional-based ones, may return the original
prompt and included line-formatting carriage returns <em>&quot;\n&quot;</em> in their outputs. For these pipeline types,
if you would like to disable the prompt return, you can set the following in the <em>model_config</em> dictionary when
saving or logging the model: <em>&quot;include_prompt&quot;: False</em>. To remove the newline characters from within the body
of the generated text output, you can add the <em>&quot;collapse_whitespace&quot;: True</em> option to the <em>model_config</em> dictionary.
If the pipeline type being saved does not inherit from <em>TextGenerationPipeline</em>, these options will not perform
any modification to the output returned from pipeline inference.</p></div></div>
<p>In the current version, audio and text-based large language
models are supported for use with <code>pyfunc</code>, while computer vision, multi-modal, timeseries,
reinforcement learning, and graph models are only supported for native type loading via <a href="/docs/latest/api_reference/python_api/mlflow.transformers.html#mlflow.transformers.load_model" target="_blank"><code>mlflow.transformers.load_model<!-- -->()</code></a></p>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>attention</div><div class="admonitionContent_BuS1"><p>Not all <code>transformers</code> pipeline types are supported. See the table below for the list of currently supported Pipeline
types that can be loaded as <code>pyfunc</code>.</p><p>Future releases of MLflow will introduce <code>pyfunc</code> support for these additional types.</p></div></div>
<p>The table below shows the mapping of <code>transformers</code> pipeline types to the <a href="/docs/latest/ml/model#pyfunc-model-flavor">python_function (pyfunc) model flavor</a>
data type inputs and outputs.</p>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>important</div><div class="admonitionContent_BuS1"><p>The inputs and outputs of the <code>pyfunc</code> implementation of these pipelines <em>are not guaranteed to match</em> the input types and output types that would
return from a native use of a given pipeline type. If your use case requires access to scores, top_k results, or other additional references within
the output from a pipeline inference call, please use the native implementation by loading via <a href="/docs/latest/api_reference/python_api/mlflow.transformers.html#mlflow.transformers.load_model" target="_blank"><code>mlflow.transformers.load_model<!-- -->()</code></a> to
receive the full output.</p><p>Similarly, if your use case requires the use of raw tensor outputs or processing of outputs through an external <code>processor</code> module, load the
model components directly as a <code>dict</code> by calling <a href="/docs/latest/api_reference/python_api/mlflow.transformers.html#mlflow.transformers.load_model" target="_blank"><code>mlflow.transformers.load_model<!-- -->()</code></a> and specify the <code>return_type</code> argument as &#x27;components&#x27;.</p></div></div>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Pipeline Type</th><th>Input Type</th><th>Output Type</th></tr></thead><tbody><tr><td>Instructional Text Generation</td><td>str or List[str]</td><td>List[str]</td></tr><tr><td>Conversational</td><td>str or List[str]</td><td>List[str]</td></tr><tr><td>Summarization</td><td>str or List[str]</td><td>List[str]</td></tr><tr><td>Text Classification</td><td>str or List[str]</td><td>pd.DataFrame (dtypes: {&#x27;label&#x27;: str, &#x27;score&#x27;: double})</td></tr><tr><td>Text Generation</td><td>str or List[str]</td><td>List[str]</td></tr><tr><td>Text2Text Generation</td><td>str or List[str]</td><td>List[str]</td></tr><tr><td>Token Classification</td><td>str or List[str]</td><td>List[str]</td></tr><tr><td>Translation</td><td>str or List[str]</td><td>List[str]</td></tr><tr><td>ZeroShot Classification*</td><td>Dict[str, [List[str] | str]*</td><td>pd.DataFrame (dtypes: {&#x27;sequence&#x27;: str, &#x27;labels&#x27;: str, &#x27;scores&#x27;: double})</td></tr><tr><td>Table Question Answering**</td><td>Dict[str, [List[str] | str]**</td><td>List[str]</td></tr><tr><td>Question Answering***</td><td>Dict[str, str]***</td><td>List[str]</td></tr><tr><td>Fill Mask****</td><td>str or List[str]****</td><td>List[str]</td></tr><tr><td>Feature Extraction</td><td>str or List[str]</td><td>np.ndarray</td></tr><tr><td>AutomaticSpeechRecognition</td><td>bytes*****, str, or np.ndarray</td><td>List[str]</td></tr><tr><td>AudioClassification</td><td>bytes*****, str, or np.ndarray</td><td>pd.DataFrame (dtypes: {&#x27;label&#x27;: str, &#x27;score&#x27;: double})</td></tr></tbody></table></div>
<p>* A collection of these inputs can also be passed. The standard required key names are &#x27;sequences&#x27; and &#x27;candidate_labels&#x27;, but these may vary.
Check the input requirements for the architecture that you&#x27;re using to ensure that the correct dictionary key names are provided.</p>
<p>** A collection of these inputs can also be passed. The reference table must be a json encoded dict (i.e. {&#x27;query&#x27;: &#x27;what did we sell most of?&#x27;, &#x27;table&#x27;: json.dumps(table_as_dict)})</p>
<p>*** A collection of these inputs can also be passed. The standard required key names are &#x27;question&#x27; and &#x27;context&#x27;. Verify the expected input key names match the
expected input to the model to ensure your inference request can be read properly.</p>
<p>**** The mask syntax for the model that you&#x27;ve chosen is going to be specific to that model&#x27;s implementation. Some are &#x27;[MASK]&#x27;, while others are &#x27;&lt;mask&gt;&#x27;. Verify the expected syntax to
avoid failed inference requests.</p>
<p>***** If using <em>pyfunc</em> in MLflow Model Serving for realtime inference, the raw audio in bytes format must be base64 encoded prior to submitting to the endpoint. String inputs will be interpreted as uri locations.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="example-of-loading-a-transformers-model-as-a-python-function">Example of loading a transformers model as a python function<a href="#example-of-loading-a-transformers-model-as-a-python-function" class="hash-link" aria-label="Direct link to Example of loading a transformers model as a python function" title="Direct link to Example of loading a transformers model as a python function">‚Äã</a></h3>
<p>In the below example, a simple pre-trained model is used within a pipeline. After logging to MLflow, the pipeline is
loaded as a <code>pyfunc</code> and used to generate a response from a passed-in list of strings.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> transformers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Read a pre-trained conversation pipeline from HuggingFace hub</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">conversational_pipeline </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pipeline</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;microsoft/DialoGPT-medium&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Define the signature</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">signature </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">models</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">infer_signature</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;Hi there, chatbot!&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">generate_signature_output</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        conversational_pipeline</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Hi there, chatbot!&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Log the pipeline</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">with</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">start_run</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_info </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">log_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        transformers_model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">conversational_pipeline</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        name</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;chatbot&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        task</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;conversational&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        signature</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">signature</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        input_example</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;A clever and witty question&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Load the saved pipeline as pyfunc</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chatbot </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pyfunc</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model_uri</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">model_info</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_uri</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Ask the chatbot a question</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">response </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> chatbot</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;What is machine learning?&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">response</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># &gt;&gt; [It&#x27;s a new thing that&#x27;s been around for a while.]</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="saving-prompt-templates-with-transformer-pipelines">Saving Prompt Templates with Transformer Pipelines<a href="#saving-prompt-templates-with-transformer-pipelines" class="hash-link" aria-label="Direct link to Saving Prompt Templates with Transformer Pipelines" title="Direct link to Saving Prompt Templates with Transformer Pipelines">‚Äã</a></h2>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>This feature is only available in MLflow 2.10.0 and above.</p></div></div>
<p>MLflow supports specifying prompt templates for certain pipeline types:</p>
<ul>
<li><a href="https://huggingface.co/transformers/main_classes/pipelines.html#transformers.FeatureExtractionPipeline" target="_blank" rel="noopener noreferrer">feature-extraction</a></li>
<li><a href="https://huggingface.co/transformers/main_classes/pipelines.html#transformers.FillMaskPipeline" target="_blank" rel="noopener noreferrer">fill-mask</a></li>
<li><a href="https://huggingface.co/transformers/main_classes/pipelines.html#transformers.SummarizationPipeline" target="_blank" rel="noopener noreferrer">summarization</a></li>
<li><a href="https://huggingface.co/transformers/main_classes/pipelines.html#transformers.Text2TextGenerationPipeline" target="_blank" rel="noopener noreferrer">text2text-generation</a></li>
<li><a href="https://huggingface.co/transformers/main_classes/pipelines.html#transformers.TextGenerationPipeline" target="_blank" rel="noopener noreferrer">text-generation</a></li>
</ul>
<p>Prompt templates are strings that are used to format user inputs prior to <code>pyfunc</code> inference. To specify a prompt template,
use the <code>prompt_template</code> argument when calling <a href="/docs/latest/api_reference/python_api/mlflow.transformers.html#mlflow.transformers.save_model" target="_blank"><code>mlflow.transformers.save_model<!-- -->()</code></a> or <a href="/docs/latest/api_reference/python_api/mlflow.transformers.html#mlflow.transformers.log_model" target="_blank"><code>mlflow.transformers.log_model<!-- -->()</code></a>.
The prompt template must be a string with a single format placeholder, <code>{prompt}</code>.</p>
<p>For example:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> pipeline</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Initialize a pipeline. `distilgpt2` uses a &quot;text-generation&quot; pipeline</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">generator </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> pipeline</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;distilgpt2&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Define a prompt template</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">prompt_template </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Answer the following question: {prompt}&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Save the model</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">save_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    transformers_model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">generator</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    path</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;path/to/model&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    prompt_template</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">prompt_template</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<p>When the model is then loaded with <a href="/docs/latest/api_reference/python_api/mlflow.pyfunc.html#mlflow.pyfunc.load_model" target="_blank"><code>mlflow.pyfunc.load_model<!-- -->()</code></a>, the prompt
template will be used to format user inputs before passing them into the pipeline:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Load the model with pyfunc</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pyfunc</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;path/to/model&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># The prompt template will be used to format this input, so the</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># string that is passed to the text-generation pipeline will be:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># &quot;Answer the following question: What is MLflow?&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;What is MLflow?&quot;</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p><code>text-generation</code> pipelines with a prompt template will have the
<a href="https://huggingface.co/docs/huggingface_hub/main/en/package_reference/inference_client#huggingface_hub.inference._text_generation.TextGenerationParameters.return_full_text" target="_blank" rel="noopener noreferrer">return_full_text pipeline argument</a>
set to <code>False</code> by default. This is to prevent the template from being shown to the users,
which could potentially cause confusion as it was not part of their original input. To
override this behaviour, either set <code>return_full_text</code> to <code>True</code> via <code>params</code>, or by
including it in a <code>model_config</code> dict in <code>log_model()</code>. See <a href="#using-model-config-and-model-signature-params-for-inference">this section</a>
for more details on how to do this.</p></div></div>
<p>For a more in-depth guide, check out the <a href="/docs/latest/ml/deep-learning/transformers/tutorials/prompt-templating/prompt-templating/">Prompt Templating notebook</a>!</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="using-model-config-and-model-signature-params-for-inference">Using model_config and Model Signature Params for Inference<a href="#using-model-config-and-model-signature-params-for-inference" class="hash-link" aria-label="Direct link to Using model_config and Model Signature Params for Inference" title="Direct link to Using model_config and Model Signature Params for Inference">‚Äã</a></h2>
<p>For <em>transformers</em> inference, there are two ways to pass in additional arguments to the pipeline.</p>
<ul>
<li>Use <code>model_config</code> when saving/logging the model. Optionally, specify <code>model_config</code> when calling <code>load_model</code>.</li>
<li>Specify params at inference time when calling <code>predict()</code></li>
</ul>
<p>Use <code>model_config</code> to control how the model is loaded and inference performed for all input samples. Configuration in
<code>model_config</code> is not overridable at <code>predict()</code> time unless a <code>ModelSignature</code> is indicated with the same parameters.</p>
<p>Use <code>ModelSignature</code> with params schema, on the other hand, to allow downstream consumers to provide additional inference
params that may be needed to compute the predictions for their specific samples.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>If both <code>model_config</code> and <code>ModelSignature</code> with parameters are saved when logging model, both of them
will be used for inference. The default parameters in <code>ModelSignature</code> will override the params in <code>model_config</code>.
If extra <code>params</code> are provided at inference time, they take precedence over all params. We recommend using
<code>model_config</code> for those parameters needed to run the model in general for all the samples. Then, add
<code>ModelSignature</code> with parameters for those extra parameters that you want downstream consumers to indicated at
per each of the samples.</p></div></div>
<ul>
<li>Using <code>model_config</code></li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">models </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> infer_signature</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> generate_signature_output</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> transformers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">architecture </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;mrm8488/t5-base-finetuned-common_gen&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pipeline</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    task</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;text2text-generation&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tokenizer</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">T5TokenizerFast</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">architecture</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">T5ForConditionalGeneration</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">architecture</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;pencil draw paper&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Infer the signature</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">signature </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> infer_signature</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    data</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    generate_signature_output</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> data</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Define an model_config</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model_config </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;num_beams&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;max_length&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">30</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;do_sample&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;remove_invalid_values&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Saving model_config with the model</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">save_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    path</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;text2text&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_config</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">model_config</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    signature</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">signature</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pyfunc_loaded </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pyfunc</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;text2text&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># model_config will be applied</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">result </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> pyfunc_loaded</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># overriding some inference configuration with different values</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pyfunc_loaded </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pyfunc</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;text2text&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> model_config</span><span class="token operator" style="color:#393A34">=</span><span class="token builtin">dict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">do_sample</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">False</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>Note that in the previous example, the user can&#x27;t override the configuration <code>do_sample</code>
when calling <code>predict</code>.</p></div></div>
<ul>
<li>Specifying params at inference time</li>
</ul>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">models </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> infer_signature</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> generate_signature_output</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> transformers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">architecture </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;mrm8488/t5-base-finetuned-common_gen&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pipeline</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    task</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;text2text-generation&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tokenizer</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">T5TokenizerFast</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">architecture</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">T5ForConditionalGeneration</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">architecture</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;pencil draw paper&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Define an model_config</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model_config </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;num_beams&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;remove_invalid_values&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Define the inference parameters params</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">inference_params </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;max_length&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">30</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;do_sample&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Infer the signature including params</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">signature_with_params </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> infer_signature</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    data</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    generate_signature_output</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> data</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    params</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">inference_params</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Saving model with signature and model config</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">save_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    path</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;text2text&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_config</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">model_config</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    signature</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">signature_with_params</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pyfunc_loaded </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pyfunc</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;text2text&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Pass params at inference time</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">params </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;max_length&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">20</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;do_sample&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">False</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># In this case we only override max_length and do_sample,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># other params will use the default one saved on ModelSignature</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># or in the model configuration.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># The final params used for prediction is as follows:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># {</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">#    &quot;num_beams&quot;: 5,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">#    &quot;max_length&quot;: 20,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">#    &quot;do_sample&quot;: False,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic">#    &quot;remove_invalid_values&quot;: True,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># }</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">result </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> pyfunc_loaded</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> params</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">params</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="pipelines-vs-component-logging">Pipelines vs. Component Logging<a href="#pipelines-vs-component-logging" class="hash-link" aria-label="Direct link to Pipelines vs. Component Logging" title="Direct link to Pipelines vs. Component Logging">‚Äã</a></h2>
<p>The transformers flavor has two different primary mechanisms for saving and loading models: pipelines and components.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>Saving transformers models with custom code (i.e. models that require <code>trust_remote_code=True</code>) requires <code>transformers &gt;= 4.26.0</code>.</p></div></div>
<p><strong>Pipelines</strong></p>
<p>Pipelines, in the context of the Transformers library, are high-level objects that combine pre-trained models and tokenizers
(as well as other components, depending on the task type) to perform a specific task. They abstract away much of the preprocessing
and postprocessing work involved in using the models.</p>
<p>For example, a text classification pipeline would handle the tokenization of text, passing the tokens through a model, and then interpret the logits to produce a human-readable classification.</p>
<p>When logging a pipeline with MLflow, you&#x27;re essentially saving this high-level abstraction, which can be loaded and used directly
for inference with minimal setup. This is ideal for end-to-end tasks where the preprocessing and postprocessing steps are standard
for the task at hand.</p>
<p><strong>Components</strong></p>
<p>Components refer to the individual parts that can make up a pipeline, such as the model itself, the tokenizer, and any additional
processors, extractors, or configuration needed for a specific task. Logging components with MLflow allows for more flexibility and
customization. You can log individual components when your project needs to have more control over the preprocessing and postprocessing
steps or when you need to access the individual components in a bespoke manner that diverges from how the pipeline abstraction would call them.</p>
<p>For example, you might log the components separately if you have a custom tokenizer or if you want to apply some special postprocessing
to the model outputs. When loading the components, you can then reconstruct the pipeline with your custom components or use the components
individually as needed.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>MLflow by default uses a 500 MB <code>max_shard_size</code> to save the model object in <a href="/docs/latest/api_reference/python_api/mlflow.transformers.html#mlflow.transformers.save_model" target="_blank"><code>mlflow.transformers.save_model<!-- -->()</code></a> or <a href="/docs/latest/api_reference/python_api/mlflow.transformers.html#mlflow.transformers.log_model" target="_blank"><code>mlflow.transformers.log_model<!-- -->()</code></a> APIs.
You can use the environment variable <em>MLFLOW_HUGGINGFACE_MODEL_MAX_SHARD_SIZE</em> to override the value.</p></div></div>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>For component-based logging, the only requirement that must be met in the submitted <code>dict</code> is that a model is provided. All other elements of the <code>dict</code> are optional.</p></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="logging-a-components-based-model">Logging a components-based model<a href="#logging-a-components-based-model" class="hash-link" aria-label="Direct link to Logging a components-based model" title="Direct link to Logging a components-based model">‚Äã</a></h3>
<p>The example below shows logging components of a <code>transformers</code> model via a dictionary mapping of specific named components. The names of the keys within the submitted dictionary
must be in the set: <code>{&quot;model&quot;, &quot;tokenizer&quot;, &quot;feature_extractor&quot;, &quot;image_processor&quot;}</code>. Processor type objects (some image processors, audio processors, and multi-modal processors)
must be saved explicitly with the <code>processor</code> argument in the <a href="/docs/latest/api_reference/python_api/mlflow.transformers.html#mlflow.transformers.save_model" target="_blank"><code>mlflow.transformers.save_model<!-- -->()</code></a> or <a href="/docs/latest/api_reference/python_api/mlflow.transformers.html#mlflow.transformers.log_model" target="_blank"><code>mlflow.transformers.log_model<!-- -->()</code></a> APIs.</p>
<p>After logging, the components are automatically inserted into the appropriate <code>Pipeline</code> type for the task being performed and are returned, ready for inference.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>The components that are logged can be retrieved in their original structure (a dictionary) by setting the attribute <code>return_type</code> to &quot;components&quot; in the <code>load_model()</code> API.</p></div></div>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>attention</div><div class="admonitionContent_BuS1"><p>Not all model types are compatible with the pipeline API constructor via component elements. Incompatible models will raise an
<code>MLflowException</code> error stating that the model is missing the <em>name_or_path</em> attribute. In
the event that this occurs, please construct the model directly via the <code>transformers.pipeline(&lt;repo name&gt;)</code> API and save the pipeline object directly.</p></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> transformers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">task </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;text-classification&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">architecture </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">AutoModelForSequenceClassification</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">architecture</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">AutoTokenizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">architecture</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Define the components of the model in a dictionary</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">transformers_model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&quot;model&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;tokenizer&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> tokenizer</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Log the model components</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">with</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">start_run</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_info </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">log_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        transformers_model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">transformers_model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        name</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;text_classifier&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        task</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">task</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Load the components as a pipeline</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">loaded_pipeline </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_info</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_uri</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> return_type</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;pipeline&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token builtin">type</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">loaded_pipeline</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">__name__</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># &gt;&gt; TextClassificationPipeline</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">loaded_pipeline</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;MLflow is awesome!&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Transformers is a great library!&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># &gt;&gt; [{&#x27;label&#x27;: &#x27;POSITIVE&#x27;, &#x27;score&#x27;: 0.9998478889465332},</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># &gt;&gt;  {&#x27;label&#x27;: &#x27;POSITIVE&#x27;, &#x27;score&#x27;: 0.9998030066490173}]</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="saving-a-pipeline-and-loading-components">Saving a pipeline and loading components<a href="#saving-a-pipeline-and-loading-components" class="hash-link" aria-label="Direct link to Saving a pipeline and loading components" title="Direct link to Saving a pipeline and loading components">‚Äã</a></h3>
<p>Some use cases can benefit from the simplicity of defining a solution as a pipeline, but need the component-level access for performing a micro-services based deployment strategy
where pre / post-processing is performed on containers that do not house the model itself. For this paradigm, a pipeline can be loaded as its constituent parts, as shown below.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> transformers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">translation_pipeline </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pipeline</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    task</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;translation_en_to_fr&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">T5ForConditionalGeneration</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;t5-small&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tokenizer</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">T5TokenizerFast</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">&quot;t5-small&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> model_max_length</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">100</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">with</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">start_run</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_info </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">log_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        transformers_model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">translation_pipeline</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        name</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;french_translator&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">translation_components </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_info</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_uri</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> return_type</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;components&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> key</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> value </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> translation_components</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">items</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">key</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c"> -&gt; </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation builtin">type</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">(</span><span class="token string-interpolation interpolation">value</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">)</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation">__name__</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># &gt;&gt; task -&gt; str</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># &gt;&gt; model -&gt; T5ForConditionalGeneration</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># &gt;&gt; tokenizer -&gt; T5TokenizerFast</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">response </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> translation_pipeline</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;MLflow is great!&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">response</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># &gt;&gt; [{&#x27;translation_text&#x27;: &#x27;MLflow est formidable!&#x27;}]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">reconstructed_pipeline </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pipeline</span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">**</span><span class="token plain">translation_components</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">reconstructed_response </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> reconstructed_pipeline</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;transformers makes using Deep Learning models easy and fun!&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">reconstructed_response</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># &gt;&gt; [{&#x27;translation_text&#x27;: &quot;Les transformateurs rendent l&#x27;utilisation de mod√®les Deep Learning facile et amusante!&quot;}]</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="automatic-metadata-and-modelcard-logging">Automatic Metadata and ModelCard logging<a href="#automatic-metadata-and-modelcard-logging" class="hash-link" aria-label="Direct link to Automatic Metadata and ModelCard logging" title="Direct link to Automatic Metadata and ModelCard logging">‚Äã</a></h2>
<p>In order to provide as much information as possible for saved models, the <code>transformers</code> flavor will automatically fetch the <code>ModelCard</code> for any model or pipeline that
is saved that has a stored card on the HuggingFace hub. This card will be logged as part of the model artifact, viewable at the same directory level as the <code>MLmodel</code> file and
the stored model object.</p>
<p>In addition to the <code>ModelCard</code>, the components that comprise any Pipeline (or the individual components if saving a dictionary of named components) will have their source types
stored. The model type, pipeline type, task, and classes of any supplementary component (such as a <code>Tokenizer</code> or <code>ImageProcessor</code>) will be stored in the <code>MLmodel</code> file as well.</p>
<p>In order to preserve any attached legal requirements to the usage of any model that is hosted on the huggingface hub, a &quot;best effort&quot; attempt
is made when logging a transformers model to retrieve and persist any license information. A file will be generated (<code>LICENSE.txt</code>) within the root of
the model directory. Within this file you will either find a copy of a declared license, the name of a common license type that applies to the model&#x27;s use (i.e., &#x27;apache-2.0&#x27;, &#x27;mit&#x27;),
or, in the event that license information was never submitted to the huggingface hub when uploading a model repository, a link to the repository for you to use
in order to determine what restrictions exist regarding the use of the model.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>Model license information was introduced in <strong>MLflow 2.10.0</strong>. Previous versions do not include license information for models.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="automatic-signature-inference">Automatic Signature inference<a href="#automatic-signature-inference" class="hash-link" aria-label="Direct link to Automatic Signature inference" title="Direct link to Automatic Signature inference">‚Äã</a></h2>
<p>For pipelines that support <code>pyfunc</code>, there are 3 means of attaching a model signature to the <code>MLmodel</code> file.</p>
<ul>
<li>
<p>Provide a model signature explicitly via setting a valid <code>ModelSignature</code> to the <code>signature</code> attribute. This can be generated via the helper utility <a href="/docs/latest/api_reference/python_api/mlflow.transformers.html#mlflow.transformers.generate_signature_output" target="_blank"><code>mlflow.transformers.generate_signature_output<!-- -->()</code></a></p>
</li>
<li>
<p>Provide an <code>input_example</code>. The signature will be inferred and validated that it matches the appropriate input type. The output type will be validated by performing inference automatically (if the model is a <code>pyfunc</code> supported type).</p>
</li>
<li>
<p>Do nothing. The <code>transformers</code> flavor will automatically apply the appropriate general signature that the pipeline type supports (only for a single-entity; collections will not be inferred).</p>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="scalability-for-inference">Scale Inference with Overriding Pytorch dtype<a href="#scalability-for-inference" class="hash-link" aria-label="Direct link to Scale Inference with Overriding Pytorch dtype" title="Direct link to Scale Inference with Overriding Pytorch dtype">‚Äã</a></h2>
<p>A common configuration for lowering the total memory pressure for pytorch models within <code>transformers</code> pipelines is to modify the
processing data type. This is achieved through setting the <code>torch_dtype</code> argument when creating a <code>Pipeline</code>.
For a full reference of these tunable arguments for configuration of pipelines, see the <a href="https://huggingface.co/docs/transformers/v4.28.1/en/perf_train_gpu_one#floating-data-types" target="_blank" rel="noopener noreferrer">training docs</a>.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>This feature does not exist in versions of <code>transformers</code> &lt; 4.26.x</p></div></div>
<p>In order to apply these configurations to a saved or logged run, there are two options:</p>
<ul>
<li>Save a pipeline with the <em>torch_dtype</em> argument set to the encoding type of your choice.</li>
</ul>
<p>Example:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> transformers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">task </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;translation_en_to_fr&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">my_pipeline </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pipeline</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    task</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">task</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">T5ForConditionalGeneration</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;t5-small&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tokenizer</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">T5TokenizerFast</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">&quot;t5-small&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> model_max_length</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">100</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    framework</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;pt&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">with</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">start_run</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_info </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">log_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        transformers_model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">my_pipeline</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        name</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;my_pipeline&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        torch_dtype</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">bfloat16</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Illustrate that the torch data type is recorded in the flavor configuration</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model_info</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">flavors</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;transformers&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<p>Result:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&#x27;transformers_version&#x27;</span><span class="token builtin class-name">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;4.28.1&#x27;</span><span class="token plain">,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&#x27;code&#x27;</span><span class="token builtin class-name">:</span><span class="token plain"> None,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&#x27;task&#x27;</span><span class="token builtin class-name">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;translation_en_to_fr&#x27;</span><span class="token plain">,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&#x27;instance_type&#x27;</span><span class="token builtin class-name">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;TranslationPipeline&#x27;</span><span class="token plain">,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&#x27;source_model_name&#x27;</span><span class="token builtin class-name">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;t5-small&#x27;</span><span class="token plain">,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&#x27;pipeline_model_type&#x27;</span><span class="token builtin class-name">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;T5ForConditionalGeneration&#x27;</span><span class="token plain">,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&#x27;framework&#x27;</span><span class="token builtin class-name">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;pt&#x27;</span><span class="token plain">,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&#x27;torch_dtype&#x27;</span><span class="token builtin class-name">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;torch.bfloat16&#x27;</span><span class="token plain">,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&#x27;tokenizer_type&#x27;</span><span class="token builtin class-name">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;T5TokenizerFast&#x27;</span><span class="token plain">,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&#x27;components&#x27;</span><span class="token builtin class-name">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&#x27;tokenizer&#x27;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain">,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">&#x27;pipeline&#x27;</span><span class="token builtin class-name">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;pipeline&#x27;</span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre></div></div>
<ul>
<li>Specify the <em>torch_dtype</em> argument when loading the model to override any values set during logging or saving.</li>
</ul>
<p>Example:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> transformers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">task </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;translation_en_to_fr&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">my_pipeline </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pipeline</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    task</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">task</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">T5ForConditionalGeneration</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;t5-small&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tokenizer</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">T5TokenizerFast</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">&quot;t5-small&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> model_max_length</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">100</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    framework</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;pt&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">with</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">start_run</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_info </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">log_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        transformers_model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">my_pipeline</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        name</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;my_pipeline&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        torch_dtype</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">bfloat16</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">loaded_pipeline </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_info</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_uri</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> return_type</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;pipeline&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> torch_dtype</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">float64</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">loaded_pipeline</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">torch_dtype</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<p>Result:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">torch.float64</span><br></span></code></pre></div></div>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>MLflow 2.12.1 slightly changed the <code>torch_dtype</code> extraction logic. Previously it depended on the <code>torch_dtype</code> attribute of the pipeline instance,
but now it is extracted from the underlying model via <code>dtype</code> property. This enables MLflow to capture the dtype change of the model after pipeline instantiation.</p></div></div>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>Logging or saving a model in &#x27;components&#x27; mode (using a dictionary to declare components) does not support setting the data type for a constructed pipeline.
If you need to override the default behavior of how data is encoded, please save or log a <em>pipeline</em> object.</p></div></div>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>Overriding the data type for a pipeline when loading as a <a href="/docs/latest/ml/model#pyfunc-model-flavor">python_function (pyfunc) model flavor</a> is not supported.
The value set for <code>torch_dtype</code> during <code>save_model()</code> or <code>log_model()</code> will persist when loading as <em>pyfunc</em>.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="input-data-types-for-audio-pipelines">Input Data Types for Audio Pipelines<a href="#input-data-types-for-audio-pipelines" class="hash-link" aria-label="Direct link to Input Data Types for Audio Pipelines" title="Direct link to Input Data Types for Audio Pipelines">‚Äã</a></h2>
<p>Note that passing raw data to an audio pipeline (raw bytes) requires two separate elements of the same effective library.
In order to use the bitrate transposition and conversion of the audio bytes data into numpy nd.array format, the library <em>ffmpeg</em> is required.
Installing this package directly from pypi (<em>pip install ffmpeg</em>) does not install the underlying <em>c</em> dll&#x27;s that are required to make <em>ffmpeg</em> function.
Please consult with the documentation at <a href="https://ffmpeg.org/download.html" target="_blank" rel="noopener noreferrer">the ffmpeg website</a> for guidance on your given operating system.</p>
<p>The Audio Pipeline types, when loaded as a <a href="/docs/latest/ml/model#pyfunc-model-flavor">python_function (pyfunc) model flavor</a> have three input types available:</p>
<ul>
<li><code>str</code></li>
</ul>
<p>The string input type is meant for blob references (uri locations) that are accessible to the instance of the <code>pyfunc</code> model.
This input mode is useful when doing large batch processing of audio inference in Spark due to the inherent limitations of handling large <code>bytes</code>
data in <code>Spark</code> <code>DataFrames</code>. Ensure that you have <code>ffmpeg</code> installed in the environment that the <code>pyfunc</code> model is running in order
to use <code>str</code> input uri-based inference. If this package is not properly installed (both from <code>pypi</code> and from the <code>ffmpeg</code> binaries), an Exception
will be thrown at inference time.</p>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>warning</div><div class="admonitionContent_BuS1"><p>If using a uri (<em>str</em>) as an input type for a <em>pyfunc</em> model that you are intending to host for realtime inference through the <em>MLflow Model Server</em>,
you <em>must</em> specify a custom model signature when logging or saving the model.
The default signature input value type of <code>bytes</code> will, in <em>MLflow Model serving</em>, force the conversion of the uri string to <code>bytes</code>, which will cause an Exception
to be thrown from the serving process stating that the soundfile is corrupt.</p></div></div>
<p>An example of specifying an appropriate uri-based input model signature for an audio model is shown below:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">models </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> infer_signature</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> generate_signature_output</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">url </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;https://www.mywebsite.com/sound/files/for/transcription/file111.mp3&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">signature </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> infer_signature</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">url</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> generate_signature_output</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">my_audio_pipeline</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> url</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">with</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">start_run</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">log_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        transformers_model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">my_audio_pipeline</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        name</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;my_transcriber&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        signature</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">signature</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<ul>
<li><code>bytes</code></li>
</ul>
<p>This is the default serialization format of audio files. It is the easiest format to utilize due to the fact that
Pipeline implementations will automatically convert the audio bitrate from the file with the use of <code>ffmpeg</code> (a required dependency if using this format)
to the bitrate required by the underlying model within the <em>Pipeline</em>. When using the <code>pyfunc</code> representation
of the pipeline directly (not through serving), the sound file can be passed directly as <code>bytes</code> without any
modification. When used through serving, the <code>bytes</code> data <em>must be</em> base64 encoded.</p>
<ul>
<li><code>np.ndarray</code></li>
</ul>
<p>This input format requires that both the bitrate has been set prior to conversion to <code>numpy.ndarray</code> (i.e., through the use of a package like
<code>librosa</code> or <code>pydub</code>) and that the model has been saved with a signature that uses the <code>np.ndarray</code> format for the input.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>Audio models being used for serving that intend to utilize pre-formatted audio in <code>np.ndarray</code> format
must have the model saved with a signature configuration that reflects this schema. Failure to do so will result in type casting errors due to the default signature for
audio transformers pipelines being set as expecting <code>binary</code> (<code>bytes</code>) data. The serving endpoint cannot accept a union of types, so a particular model instance must choose one
or the other as an allowed input type.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="peft-models-in-mlflow-transformers-flavor">PEFT Models in MLflow Transformers flavor<a href="#peft-models-in-mlflow-transformers-flavor" class="hash-link" aria-label="Direct link to PEFT Models in MLflow Transformers flavor" title="Direct link to PEFT Models in MLflow Transformers flavor">‚Äã</a></h2>
<p><a href="https://huggingface.co/docs/peft/en/index" target="_blank" rel="noopener noreferrer">PEFT</a> is a library developed by HuggingFaceü§ó, that provides various optimization methods for pretrained models available on the HuggingFace Hub.
With PEFT, you can easily apply various optimization techniques like LoRA and QLoRA to reduce the cost of fine-tuning Transformers models.</p>
<p>For example, <a href="https://huggingface.co/docs/peft/main/en/conceptual_guides/lora" target="_blank" rel="noopener noreferrer">LoRA (Low-Rank Adaptation)</a> is a method that approximate the weight updates of fine-tuning
process with two smaller matrices through low-rank decomposition. LoRA typically shrinks the number of parameters to train to only 0.01% ~ a few % of the full model fine-tuning
(depending on the configuration), which significantly accelerates the fine-tuning process and reduces the memory footprint, such that you can even
<a href="/docs/latest/ml/deep-learning/transformers/tutorials/fine-tuning/transformers-peft/">train a Mistral/Llama2 7B model on a single Nvidia A10G GPU in an hour</a>.
By using PEFT, you can apply LoRA to your Transformers model with only a few lines of code:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> peft </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> LoraConfig</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> get_peft_model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">base_model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoModelForCausalLM</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">lora_config </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> LoraConfig</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">peft_model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> get_peft_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">base_model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> lora_config</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<p>In MLflow 2.11.0, we introduced support for tracking PEFT models in the MLflow Transformers flavor.
You can log and load PEFT models using the same APIs as other Transformers models, such as <a href="/docs/latest/api_reference/python_api/mlflow.transformers.html#mlflow.transformers.log_model" target="_blank"><code>mlflow.transformers.log_model<!-- -->()</code></a> and <a href="/docs/latest/api_reference/python_api/mlflow.transformers.html#mlflow.transformers.load_model" target="_blank"><code>mlflow.transformers.load_model<!-- -->()</code></a>.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> peft </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> LoraConfig</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> get_peft_model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> AutoModelForCausalLM</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> AutoTokenizer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model_id </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;databricks/dolly-v2-7b&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">base_model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoModelForCausalLM</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model_id</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoTokenizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model_id</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">peft_config </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> LoraConfig</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">peft_model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> get_peft_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">base_model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> peft_config</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">with</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">start_run</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Your training code here</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Log the PEFT model</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_info </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">log_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        transformers_model</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token string" style="color:#e3116c">&quot;model&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> peft_model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token string" style="color:#e3116c">&quot;tokenizer&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> tokenizer</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        name</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;peft_model&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Load the PEFT model</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">loaded_model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model_info</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_uri</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="peft-models-in-mlflow-tutorial">PEFT Models in MLflow Tutorial<a href="#peft-models-in-mlflow-tutorial" class="hash-link" aria-label="Direct link to PEFT Models in MLflow Tutorial" title="Direct link to PEFT Models in MLflow Tutorial">‚Äã</a></h3>
<p>Check out the tutorial <a href="/docs/latest/ml/deep-learning/transformers/tutorials/fine-tuning/transformers-peft/">Fine-Tuning Open-Source LLM using QLoRA with MLflow and PEFT</a>
for a more in-depth guide on how to use PEFT with MLflow,</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="format-of-saved-peft-model">Format of Saved PEFT Model<a href="#format-of-saved-peft-model" class="hash-link" aria-label="Direct link to Format of Saved PEFT Model" title="Direct link to Format of Saved PEFT Model">‚Äã</a></h3>
<p>When saving PEFT models, MLflow only saves the PEFT adapter and the configuration, but not the base model&#x27;s weights. This is the same behavior as the Transformer&#x27;s
<a href="https://huggingface.co/docs/transformers/v4.38.1/en/main_classes/model#transformers.PreTrainedModel.save_pretrained" target="_blank" rel="noopener noreferrer">save_pretrained()</a> method and is highly efficient
in terms of storage space and logging latency. One difference is that MLflow will also save the HuggingFace Hub repository name and version for the base model in
the model metadata, so that it can load the same base model when loading the PEFT model. Concretely, the following artifacts are saved in MLflow for PEFT models:</p>
<ul>
<li>The PEFT adapter weight under the <code>/peft</code> directory.</li>
<li>The PEFT configuration as a JSON file under the <code>/peft</code> directory.</li>
<li>The HuggingFace Hub repository name and commit hash for the base model in the <code>MLModel</code> metadata file.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="limitations-of-peft-models-in-mlflow">Limitations of PEFT Models in MLflow<a href="#limitations-of-peft-models-in-mlflow" class="hash-link" aria-label="Direct link to Limitations of PEFT Models in MLflow" title="Direct link to Limitations of PEFT Models in MLflow">‚Äã</a></h3>
<p>Since the model saving/loading behavior for PEFT models is similar to that of <code>save_pretrained=False</code>, <a href="/docs/latest/ml/deep-learning/transformers/large-models#caveats-of-save-pretrained">the same caveats</a> apply to PEFT models.
For example, the base model weight may be deleted or become private in the HuggingFace Hub, and PEFT models cannot be registered to the legacy Databricks Workspace Model Registry.</p>
<p>To save the base model weight for PEFT models, you can use the <a href="/docs/latest/api_reference/python_api/mlflow.transformers.html#mlflow.transformers.persist_pretrained_model" target="_blank"><code>mlflow.transformers.persist_pretrained_model<!-- -->()</code></a> API.
This will download the base model weight from the HuggingFace Hub and save it to the artifact location, updating the metadata of the given PEFT model.
Please refer to <a href="/docs/latest/ml/deep-learning/transformers/large-models#persist-pretrained-guide">this section</a> for the detailed usage of this API.</p></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/latest/ml/deep-learning/transformers/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">MLflow Transformers Flavor</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/latest/ml/deep-learning/transformers/large-models/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Working with Large Transformers Models</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#loading-a-transformers-model-as-a-python-function" class="table-of-contents__link toc-highlight">Loading a Transformers Model as a Python Function</a><ul><li><a href="#supported-transformers-pipeline-types" class="table-of-contents__link toc-highlight">Supported Transformers Pipeline types</a></li><li><a href="#example-of-loading-a-transformers-model-as-a-python-function" class="table-of-contents__link toc-highlight">Example of loading a transformers model as a python function</a></li></ul></li><li><a href="#saving-prompt-templates-with-transformer-pipelines" class="table-of-contents__link toc-highlight">Saving Prompt Templates with Transformer Pipelines</a></li><li><a href="#using-model-config-and-model-signature-params-for-inference" class="table-of-contents__link toc-highlight">Using model_config and Model Signature Params for Inference</a></li><li><a href="#pipelines-vs-component-logging" class="table-of-contents__link toc-highlight">Pipelines vs. Component Logging</a><ul><li><a href="#logging-a-components-based-model" class="table-of-contents__link toc-highlight">Logging a components-based model</a></li><li><a href="#saving-a-pipeline-and-loading-components" class="table-of-contents__link toc-highlight">Saving a pipeline and loading components</a></li></ul></li><li><a href="#automatic-metadata-and-modelcard-logging" class="table-of-contents__link toc-highlight">Automatic Metadata and ModelCard logging</a></li><li><a href="#automatic-signature-inference" class="table-of-contents__link toc-highlight">Automatic Signature inference</a></li><li><a href="#scalability-for-inference" class="table-of-contents__link toc-highlight">Scale Inference with Overriding Pytorch dtype</a></li><li><a href="#input-data-types-for-audio-pipelines" class="table-of-contents__link toc-highlight">Input Data Types for Audio Pipelines</a></li><li><a href="#peft-models-in-mlflow-transformers-flavor" class="table-of-contents__link toc-highlight">PEFT Models in MLflow Transformers flavor</a><ul><li><a href="#peft-models-in-mlflow-tutorial" class="table-of-contents__link toc-highlight">PEFT Models in MLflow Tutorial</a></li><li><a href="#format-of-saved-peft-model" class="table-of-contents__link toc-highlight">Format of Saved PEFT Model</a></li><li><a href="#limitations-of-peft-models-in-mlflow" class="table-of-contents__link toc-highlight">Limitations of PEFT Models in MLflow</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="pb-150 flex flex-col pt-37 bg-linear-to-b from-brand-black to-brand-black bg-bottom bg-no-repeat bg-cover w-full bg-(--background-color-dark) bg-size-[100%_340px]" style="background-image:url(/docs/latest/assets/images/footer-blue-bg-2664116e3788212e9f50cfc6024806f8.png)"><div class="flex flex-row justify-between items-start md:items-center px-6 lg:px-20 gap-10 xs:gap-0 max-w-container"><svg xmlns="http://www.w3.org/2000/svg" width="109" height="40" fill="none" viewBox="0 0 109 40" class="h-[36px] shrink-0"><path fill="#fff" d="M0 31.032v-15.53h3.543v1.968c.893-1.594 2.84-2.425 4.593-2.425 2.042 0 3.828.926 4.658 2.745 1.216-2.043 3.034-2.745 5.043-2.745 2.81 0 5.49 1.787 5.49 5.904v10.083h-3.574v-9.478c0-1.818-.926-3.19-3-3.19-1.947 0-3.224 1.53-3.224 3.445v9.22H9.893v-9.475c0-1.786-.898-3.18-3.003-3.18-1.977 0-3.223 1.467-3.223 3.444v9.221ZM27.855 31.032V7.929h3.703v23.103ZM30.07 39.487c.833.232 1.582.383 3.17.383 2.953 0 6.436-1.665 7.353-6.339l3.786-18.739h5.629l.687-3.117h-5.686l.765-3.725c.586-2.892 2.186-4.358 4.754-4.358.668 0 .48.058 1.076.17L52.427.57c-.793-.237-1.503-.379-3.049-.379a7.32 7.32 0 0 0-4.528 1.484c-1.441 1.114-2.393 2.75-2.827 4.863l-1.066 5.137h-5.034l-.411 3.12h4.823L36.859 32.12c-.383 1.965-1.5 4.315-4.708 4.315-.727 0-.463-.055-1.121-.162ZM53.342 30.905H49.64l5.074-23.309h3.701ZM71.807 16.477A7.962 7.962 0 0 0 60.97 27.904l2.425-1.78a5.005 5.005 0 0 1 3.845-8.145v1.895ZM62.618 29.472a7.962 7.962 0 0 0 10.836-11.428l-2.425 1.78a5.005 5.005 0 0 1-3.845 8.145v-1.894ZM78.092 15.493h4.044l.823 10.612 5.759-10.612 3.839.055 1.508 10.557 5.074-10.612 3.701.055-7.678 15.493H91.46l-1.783-11.106-5.895 11.106h-3.84ZM105.072 15.768h-.766v-.266h1.845v.272h-.765v2.243h-.314ZM106.614 15.502h.383l.482 1.34q.091.259.178.524h.018c.059-.176.113-.352.172-.524l.478-1.34h.383v2.515h-.298V16.63c0-.22.024-.523.04-.747h-.016l-.191.574-.475 1.304h-.208l-.481-1.302-.191-.574h-.015c.017.224.042.527.042.747v1.387h-.291Z"></path></svg><div class="flex flex-col md:flex-row gap-10"><div class="min-w-[120px]"><a href="https://mllfow.org" target="_blank" rel="noopener noreferrer" class="link_LVIP">Product</a></div><div class="min-w-[120px]"><a href="https://mlflow.org/releases" target="_blank" rel="noopener noreferrer" class="link_LVIP">Releases</a></div><div class="min-w-[120px]"><a href="https://mlflow.org/blog" target="_blank" rel="noopener noreferrer" class="link_LVIP">Blog</a></div><div class="min-w-[120px]"><a class="link_LVIP" href="/docs/latest/">Docs</a></div></div></div></footer></div>
</body>
</html>