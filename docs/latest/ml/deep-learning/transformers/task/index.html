<!doctype html><html lang=en dir=ltr class="docs-wrapper plugin-docs plugin-id-classic-ml docs-version-current docs-doc-page docs-doc-id-deep-learning/transformers/task/index" data-has-hydrated=false><head><meta charset=UTF-8><meta name=generator content="Docusaurus v3.9.2"><title data-rh=true>Tasks in MLflow Transformers Flavor | MLflow</title><meta data-rh=true name=viewport content="width=device-width, initial-scale=1.0"/><meta data-rh=true name=twitter:card content=summary_large_image /><meta data-rh=true property=og:url content=https://mlflow.org/mlflow-website/docs/latest/ml/deep-learning/transformers/task/ /><meta data-rh=true property=og:locale content=en /><meta data-rh=true name=docusaurus_locale content=en /><meta data-rh=true name=docsearch:language content=en /><meta data-rh=true name=docusaurus_version content=current /><meta data-rh=true name=docusaurus_tag content=docs-classic-ml-current /><meta data-rh=true name=docsearch:version content=current /><meta data-rh=true name=docsearch:docusaurus_tag content=docs-classic-ml-current /><meta data-rh=true property=og:title content="Tasks in MLflow Transformers Flavor | MLflow"/><meta data-rh=true name=description content="This page provides an overview of how to use the task parameter in the MLflow Transformers flavor to control"/><meta data-rh=true property=og:description content="This page provides an overview of how to use the task parameter in the MLflow Transformers flavor to control"/><link data-rh=true rel=icon href=/mlflow-website/docs/latest/images/favicon.ico /><link data-rh=true rel=canonical href=https://mlflow.org/mlflow-website/docs/latest/ml/deep-learning/transformers/task/ /><link data-rh=true rel=alternate href=https://mlflow.org/mlflow-website/docs/latest/ml/deep-learning/transformers/task/ hreflang=en /><link data-rh=true rel=alternate href=https://mlflow.org/mlflow-website/docs/latest/ml/deep-learning/transformers/task/ hreflang=x-default /><link data-rh=true rel=preconnect href=https://XKVLO8P882-dsn.algolia.net crossorigin=anonymous /><script data-rh=true type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://mlflow.org/mlflow-website/docs/latest/ml/deep-learning/","name":"Deep Learning","position":1},{"@type":"ListItem","item":"https://mlflow.org/mlflow-website/docs/latest/ml/deep-learning/transformers/","name":"Transformers","position":2},{"@type":"ListItem","item":"https://mlflow.org/mlflow-website/docs/latest/ml/deep-learning/transformers/task/","name":"Transformers Task Types","position":3}]}</script><link rel=preconnect href=https://www.google-analytics.com><link rel=preconnect href=https://www.googletagmanager.com><script async src="https://www.googletagmanager.com/gtag/js?id=GTM-N6WMTTJ"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","GTM-N6WMTTJ",{anonymize_ip:!0}),gtag("config","AW-16857946923",{anonymize_ip:!0})</script><link rel=preconnect href=https://www.googletagmanager.com><script>window.dataLayer=window.dataLayer||[],function(e,t,a,n,r){e[n]=e[n]||[],e[n].push({"gtm.start":new Date().getTime(),event:"gtm.js"});var d=t.getElementsByTagName(a)[0],g=t.createElement(a);g.async=!0,g.src="https://www.googletagmanager.com/gtm.js?id="+r+("dataLayer"!=n?"&l="+n:""),d.parentNode.insertBefore(g,d)}(window,document,"script","dataLayer","GTM-N6WMTTJ")</script><link rel=search type=application/opensearchdescription+xml title=MLflow href=/mlflow-website/docs/latest/opensearch.xml><script src=/mlflow-website/docs/latest/js/runllm.js defer></script><link rel=stylesheet href=/mlflow-website/docs/latest/assets/css/styles.65681509.css /><script src=/mlflow-website/docs/latest/assets/js/runtime~main.a0db6d66.js defer></script><script src=/mlflow-website/docs/latest/assets/js/main.5d15b684.js defer></script></head><body class=navigation-with-keyboard><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ" height=0 width=0 style=display:none;visibility:hidden></iframe></noscript>


<svg style="display: none;"><defs>
<symbol id=theme-svg-external-link viewBox="0 0 24 24"><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label="Skip to main content"><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>Skip to main content</a></div><nav aria-label=Main class="theme-layout-navbar navbar navbar--fixed-top"><div class=navbar__inner><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/mlflow-website/docs/latest/><div class=navbar__logo><img src=/mlflow-website/docs/latest/images/logo-light.svg alt="MLflow Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"/><img src=/mlflow-website/docs/latest/images/logo-dark.svg alt="MLflow Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"/></div></a><div class="navbar__item dropdown dropdown--hoverable"><a href=# aria-haspopup=true aria-expanded=false role=button class="navbar__link docsDropdown_VGp6" data-active=ml><div style=display:flex;gap:8px;align-items:center><div class=dropdownCircle_n91F style=width:10px;height:10px;background-color:var(--ml-color-primary);border-radius:4px></div>ML Docs</div></a><ul class=dropdown__menu><li><a aria-current=page class="dropdown__link ml-docs-link dropdown__link--active" href=/mlflow-website/docs/latest/ml/><div style=display:flex;gap:8px;align-items:center><div style=width:10px;height:10px;background-color:var(--ml-color-primary);border-radius:4px></div>ML Docs</div></a><li><a class="dropdown__link genai-docs-link" href=/mlflow-website/docs/latest/genai/><div style=display:flex;gap:8px;align-items:center><div style=width:10px;height:10px;background-color:var(--genai-color-primary);border-radius:4px></div>GenAI Docs</div></a></ul></div><a href=https://mlflow.org/docs/latest/api_reference/index.html target=_blank rel="noopener noreferrer" class="navbar__item navbar__link">API Reference</a><a class="navbar__item navbar__link" href=/mlflow-website/docs/latest/self-hosting/>Self-Hosting</a><a class="navbar__item navbar__link" href=/mlflow-website/docs/latest/community/>Community</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href=https://github.com/mlflow/mlflow target=_blank rel="noopener noreferrer" class="navbar__item navbar__link github-link">GitHub<svg width=13.5 height=13.5 aria-label="(opens in new tab)" class=iconExternalLink_nPIU><use href=#theme-svg-external-link /></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type=button disabled title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width=24 height=24 aria-hidden=true class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill=currentColor d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"/></svg><svg viewBox="0 0 24 24" width=24 height=24 aria-hidden=true class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill=currentColor d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"/></svg><svg viewBox="0 0 24 24" width=24 height=24 aria-hidden=true class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill=currentColor d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"/></svg></button></div><div class=navbarSearchContainer_Bca1><button type=button class="DocSearch DocSearch-Button" aria-label="Search (Meta+k)" aria-keyshortcuts=Meta+k><span class=DocSearch-Button-Container><svg width=20 height=20 class=DocSearch-Search-Icon viewBox="0 0 24 24" aria-hidden=true><circle cx=11 cy=11 r=8 stroke=currentColor fill=none stroke-width=1.4 /><path d="m21 21-4.3-4.3" stroke=currentColor fill=none stroke-linecap=round stroke-linejoin=round /></svg><span class=DocSearch-Button-Placeholder>Search</span></span><span class=DocSearch-Button-Keys></span></button></div></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class=docsWrapper_hBAB><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class=sidebar_njMd><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sidebar-top-level-category"><a class=menu__link href=/mlflow-website/docs/latest/ml/><span title=MLflow class=linkLabel_WmDU>MLflow</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" href=/mlflow-website/docs/latest/ml/getting-started/><span title="Getting Started" class=categoryLinkLabel_W154>Getting Started</span></a><button aria-label="Expand sidebar category 'Getting Started'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-top-level-category"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role=button aria-expanded=true href=/mlflow-website/docs/latest/ml/traditional-ml/><span title="Machine Learning" class=categoryLinkLabel_W154>Machine Learning</span></a></div><ul class=menu__list><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex=0 href=/mlflow-website/docs/latest/ml/traditional-ml/><span title="Traditional ML" class=categoryLinkLabel_W154>Traditional ML</span></a><button aria-label="Expand sidebar category 'Traditional ML'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex=0 href=/mlflow-website/docs/latest/ml/deep-learning/><span title="Deep Learning" class=categoryLinkLabel_W154>Deep Learning</span></a><button aria-label="Collapse sidebar category 'Deep Learning'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/mlflow-website/docs/latest/ml/deep-learning/pytorch/><span title=Pytorch class=linkLabel_WmDU>Pytorch</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/mlflow-website/docs/latest/ml/deep-learning/tensorflow/><span title=TensorFlow class=linkLabel_WmDU>TensorFlow</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/mlflow-website/docs/latest/ml/deep-learning/keras/><span title=Keras class=linkLabel_WmDU>Keras</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex=0 href=/mlflow-website/docs/latest/ml/deep-learning/transformers/><span title=Transformers class=categoryLinkLabel_W154>Transformers</span></a><button aria-label="Collapse sidebar category 'Transformers'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class=menu__link tabindex=0 href=/mlflow-website/docs/latest/ml/deep-learning/transformers/guide/><span title="ðŸ¤— Transformers within MLflow" class=linkLabel_WmDU>ðŸ¤— Transformers within MLflow</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class=menu__link tabindex=0 href=/mlflow-website/docs/latest/ml/deep-learning/transformers/large-models/><span title="Working with Large Transformers Models" class=linkLabel_WmDU>Working with Large Transformers Models</span></a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/mlflow-website/docs/latest/ml/deep-learning/transformers/task/><span title="Transformers Task Types" class=linkLabel_WmDU>Transformers Task Types</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex=0 href=/mlflow-website/docs/latest/ml/deep-learning/transformers/tutorials/><span title=Tutorials class=categoryLinkLabel_W154>Tutorials</span></a><button aria-label="Expand sidebar category 'Tutorials'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex=0 href=/mlflow-website/docs/latest/ml/deep-learning/sentence-transformers/><span title="Sentence Transformers" class=categoryLinkLabel_W154>Sentence Transformers</span></a><button aria-label="Expand sidebar category 'Sentence Transformers'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class=menu__link tabindex=0 href=/mlflow-website/docs/latest/ml/deep-learning/spacy/><span title=spaCy class=linkLabel_WmDU>spaCy</span></a></ul></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-top-level-category"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=true href=/mlflow-website/docs/latest/ml/tracking/><span title="Build " class=categoryLinkLabel_W154>Build </span></a></div><ul class=menu__list><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex=0 href=/mlflow-website/docs/latest/ml/tracking/><span title="MLflow Tracking" class=categoryLinkLabel_W154>MLflow Tracking</span></a><button aria-label="Expand sidebar category 'MLflow Tracking'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false tabindex=0 href=/mlflow-website/docs/latest/ml/model/><span title="MLflow Model" class=categoryLinkLabel_W154>MLflow Model</span></a></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/mlflow-website/docs/latest/ml/dataset/><span title="MLflow Datasets" class=linkLabel_WmDU>MLflow Datasets</span></a></ul><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sidebar-top-level-category"><a class=menu__link href=/mlflow-website/docs/latest/ml/evaluation/><span title=Evaluate class=linkLabel_WmDU>Evaluate</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false href=/mlflow-website/docs/latest/ml/model-registry/><span title=Deploy class=categoryLinkLabel_W154>Deploy</span></a></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/mlflow-website/docs/latest/ml/webhooks/><span title=Webhooks class=linkLabel_WmDU>Webhooks</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class=menu__list-item-collapsible><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false href=/mlflow-website/docs/latest/self-hosting/><span title="Team Collaboration" class=categoryLinkLabel_W154>Team Collaboration</span></a></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class=menu__list-item-collapsible><a href=https://mlflow.org/docs/latest/api_reference/python_api/index.html target=_blank rel="noopener noreferrer" class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false><span title="API References" class=categoryLinkLabel_W154>API References</span></a></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sidebar-top-level-category"><a class=menu__link href=/mlflow-website/docs/latest/ml/mlflow-3/><span title="MLflow 3 Migration Guide" class=linkLabel_WmDU>MLflow 3 Migration Guide</span></a><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class=menu__list-item-collapsible><a href=https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md target=_blank rel="noopener noreferrer" class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role=button aria-expanded=false><span title=More class=categoryLinkLabel_W154>More</span></a></div></ul></nav></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class="col docItemCol_VOVn"><div class=docItemContainer_Djhp><article><div class=breadcrumbsWrapper_xlkt><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=Breadcrumbs><ul class=breadcrumbs><li class=breadcrumbs__item><a aria-label="Home page" class=breadcrumbs__link href=/mlflow-website/docs/latest/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li class=breadcrumbs__item><span class=breadcrumbs__link>Machine Learning</span><li class=breadcrumbs__item><a class=breadcrumbs__link href=/mlflow-website/docs/latest/ml/deep-learning/><span>Deep Learning</span></a><li class=breadcrumbs__item><a class=breadcrumbs__link href=/mlflow-website/docs/latest/ml/deep-learning/transformers/><span>Transformers</span></a><li class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link>Transformers Task Types</span></ul></nav></div><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type=button class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Tasks in MLflow Transformers Flavor</h1></header>
<p>This page provides an overview of how to use the <code>task</code> parameter in the MLflow Transformers flavor to control
the inference interface of the model.</p>
<div class=tableOfContentsInline_prmo><ul class=table-of-contents><li><a href=#overview>Overview</a><li><a href=#native-transformers-task-types>Native Transformers Task Types</a><li><a href=#advanced-tasks-for-openai-compatible-inference>Advanced Tasks for OpenAI-Compatible Inference</a><ul><li><a href=#input-and-output-formats>Input and Output Formats</a><li><a href=#code-example-of-using-llmv1-tasks>Code Example of Using <code>llm/v1</code> Tasks</a></ul><li><a href=#provisioned-throughput-on-databricks-model-serving>Provisioned Throughput on Databricks Model Serving</a><li><a href=#faq>FAQ</a><ul><li><a href=#how-to-override-the-default-query-parameters-for-the-openai-compatible-inference>How to override the default query parameters for the OpenAI-compatible inference?</a></ul></ul></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=overview>Overview<a href=#overview class=hash-link aria-label="Direct link to Overview" title="Direct link to Overview" translate=no>â€‹</a></h2>
<p>In the MLflow Transformers flavor, <code>task</code> plays a crucial role in determining the input and output format of the model.
The <code>task</code> is a fundamental concept in the Transformers library, which describe the structure of each model's API
(inputs and outputs) and are used to determine which Inference API and widget we want to display for any given model.</p>
<p>MLflow utilizes this concept to determine the input and output format of the model, persists the correct
<a class="" href=/mlflow-website/docs/latest/ml/model/#model-signatures-and-input-examples>Model Signature</a>, and provides a consistent <a href=/mlflow-website/docs/latest/api_reference/python_api/mlflow.pyfunc.html#inference-api target=_blank>Pyfunc Inference API</a>
for serving different types of models. Additionally, on top of the native Transformers task types, MLflow defines a few additional task types to support more complex use cases, such as chat-style applications.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=native-transformers-task-types>Native Transformers Task Types<a href=#native-transformers-task-types class=hash-link aria-label="Direct link to Native Transformers Task Types" title="Direct link to Native Transformers Task Types" translate=no>â€‹</a></h2>
<p>For native Transformers tasks, MLflow will automatically infer the task type from the pipeline when you save a pipeline
with <a href=/mlflow-website/docs/latest/api_reference/python_api/mlflow.transformers.html#mlflow.transformers.log_model target=_blank><code>mlflow.transformers.log_model<!-- -->()</code></a>. You can also specify the task type explicitly by passing the
<code>task</code> parameter. The full list of supported task types is available in the <a href=https://huggingface.co/tasks target=_blank rel="noopener noreferrer" class="">Transformers documentation</a>,
but note that <strong>not all task types are supported in MLflow</strong>.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#F8F8F2;--prism-background-color:#282A36><div class=codeBlockContent_bxn0><div class=codeBlockHeader_C_1e aria-label="Code block header for python code with copy and toggle buttons"><span class=languageLabel_zr_I>python</span></div><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#F8F8F2;background-color:#282A36><code class=codeBlockLines_e6Vv><span class=token-line style=color:#F8F8F2><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> mlflow</span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> transformers</span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain" style=display:inline-block></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">pipeline </span><span class="token operator">=</span><span class="token plain"> transformers</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">pipeline</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">"text-generation"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> model</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">"gpt2"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain" style=display:inline-block></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">with</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">start_run</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">    model_info </span><span class="token operator">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">save_model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        transformers_model</span><span class="token operator">=</span><span class="token plain">pipeline</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        artifact_path</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">"model"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        save_pretrained</span><span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain" style=display:inline-block></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">print</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">f"Inferred task: </span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string-interpolation interpolation">model_info</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token string-interpolation interpolation">flavors</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string-interpolation interpolation string" style="color:rgb(255, 121, 198)">'transformers'</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string-interpolation interpolation string" style="color:rgb(255, 121, 198)">'task'</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># >> Inferred task: text-generation</span><br/></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=advanced-tasks-for-openai-compatible-inference>Advanced Tasks for OpenAI-Compatible Inference<a href=#advanced-tasks-for-openai-compatible-inference class=hash-link aria-label="Direct link to Advanced Tasks for OpenAI-Compatible Inference" title="Direct link to Advanced Tasks for OpenAI-Compatible Inference" translate=no>â€‹</a></h2>
<p>In addition to the native Transformers task types, MLflow defines a few additional task types. Those advanced task types allows you to extend the Transformers pipeline with OpenAI-compatible inference interface, to serve models for specific use cases.</p>
<p>For example, the Transformers <code>text-generation</code> pipeline inputs and outputs a single string or a list of strings. However, when serving a model, it is often necessary to have a more structured input and output format. For instance, in a chat-style application, the input may be a list of messages.</p>
<p>To support these use cases, MLflow defines a set of advanced task types prefixed with <code>llm/v1</code>:</p>
<ul>
<li class=""><code>"llm/v1/chat"</code> for chat-style applications</li>
<li class=""><code>"llm/v1/completions"</code> for generic completions</li>
<li class=""><code>"llm/v1/embeddings"</code> for text embeddings generation</li>
</ul>
<p>The required step to use these advanced task types is just to specify the <code>task</code> parameter as an <code>llm/v1</code> task when logging the models.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#F8F8F2;--prism-background-color:#282A36><div class=codeBlockContent_bxn0><div class=codeBlockHeader_C_1e aria-label="Code block header for python code with copy and toggle buttons"><span class=languageLabel_zr_I>python</span></div><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#F8F8F2;background-color:#282A36><code class=codeBlockLines_e6Vv><span class=token-line style=color:#F8F8F2><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> mlflow</span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain" style=display:inline-block></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">with</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">start_run</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">    mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">log_model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        transformers_model</span><span class="token operator">=</span><span class="token plain">pipeline</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        name</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">"model"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        task</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">"llm/v1/chat"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># &lt;= Specify the llm/v1 task type</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        </span><span class="token comment" style="color:rgb(98, 114, 164)"># Optional, recommended for large models to avoid creating a local copy of the model weights</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        save_pretrained</span><span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br/></span></code></pre></div></div>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"/></svg></span>note</div><div class=admonitionContent_BuS1><p>This feature is only available in MLflow 2.11.0 and above. Also, the <code>llm/v1/chat</code> task type is only available for models saved with <code>transformers >= 4.34.0</code>.</div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=input-and-output-formats>Input and Output Formats<a href=#input-and-output-formats class=hash-link aria-label="Direct link to Input and Output Formats" title="Direct link to Input and Output Formats" translate=no>â€‹</a></h3>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Task<th>Supported pipeline<th>Input<th>Output<tbody><tr><td><code>llm/v1/chat</code><td><code>text-generation</code><td><a class="" href=/mlflow-website/docs/latest/genai/serving/>Chat API spec</a><td>Returns a <a href=https://platform.openai.com/docs/api-reference/chat/object target=_blank rel="noopener noreferrer" class="">Chat Completion</a> object in the json format.<tr><td><code>llm/v1/completions</code><td><code>text-generation</code><td><a class="" href=/mlflow-website/docs/latest/genai/serving/>Completions API spec</a><td>Returns a <a href=https://platform.openai.com/docs/guides/text-generation/completions-api target=_blank rel="noopener noreferrer" class="">Completion</a> object in the json format.<tr><td><code>llm/v1/embeddings</code><td><code>feature-extraction</code><td><a class="" href=/mlflow-website/docs/latest/genai/serving/>Embeddings API spec</a><td>Returns a list of <a href=https://platform.openai.com/docs/api-reference/embeddings/object target=_blank rel="noopener noreferrer" class="">Embedding</a> object. Additionally, the model returns <code>usage</code> field, which contains the number of tokens used for the embeddings generation.</table></div>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 14 16"><path fill-rule=evenodd d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"/></svg></span>note</div><div class=admonitionContent_BuS1><p>The Completion API is considered as legacy, but it is still supported in MLflow for backward compatibility. We recommend using the Chat API for compatibility with the latest APIs from OpenAI and other model providers.</div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=code-example-of-using-llmv1-tasks>Code Example of Using <code>llm/v1</code> Tasks<a href=#code-example-of-using-llmv1-tasks class=hash-link aria-label="Direct link to code-example-of-using-llmv1-tasks" title="Direct link to code-example-of-using-llmv1-tasks" translate=no>â€‹</a></h3>
<p>The following code snippet demonstrates how to log a Transformers pipeline with the <code>llm/v1/chat</code> task type, and use the model for chat-style inference. Check out the
<a class="" href=/mlflow-website/docs/latest/ml/deep-learning/transformers/tutorials/conversational/pyfunc-chat-model/>notebook tutorial</a> to see more examples in action!</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#F8F8F2;--prism-background-color:#282A36><div class=codeBlockContent_bxn0><div class=codeBlockHeader_C_1e aria-label="Code block header for python code with copy and toggle buttons"><span class=languageLabel_zr_I>python</span></div><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#F8F8F2;background-color:#282A36><code class=codeBlockLines_e6Vv><span class=token-line style=color:#F8F8F2><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> mlflow</span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> transformers</span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain" style=display:inline-block></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">pipeline </span><span class="token operator">=</span><span class="token plain"> transformers</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">pipeline</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">"text-generation"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"gpt2"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain" style=display:inline-block></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">with</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">start_run</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">    model_info </span><span class="token operator">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">log_model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        transformers_model</span><span class="token operator">=</span><span class="token plain">pipeline</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        name</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">"model"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        task</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">"llm/v1/chat"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        input_example</span><span class="token operator">=</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">            </span><span class="token string" style="color:rgb(255, 121, 198)">"messages"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">                </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string" style="color:rgb(255, 121, 198)">"role"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"system"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"content"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"You are a bot."</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">                </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string" style="color:rgb(255, 121, 198)">"role"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"user"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"content"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"Hello, how are you?"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">            </span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        save_pretrained</span><span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain" style=display:inline-block></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Model metadata logs additional field "inference_task"</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">print</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">model_info</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">flavors</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">"transformers"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">"inference_task"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># >> llm/v1/chat</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain" style=display:inline-block></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># The original native task type is also saved</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">print</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">model_info</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">flavors</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">"transformers"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">"task"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># >> text-generation</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain" style=display:inline-block></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Model signature is set to the chat API spec</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">print</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">model_info</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">signature</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># >> inputs:</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># >>   ['messages': Array({content: string (required), name: string (optional), role: string (required)}) (required), 'temperature': double (optional), 'max_tokens': long (optional), 'stop': Array(string) (optional), 'n': long (optional), 'stream': boolean (optional)]</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># >> outputs:</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># >>   ['id': string (required), 'object': string (required), 'created': long (required), 'model': string (required), 'choices': Array({finish_reason: string (required), index: long (required), message: {content: string (required), name: string (optional), role: string (required)} (required)}) (required), 'usage': {completion_tokens: long (required), prompt_tokens: long (required), total_tokens: long (required)} (required)]</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># >> params:</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># >>     None</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain" style=display:inline-block></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># The model can be served with the OpenAI-compatible inference API</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">pyfunc_model </span><span class="token operator">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">pyfunc</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">load_model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">model_info</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">model_uri</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">prediction </span><span class="token operator">=</span><span class="token plain"> pyfunc_model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        </span><span class="token string" style="color:rgb(255, 121, 198)">"messages"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">            </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string" style="color:rgb(255, 121, 198)">"role"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"system"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"content"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"You are a bot."</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">            </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string" style="color:rgb(255, 121, 198)">"role"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"user"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"content"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"Hello, how are you?"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        </span><span class="token string" style="color:rgb(255, 121, 198)">"temperature"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">0.5</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        </span><span class="token string" style="color:rgb(255, 121, 198)">"max_tokens"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">200</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">print</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">prediction</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># >> [{'choices': [{'finish_reason': 'stop',</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># >>               'index': 0,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># >>               'message': {'content': 'I'm doing well, thank you for asking.', 'role': 'assistant'}}],</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># >>   'created': 1719875820,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># >>   'id': '355c4e9e-040b-46b0-bf22-00e93486100c',</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># >>   'model': 'gpt2',</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># >>   'object': 'chat.completion',</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># >>   'usage': {'completion_tokens': 7, 'prompt_tokens': 13, 'total_tokens': 20}}]</span><br/></span></code></pre></div></div>
<p>Note that the input and output modifications only apply when the model is loaded with <a href=/mlflow-website/docs/latest/api_reference/python_api/mlflow.pyfunc.html#mlflow.pyfunc.load_model target=_blank><code>mlflow.pyfunc.load_model<!-- -->()</code></a> (e.g. when
serving the model with the <code>mlflow models serve</code> CLI tool). If you want to load just the raw pipeline, you can
use <a href=/mlflow-website/docs/latest/api_reference/python_api/mlflow.transformers.html#mlflow.transformers.load_model target=_blank><code>mlflow.transformers.load_model<!-- -->()</code></a>.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=provisioned-throughput-on-databricks-model-serving>Provisioned Throughput on Databricks Model Serving<a href=#provisioned-throughput-on-databricks-model-serving class=hash-link aria-label="Direct link to Provisioned Throughput on Databricks Model Serving" title="Direct link to Provisioned Throughput on Databricks Model Serving" translate=no>â€‹</a></h2>
<p><a href=https://docs.databricks.com/en/machine-learning/foundation-models/deploy-prov-throughput-foundation-model-apis.html target=_blank rel="noopener noreferrer" class="">Provisioned Throughput</a>
on Databricks Model Serving is a capability that optimizes inference performance for foundation models with performance guarantees.
To serve Transformers models with provisioned throughput, specify <code>llm/v1/xxx</code> task type when logging the model. MLflow logs the required metadata
to enable provisioned throughput on Databricks Model Serving.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 12 16"><path fill-rule=evenodd d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"/></svg></span>tip</div><div class=admonitionContent_BuS1><p>When logging large models, you can use <code>save_pretrained=False</code> to avoid creating a local copy of the model weights for saving time and disk space.
Please refer to the <a class="" href=/mlflow-website/docs/latest/ml/deep-learning/transformers/large-models/#transformers-save-pretrained-guide>documentation</a> for more details.</div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id=faq>FAQ<a href=#faq class=hash-link aria-label="Direct link to FAQ" title="Direct link to FAQ" translate=no>â€‹</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id=how-to-override-the-default-query-parameters-for-the-openai-compatible-inference>How to override the default query parameters for the OpenAI-compatible inference?<a href=#how-to-override-the-default-query-parameters-for-the-openai-compatible-inference class=hash-link aria-label="Direct link to How to override the default query parameters for the OpenAI-compatible inference?" title="Direct link to How to override the default query parameters for the OpenAI-compatible inference?" translate=no>â€‹</a></h3>
<p>When serving the model saved with the <code>llm/v1</code> task type, MLflow uses the same default value as OpenAI APIs for the parameters like <code>temperature</code> and <code>stop</code>.
You can override them by either passing the values at inference time, or by setting different default values when logging the model.</p>
<ol>
<li class="">At inference time: You can pass the parameters as part of the input dictionary when calling the <code>predict()</code> method, just like how you pass the input messages.</li>
<li class="">When logging the model: You can override the default values for the parameters by saving a <code>model_config</code> parameter when logging the model.</li>
</ol>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#F8F8F2;--prism-background-color:#282A36><div class=codeBlockContent_bxn0><div class=codeBlockHeader_C_1e aria-label="Code block header for python code with copy and toggle buttons"><span class=languageLabel_zr_I>python</span></div><pre tabindex=0 class="prism-code language-python codeBlock_bY9V thin-scrollbar" style=color:#F8F8F2;background-color:#282A36><code class=codeBlockLines_e6Vv><span class=token-line style=color:#F8F8F2><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">with</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">start_run</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">    model_info </span><span class="token operator">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">log_model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        transformers_model</span><span class="token operator">=</span><span class="token plain">pipeline</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        name</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">"model"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        task</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">"llm/v1/chat"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        model_config</span><span class="token operator">=</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">            </span><span class="token string" style="color:rgb(255, 121, 198)">"temperature"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">0.5</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># &lt;= Set the default temperature</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">            </span><span class="token string" style="color:rgb(255, 121, 198)">"stop"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">"foo"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"bar"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># &lt;= Set the default stop sequence</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">        save_pretrained</span><span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br/></span><span class=token-line style=color:#F8F8F2><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br/></span></code></pre></div></div>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class=admonitionHeading_Gvgb><span class=admonitionIcon_Rf37><svg viewBox="0 0 16 16"><path fill-rule=evenodd d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"/></svg></span>attention</div><div class=admonitionContent_BuS1><p>The <code>stop</code> parameter can be used to specify the stop sequence for the <code>llm/v1/chat</code> and <code>llm/v1/completions</code> tasks.
We emulate the behavior of the <code>stop</code> parameter in the OpenAI APIs by passing the
<a href=https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.GenerationMixin.generate.stopping_criteria target=_blank rel="noopener noreferrer" class="">stopping_criteria</a>
to the Transformers pipeline, with the token IDs of the given stop sequence. However, the behavior may not be stable because
the tokenizer does not always generate the same token IDs for the same sequence in different sentences, especially for <code>sentence-piece</code> based tokenizers.</div></div></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href=/mlflow-website/docs/latest/ml/deep-learning/transformers/large-models/><div class=pagination-nav__sublabel>Previous</div><div class=pagination-nav__label>Working with Large Transformers Models</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/mlflow-website/docs/latest/ml/deep-learning/transformers/tutorials/><div class=pagination-nav__sublabel>Next</div><div class=pagination-nav__label>Tutorials</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href=#overview class="table-of-contents__link toc-highlight">Overview</a><li><a href=#native-transformers-task-types class="table-of-contents__link toc-highlight">Native Transformers Task Types</a><li><a href=#advanced-tasks-for-openai-compatible-inference class="table-of-contents__link toc-highlight">Advanced Tasks for OpenAI-Compatible Inference</a><ul><li><a href=#input-and-output-formats class="table-of-contents__link toc-highlight">Input and Output Formats</a><li><a href=#code-example-of-using-llmv1-tasks class="table-of-contents__link toc-highlight">Code Example of Using <code>llm/v1</code> Tasks</a></ul><li><a href=#provisioned-throughput-on-databricks-model-serving class="table-of-contents__link toc-highlight">Provisioned Throughput on Databricks Model Serving</a><li><a href=#faq class="table-of-contents__link toc-highlight">FAQ</a><ul><li><a href=#how-to-override-the-default-query-parameters-for-the-openai-compatible-inference class="table-of-contents__link toc-highlight">How to override the default query parameters for the OpenAI-compatible inference?</a></ul></ul></div></div></div></div></main></div></div></div><footer class="relative pb-30 flex flex-col pt-30 bg-bottom bg-no-repeat bg-cover bg-size-[auto_360px] 2xl:bg-size-[100%_360px] bg-brand-black"><div style="position:absolute;width:100%;bottom:0;pointer-events:none;mask-composite:intersect;height:360px;background-image:repeating-linear-gradient(
        to right,
        rgba(0, 0, 0, 0.05),
        rgba(0, 0, 0, 0.25) 18px,
        transparent 2px,
        transparent 10px
      ),
      radial-gradient(
        circle at bottom center,
        oklch(0.7533 0.11 216.4) 0%,
        transparent 60%
      ),
      linear-gradient(to right, color-mix(in srgb, oklch(0.7533 0.11 216.4), navy 40%), color-mix(in srgb, oklch(0.7533 0.11 216.4), teal 40%));mask-image:radial-gradient(ellipse at center bottom, black 60%, transparent 80%),
      linear-gradient(to top, black 10%, transparent 40%)"></div><div class=z-1><div class="flex flex-row justify-between items-start md:items-center px-6 lg:px-20 gap-10 xs:gap-0 max-w-container"><div class="flex flex-col gap-8"><svg xmlns=http://www.w3.org/2000/svg width=109 height=40 fill=none viewBox="0 0 109 40" class="h-[36px] shrink-0"><path fill=#fff d="M0 31.032v-15.53h3.543v1.968c.893-1.594 2.84-2.425 4.593-2.425 2.042 0 3.828.926 4.658 2.745 1.216-2.043 3.034-2.745 5.043-2.745 2.81 0 5.49 1.787 5.49 5.904v10.083h-3.574v-9.478c0-1.818-.926-3.19-3-3.19-1.947 0-3.224 1.53-3.224 3.445v9.22H9.893v-9.475c0-1.786-.898-3.18-3.003-3.18-1.977 0-3.223 1.467-3.223 3.444v9.221ZM27.855 31.032V7.929h3.703v23.103ZM30.07 39.487c.833.232 1.582.383 3.17.383 2.953 0 6.436-1.665 7.353-6.339l3.786-18.739h5.629l.687-3.117h-5.686l.765-3.725c.586-2.892 2.186-4.358 4.754-4.358.668 0 .48.058 1.076.17L52.427.57c-.793-.237-1.503-.379-3.049-.379a7.32 7.32 0 0 0-4.528 1.484c-1.441 1.114-2.393 2.75-2.827 4.863l-1.066 5.137h-5.034l-.411 3.12h4.823L36.859 32.12c-.383 1.965-1.5 4.315-4.708 4.315-.727 0-.463-.055-1.121-.162ZM53.342 30.905H49.64l5.074-23.309h3.701ZM71.807 16.477A7.962 7.962 0 0 0 60.97 27.904l2.425-1.78a5.005 5.005 0 0 1 3.845-8.145v1.895ZM62.618 29.472a7.962 7.962 0 0 0 10.836-11.428l-2.425 1.78a5.005 5.005 0 0 1-3.845 8.145v-1.894ZM78.092 15.493h4.044l.823 10.612 5.759-10.612 3.839.055 1.508 10.557 5.074-10.612 3.701.055-7.678 15.493H91.46l-1.783-11.106-5.895 11.106h-3.84ZM105.072 15.768h-.766v-.266h1.845v.272h-.765v2.243h-.314ZM106.614 15.502h.383l.482 1.34q.091.259.178.524h.018c.059-.176.113-.352.172-.524l.478-1.34h.383v2.515h-.298V16.63c0-.22.024-.523.04-.747h-.016l-.191.574-.475 1.304h-.208l-.481-1.302-.191-.574h-.015c.017.224.042.527.042.747v1.387h-.291Z"/></svg><div class="text-xs text-left md:text-nowrap md:w-0">Â© 2025 MLflow Project, a Series of LF Projects, LLC.</div></div><div class="flex flex-col flex-wrap justify-end md:text-right md:flex-row gap-x-10 lg:gap-x-20 gap-y-5 w-2/5 md:w-auto md:pt-2 max-w-fit"><div><a href=https://mlflow.org target=_blank rel="noopener noreferrer" class="text-[15px] font-medium no-underline hover:no-underline transition-opacity hover:opacity-80 text-white visited:text-white">Components</a></div><div><a href=https://mlflow.org/releases target=_blank rel="noopener noreferrer" class="text-[15px] font-medium no-underline hover:no-underline transition-opacity hover:opacity-80 text-white visited:text-white">Releases</a></div><div><a href=https://mlflow.org/blog target=_blank rel="noopener noreferrer" class="text-[15px] font-medium no-underline hover:no-underline transition-opacity hover:opacity-80 text-white visited:text-white">Blog</a></div><div><a class="text-[15px] font-medium no-underline hover:no-underline transition-opacity hover:opacity-80 text-white visited:text-white" href=/mlflow-website/docs/latest/>Docs</a></div><div><a href=https://mlflow.org/ambassadors target=_blank rel="noopener noreferrer" class="text-[15px] font-medium no-underline hover:no-underline transition-opacity hover:opacity-80 text-white visited:text-white">Ambassador Program</a></div></div></div></div></footer></div></body>