<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-classic-ml docs-version-current docs-doc-page docs-doc-id-deep-learning/transformers/tutorials/prompt-templating/prompt-templating-ipynb" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">Prompt Templating with MLflow and Transformers | MLflow</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://mlflow.org/docs/latest/ml/deep-learning/transformers/tutorials/prompt-templating/prompt-templating"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-classic-ml-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-classic-ml-current"><meta data-rh="true" property="og:title" content="Prompt Templating with MLflow and Transformers | MLflow"><meta data-rh="true" name="description" content="Download this notebook"><meta data-rh="true" property="og:description" content="Download this notebook"><link data-rh="true" rel="icon" href="/docs/latest/images/favicon.ico"><link data-rh="true" rel="canonical" href="https://mlflow.org/docs/latest/ml/deep-learning/transformers/tutorials/prompt-templating/prompt-templating"><link data-rh="true" rel="alternate" href="https://mlflow.org/docs/latest/ml/deep-learning/transformers/tutorials/prompt-templating/prompt-templating" hreflang="en"><link data-rh="true" rel="alternate" href="https://mlflow.org/docs/latest/ml/deep-learning/transformers/tutorials/prompt-templating/prompt-templating" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://XKVLO8P882-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Deep Learning üï∏Ô∏è","item":"https://mlflow.org/docs/latest/ml/deep-learning/"},{"@type":"ListItem","position":2,"name":"Transformers","item":"https://mlflow.org/docs/latest/ml/deep-learning/transformers/"},{"@type":"ListItem","position":3,"name":"Tutorials","item":"https://mlflow.org/docs/latest/ml/deep-learning/transformers/tutorials/"},{"@type":"ListItem","position":4,"name":"Introduction to Prompt Templating","item":"https://mlflow.org/docs/latest/ml/deep-learning/transformers/tutorials/prompt-templating/prompt-templating"}]}</script><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=GTM-N6WMTTJ"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","GTM-N6WMTTJ",{anonymize_ip:!0}),gtag("config","AW-16857946923",{anonymize_ip:!0})</script>
<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var g=t.getElementsByTagName(a)[0],m=t.createElement(a);m.async=!0,m.src="https://www.googletagmanager.com/gtm.js?id=GTM-N6WMTTJ",g.parentNode.insertBefore(m,g)}(window,document,"script","dataLayer")</script>



<link rel="search" type="application/opensearchdescription+xml" title="MLflow" href="/docs/latest/opensearch.xml">





<script src="/docs/latest/js/runllm.js" defer="defer"></script><link rel="stylesheet" href="/docs/latest/assets/css/styles.4bfc27eb.css">
<script src="/docs/latest/assets/js/runtime~main.db9e35ae.js" defer="defer"></script>
<script src="/docs/latest/assets/js/main.6f2d163a.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>


<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/docs/latest/"><div class="navbar__logo"><img src="/docs/latest/images/logo-light.svg" alt="MLflow Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/docs/latest/images/logo-dark.svg" alt="MLflow Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link docsDropdown_VGp6" data-active="ml"><div style="display:flex;gap:8px;align-items:center"><div class="dropdownCircle_n91F" style="width:10px;height:10px;background-color:var(--ml-color-primary);border-radius:4px"></div>ML Docs</div></a><ul class="dropdown__menu"><li><a aria-current="page" class="dropdown__link ml-docs-link dropdown__link--active" href="/docs/latest/ml/"><div style="display:flex;gap:8px;align-items:center"><div style="width:10px;height:10px;background-color:var(--ml-color-primary);border-radius:4px"></div>ML Docs</div></a></li><li><a class="dropdown__link genai-docs-link" href="/docs/latest/genai/"><div style="display:flex;gap:8px;align-items:center"><div style="width:10px;height:10px;background-color:var(--genai-color-primary);border-radius:4px"></div>GenAI Docs</div></a></li></ul></div><a href="https://mlflow.org/docs/latest/api_reference/index.html" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">API Reference</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/mlflow/mlflow" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link github-link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sidebar-top-level-category"><a class="menu__link" href="/docs/latest/ml/">MLflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a href="https://mlflow.org/docs/latest/genai/mlflow-3" target="_blank" rel="noopener noreferrer" class="menu__link menuExternalLink_NmtK">MLflow 3.0<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/ml/getting-started/">Getting Started üöÄ</a><button aria-label="Expand sidebar category &#x27;Getting Started üöÄ&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/latest/ml/traditional-ml/">Machine Learning ü§ñ</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/ml/traditional-ml/">Traditional ML</a><button aria-label="Expand sidebar category &#x27;Traditional ML&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/docs/latest/ml/deep-learning/">Deep Learning üï∏Ô∏è</a><button aria-label="Collapse sidebar category &#x27;Deep Learning üï∏Ô∏è&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/ml/deep-learning/keras/">Keras</a><button aria-label="Expand sidebar category &#x27;Keras&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/ml/deep-learning/pytorch/">PyTorch</a><button aria-label="Expand sidebar category &#x27;PyTorch&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/ml/deep-learning/tensorflow/">TensorFlow</a><button aria-label="Expand sidebar category &#x27;TensorFlow&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/docs/latest/ml/deep-learning/transformers/">Transformers</a><button aria-label="Collapse sidebar category &#x27;Transformers&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/ml/deep-learning/transformers/guide/">ü§ó Transformers within MLflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/ml/deep-learning/transformers/large-models/">Working with Large Transformers Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/ml/deep-learning/transformers/task/">Transformers Task Types</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/docs/latest/ml/deep-learning/transformers/tutorials/">Tutorials</a><button aria-label="Collapse sidebar category &#x27;Tutorials&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/ml/deep-learning/transformers/tutorials/conversational/conversational-model">Introduction to Conversational Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/ml/deep-learning/transformers/tutorials/conversational/pyfunc-chat-model">Custom Conversational Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/ml/deep-learning/transformers/tutorials/fine-tuning/transformers-fine-tuning">Introduction to Fine Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/ml/deep-learning/transformers/tutorials/fine-tuning/transformers-peft">Leveraging PEFT for Fine Tuning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/ml/deep-learning/transformers/tutorials/audio-transcription/whisper">Introduction to Audio Transcription</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/latest/ml/deep-learning/transformers/tutorials/prompt-templating/prompt-templating">Introduction to Prompt Templating</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/ml/deep-learning/transformers/tutorials/text-generation/text-generation">Text Generation Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/ml/deep-learning/transformers/tutorials/translation/component-translation">Translation Models</a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/ml/deep-learning/sentence-transformers/">Sentence Transformers</a><button aria-label="Expand sidebar category &#x27;Sentence Transformers&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/ml/deep-learning/spacy/">spaCy</a><button aria-label="Expand sidebar category &#x27;spaCy&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/docs/latest/ml/tracking/">Build üî® </a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/ml/tracking/">MLflow Tracking üìà</a><button aria-label="Expand sidebar category &#x27;MLflow Tracking üìà&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/latest/ml/model/">MLflow Model üß†</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/ml/dataset/">MLflow Datasets üóÉÔ∏è</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/ml/evaluation/">Evaluate üéØ</a><button aria-label="Expand sidebar category &#x27;Evaluate üéØ&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/latest/ml/model-registry/">Deploy üö¢</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/latest/ml/tracking/#tracking-setup">Team Collaboration üë•</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a href="https://mlflow.org/docs/latest/api_reference/python_api/index.html" target="_blank" rel="noopener noreferrer" class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false">API References</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.md" target="_blank" rel="noopener noreferrer" class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false">More</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/docs/latest/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Machine Learning ü§ñ</span></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/docs/latest/ml/deep-learning/"><span>Deep Learning üï∏Ô∏è</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/docs/latest/ml/deep-learning/transformers/"><span>Transformers</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/docs/latest/ml/deep-learning/transformers/tutorials/"><span>Tutorials</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Introduction to Prompt Templating</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Prompt Templating with MLflow and Transformers</h1></header>
<a class="button button--primary" style="margin-bottom:1rem;display:block;width:min-content" href="https://raw.githubusercontent.com/mlflow/mlflow/master/docs/docs/classic-ml/deep-learning/transformers/tutorials/prompt-templating/prompt-templating.ipynb" download="">Download this notebook</a>
<p>Welcome to our in-depth tutorial on using prompt templates to conveniently customize the behavior of Transformers pipelines using MLflow.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="learning-objectives">Learning Objectives<a href="#learning-objectives" class="hash-link" aria-label="Direct link to Learning Objectives" title="Direct link to Learning Objectives">‚Äã</a></h3>
<p>In this tutorial, you will:</p>
<ul>
<li>Set up a text generation pipeline using TinyLlama-1.1B as an example model</li>
<li>Set a prompt template that will be used to format user queries at inference time</li>
<li>Load the model for querying</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-a-prompt-template-and-why-use-one">What is a prompt template, and why use one?<a href="#what-is-a-prompt-template-and-why-use-one" class="hash-link" aria-label="Direct link to What is a prompt template, and why use one?" title="Direct link to What is a prompt template, and why use one?">‚Äã</a></h3>
<p>When dealing with large language models, the way a query is structured can significantly impact the model&#x27;s performance. We often need to add some preamble, or format the query in a way that gives us the results that we want. It&#x27;s not ideal to expect the end-user of our applications to know exactly what this format should be, so we typically have a pre-processing step to format the user input in a way that works best with the underlying model. In other words, we apply a prompt template to the user&#x27;s input.</p>
<p>MLflow provides a convenient way to set this on certain pipeline types using the <code>transformers</code> flavor. As of now, the only pipelines that we support are:</p>
<ul>
<li><a href="https://huggingface.co/transformers/main_classes/pipelines.html#transformers.FeatureExtractionPipeline" target="_blank" rel="noopener noreferrer">feature-extraction</a></li>
<li><a href="https://huggingface.co/transformers/main_classes/pipelines.html#transformers.FillMaskPipeline" target="_blank" rel="noopener noreferrer">fill-mask</a></li>
<li><a href="https://huggingface.co/transformers/main_classes/pipelines.html#transformers.SummarizationPipeline" target="_blank" rel="noopener noreferrer">summarization</a></li>
<li><a href="https://huggingface.co/transformers/main_classes/pipelines.html#transformers.Text2TextGenerationPipeline" target="_blank" rel="noopener noreferrer">text2text-generation</a></li>
<li><a href="https://huggingface.co/transformers/main_classes/pipelines.html#transformers.TextGenerationPipeline" target="_blank" rel="noopener noreferrer">text-generation</a></li>
</ul>
<p>If you need a runthrough of the basics of how to use the <code>transformers</code> flavor, check out the <a href="https://mlflow.org/docs/latest/ml/deep-learning/transformers/guide/index.html" target="_blank" rel="noopener noreferrer">Introductory Guide</a>!</p>
<p>Now, let&#x27;s dive in and see how it&#x27;s done!</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)"># Disable tokenizers warnings when constructing pipelines</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token operator">%</span><span class="token plain">env TOKENIZERS_PARALLELISM</span><span class="token operator">=</span><span class="token plain">false</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> warnings</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Disable a few less-than-useful UserWarnings from setuptools and pydantic</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">warnings</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">filterwarnings</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;ignore&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> category</span><span class="token operator">=</span><span class="token plain">UserWarning</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">env: TOKENIZERS_PARALLELISM=false</pre>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="pipeline-setup-and-inference">Pipeline setup and inference<a href="#pipeline-setup-and-inference" class="hash-link" aria-label="Direct link to Pipeline setup and inference" title="Direct link to Pipeline setup and inference">‚Äã</a></h3>
<p>First, let&#x27;s configure our Transformers pipeline. This is a helpful abstraction that makes it seamless to get started with using an LLM for inference.</p>
<p>For this demonstration, let&#x27;s say the user&#x27;s input is the phrase &quot;Tell me the largest bird&quot;. Let&#x27;s experiment with a few different prompt templates, and see which one we like best.</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> pipeline</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">generator </span><span class="token operator">=</span><span class="token plain"> pipeline</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;text-generation&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> model</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">user_input </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;Tell me the largest bird&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">prompt_templates </span><span class="token operator">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># no template</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;{prompt}&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># question-answer style template</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  &quot;Q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">prompt</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">A</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># dialogue style template with a system prompt</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;You are an assistant that is knowledgeable about birds. &quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;If asked about the largest bird</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> you will reply </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;Duck&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      &quot;User</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">prompt</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;Assistant:&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">responses </span><span class="token operator">=</span><span class="token plain"> generator</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">template</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token builtin" style="color:rgb(189, 147, 249)">format</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">prompt</span><span class="token operator">=</span><span class="token plain">user_input</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">for</span><span class="token plain"> template </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">in</span><span class="token plain"> prompt_templates</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> max_new_tokens</span><span class="token operator">=</span><span class="token number">15</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">for</span><span class="token plain"> idx</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> response </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">in</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">enumerate</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">responses</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">print</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">f&quot;Response to Template #</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string-interpolation interpolation">idx</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">:&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">print</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">response</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;generated_text&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token operator">+</span><span class="token plain"> &quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">Response to Template #0:
Tell me the largest bird you&#x27;ve ever seen.
I&#x27;ve seen a lot of birds

Response to Template #1:
Q: Tell me the largest bird
A: The largest bird is a pigeon.

A: The largest

Response to Template #2:
You are an assistant that is knowledgeable about birds. If asked about the largest bird, you will reply &#x27;Duck&#x27;.
User: Tell me the largest bird
Assistant: Duck
User: What is the largest bird?
Assistant:</pre>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="saving-the-model-and-template-with-mlflow">Saving the model and template with MLflow<a href="#saving-the-model-and-template-with-mlflow" class="hash-link" aria-label="Direct link to Saving the model and template with MLflow" title="Direct link to Saving the model and template with MLflow">‚Äã</a></h2>
<p>Now that we&#x27;ve experimented with a few prompt templates, let&#x27;s pick one, and save it together with our pipeline using MLflow. Before we do this, let&#x27;s take a few minutes to learn about an important component of MLflow models‚Äîsignatures!</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="creating-a-model-signature">Creating a model signature<a href="#creating-a-model-signature" class="hash-link" aria-label="Direct link to Creating a model signature" title="Direct link to Creating a model signature">‚Äã</a></h3>
<p>A model signature codifies a model&#x27;s expected inputs, outputs, and inference params. MLflow enforces this signature at inference time, and will raise a helpful exception if the user input does not match up with the expected format.</p>
<p>Creating a signature can be done simply by calling <code>mlflow.models.infer_signature()</code>, and providing a sample input and output value. We can use <code>mlflow.transformers.generate_signature_output()</code> to easily generate a sample output. If we want to pass any additional arguments to the pipeline at inference time (e.g. <code>max_new_tokens</code> above), we can do so via <code>params</code>.</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sample_input </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;Tell me the largest bird&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">params </span><span class="token operator">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;max_new_tokens&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">15</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">signature </span><span class="token operator">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">models</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">infer_signature</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  sample_input</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">generate_signature_output</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">generator</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> sample_input</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> params</span><span class="token operator">=</span><span class="token plain">params</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  params</span><span class="token operator">=</span><span class="token plain">params</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># visualize the signature</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">signature</span><br></span></code></pre></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">2024/01/16 17:28:42 WARNING mlflow.transformers: params provided to the `predict` method will override the inference configuration saved with the model. If the params provided are not valid for the pipeline, MlflowException will be raised.</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">inputs: 
[string (required)]
outputs: 
[string (required)]
params: 
[&#x27;max_new_tokens&#x27;: long (default: 15)]</pre>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="starting-a-new-experiment">Starting a new experiment<a href="#starting-a-new-experiment" class="hash-link" aria-label="Direct link to Starting a new experiment" title="Direct link to Starting a new experiment">‚Äã</a></h3>
<p>We create a new <a href="https://mlflow.org/docs/latest/ml/tracking.html#experiments" target="_blank" rel="noopener noreferrer">MLflow Experiment</a> so that the run we&#x27;re going to log our model to does not log to the default experiment and instead has its own contextually relevant entry.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="logging-the-model-with-the-prompt-template">Logging the model with the prompt template<a href="#logging-the-model-with-the-prompt-template" class="hash-link" aria-label="Direct link to Logging the model with the prompt template" title="Direct link to Logging the model with the prompt template">‚Äã</a></h3>
<p>Logging the model using MLflow saves the model and its essential metadata so it can be efficiently tracked and versioned. We&#x27;ll use <code>mlflow.transformers.log_model()</code>, which is tailored to make this process as seamless as possible. To save the prompt template, all we have to do is pass it in using the <code>prompt_template</code> keyword argument.</p>
<p>Two important thing to take note of:</p>
<ol>
<li>
<p>A prompt template must be a string with exactly one named placeholder <code>{prompt}</code>. MLflow will raise an error if a prompt template is provided that does not conform to this format.</p>
</li>
<li>
<p><code>text-generation</code> pipelines with a prompt template will have the <a href="https://huggingface.co/docs/huggingface_hub/main/en/package_reference/inference_client#huggingface_hub.inference._text_generation.TextGenerationParameters.return_full_text" target="_blank" rel="noopener noreferrer">return_full_text pipeline argument</a> set to <code>False</code> by default. This is to prevent the template from being shown to the users, which could potentially cause confusion as it was not part of their original input. To override this behaviour, either set <code>return_full_text</code> to <code>True</code> via <code>params</code>, or by including it in a <code>model_config</code> dict in <code>log_model()</code>.</p>
</li>
</ol>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)"># If you are running this tutorial in local mode, leave the next line commented out.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Otherwise, uncomment the following line and set your tracking uri to your local or remote tracking server.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">set_tracking_uri</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;http://127.0.0.1:5000&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Set a name for the experiment that is indicative of what the runs being created within it are in regards to</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">set_experiment</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;prompt-templating&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">prompt_template </span><span class="token operator">=</span><span class="token plain"> &quot;Q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain">prompt</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">A</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">with</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">start_run</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  model_info </span><span class="token operator">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">transformers</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">log_model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      transformers_model</span><span class="token operator">=</span><span class="token plain">generator</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      name</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;model&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      task</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;text-generation&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      signature</span><span class="token operator">=</span><span class="token plain">signature</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      input_example</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;Tell me the largest bird&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      prompt_template</span><span class="token operator">=</span><span class="token plain">prompt_template</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token comment" style="color:rgb(98, 114, 164)"># Since MLflow 2.11.0, you can save the model in &#x27;reference-only&#x27; mode to reduce storage usage by not saving</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token comment" style="color:rgb(98, 114, 164)"># the base model weights but only the reference to the HuggingFace model hub. To enable this, uncomment the</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token comment" style="color:rgb(98, 114, 164)"># following line:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token comment" style="color:rgb(98, 114, 164)"># save_pretrained=False,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">2024/01/16 17:28:45 INFO mlflow.tracking.fluent: Experiment with name &#x27;prompt-templating&#x27; does not exist. Creating a new experiment.
2024/01/16 17:28:52 INFO mlflow.transformers: text-generation pipelines saved with prompt templates have the `return_full_text` pipeline kwarg set to False by default. To override this behavior, provide a `model_config` dict with `return_full_text` set to `True` when saving the model.
2024/01/16 17:32:57 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /var/folders/qd/9rwd0_gd0qs65g4sdqlm51hr0000gp/T/tmpbs0poq1a/model, flavor: transformers), fall back to return [&#x27;transformers==4.34.1&#x27;, &#x27;torch==2.1.1&#x27;, &#x27;torchvision==0.16.1&#x27;, &#x27;accelerate==0.25.0&#x27;]. Set logging level to DEBUG to see the full traceback.</pre>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="loading-the-model-for-inference">Loading the model for inference<a href="#loading-the-model-for-inference" class="hash-link" aria-label="Direct link to Loading the model for inference" title="Direct link to Loading the model for inference">‚Äã</a></h2>
<p>Next, we can load the model using <code>mlflow.pyfunc.load_model()</code>.</p>
<p>The <code>pyfunc</code> module in MLflow serves as a generic wrapper for Python functions. It gives us a standard interface for loading and querying models as python functions, without having to worry about the specifics of the underlying models.</p>
<p>Utilizing <a href="https://www.mlflow.org/docs/latest/python_api/mlflow.pyfunc.html#mlflow.pyfunc.load_model" target="_blank" rel="noopener noreferrer">mlflow.pyfunc.load_model</a>, our previously logged text generation model is loaded using its unique model URI. This URI is a reference to the stored model artifacts. MLflow efficiently handles the model&#x27;s deserialization, along with any associated dependencies, preparing it for immediate use.</p>
<p>Now, when we call the <code>predict()</code> method on our loaded model, the user&#x27;s input should be formatted with our chosen prompt template prior to inference!</p>
<div style="flex-grow:1;min-width:0;margin-top:var(--padding-md);width:100%"><div class="codeBlock_oJcR language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">loaded_generator </span><span class="token operator">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">pyfunc</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">load_model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">model_uri</span><span class="token operator">=</span><span class="token plain">model_info</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">model_uri</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">loaded_generator</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;Tell me the largest bird&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre></div></div></div>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">Downloading artifacts:   0%|          | 0/23 [00:00&lt;?, ?it/s]</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">2024/01/16 17:33:16 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">Loading checkpoint shards:   0%|          | 0/10 [00:00&lt;?, ?it/s]</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">2024/01/16 17:33:56 WARNING mlflow.transformers: params provided to the `predict` method will override the inference configuration saved with the model. If the params provided are not valid for the pipeline, MlflowException will be raised.</pre>
<pre style="margin:0;border-radius:0;background:none;font-size:0.85rem;flex-grow:1;padding:var(--padding-sm)">[&#x27;The largest bird is a pigeon.

A: The largest&#x27;]</pre>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="closing-remarks">Closing Remarks<a href="#closing-remarks" class="hash-link" aria-label="Direct link to Closing Remarks" title="Direct link to Closing Remarks">‚Äã</a></h2>
<p>This demonstration showcased a simple way to format user queries using prompt templates. However, this feature is relatively limited in scope, and is only supported for a few types of pipelines. If your use-case is more complex, you might want to check out our <a href="https://www.mlflow.org/docs/latest/llms/custom-pyfunc-for-llms/notebooks/custom-pyfunc-advanced-llm.html" target="_blank" rel="noopener noreferrer">guide for creating a custom PyFunc</a>!</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/mlflow/mlflow/edit/master/docs/docs/classic-ml/deep-learning/transformers/tutorials/prompt-templating/prompt-templating.ipynb" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/latest/ml/deep-learning/transformers/tutorials/audio-transcription/whisper"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Introduction to Audio Transcription</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/latest/ml/deep-learning/transformers/tutorials/text-generation/text-generation"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Text Generation Models</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#learning-objectives" class="table-of-contents__link toc-highlight">Learning Objectives</a></li><li><a href="#what-is-a-prompt-template-and-why-use-one" class="table-of-contents__link toc-highlight">What is a prompt template, and why use one?</a></li><li><a href="#pipeline-setup-and-inference" class="table-of-contents__link toc-highlight">Pipeline setup and inference</a></li><li><a href="#saving-the-model-and-template-with-mlflow" class="table-of-contents__link toc-highlight">Saving the model and template with MLflow</a><ul><li><a href="#creating-a-model-signature" class="table-of-contents__link toc-highlight">Creating a model signature</a></li><li><a href="#starting-a-new-experiment" class="table-of-contents__link toc-highlight">Starting a new experiment</a></li><li><a href="#logging-the-model-with-the-prompt-template" class="table-of-contents__link toc-highlight">Logging the model with the prompt template</a></li></ul></li><li><a href="#loading-the-model-for-inference" class="table-of-contents__link toc-highlight">Loading the model for inference</a></li><li><a href="#closing-remarks" class="table-of-contents__link toc-highlight">Closing Remarks</a></li></ul></div></div></div></div></main></div></div></div><footer class="pb-30 flex flex-col pt-30 bg-bottom bg-no-repeat bg-cover bg-size-[auto_360px] 2xl:bg-size-[100%_360px] bg-brand-black" style="background-image:linear-gradient(#0e1414 60%, #0c141400 90% 100%),url(/docs/latest/assets/images/footer-blue-bg-2664116e3788212e9f50cfc6024806f8.png)"><div class="flex flex-row justify-between items-start md:items-center px-6 lg:px-20 gap-10 xs:gap-0 max-w-container"><div class="flex flex-col gap-8"><svg xmlns="http://www.w3.org/2000/svg" width="109" height="40" fill="none" viewBox="0 0 109 40" class="h-[36px] shrink-0"><path fill="#fff" d="M0 31.032v-15.53h3.543v1.968c.893-1.594 2.84-2.425 4.593-2.425 2.042 0 3.828.926 4.658 2.745 1.216-2.043 3.034-2.745 5.043-2.745 2.81 0 5.49 1.787 5.49 5.904v10.083h-3.574v-9.478c0-1.818-.926-3.19-3-3.19-1.947 0-3.224 1.53-3.224 3.445v9.22H9.893v-9.475c0-1.786-.898-3.18-3.003-3.18-1.977 0-3.223 1.467-3.223 3.444v9.221ZM27.855 31.032V7.929h3.703v23.103ZM30.07 39.487c.833.232 1.582.383 3.17.383 2.953 0 6.436-1.665 7.353-6.339l3.786-18.739h5.629l.687-3.117h-5.686l.765-3.725c.586-2.892 2.186-4.358 4.754-4.358.668 0 .48.058 1.076.17L52.427.57c-.793-.237-1.503-.379-3.049-.379a7.32 7.32 0 0 0-4.528 1.484c-1.441 1.114-2.393 2.75-2.827 4.863l-1.066 5.137h-5.034l-.411 3.12h4.823L36.859 32.12c-.383 1.965-1.5 4.315-4.708 4.315-.727 0-.463-.055-1.121-.162ZM53.342 30.905H49.64l5.074-23.309h3.701ZM71.807 16.477A7.962 7.962 0 0 0 60.97 27.904l2.425-1.78a5.005 5.005 0 0 1 3.845-8.145v1.895ZM62.618 29.472a7.962 7.962 0 0 0 10.836-11.428l-2.425 1.78a5.005 5.005 0 0 1-3.845 8.145v-1.894ZM78.092 15.493h4.044l.823 10.612 5.759-10.612 3.839.055 1.508 10.557 5.074-10.612 3.701.055-7.678 15.493H91.46l-1.783-11.106-5.895 11.106h-3.84ZM105.072 15.768h-.766v-.266h1.845v.272h-.765v2.243h-.314ZM106.614 15.502h.383l.482 1.34q.091.259.178.524h.018c.059-.176.113-.352.172-.524l.478-1.34h.383v2.515h-.298V16.63c0-.22.024-.523.04-.747h-.016l-.191.574-.475 1.304h-.208l-.481-1.302-.191-.574h-.015c.017.224.042.527.042.747v1.387h-.291Z"></path></svg><div class="text-xs text-left md:text-nowrap md:w-0">¬© 2025 MLflow Project, a Series of LF Projects, LLC.</div></div><div class="flex flex-col flex-wrap justify-end md:text-right md:flex-row gap-x-10 lg:gap-x-20 gap-y-5 w-2/5 md:w-auto md:pt-2 max-w-fit"><div><a href="https://mlflow.org" target="_blank" rel="noopener noreferrer" class="text-[15px] font-medium no-underline hover:no-underline transition-opacity hover:opacity-80 text-white visited:text-white">Components</a></div><div><a href="https://mlflow.org/releases" target="_blank" rel="noopener noreferrer" class="text-[15px] font-medium no-underline hover:no-underline transition-opacity hover:opacity-80 text-white visited:text-white">Releases</a></div><div><a href="https://mlflow.org/blog" target="_blank" rel="noopener noreferrer" class="text-[15px] font-medium no-underline hover:no-underline transition-opacity hover:opacity-80 text-white visited:text-white">Blog</a></div><div><a class="text-[15px] font-medium no-underline hover:no-underline transition-opacity hover:opacity-80 text-white visited:text-white" href="/docs/latest/">Docs</a></div><div><a href="https://mlflow.org/ambassadors" target="_blank" rel="noopener noreferrer" class="text-[15px] font-medium no-underline hover:no-underline transition-opacity hover:opacity-80 text-white visited:text-white">Ambassador Program</a></div></div></div></footer></div>
</body>
</html>