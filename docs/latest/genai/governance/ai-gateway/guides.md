# Getting Started with MLflow AI Gateway

MLflow AI Gateway provides a unified interface for deploying and managing LLM providers, offering centralized API key management and seamless integration with multiple language model services.

#### Installation & Setup

Install dependencies and configure your AI Gateway environment

#### Configuration

Set up API keys and define endpoints for multiple LLM providers

#### Gateway Server

Launch and manage your AI Gateway server with zero downtime updates

#### API Integration

Query endpoints using REST APIs and Python client libraries

By following this guide, you'll have a production-ready MLflow AI Gateway that centralizes access to multiple LLM providers with secure API key management and unified endpoint configuration.

## Step-by-Step Tutorials[​](#step-by-step-tutorials "Direct link to Step-by-Step Tutorials")

### [Setting Up the MLflow AI Gateway](/mlflow-website/docs/latest/genai/governance/ai-gateway/guides/step1-create-deployments.md)

[Install dependencies, configure providers, and launch your gateway server](/mlflow-website/docs/latest/genai/governance/ai-gateway/guides/step1-create-deployments.md)

[Setup guide →](/mlflow-website/docs/latest/genai/governance/ai-gateway/guides/step1-create-deployments.md)

### [Querying the MLflow AI Gateway](/mlflow-website/docs/latest/genai/governance/ai-gateway/guides/step2-query-deployments.md)

[Interact with endpoints using Python client APIs and REST requests](/mlflow-website/docs/latest/genai/governance/ai-gateway/guides/step2-query-deployments.md)

[Query guide →](/mlflow-website/docs/latest/genai/governance/ai-gateway/guides/step2-query-deployments.md)
