<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-genai docs-version-current docs-doc-page docs-doc-id-governance/ai-gateway/index" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">MLflow AI Gateway | MLflow</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://mlflow.org/docs/latest/genai/governance/ai-gateway/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-genai-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-genai-current"><meta data-rh="true" property="og:title" content="MLflow AI Gateway | MLflow"><meta data-rh="true" name="description" content="MLflow AI Gateway does not support Windows."><meta data-rh="true" property="og:description" content="MLflow AI Gateway does not support Windows."><link data-rh="true" rel="icon" href="/docs/latest/images/favicon.ico"><link data-rh="true" rel="canonical" href="https://mlflow.org/docs/latest/genai/governance/ai-gateway/"><link data-rh="true" rel="alternate" href="https://mlflow.org/docs/latest/genai/governance/ai-gateway/" hreflang="en"><link data-rh="true" rel="alternate" href="https://mlflow.org/docs/latest/genai/governance/ai-gateway/" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://XKVLO8P882-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Governance üõ°Ô∏è","item":"https://mlflow.org/docs/latest/genai/governance/ai-gateway/"}]}</script><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=GTM-N6WMTTJ"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","GTM-N6WMTTJ",{anonymize_ip:!0}),gtag("config","AW-16857946923",{anonymize_ip:!0})</script>
<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var g=t.getElementsByTagName(a)[0],m=t.createElement(a);m.async=!0,m.src="https://www.googletagmanager.com/gtm.js?id=GTM-N6WMTTJ",g.parentNode.insertBefore(m,g)}(window,document,"script","dataLayer")</script>



<link rel="search" type="application/opensearchdescription+xml" title="MLflow" href="/docs/latest/opensearch.xml">





<script src="/docs/latest/js/runllm.js" defer="defer"></script><link rel="stylesheet" href="/docs/latest/assets/css/styles.d8f6f8a6.css">
<script src="/docs/latest/assets/js/runtime~main.db795cf9.js" defer="defer"></script>
<script src="/docs/latest/assets/js/main.26da0263.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>


<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/docs/latest/"><div class="navbar__logo"><img src="/docs/latest/images/logo-light.svg" alt="MLflow Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/docs/latest/images/logo-dark.svg" alt="MLflow Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Documentation</a><ul class="dropdown__menu"><li><a class="dropdown__link ml-docs-link" href="/docs/latest/ml/">ML Docs</a></li><li><a aria-current="page" class="dropdown__link genai-docs-link dropdown__link--active" href="/docs/latest/genai/">GenAI Docs</a></li></ul></div><a href="https://mlflow.org/docs/latest/api_reference/index.html" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">API Reference</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/mlflow/mlflow" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link github-link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sidebar-top-level-category"><a class="menu__link" href="/docs/latest/genai/">MLflow for GenAI</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/mlflow-3/">MLflow 3.0</a><button aria-label="Expand sidebar category &#x27;MLflow 3.0&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/overview/">Overview üåü</a><button aria-label="Collapse sidebar category &#x27;Overview üåü&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/genai/overview/key-challenges">Key Challenges</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/genai/overview/why-mlflow">Why use MLflow</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/developer-workflow/">Developer Workflow üëâ</a><button aria-label="Expand sidebar category &#x27;Developer Workflow üëâ&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/getting-started/">Getting Started üöÄ</a><button aria-label="Expand sidebar category &#x27;Getting Started üöÄ&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/tracing/">Tracing (Observability) üîé</a><button aria-label="Expand sidebar category &#x27;Tracing (Observability) üîé&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/eval-monitor/">Evaluate &amp; Monitor üìä</a><button aria-label="Expand sidebar category &#x27;Evaluate &amp; Monitor üìä&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/docs/latest/genai/prompt-version-mgmt/version-tracking/">Prompt and Version Management üî®</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/genai/prompt-version-mgmt/version-tracking/">Version Tracking</a><button aria-label="Expand sidebar category &#x27;Version Tracking&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/genai/prompt-version-mgmt/prompt-registry/">Prompt Registry</a><button aria-label="Expand sidebar category &#x27;Prompt Registry&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/genai/prompt-version-mgmt/prompt-engineering/">Prompt Engineering UI</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/serving/">Application Serving ‚õµ</a><button aria-label="Expand sidebar category &#x27;Application Serving ‚õµ&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-top-level-category"><div class="menu__list-item-collapsible menu__list-item-collapsible--active"><a class="menu__link menu__link--sublist menu__link--active" aria-current="page" href="/docs/latest/genai/governance/ai-gateway/">Governance üõ°Ô∏è</a><button aria-label="Collapse sidebar category &#x27;Governance üõ°Ô∏è&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible menu__list-item-collapsible--active"><a class="menu__link menu__link--sublist menu__link--active" aria-current="page" tabindex="0" href="/docs/latest/genai/governance/ai-gateway/">AI Gateway</a><button aria-label="Collapse sidebar category &#x27;AI Gateway&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/genai/governance/ai-gateway/guides/">Getting Started with AI Gateway</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/genai/governance/ai-gateway/guides/step1-create-deployments/">Setup the AI Gateway</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/genai/governance/ai-gateway/guides/step2-query-deployments/">Use the AI Gateway</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/genai/governance/unity-catalog">Unity Catalog</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/data-model/">Data Model üß©</a><button aria-label="Expand sidebar category &#x27;Data Model üß©&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/docs/latest/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Governance üõ°Ô∏è</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>MLflow AI Gateway</h1></header>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>warning</div><div class="admonitionContent_BuS1"><p>MLflow AI Gateway does not support Windows.</p></div></div>
<p>The MLflow AI Gateway is a powerful tool designed to streamline the usage and management of
various large language model (LLM) providers, such as OpenAI and Anthropic, within an organization.
It offers a high-level interface that simplifies the interaction with these services by providing
a unified endpoint to handle specific LLM related requests.</p>
<p>A major advantage of using the MLflow AI Gateway is its centralized management of API keys.
By storing these keys in one secure location, organizations can significantly enhance their
security posture by minimizing the exposure of sensitive API keys throughout the system. It also
helps to prevent exposing these keys within code or requiring end-users to manage keys safely.</p>
<p>The gateway server is designed to be flexible and adaptable, capable of easily defining and managing endpoints by updating the
configuration file. This enables the easy incorporation
of new LLM providers or provider LLM types into the system without necessitating changes to
applications that interface with the gateway server. This level of adaptability makes the MLflow AI Gateway
Service an invaluable tool in environments that require agility and quick response to changes.</p>
<p>This simplification and centralization of language model interactions, coupled with the added
layer of security for API key management, make the MLflow AI Gateway an ideal choice for
organizations that use LLMs on a regular basis.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="tutorials-and-guides">Tutorials and Guides<a href="#tutorials-and-guides" class="hash-link" aria-label="Direct link to Tutorials and Guides" title="Direct link to Tutorials and Guides">‚Äã</a></h2>
<p>If you&#x27;re interested in diving right in to a step by step guide that will get you up and running with the MLflow AI Gateway
as fast as possible, the guides below will be your best first stop.</p>
<a class="button button--primary" href="/docs/latest/genai/governance/ai-gateway/guides"><span>View the gateway server Getting Started Guide</span></a>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deployments-quickstart">Quickstart<a href="#deployments-quickstart" class="hash-link" aria-label="Direct link to Quickstart" title="Direct link to Quickstart">‚Äã</a></h2>
<p>The following guide will assist you in getting up and running, using a 3-endpoint configuration to
OpenAI services for chat, completions, and embeddings.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-1-install-the-mlflow-ai-gateway">Step 1: Install the MLflow AI Gateway<a href="#step-1-install-the-mlflow-ai-gateway" class="hash-link" aria-label="Direct link to Step 1: Install the MLflow AI Gateway" title="Direct link to Step 1: Install the MLflow AI Gateway">‚Äã</a></h3>
<p>First, you need to install the MLflow AI Gateway on your machine. You can do this using pip from PyPI or from the MLflow repository.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="installing-from-pypi">Installing from PyPI<a href="#installing-from-pypi" class="hash-link" aria-label="Direct link to Installing from PyPI" title="Direct link to Installing from PyPI">‚Äã</a></h4>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;mlflow[genai]&#x27;</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-2-set-the-openai-api-keys-for-each-provider">Step 2: Set the OpenAI API Key(s) for each provider<a href="#step-2-set-the-openai-api-keys-for-each-provider" class="hash-link" aria-label="Direct link to Step 2: Set the OpenAI API Key(s) for each provider" title="Direct link to Step 2: Set the OpenAI API Key(s) for each provider">‚Äã</a></h3>
<p>The gateway server needs to communicate with the OpenAI API. To do this, it requires an API key.
You can create an API key from the OpenAI dashboard.</p>
<p>For this example, we&#x27;re only connecting with OpenAI. If there are additional providers within the
configuration, these keys will need to be set as well.</p>
<p>Once you have the key, you can set it as an environment variable in your terminal:</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">export</span><span class="token plain"> </span><span class="token assign-left variable" style="color:#36acaa">OPENAI_API_KEY</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">your_api_key_here</span><br></span></code></pre></div></div>
<p>This sets a temporary session-based environment variable. For production use cases, it is advisable
to store this key in the <code>.bashrc</code> or <code>.zshrc</code> files so that the key doesn&#x27;t have to be re-entered upon
system restart.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-3-create-a-gateway-server-configuration-file">Step 3: Create a gateway server Configuration File<a href="#step-3-create-a-gateway-server-configuration-file" class="hash-link" aria-label="Direct link to Step 3: Create a gateway server Configuration File" title="Direct link to Step 3: Create a gateway server Configuration File">‚Äã</a></h3>
<p>Next, you need to create a gateway server configuration file. This is a YAML file where you specify the
endpoints that the MLflow AI Gateway should expose. Let&#x27;s create a file with three endpoints using OpenAI as a provider: completions, chat, and embeddings.</p>
<p>For details about the configuration file&#x27;s parameters (including parameters for other providers besides OpenAI), see the <a href="#deployments-configuration-details">AI Gateway server Configuration Details</a> section below.</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">endpoints</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> completions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">endpoint_type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> llm/v1/completions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">model</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">provider</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpt</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">4o</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">mini</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">openai_api_key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> $OPENAI_API_KEY</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">limit</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">renewal_period</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> minute</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">calls</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> chat</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">endpoint_type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> llm/v1/chat</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">model</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">provider</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpt</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">4o</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">mini</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">openai_api_key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> $OPENAI_API_KEY</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> embeddings</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">endpoint_type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> llm/v1/embeddings</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">model</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">provider</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> text</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">embedding</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">ada</span><span class="token punctuation" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">002</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">openai_api_key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> $OPENAI_API_KEY</span><br></span></code></pre></div></div>
<p>Save this file to a location on the system that is going to be running the MLflow AI Gateway.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-4-start-the-gateway-server">Step 4: Start the gateway server<a href="#step-4-start-the-gateway-server" class="hash-link" aria-label="Direct link to Step 4: Start the gateway server" title="Direct link to Step 4: Start the gateway server">‚Äã</a></h3>
<p>You&#x27;re now ready to start the gateway server!</p>
<p>Use the MLflow AI Gateway <code>start</code> command and specify the path to your configuration file:</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">mlflow gateway start --config-path config.yaml </span><span class="token parameter variable" style="color:#36acaa">--port</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">port</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">--host</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">host</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">--workers</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain">worker count</span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre></div></div>
<p>The configuration file can also be set using the <code>MLFLOW_DEPLOYMENTS_CONFIG</code> environment variable:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">export</span><span class="token plain"> </span><span class="token assign-left variable" style="color:#36acaa">MLFLOW_DEPLOYMENTS_CONFIG</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">/path/to/config.yaml</span><br></span></code></pre></div></div>
<p>If you do not specify the host, a localhost address will be used.</p>
<p>If you do not specify the port, port 5000 will be used.</p>
<p>The worker count for gunicorn defaults to 2 workers.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-5-access-the-interactive-api-documentation">Step 5: Access the Interactive API Documentation<a href="#step-5-access-the-interactive-api-documentation" class="hash-link" aria-label="Direct link to Step 5: Access the Interactive API Documentation" title="Direct link to Step 5: Access the Interactive API Documentation">‚Äã</a></h3>
<p>The MLflow AI Gateway provides an interactive API documentation endpoint that you can use to explore
and test the exposed endpoints. Navigate to <code>http://{host}:{port}/</code> (or <code>http://{host}:{port}/docs</code>) in your browser to access it.</p>
<p>The docs endpoint allow for direct interaction with the endpoints and permits submitting actual requests to the
provider services by click on the &quot;try it now&quot; option within the endpoint definition entry.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-6-send-requests-using-the-client-api">Step 6: Send Requests Using the Client API<a href="#step-6-send-requests-using-the-client-api" class="hash-link" aria-label="Direct link to Step 6: Send Requests Using the Client API" title="Direct link to Step 6: Send Requests Using the Client API">‚Äã</a></h3>
<p>See the <a href="#deployments-client-api">Client API</a> section for further information.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-7-send-requests-to-endpoints-via-rest-api">Step 7: Send Requests to Endpoints via REST API<a href="#step-7-send-requests-to-endpoints-via-rest-api" class="hash-link" aria-label="Direct link to Step 7: Send Requests to Endpoints via REST API" title="Direct link to Step 7: Send Requests to Endpoints via REST API">‚Äã</a></h3>
<p>You can now send requests to the exposed endpoints.
See the <a href="#deployments-rest-api">REST examples</a> for guidance on request formatting.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-8-compare-provider-models">Step 8: Compare Provider Models<a href="#step-8-compare-provider-models" class="hash-link" aria-label="Direct link to Step 8: Compare Provider Models" title="Direct link to Step 8: Compare Provider Models">‚Äã</a></h3>
<p>Here&#x27;s an example of adding a new model from a provider to determine which model instance is better for a given use case.</p>
<p>Firstly, update the <a href="#deployments-configuration">MLflow AI Gateway config</a> YAML file with the additional endpoint definition to test:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">endpoints</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> completions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">endpoint_type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> llm/v1/completions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">model</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">provider</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpt</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">4o</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">mini</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">openai_api_key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> $OPENAI_API_KEY</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> completions</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">gpt4</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">endpoint_type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> llm/v1/completions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">model</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">provider</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpt</span><span class="token punctuation" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">4</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">openai_api_key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> $OPENAI_API_KEY</span><br></span></code></pre></div></div>
<p>This updated configuration adds a new completions endpoint <code>completions-gpt4</code> while still preserving the original <code>completions</code>
endpoint that was configured with the <code>gpt-4o-mini</code> model.</p>
<p>Once the configuration file is updated, simply save your changes. The gateway server will automatically create the new endpoint with zero downtime.</p>
<p>If you no longer need an endpoint, you can delete it from the configuration YAML and save your changes. The gateway server will automatically remove the endpoint.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-9-use-gateway-server-endpoints-for-model-development">Step 9: Use gateway server endpoints for model development<a href="#step-9-use-gateway-server-endpoints-for-model-development" class="hash-link" aria-label="Direct link to Step 9: Use gateway server endpoints for model development" title="Direct link to Step 9: Use gateway server endpoints for model development">‚Äã</a></h3>
<p>Now that you have created several gateway server endpoints, you can create MLflow Models that query these
endpoints to build application-specific logic using techniques like prompt engineering. For more
information, see <a href="#deployments-mlflow-models">gateway server and MLflow Models</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deployments-concepts">Concepts<a href="#deployments-concepts" class="hash-link" aria-label="Direct link to Concepts" title="Direct link to Concepts">‚Äã</a></h2>
<p>There are several concepts that are referred to within the MLflow AI Gateway APIs, the configuration definitions, examples, and documentation.
Becoming familiar with these terms will help to simplify both configuring new endpoints and using the MLflow AI Gateway APIs.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="deployments-providers">Providers<a href="#deployments-providers" class="hash-link" aria-label="Direct link to Providers" title="Direct link to Providers">‚Äã</a></h3>
<p>The MLflow AI Gateway is designed to support a variety of model providers.
A provider represents the source of the machine learning models, such as OpenAI, Anthropic, and so on.
Each provider has its specific characteristics and configurations that are encapsulated within the model part of an endpoint in the MLflow AI Gateway.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="supported-providers">Supported Providers<a href="#supported-providers" class="hash-link" aria-label="Direct link to Supported Providers" title="Direct link to Supported Providers">‚Äã</a></h4>
<p>The table below presents supported corresponding endpoint type for each LLM provider within the MLflow AI Gateway.
Note that ‚úÖ mark does not mean all models from the provider are compatible with the endpoint types. For example, OpenAI provider supports all three endpoint types, but the model <code>gpt-4</code> is only compatible with the <code>llm/v1/chat</code> endpoint types.</p>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Provider</th><th>llm/v1/completions</th><th>llm/v1/chat</th><th>llm/v1/embeddings</th></tr></thead><tbody><tr><td>OpenAI ¬ß</td><td>‚úÖ</td><td>‚úÖ</td><td>‚úÖ</td></tr><tr><td>Azure OpenAI</td><td>‚úÖ</td><td>‚úÖ</td><td>‚úÖ</td></tr><tr><td>MosaicML</td><td>‚úÖ</td><td>‚úÖ</td><td>‚úÖ</td></tr><tr><td>Anthropic</td><td>‚úÖ</td><td>‚úÖ</td><td>‚ùå</td></tr><tr><td>Cohere</td><td>‚úÖ</td><td>‚úÖ</td><td>‚úÖ</td></tr><tr><td>PaLM</td><td>‚úÖ</td><td>‚úÖ</td><td>‚úÖ</td></tr><tr><td>MLflow</td><td>‚úÖ*</td><td>‚úÖ*</td><td>‚úÖ**</td></tr><tr><td>HuggingFace TGI</td><td>‚ùå</td><td>‚úÖ</td><td>‚ùå</td></tr><tr><td>AI21 Labs</td><td>‚úÖ</td><td>‚ùå</td><td>‚ùå</td></tr><tr><td>Amazon Bedrock</td><td>‚úÖ</td><td>‚úÖ</td><td>‚ùå</td></tr><tr><td>Mistral</td><td>‚úÖ</td><td>‚úÖ</td><td>‚úÖ</td></tr><tr><td>TogetherAI</td><td>‚úÖ</td><td>‚úÖ</td><td>‚úÖ</td></tr><tr><td>Gemini</td><td>‚úÖ*</td><td>‚úÖ*</td><td>‚úÖ**</td></tr></tbody></table></div>
<p>¬ß For full compatibility references for <code>OpenAI</code>, see the <a href="https://platform.openai.com/docs/models/model-endpoint-compatibility" target="_blank" rel="noopener noreferrer">OpenAI Model Compatibility Matrix</a>.</p>
<p>Within each model block in the configuration file, the provider field is used to specify the name
of the provider for that model. This is a string value that needs to correspond to a provider the MLflow AI Gateway supports.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p><em>*</em> MLflow Model Serving will only work for chat or completions if the output return is in an endpoint-compatible format. The
response must conform to either an output of <code>{&quot;predictions&quot;: str}</code> or <code>{&quot;predictions&quot;: {&quot;candidates&quot;: str}}</code>. Any complex return type from a model that
does not conform to these structures will raise an exception at query time.</p><p><em>**</em> Embeddings support is only available for models whose response signatures conform to the structured format of <code>{&quot;predictions&quot;: List[float]}</code>
or <code>{&quot;predictions&quot;: List[List[float]]}</code>. Any other return type will raise an exception at query time. <code>FeatureExtractionPipeline</code> in <code>transformers</code> and
models using the <code>sentence_transformers</code> flavor will return the correct data structures for the embeddings endpoint.</p></div></div>
<p>Here&#x27;s an example of a provider configuration within an endpoint:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">endpoints</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> chat</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">endpoint_type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> llm/v1/chat</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">model</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">provider</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpt</span><span class="token punctuation" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">4</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">openai_api_key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> $OPENAI_API_KEY</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">limit</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">renewal_period</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> minute</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">calls</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><br></span></code></pre></div></div>
<p>In the above configuration, <code>openai</code> is the <em>provider</em> for the model.</p>
<p>As of now, the MLflow AI Gateway supports the following providers:</p>
<ul>
<li><strong>mosaicml</strong>: This is used for models offered by <a href="https://docs.mosaicml.com/en/latest/" target="_blank" rel="noopener noreferrer">MosaicML</a>.</li>
<li><strong>openai</strong>: This is used for models offered by <a href="https://platform.openai.com/" target="_blank" rel="noopener noreferrer">OpenAI</a> and the <a href="https://learn.microsoft.com/en-gb/azure/cognitive-services/openai/" target="_blank" rel="noopener noreferrer">Azure</a> integrations for Azure OpenAI and Azure OpenAI with AAD.</li>
<li><strong>anthropic</strong>: This is used for models offered by <a href="https://docs.anthropic.com/claude/docs" target="_blank" rel="noopener noreferrer">Anthropic</a>.</li>
<li><strong>cohere</strong>: This is used for models offered by <a href="https://docs.cohere.com/docs" target="_blank" rel="noopener noreferrer">Cohere</a>.</li>
<li><strong>palm</strong>: This is used for models offered by <a href="https://developers.generativeai.google/api/rest/generativelanguage/models/" target="_blank" rel="noopener noreferrer">PaLM</a>.</li>
<li><strong>huggingface text generation inference</strong>: This is used for models deployed using <a href="https://huggingface.co/docs/text-generation-inference/index" target="_blank" rel="noopener noreferrer">Huggingface Text Generation Inference</a>.</li>
<li><strong>ai21labs</strong>: This is used for models offered by <a href="https://studio.ai21.com/foundation-models" target="_blank" rel="noopener noreferrer">AI21 Labs</a>.</li>
<li><strong>bedrock</strong>: This is used for models offered by <a href="https://aws.amazon.com/bedrock/" target="_blank" rel="noopener noreferrer">Amazon Bedrock</a>.</li>
<li><strong>mistral</strong>: This is used for models offered by <a href="https://docs.mistral.ai/" target="_blank" rel="noopener noreferrer">Mistral</a>.</li>
<li><strong>togetherai</strong>: This is used for models offered by <a href="https://docs.together.ai/docs/" target="_blank" rel="noopener noreferrer">TogetherAI</a>.</li>
<li><strong>gemini</strong>: This is used for models offered by <a href="https://ai.google.dev/api/models#rest-resource:-models" target="_blank" rel="noopener noreferrer">Gemini</a>.</li>
</ul>
<p>More providers are being added continually. Check the latest version of the MLflow AI Gateway Docs for the
most up-to-date list of supported providers.</p>
<p>If you would like to use a LLM model that is not offered by the above providers, or if you
would like to integrate a private LLM model, you can create a <a href="#deployments-plugin">provider plugin</a>
to integrate with the MLflow AI Gateway.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deployments-endpoints">Endpoints<a href="#deployments-endpoints" class="hash-link" aria-label="Direct link to Endpoints" title="Direct link to Endpoints">‚Äã</a></h2>
<p><em>Endpoints</em> are central to how the MLflow AI Gateway functions. Each endpoint acts as a proxy endpoint for the
user, forwarding requests to the underlying <a href="#deployments-models">Models</a> and <a href="#deployments-providers">providers</a> specified in the configuration file.</p>
<p>an endpoint in the MLflow AI Gateway consists of the following fields:</p>
<ul>
<li><strong>name</strong>: This is the unique identifier for the endpoint. This will be part of the URL when making API calls via the MLflow AI Gateway.</li>
<li><strong>type</strong>: The type of the endpoint corresponds to the type of language model interaction you desire. For instance, <code>llm/v1/completions</code> for text completion operations, <code>llm/v1/embeddings</code> for text embeddings, and <code>llm/v1/chat</code> for chat operations.</li>
<li><strong>model</strong>: Defines the model to which this endpoint will forward requests. The model contains the following details:<!-- -->
<ul>
<li><strong>provider</strong>: Specifies the name of the <a href="#deployments-providers">provider</a> for this model. For example, <code>openai</code> for OpenAI&#x27;s <code>GPT-4o</code> models.</li>
<li><strong>name</strong>: The name of the model to use. For example, <code>gpt-4o-mini</code> for OpenAI&#x27;s <code>GPT-4o-Mini</code> model.</li>
<li><strong>config</strong>: Contains any additional configuration details required for the model. This includes specifying the API base URL and the API key.</li>
</ul>
</li>
<li><strong>limit</strong>: Specify the rate limit setting this endpoint will follow. The limit field contains the following fields:<!-- -->
<ul>
<li><strong>renewal_period</strong>: The time unit of the rate limit, one of [second|minute|hour|day|month|year].</li>
<li><strong>calls</strong>: The number of calls this endpoint will accept within the specified time unit.</li>
</ul>
</li>
</ul>
<p>Here&#x27;s an example of an endpoint configuration:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">endpoints</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> completions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">endpoint_type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> llm/v1/chat</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">model</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">provider</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpt</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">4o</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">mini</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">openai_api_key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> $OPENAI_API_KEY</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">limit</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">renewal_period</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> minute</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">calls</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><br></span></code></pre></div></div>
<p>In the example above, a request sent to the completions endpoint would be forwarded to the
<code>gpt-4o-mini</code> model provided by <code>openai</code>.</p>
<p>The endpoints in the configuration file can be updated at any time, and the MLflow AI Gateway will
automatically update its available endpoints without requiring a restart. This feature provides you
with the flexibility to add, remove, or modify endpoints as your needs change. It enables &#x27;hot-swapping&#x27;
of endpoints, providing a seamless experience for any applications or services that interact with the MLflow AI Gateway.</p>
<p>When defining endpoints in the configuration file, ensure that each name is unique to prevent conflicts.
Duplicate endpoint names will raise an <code>MlflowException</code>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deployments-models">Models<a href="#deployments-models" class="hash-link" aria-label="Direct link to Models" title="Direct link to Models">‚Äã</a></h2>
<p>The <code>model</code> section within an <code>endpoint</code> specifies which model to use for generating responses.
This configuration block needs to contain a <code>name</code> field which is used to specify the exact model instance to be used.
Additionally, a <a href="#deployments-providers">provider</a> needs to be specified, one that you have an authenticated access api key for.</p>
<p>Different endpoint types are often associated with specific models.
For instance, the <code>llm/v1/chat</code> and <code>llm/v1/completions</code> endpoints are generally associated with
conversational models, while <code>llm/v1/embeddings</code> endpoints would typically be associated with
embedding or transformer models. The model you choose should be appropriate for the type of endpoint specified.</p>
<p>Here&#x27;s an example of a model name configuration within an endpoint:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">endpoints</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> embeddings</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">endpoint_type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> llm/v1/embeddings</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">model</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">provider</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> text</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">embedding</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">ada</span><span class="token punctuation" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">002</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">openai_api_key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> $OPENAI_API_KEY</span><br></span></code></pre></div></div>
<p>In the above configuration, <code>text-embedding-ada-002</code> is the model used for the embeddings endpoint.</p>
<p>When specifying a model, it is critical that the provider supports the model you are requesting.
For instance, <code>openai</code> as a provider supports models like <code>text-embedding-ada-002</code>, but other providers
may not. If the model is not supported by the provider, the MLflow AI Gateway will return an HTTP 4xx error
when trying to route requests to that model.</p>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>important</div><div class="admonitionContent_BuS1"><p>Always check the latest documentation of the specified provider to ensure that the model you want
to use is supported for the type of endpoint you&#x27;re configuring.</p></div></div>
<p>Remember, the model you choose directly affects the results of the responses you&#x27;ll get from the
API calls. Therefore, choose a model that fits your use-case requirements. For instance,
for generating conversational responses, you would typically choose a chat model.
Conversely, for generating embeddings of text, you would choose an embedding model.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deployments-configuration">Configuring the gateway server<a href="#deployments-configuration" class="hash-link" aria-label="Direct link to Configuring the gateway server" title="Direct link to Configuring the gateway server">‚Äã</a></h2>
<p>The MLflow AI Gateway relies on a user-provided configuration file, written in YAML,
that defines the endpoints and providers available to the server. The configuration file dictates
how the gateway server interacts with various language model providers and determines the end-points that
users can access.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="ai-gateway-server-configuration">AI Gateway server Configuration<a href="#ai-gateway-server-configuration" class="hash-link" aria-label="Direct link to AI Gateway server Configuration" title="Direct link to AI Gateway server Configuration">‚Äã</a></h3>
<p>The configuration file includes a series of sections, each representing a unique endpoint.
Each endpoint section has a name, a type, and a model specification, which includes the model
provider, name, and configuration details. The configuration section typically contains the base
URL for the API and an environment variable for the API key.</p>
<p>Here is an example of a single-endpoint configuration:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">endpoints</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> chat</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">endpoint_type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> llm/v1/chat</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">model</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">provider</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpt</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">4o</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">mini</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">openai_api_key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> $OPENAI_API_KEY</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">limit</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">renewal_period</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> minute</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">calls</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><br></span></code></pre></div></div>
<p>In this example, we define an endpoint named <code>chat</code> that corresponds to the <code>llm/v1/chat</code> type, which
will use the <code>gpt-4o-mini</code> model from OpenAI to return query responses from the OpenAI service, and accept up to 10 requests per minute.</p>
<p>The MLflow AI Gateway configuration is very easy to update.
Simply edit the configuration file and save your changes, and the MLflow AI Gateway will automatically
update the endpoints with zero disruption or down time. This allows you to try out new providers or model types while keeping your applications steady and reliable.</p>
<p>In order to define an API key for a given provider, there are three primary options:</p>
<ol>
<li>Directly include it in the YAML configuration file.</li>
<li>Use an environment variable to store the API key and reference it in the YAML configuration file.</li>
<li>Define your API key in a file and reference the location of that key-bearing file within the YAML configuration file.</li>
</ol>
<p>If you choose to include the API key directly, replace <code>$OPENAI_API_KEY</code> in the YAML file with your
actual API key.</p>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>warning</div><div class="admonitionContent_BuS1"><p>The MLflow AI Gateway provides direct access to billed external LLM services. It is strongly recommended to restrict access to this server. See the section on <a href="#deployments-security">security</a> for guidance.</p></div></div>
<p>If you prefer to use an environment variable (recommended), you can define it in your shell
environment. For example:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">export</span><span class="token plain"> </span><span class="token assign-left variable" style="color:#36acaa">OPENAI_API_KEY</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;your_openai_api_key&quot;</span><br></span></code></pre></div></div>
<p><strong>Note:</strong> Replace &quot;your_openai_api_key&quot; with your actual OpenAI API key.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="deployments-configuration-details">AI Gateway server Configuration Details<a href="#deployments-configuration-details" class="hash-link" aria-label="Direct link to AI Gateway server Configuration Details" title="Direct link to AI Gateway server Configuration Details">‚Äã</a></h4>
<p>The MLflow AI Gateway relies on a user-provided configuration file. It defines how the gateway server interacts with various language model providers and dictates the endpoints that users can access.</p>
<p>The configuration file is written in YAML and includes a series of sections, each representing a unique endpoint. Each endpoint section has a name, a type, and a model specification,
which includes the provider, model name, and provider-specific configuration details.</p>
<p>Here are the details of each configuration parameter:</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="general-configuration-parameters">General Configuration Parameters<a href="#general-configuration-parameters" class="hash-link" aria-label="Direct link to General Configuration Parameters" title="Direct link to General Configuration Parameters">‚Äã</a></h5>
<ul>
<li><strong>endpoints</strong>: This is a list of endpoint configurations. Each endpoint represents a unique endpoint that maps to a particular language model service.</li>
</ul>
<p>Each endpoint has the following configuration parameters:</p>
<ul>
<li><strong>name</strong>: This is the name of the endpoint. It needs to be a unique name without spaces or any non-alphanumeric characters other than hyphen and underscore.</li>
<li><strong>endpoint_type</strong>: This specifies the type of service offered by this endpoint. This determines the interface for inputs to an endpoint and the returned outputs. Current supported endpoint types are:<!-- -->
<ul>
<li>&quot;llm/v1/completions&quot;</li>
<li>&quot;llm/v1/chat&quot;</li>
<li>&quot;llm/v1/embeddings&quot;</li>
</ul>
</li>
<li><strong>model</strong>: This defines the provider-specific details of the language model. It contains the following fields:<!-- -->
<ul>
<li><strong>provider</strong>: This indicates the provider of the AI model. It accepts the following values:<!-- -->
<ul>
<li>&quot;openai&quot;</li>
<li>&quot;mosaicml&quot;</li>
<li>&quot;anthropic&quot;</li>
<li>&quot;cohere&quot;</li>
<li>&quot;palm&quot;</li>
<li>&quot;azure&quot; / &quot;azuread&quot;</li>
<li>&quot;mlflow-model-serving&quot;</li>
<li>&quot;huggingface-text-generation-inference&quot;</li>
<li>&quot;ai21labs&quot;</li>
<li>&quot;bedrock&quot;</li>
<li>&quot;mistral&quot;</li>
<li>&quot;togetherai&quot;</li>
</ul>
</li>
<li><strong>name</strong>: This is an optional field to specify the name of the model.</li>
<li><strong>config</strong>: This contains provider-specific configuration details.</li>
</ul>
</li>
</ul>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="provider-specific-configuration-parameters">Provider-Specific Configuration Parameters<a href="#provider-specific-configuration-parameters" class="hash-link" aria-label="Direct link to Provider-Specific Configuration Parameters" title="Direct link to Provider-Specific Configuration Parameters">‚Äã</a></h5>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="openai">OpenAI<a href="#openai" class="hash-link" aria-label="Direct link to OpenAI" title="Direct link to OpenAI">‚Äã</a></h6>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Configuration Parameter</th><th>Required</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><strong>openai_api_key</strong></td><td>Yes</td><td></td><td>This is the API key for the OpenAI service.</td></tr><tr><td><strong>openai_api_type</strong></td><td>No</td><td></td><td>This is an optional field to specify the type of OpenAI API to use.</td></tr><tr><td><strong>openai_api_base</strong></td><td>No</td><td><em><a href="https://api.openai.com/v1" target="_blank" rel="noopener noreferrer">https://api.openai.com/v1</a></em></td><td>This is the base URL for the OpenAI API.</td></tr><tr><td><strong>openai_api_version</strong></td><td>No</td><td></td><td>This is an optional field to specify the OpenAI API version.</td></tr><tr><td><strong>openai_organization</strong></td><td>No</td><td></td><td>This is an optional field to specify the organization in OpenAI.</td></tr></tbody></table></div>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="mosaicml">MosaicML<a href="#mosaicml" class="hash-link" aria-label="Direct link to MosaicML" title="Direct link to MosaicML">‚Äã</a></h6>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Configuration Parameter</th><th>Required</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><strong>mosaicml_api_key</strong></td><td>Yes</td><td>N/A</td><td>This is the API key for the MosaicML service.</td></tr></tbody></table></div>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="cohere">Cohere<a href="#cohere" class="hash-link" aria-label="Direct link to Cohere" title="Direct link to Cohere">‚Äã</a></h6>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Configuration Parameter</th><th>Required</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><strong>cohere_api_key</strong></td><td>Yes</td><td>N/A</td><td>This is the API key for the Cohere service.</td></tr></tbody></table></div>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="huggingface-text-generation-inference">HuggingFace Text Generation Inference<a href="#huggingface-text-generation-inference" class="hash-link" aria-label="Direct link to HuggingFace Text Generation Inference" title="Direct link to HuggingFace Text Generation Inference">‚Äã</a></h6>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Configuration Parameter</th><th>Required</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><strong>hf_server_url</strong></td><td>Yes</td><td>N/A</td><td>This is the url of the Huggingface TGI Server.</td></tr></tbody></table></div>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="palm">PaLM<a href="#palm" class="hash-link" aria-label="Direct link to PaLM" title="Direct link to PaLM">‚Äã</a></h6>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Configuration Parameter</th><th>Required</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><strong>palm_api_key</strong></td><td>Yes</td><td>N/A</td><td>This is the API key for the PaLM service.</td></tr></tbody></table></div>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="ai21-labs">AI21 Labs<a href="#ai21-labs" class="hash-link" aria-label="Direct link to AI21 Labs" title="Direct link to AI21 Labs">‚Äã</a></h6>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Configuration Parameter</th><th>Required</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><strong>ai21labs_api_key</strong></td><td>Yes</td><td>N/A</td><td>This is the API key for the AI21 Labs service.</td></tr></tbody></table></div>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="anthropic">Anthropic<a href="#anthropic" class="hash-link" aria-label="Direct link to Anthropic" title="Direct link to Anthropic">‚Äã</a></h6>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Configuration Parameter</th><th>Required</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><strong>anthropic_api_key</strong></td><td>Yes</td><td>N/A</td><td>This is the API key for the Anthropic service.</td></tr></tbody></table></div>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="amazon-bedrock">Amazon Bedrock<a href="#amazon-bedrock" class="hash-link" aria-label="Direct link to Amazon Bedrock" title="Direct link to Amazon Bedrock">‚Äã</a></h6>
<p>Top-level model configuration for Amazon Bedrock endpoints must be one of the following two supported authentication modes: <em>key-based</em> or <em>role-based</em>.</p>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Configuration Parameter</th><th>Required</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><strong>aws_config</strong></td><td>No</td><td></td><td>An object with either the key-based or role-based schema below.</td></tr></tbody></table></div>
<p>To use key-based authentication, define an Amazon Bedrock endpoint with the required fields below.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>If using a configured endpoint purely for development or testing, utilizing an IAM User role or a temporary short-lived standard IAM role are recommended;
while for production deployments, a standard long-expiry IAM role is recommended to ensure that the endpoint is capable of handling authentication for a long period.
If the authentication expires and a new set of keys need to be supplied, the endpoint must be recreated in order to persist the new keys.</p></div></div>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Configuration Parameter</th><th>Required</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><strong>aws_region</strong></td><td>No</td><td>AWS_REGION/AWS_DEFAULT_REGION</td><td>The AWS Region to use for bedrock access.</td></tr><tr><td><strong>aws_secret_access_key</strong></td><td>Yes</td><td></td><td>AWS secret access key for the IAM user/role authorized to use bedrock.</td></tr><tr><td><strong>aws_access_key_id</strong></td><td>Yes</td><td></td><td>AWS access key ID for the IAM user/role authorized to use Bedrock.</td></tr><tr><td><strong>aws_session_token</strong></td><td>No</td><td>None</td><td>Optional session token, if required.</td></tr></tbody></table></div>
<p>Alternatively, for role-based authentication, an Amazon Bedrock endpoint can be defined and initialized with an a IAM Role ARN that is authorized to access Bedrock.
The MLflow AI Gateway will attempt to assume this role with using the standard credential provider chain and will renew the role credentials if they have expired.</p>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Configuration Parameter</th><th>Required</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><strong>aws_region</strong></td><td>No</td><td>AWS_REGION/AWS_DEFAULT_REGION</td><td>The AWS Region to use for bedrock access.</td></tr><tr><td><strong>aws_role_arn</strong></td><td>Yes</td><td></td><td>An AWS role authorized to use Bedrock. The standard credential provider chain <em>must</em> be able to find credentials authorized to assume this role.</td></tr><tr><td><strong>session_length_seconds</strong></td><td>No</td><td>900</td><td>The length of session to request.</td></tr></tbody></table></div>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="mlflow-model-serving">MLflow Model Serving<a href="#mlflow-model-serving" class="hash-link" aria-label="Direct link to MLflow Model Serving" title="Direct link to MLflow Model Serving">‚Äã</a></h6>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Configuration Parameter</th><th>Required</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><strong>model_server_url</strong></td><td>Yes</td><td>N/A</td><td>This is the url of the MLflow Model Server.</td></tr></tbody></table></div>
<p>Note that with MLflow model serving, the <code>name</code> parameter for the <code>model</code> definition is not used for validation and is only present for reference purposes. This alias can be
useful for understanding a particular version or endpoint definition that was used that can be referenced back to a deployed model. You may choose any name that you wish, provided that
it is JSON serializable.</p>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="azure-openai">Azure OpenAI<a href="#azure-openai" class="hash-link" aria-label="Direct link to Azure OpenAI" title="Direct link to Azure OpenAI">‚Äã</a></h6>
<p>Azure provides two different mechanisms for integrating with OpenAI, each corresponding to a different type of security validation. One relies on an access token for validation,
referred to as <code>azure</code>, while the other uses Azure Active Directory (Azure AD) integration for authentication, termed as <code>azuread</code>.</p>
<p>To match your user&#x27;s interaction and security access requirements, adjust the <code>openai_api_type</code> parameter to represent the preferred security validation model.
This will ensure seamless interaction and reliable security for your Azure-OpenAI integration.</p>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Configuration Parameter</th><th>Required</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><strong>openai_api_key</strong></td><td>Yes</td><td></td><td>This is the API key for the Azure OpenAI service.</td></tr><tr><td><strong>openai_api_type</strong></td><td>Yes</td><td></td><td>This field must be either <code>azure</code> or <code>azuread</code> depending on the security access protocol.</td></tr><tr><td><strong>openai_api_base</strong></td><td>Yes</td><td></td><td>This is the base URL for the Azure OpenAI API service provided by Azure.</td></tr><tr><td><strong>openai_api_version</strong></td><td>Yes</td><td></td><td>The version of the Azure OpenAI service to utilize, specified by a date.</td></tr><tr><td><strong>openai_deployment_name</strong></td><td>Yes</td><td></td><td>This is the name of the deployment resource for the Azure OpenAI service.</td></tr><tr><td><strong>openai_organization</strong></td><td>No</td><td></td><td>This is an optional field to specify the organization in OpenAI.</td></tr></tbody></table></div>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="mistral">Mistral<a href="#mistral" class="hash-link" aria-label="Direct link to Mistral" title="Direct link to Mistral">‚Äã</a></h6>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Configuration Parameter</th><th>Required</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><strong>mistral_api_key</strong></td><td>Yes</td><td>N/A</td><td>This is the API key for the Mistral service.</td></tr></tbody></table></div>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="togetherai">TogetherAI<a href="#togetherai" class="hash-link" aria-label="Direct link to TogetherAI" title="Direct link to TogetherAI">‚Äã</a></h6>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Configuration Parameter</th><th>Required</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><strong>togetherai_api_key</strong></td><td>Yes</td><td>N/A</td><td>This is the API key for the TogetherAI service.</td></tr></tbody></table></div>
<h6 class="anchor anchorWithStickyNavbar_LWe7" id="gemini">Gemini<a href="#gemini" class="hash-link" aria-label="Direct link to Gemini" title="Direct link to Gemini">‚Äã</a></h6>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Configuration Parameter</th><th>Required</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><strong>gemini_api_key</strong></td><td>Yes</td><td>N/A</td><td>This is the API key for the Gemini service.</td></tr></tbody></table></div>
<p>An example configuration for Azure OpenAI is:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">endpoints</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> completions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">endpoint_type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> llm/v1/completions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">model</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">provider</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpt</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">35</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">turbo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">openai_api_type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;azuread&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">openai_api_key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> $AZURE_AAD_TOKEN</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">openai_deployment_name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;{your_deployment_name}&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">openai_api_base</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;https://{your_resource_name}-azureopenai.openai.azure.com/&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">openai_api_version</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;2023-05-15&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">limit</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">renewal_period</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> minute</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">calls</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><br></span></code></pre></div></div>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>Azure OpenAI has distinct features as compared with the direct OpenAI service. For an overview, please see <a href="https://learn.microsoft.com/en-gb/azure/cognitive-services/openai/how-to/switching-endpoints" target="_blank" rel="noopener noreferrer">the comparison documentation</a>.</p></div></div>
<p>For specifying an API key, there are three options:</p>
<ol>
<li>(Preferred) Use an environment variable to store the API key and reference it in the YAML configuration file. This is denoted by a <code>$</code> symbol before the name of the environment variable.</li>
<li>(Preferred) Define the API key in a file and reference the location of that key-bearing file within the YAML configuration file.</li>
<li>Directly include it in the YAML configuration file.</li>
</ol>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>important</div><div class="admonitionContent_BuS1"><p>The use of environment variables or file-based keys is recommended for better security practices. If the API key is directly included in the configuration file, it should be ensured that the file is securely stored and appropriately access controlled.
Please ensure that the configuration file is stored in a secure location as it contains sensitive API keys.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deployments-query">Querying the AI Gateway server<a href="#deployments-query" class="hash-link" aria-label="Direct link to Querying the AI Gateway server" title="Direct link to Querying the AI Gateway server">‚Äã</a></h2>
<p>Once the MLflow AI Gateway has been configured and started, it is ready to receive traffic from users.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="standard-deployments-parameters">Standard Query Parameters<a href="#standard-deployments-parameters" class="hash-link" aria-label="Direct link to Standard Query Parameters" title="Direct link to Standard Query Parameters">‚Äã</a></h3>
<p>The MLflow AI Gateway defines standard parameters for chat, completions, and embeddings that can be
used when querying any endpoint regardless of its provider. Each parameter has a standard range and
default value. When querying an endpoint with a particular provider, the MLflow AI Gateway automatically
scales parameter values according to the provider&#x27;s value ranges for that parameter.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="completions">Completions<a href="#completions" class="hash-link" aria-label="Direct link to Completions" title="Direct link to Completions">‚Äã</a></h4>
<p>The standard parameters for completions endpoints with type <code>llm/v1/completions</code> are:</p>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Query Parameter</th><th>Type</th><th>Required</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><strong>prompt</strong></td><td>string</td><td>Yes</td><td>N/A</td><td>The prompt for which to generate completions.</td></tr><tr><td><strong>n</strong></td><td>integer</td><td>No</td><td>1</td><td>The number of completions to generate for the specified prompt, between 1 and 5.</td></tr><tr><td><strong>temperature</strong></td><td>float</td><td>No</td><td>0.0</td><td>The sampling temperature to use, between 0 and 1. Higher values will make the output more random, and lower values will make the output more deterministic.</td></tr><tr><td><strong>max_tokens</strong></td><td>integer</td><td>No</td><td>None</td><td>The maximum completion length, between 1 and infinity (unlimited).</td></tr><tr><td><strong>stop</strong></td><td>array[string]</td><td>No</td><td>None</td><td>Sequences where the model should stop generating tokens and return the completion.</td></tr></tbody></table></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="chat">Chat<a href="#chat" class="hash-link" aria-label="Direct link to Chat" title="Direct link to Chat">‚Äã</a></h4>
<p>The standard parameters for chat endpoints with type <code>llm/v1/chat</code> are:</p>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Query Parameter</th><th>Type</th><th>Required</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><strong>messages</strong></td><td>array[message]</td><td>Yes</td><td>N/A</td><td>A list of messages in a conversation from which to generate a new message (chat completion). For information about the message structure, see <a href="#deployments-chat-message-structure">Messages</a>.</td></tr><tr><td><strong>n</strong></td><td>integer</td><td>No</td><td>1</td><td>The number of chat completions to generate for the specified prompt, between 1 and 5.</td></tr><tr><td><strong>temperature</strong></td><td>float</td><td>No</td><td>0.0</td><td>The sampling temperature to use, between 0 and 1. Higher values will make the output more random, and lower values will make the output more deterministic.</td></tr><tr><td><strong>max_tokens</strong></td><td>integer</td><td>No</td><td>None</td><td>The maximum completion length, between 1 and infinity (unlimited).</td></tr><tr><td><strong>stop</strong></td><td>array[string]</td><td>No</td><td>None</td><td>Sequences where the model should stop generating tokens and return the chat completion.</td></tr></tbody></table></div>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="deployments-chat-message-structure">Messages<a href="#deployments-chat-message-structure" class="hash-link" aria-label="Direct link to Messages" title="Direct link to Messages">‚Äã</a></h5>
<p>Each chat message is a string dictionary containing the following fields:</p>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Field Name</th><th>Required</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><strong>role</strong></td><td>Yes</td><td>N/A</td><td>The role of the conversation participant who sent the message. Must be one of: <code>&quot;system&quot;</code>, <code>&quot;user&quot;</code>, or <code>&quot;assistant&quot;</code>.</td></tr><tr><td><strong>content</strong></td><td>Yes</td><td>N/A</td><td>The message content.</td></tr></tbody></table></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="embeddings">Embeddings<a href="#embeddings" class="hash-link" aria-label="Direct link to Embeddings" title="Direct link to Embeddings">‚Äã</a></h4>
<p>The standard parameters for completions endpoints with type <code>llm/v1/embeddings</code> are:</p>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Query Parameter</th><th>Type</th><th>Required</th><th>Default</th><th>Description</th></tr></thead><tbody><tr><td><strong>input</strong></td><td>string or array[string]</td><td>Yes</td><td>N/A</td><td>A string or list of strings for which to generate embeddings.</td></tr></tbody></table></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="additional-query-parameters">Additional Query Parameters<a href="#additional-query-parameters" class="hash-link" aria-label="Direct link to Additional Query Parameters" title="Direct link to Additional Query Parameters">‚Äã</a></h3>
<p>In addition to the <a href="#standard-deployments-parameters">Standard Query Parameters</a>, you can pass any additional parameters supported by the endpoint&#x27;s provider as part of your query. For example:</p>
<ul>
<li><code>logit_bias</code> (supported by OpenAI, Cohere)</li>
<li><code>top_k</code> (supported by MosaicML, Anthropic, PaLM, Cohere)</li>
<li><code>frequency_penalty</code> (supported by OpenAI, Cohere, AI21 Labs)</li>
<li><code>presence_penalty</code> (supported by OpenAI, Cohere, AI21 Labs)</li>
<li><code>stream</code> (supported by OpenAI, Cohere)</li>
</ul>
<p>Below is an example of submitting a query request to an MLflow AI Gateway endpoint using additional parameters:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">deployments </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> get_deploy_client</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">client </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> get_deploy_client</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;http://my.deployments:8888&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;prompt&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">&quot;What would happen if an asteroid the size of &quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">&quot;a basketball encountered the Earth traveling at 0.5c? &quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">&quot;Please provide your answer in .rst format for the purposes of documentation.&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;temperature&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.5</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;max_tokens&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1000</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;n&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;frequency_penalty&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;presence_penalty&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.2</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">client</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">endpoint</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;completions-gpt4&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> inputs</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<p>The results of the query are:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;id&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;chatcmpl-8Pr33fsCAtD2L4oZHlyfOkiYHLapc&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;object&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;text_completion&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;created&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1701172809</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;model&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;gpt-4-0613&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;choices&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token string" style="color:#e3116c">&quot;index&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token string" style="color:#e3116c">&quot;text&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;If an asteroid the size of a basketball ...&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;usage&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">&quot;prompt_tokens&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">43</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">&quot;completion_tokens&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">592</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">&quot;total_tokens&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">635</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="streaming">Streaming<a href="#streaming" class="hash-link" aria-label="Direct link to Streaming" title="Direct link to Streaming">‚Äã</a></h4>
<p>Some providers support streaming responses. Streaming responses are useful when you want to
receive responses as they are generated, rather than waiting for the entire response to be
generated before receiving it. Streaming responses are supported by the following providers:</p>
<div class="w-full overflow-x-auto"><table><thead><tr><th>Provider</th><th colspan="2">Endpoints</th></tr><tr><th></th><th>llm/v1/completions</th><th>llm/v1/completions</th></tr></thead><tbody><tr><td>OpenAI</td><td>‚úì</td><td>‚úì</td></tr><tr><td>Cohere</td><td>‚úì</td><td>‚úì</td></tr><tr><td>Anthropic</td><td>‚úò</td><td>‚úì</td></tr></tbody></table></div>
<p>To enable streaming responses, set the <code>stream</code> parameter to <code>true</code> in your request. For example:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token function" style="color:#d73a49">curl</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-X</span><span class="token plain"> POST http://my.deployments:8888/endpoints/chat/invocations </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-H</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Content-Type: application/json&quot;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-d</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;hello&quot;}], &quot;stream&quot;: true}&#x27;</span><br></span></code></pre></div></div>
<p>The results of the query follow the <a href="https://platform.openai.com/docs/api-reference/chat/streaming" target="_blank" rel="noopener noreferrer">OpenAI schema</a>.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="chat-1">Chat<a href="#chat-1" class="hash-link" aria-label="Direct link to Chat" title="Direct link to Chat">‚Äã</a></h5>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">data: {&quot;choices&quot;: [{&quot;delta&quot;: {&quot;content&quot;: null, &quot;role&quot;: &quot;assistant&quot;}, &quot;finish_reason&quot;: null, &quot;index&quot;: 0}], &quot;created&quot;: 1701161926, &quot;id&quot;: &quot;chatcmpl-8PoDWSiVE8MHNsUZF2awkW5gNGYs3&quot;, &quot;model&quot;: &quot;gpt-35-turbo&quot;, &quot;object&quot;: &quot;chat.completion.chunk&quot;}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data: {&quot;choices&quot;: [{&quot;delta&quot;: {&quot;content&quot;: &quot;Hello&quot;, &quot;role&quot;: null}, &quot;finish_reason&quot;: null, &quot;index&quot;: 0}], &quot;created&quot;: 1701161926, &quot;id&quot;: &quot;chatcmpl-8PoDWSiVE8MHNsUZF2awkW5gNGYs3&quot;, &quot;model&quot;: &quot;gpt-35-turbo&quot;, &quot;object&quot;: &quot;chat.completion.chunk&quot;}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data: {&quot;choices&quot;: [{&quot;delta&quot;: {&quot;content&quot;: &quot; there&quot;, &quot;role&quot;: null}, &quot;finish_reason&quot;: null, &quot;index&quot;: 0}], &quot;created&quot;: 1701161926, &quot;id&quot;: &quot;chatcmpl-8PoDWSiVE8MHNsUZF2awkW5gNGYs3&quot;, &quot;model&quot;: &quot;gpt-35-turbo&quot;, &quot;object&quot;: &quot;chat.completion.chunk&quot;}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data: {&quot;choices&quot;: [{&quot;delta&quot;: {&quot;content&quot;: null, &quot;role&quot;: null}, &quot;finish_reason&quot;: &quot;stop&quot;, &quot;index&quot;: 0}], &quot;created&quot;: 1701161926, &quot;id&quot;: &quot;chatcmpl-8PoDWSiVE8MHNsUZF2awkW5gNGYs3&quot;, &quot;model&quot;: &quot;gpt-35-turbo&quot;, &quot;object&quot;: &quot;chat.completion.chunk&quot;}</span><br></span></code></pre></div></div>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="completions-1">Completions<a href="#completions-1" class="hash-link" aria-label="Direct link to Completions" title="Direct link to Completions">‚Äã</a></h5>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">data: {&quot;choices&quot;: [{&quot;delta&quot;: {&quot;role&quot;: null, &quot;content&quot;: null}, &quot;finish_reason&quot;: null, &quot;index&quot;: 0}], &quot;created&quot;: 1701161629, &quot;id&quot;: &quot;chatcmpl-8Po8jVXzljc245k1Ah4UsAcm2zxQ2&quot;, &quot;model&quot;: &quot;gpt-35-turbo&quot;, &quot;object&quot;: &quot;text_completion_chunk&quot;}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data: {&quot;choices&quot;: [{&quot;delta&quot;: {&quot;role&quot;: null, &quot;content&quot;: &quot;If&quot;}, &quot;finish_reason&quot;: null, &quot;index&quot;: 0}], &quot;created&quot;: 1701161629, &quot;id&quot;: &quot;chatcmpl-8Po8jVXzljc245k1Ah4UsAcm2zxQ2&quot;, &quot;model&quot;: &quot;gpt-35-turbo&quot;, &quot;object&quot;: &quot;text_completion_chunk&quot;}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data: {&quot;choices&quot;: [{&quot;delta&quot;: {&quot;role&quot;: null, &quot;content&quot;: &quot; an&quot;}, &quot;finish_reason&quot;: null, &quot;index&quot;: 0}], &quot;created&quot;: 1701161629, &quot;id&quot;: &quot;chatcmpl-8Po8jVXzljc245k1Ah4UsAcm2zxQ2&quot;, &quot;model&quot;: &quot;gpt-35-turbo&quot;, &quot;object&quot;: &quot;text_completion_chunk&quot;}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data: {&quot;choices&quot;: [{&quot;delta&quot;: {&quot;role&quot;: null, &quot;content&quot;: &quot; asteroid&quot;}, &quot;finish_reason&quot;: null, &quot;index&quot;: 0}], &quot;created&quot;: 1701161629, &quot;id&quot;: &quot;chatcmpl-8Po8jVXzljc245k1Ah4UsAcm2zxQ2&quot;, &quot;model&quot;: &quot;gpt-35-turbo&quot;, &quot;object&quot;: &quot;text_completion_chunk&quot;}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data: {&quot;choices&quot;: [{&quot;delta&quot;: {&quot;role&quot;: null, &quot;content&quot;: null}, &quot;finish_reason&quot;: &quot;length&quot;, &quot;index&quot;: 0}], &quot;created&quot;: 1701161629, &quot;id&quot;: &quot;chatcmpl-8Po8jVXzljc245k1Ah4UsAcm2zxQ2&quot;, &quot;model&quot;: &quot;gpt-35-turbo&quot;, &quot;object&quot;: &quot;text_completion_chunk&quot;}</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="fastapi-documentation-docs">FastAPI Documentation (&quot;/docs&quot;)<a href="#fastapi-documentation-docs" class="hash-link" aria-label="Direct link to FastAPI Documentation (&quot;/docs&quot;)" title="Direct link to FastAPI Documentation (&quot;/docs&quot;)">‚Äã</a></h3>
<p>FastAPI, the framework used for building the MLflow AI Gateway, provides an automatic interactive API
documentation interface, which is accessible at the &quot;/docs&quot; endpoint (e.g., <code>http://my.deployments:9000/docs</code>).
This interactive interface is very handy for exploring and testing the available API endpoints.</p>
<p>As a convenience, accessing the root URL (e.g., <code>http://my.deployments:9000</code>) redirects to this &quot;/docs&quot; endpoint.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="mlflow-python-client-apis">MLflow Python Client APIs<a href="#mlflow-python-client-apis" class="hash-link" aria-label="Direct link to MLflow Python Client APIs" title="Direct link to MLflow Python Client APIs">‚Äã</a></h3>
<p><a href="/docs/latest/api_reference/python_api/mlflow.deployments.html#mlflow.deployments.MlflowDeploymentClient" target="_blank"><code>MlflowDeploymentClient</code></a> is the user-facing client API that is used to interact with the MLflow AI Gateway. It abstracts the HTTP requests to the gateway server via a simple, easy-to-use Python API.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="deployments-client-api">Client API<a href="#deployments-client-api" class="hash-link" aria-label="Direct link to Client API" title="Direct link to Client API">‚Äã</a></h4>
<p>To use the <code>MlflowDeploymentClient</code> API, see the below examples for the available API methods:</p>
<ol>
<li>Create an <code>MlflowDeploymentClient</code></li>
</ol>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">deployments </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> get_deploy_client</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">client </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> get_deploy_client</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;http://my.deployments:8888&quot;</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<ol start="2">
<li>
<p>List all endpoints:</p>
<p>The <a href="/docs/latest/api_reference/python_api/mlflow.deployments.html#mlflow.deployments.MlflowDeploymentClient.list_endpoints" target="_blank"><code>list_endpoints()</code></a> method returns a list of all endpoints.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">endpoint </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> client</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">list_endpoints</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> endpoint </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> endpoints</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">endpoint</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
</li>
<li>
<p>Query an endpoint:</p>
<p>The <a href="/docs/latest/api_reference/python_api/mlflow.deployments.html#mlflow.deployments.MlflowDeploymentClient.predict" target="_blank"><code>predict()</code></a> method submits a query to a configured provider endpoint.
The data structure you send in the query depends on the endpoint.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">response </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> client</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    endpoint</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;chat&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    inputs</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&quot;messages&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&quot;role&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;user&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;content&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Tell me a joke about rabbits&quot;</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">response</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
</li>
</ol>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="langchain-integration">LangChain Integration<a href="#langchain-integration" class="hash-link" aria-label="Direct link to LangChain Integration" title="Direct link to LangChain Integration">‚Äã</a></h4>
<p><a href="https://github.com/langchain-ai/langchain" target="_blank" rel="noopener noreferrer">LangChain</a> supports <a href="https://python.langchain.com/docs/integrations/providers/mlflow_tracking/" target="_blank" rel="noopener noreferrer">an integration for MLflow Deployments</a>.
This integration enable users to use prompt engineering, retrieval augmented generation, and other techniques with LLMs in the gateway server.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">Example</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> langchain </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> LLMChain</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> PromptTemplate</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> langchain</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">llms </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> Mlflow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">llm </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> Mlflow</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">target_uri</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;http://127.0.0.1:5000&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> endpoint</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;completions&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">llm_chain </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> LLMChain</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    llm</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">llm</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    prompt</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">PromptTemplate</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        input_variables</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;adjective&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        template</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;Tell me a {adjective} joke&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">result </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> llm_chain</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">run</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">adjective</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;funny&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">result</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">with</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">start_run</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_info </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">langchain</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">log_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">llm_chain</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> name</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;model&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pyfunc</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model_info</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_uri</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&quot;adjective&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;funny&quot;</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="deployments-mlflow-models">MLflow Models<a href="#deployments-mlflow-models" class="hash-link" aria-label="Direct link to MLflow Models" title="Direct link to MLflow Models">‚Äã</a></h4>
<p>Interfacing with MLflow Models can be done in two ways. With the use of a custom PyFunc Model, a query can be issued directly to a gateway server endpoint and used in a broader context within a model.
Data may be augmented, manipulated, or used in a mixture of experts paradigm. The other means of utilizing the MLflow AI Gateway along with MLflow Models is to define a served MLflow model directly as
an endpoint within a gateway server.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="using-the-gateway-server-to-query-a-served-mlflow-model">Using the gateway server to Query a served MLflow Model<a href="#using-the-gateway-server-to-query-a-served-mlflow-model" class="hash-link" aria-label="Direct link to Using the gateway server to Query a served MLflow Model" title="Direct link to Using the gateway server to Query a served MLflow Model">‚Äã</a></h5>
<p>For a full walkthrough and example of using the MLflow serving integration to query a model directly through the MLflow AI Gateway, please see <a href="https://github.com/mlflow/mlflow/blob/master/examples/gateway/README.md" target="_blank" rel="noopener noreferrer">the full example</a>.
Within the guide, you will see the entire end-to-end process of serving multiple models from different servers and configuring an MLflow AI Gateway instance to provide a single unified point to handle queries from.</p>
<h5 class="anchor anchorWithStickyNavbar_LWe7" id="using-an-mlflow-model-to-query-the-gateway-server">Using an MLflow Model to Query the gateway server<a href="#using-an-mlflow-model-to-query-the-gateway-server" class="hash-link" aria-label="Direct link to Using an MLflow Model to Query the gateway server" title="Direct link to Using an MLflow Model to Query the gateway server">‚Äã</a></h5>
<p>You can also build and deploy MLflow Models that call the MLflow AI Gateway.
The example below demonstrates how to use a gateway server from within a custom <code>pyfunc</code> model.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>The custom <code>Model</code> shown in the example below is utilizing environment variables for the gateway server&#x27;s uri. These values can also be set manually within the
definition or can be applied via <a href="/docs/latest/api_reference/python_api/mlflow.deployments.html#mlflow.deployments.get_deployments_target" target="_blank"><code>mlflow.deployments.get_deployments_target<!-- -->()</code></a> after the uri has been set. For the example below, the value for <code>MLFLOW_DEPLOYMENTS_TARGET</code> is
<code>http://127.0.0.1:5000/</code>. For an actual deployment use case, this value would be set to the configured and production deployment server.</p></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> pandas </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> pd</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">predict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">data</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">deployments </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> get_deploy_client</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    client </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> get_deploy_client</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">os</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">environ</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;MLFLOW_DEPLOYMENTS_TARGET&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    payload </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> data</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">to_dict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">orient</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;records&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        client</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">endpoint</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;completions&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> inputs</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">query</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;choices&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;text&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> query </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> payload</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">input_example </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> pd</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">DataFrame</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_dict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&quot;prompt&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;Where is the moon?&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;What is a comet made of?&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">signature </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">models</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">infer_signature</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    input_example</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;Above our heads.&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;It&#x27;s mostly ice and rocks.&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">with</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">start_run</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_info </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pyfunc</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">log_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        python_model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">predict</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        registered_model_name</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;anthropic_completions&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        name</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;anthropic_completions&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        input_example</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">input_example</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        signature</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">signature</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> pd</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">DataFrame</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_dict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">&quot;prompt&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;Tell me about Jupiter&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Tell me about Saturn&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">&quot;temperature&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0.6</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token string" style="color:#e3116c">&quot;max_records&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">500</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">loaded_model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pyfunc</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">model_info</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model_uri</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">loaded_model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">df</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<p>This custom MLflow model can be used in the same way as any other MLflow model. It can be used within a <code>spark_udf</code>, used with <a href="/docs/latest/api_reference/python_api/mlflow.html#mlflow.genai.evaluate" target="_blank"><code>mlflow.genai.evaluate<!-- -->()</code></a>, or the deploy API like any other model.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="deployments-rest-api">REST API<a href="#deployments-rest-api" class="hash-link" aria-label="Direct link to REST API" title="Direct link to REST API">‚Äã</a></h4>
<p>The REST API allows you to send HTTP requests directly to the MLflow AI Gateway. This is useful if you&#x27;re not using Python or if you prefer to interact with a gateway server using HTTP directly.</p>
<p>Here are some examples for how you might use curl to interact with the MLflow AI Gateway:</p>
<ol>
<li>
<p>Get information about a particular endpoint: <code>GET /api/2.0/endpoints/{name}</code></p>
<p>This route returns a serialized representation of the endpoint data structure.
This provides information about the name and type, as well as the model details for the requested endpoint.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token function" style="color:#d73a49">curl</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-X</span><span class="token plain"> GET http://my.deployments:8888/api/2.0/endpoints/embeddings</span><br></span></code></pre></div></div>
</li>
<li>
<p>List all endpoints: <code>GET /api/2.0/endpoints/</code></p>
<p>This route returns a list of all endpoints.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token function" style="color:#d73a49">curl</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-X</span><span class="token plain"> GET http://my.deployments:8888/api/2.0/endpoints/</span><br></span></code></pre></div></div>
</li>
<li>
<p>Query an endpoint: <code>POST /endpoints/{name}/invocations</code></p>
<p>This route allows you to submit a query to a configured provider endpoint. The data structure you send in the query depends on the endpoint. Here are examples for the &quot;completions&quot;, &quot;chat&quot;, and &quot;embeddings&quot; endpoints:</p>
<ul>
<li>
<p><code>Completions</code></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token function" style="color:#d73a49">curl</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-X</span><span class="token plain"> POST http://my.deployments:8888/endpoints/completions/invocations </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-H</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Content-Type: application/json&quot;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-d</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;{&quot;prompt&quot;: &quot;Describe the probability distribution of the decay chain of U-235&quot;}&#x27;</span><br></span></code></pre></div></div>
</li>
<li>
<p><code>Chat</code></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token function" style="color:#d73a49">curl</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-X</span><span class="token plain"> POST http://my.deployments:8888/endpoints/chat/invocations </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-H</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Content-Type: application/json&quot;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-d</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Can you write a limerick about orange flavored popsicles?&quot;}]}&#x27;</span><br></span></code></pre></div></div>
</li>
<li>
<p><code>Embeddings</code></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token function" style="color:#d73a49">curl</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-X</span><span class="token plain"> POST http://my.deployments:8888/endpoints/embeddings/invocations </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-H</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Content-Type: application/json&quot;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-d</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;{&quot;input&quot;: [&quot;I would like to return my shipment of beanie babies, please&quot;, &quot;Can I please speak to a human now?&quot;]}&#x27;</span><br></span></code></pre></div></div>
</li>
</ul>
</li>
</ol>
<p><strong>Note:</strong> Remember to replace <code>my.deployments:8888</code> with the URL of your actual MLflow AI Gateway.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deployments-plugin">Plugin LLM Provider<a href="#deployments-plugin" class="hash-link" aria-label="Direct link to Plugin LLM Provider" title="Direct link to Plugin LLM Provider">‚Äã</a></h2>
<p>The MLflow AI Gateway supports the use of custom language model providers through the use of plugins.
A plugin is a Python package that provides a custom implementation of a language model provider.
This allows users to integrate their own language model services with the MLflow AI Gateway.</p>
<p>To create a custom plugin, you need to implement a provider class that inherits from <code>mlflow.gateway.providers.BaseProvider</code>,
and a config class that inherits from <code>mlflow.gateway.base_models.ConfigModel</code>.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">Example</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> typing </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> AsyncIterable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">utils</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pydantic_utils </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> field_validator</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">gateway</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">base_models </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> ConfigModel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">gateway</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">config </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> RouteConfig</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">gateway</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">providers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> BaseProvider</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">gateway</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">schemas </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> chat</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> completions</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> embeddings</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">MyLLMConfig</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">ConfigModel</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># This model defines the configuration for the provider such as API keys</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    my_llm_api_key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token decorator annotation punctuation" style="color:#393A34">@field_validator</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;my_llm_api_key&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> mode</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;before&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">validate_my_llm_api_key</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">cls</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> value</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> os</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">environ</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">value</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">lstrip</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;$&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">MyLLMProvider</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">BaseProvider</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Define the provider name. This will be displayed in log and error messages.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    NAME </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;my_llm&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Define the config model for the provider.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># This must be a subclass of ConfigModel.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    CONFIG_TYPE </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> MyLLMConfig</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> RouteConfig</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">None</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token builtin">super</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">config</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> config</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">config </span><span class="token keyword" style="color:#00009f">is</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">None</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">or</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">not</span><span class="token plain"> </span><span class="token builtin">isinstance</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            config</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">config</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> MyLLMConfig</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token keyword" style="color:#00009f">raise</span><span class="token plain"> TypeError</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;Unexpected config type </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">config</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation">model</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation">config</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">my_llm_config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> MyLLMConfig </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> config</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">config</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># You can implement one or more of the following methods</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># depending on the capabilities of your provider.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Implementing `completions`, `chat` and `embeddings` will enable the respective endpoints.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Implementing `completions_stream` and `chat_stream` will enable the `stream=True`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># option for the respective endpoints.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Unimplemented methods will return a 501 Not Implemented HTTP response upon invocation.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">async</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">completions_stream</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> payload</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> completions</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">RequestPayload</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> AsyncIterable</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">completions</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">StreamResponsePayload</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">async</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">completions</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> payload</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> completions</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">RequestPayload</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> completions</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ResponsePayload</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">async</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">chat_stream</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> payload</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> chat</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">RequestPayload</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> AsyncIterable</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">chat</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">StreamResponsePayload</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">async</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">chat</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> payload</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> chat</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">RequestPayload</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> chat</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ResponsePayload</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">async</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">embeddings</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> payload</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> embeddings</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">RequestPayload</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> embeddings</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ResponsePayload</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><span class="token punctuation" style="color:#393A34">.</span><br></span></code></pre></div></div>
<p>Then, you need to create a Python package that contains the plugin implementation.
You must specify an entry point under the <code>mlflow.gateway.providers</code> group, so that your plugin can be detected by MLflow.
The entry point should be in the format <code>&lt;name&gt; = &lt;module&gt;:&lt;class&gt;</code>.</p>
<div class="language-toml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_OeMC">pyproject.toml</div><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-toml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">[</span><span class="token table class-name">project</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key property" style="color:#36acaa">name</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;my_llm&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key property" style="color:#36acaa">version</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;1.0&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">[</span><span class="token table class-name">project.entry-points.&quot;mlflow.gateway.providers&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key property" style="color:#36acaa">my_llm</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;my_llm.providers:MyLLMProvider&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">[</span><span class="token table class-name">tool.setuptools.packages.find</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key property" style="color:#36acaa">include</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;my_llm*&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token key property" style="color:#36acaa">namespaces</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">=</span><span class="token plain"> </span><span class="token boolean" style="color:#36acaa">false</span><br></span></code></pre></div></div>
<p>You can specify more than one entry point in the same package if you have multiple providers.
Note that entry point names must be globally unique. If two plugins specify the same entry point name,
MLflow will raise an error at startup time.</p>
<p>MLflow already provides a number of providers by default. Your plugin name cannot be the same as any one
of them. See <a href="#deployments-configuration-details">AI Gateway server Configuration Details</a> for a complete list of default providers.</p>
<p>Finally, you need to install the plugin package in the same environment as the MLflow AI Gateway.</p>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>important</div><div class="admonitionContent_BuS1"><p>Only install plugin packages from sources that you trust. Starting a server with a plugin provider will
execute any arbitrary code that is defined within the plugin package.</p></div></div>
<p>Then, you can specify the plugin provider according to the entry point name
in the MLflow AI Gateway configuration file.</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">endpoints</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> chat</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">endpoint_type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> llm/v1/chat</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">model</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">provider</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> my_llm</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> my</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">0.1.2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">my_llm_api_key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> $MY_LLM_API_KEY</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="example">Example<a href="#example" class="hash-link" aria-label="Direct link to Example" title="Direct link to Example">‚Äã</a></h3>
<p>A working example can be found in the MLflow repository at
<a href="https://github.com/mlflow/mlflow/tree/master/examples/gateway/plugin" target="_blank" rel="noopener noreferrer">examples/gateway/plugin</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="mlflow-ai-gateway-api-documentation">MLflow AI Gateway API Documentation<a href="#mlflow-ai-gateway-api-documentation" class="hash-link" aria-label="Direct link to MLflow AI Gateway API Documentation" title="Direct link to MLflow AI Gateway API Documentation">‚Äã</a></h2>
<a href="/docs/latest/api_reference/llms/deployments/api.html" target="_blank">API documentation</a>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="openai-compatibility">OpenAI Compatibility<a href="#openai-compatibility" class="hash-link" aria-label="Direct link to OpenAI Compatibility" title="Direct link to OpenAI Compatibility">‚Äã</a></h2>
<p>MLflow AI Gateway is compatible with OpenAI API and supports the <code>chat</code>, <code>completions</code>, and <code>embeddings</code> APIs.
The OpenAI client can be used to query the server as shown in the example below:</p>
<ol>
<li>Create a configuration file:</li>
</ol>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">endpoints</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> my</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">chat</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">endpoint_type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> llm/v1/chat</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">model</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">provider</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> gpt</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">4o</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">mini</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">config</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">openai_api_key</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> $OPENAI_API_KEY</span><br></span></code></pre></div></div>
<ol start="2">
<li>Start the server with the configuration file:</li>
</ol>
<div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">mlflow gateway start --config-path /path/to/config.yaml </span><span class="token parameter variable" style="color:#36acaa">--port</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">7000</span><br></span></code></pre></div></div>
<ol start="3">
<li>Once the server is up and running, query the server using the OpenAI client:</li>
</ol>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> openai </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> OpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">client </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> OpenAI</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">base_url</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;http://localhost:7000/v1&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">completion </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> client</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">chat</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">completions</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">create</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;my-chat&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    messages</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&quot;role&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;user&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;content&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Hello&quot;</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">completion</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">choices</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">message</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">content</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="unity-catalog-integration">Unity Catalog Integration<a href="#unity-catalog-integration" class="hash-link" aria-label="Direct link to Unity Catalog Integration" title="Direct link to Unity Catalog Integration">‚Äã</a></h2>
<p>See <a href="/docs/latest/genai/governance/unity-catalog">Unity Catalog Integration</a> for how to integrate the MLflow AI Gateway with Unity Catalog.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deployments-security">gateway server Security Considerations<a href="#deployments-security" class="hash-link" aria-label="Direct link to gateway server Security Considerations" title="Direct link to gateway server Security Considerations">‚Äã</a></h2>
<p>Remember to ensure secure access to the system that the MLflow AI Gateway is running in to protect access to these keys.</p>
<p>An effective way to secure your gateway server is by placing it behind a reverse proxy. This will allow the reverse proxy to handle incoming requests and forward them to the MLflow AI Gateway. The reverse proxy effectively shields your application from direct exposure to Internet traffic.</p>
<p>A popular choice for a reverse proxy is <em>Nginx</em>. In addition to handling the traffic to your application, <em>Nginx</em> can also serve static files and load balance the traffic if you have multiple instances of your application running.</p>
<p>Furthermore, to ensure the integrity and confidentiality of data between the client and the server, it&#x27;s highly recommended to enable HTTPS on your reverse proxy.</p>
<p>In addition to the reverse proxy, it&#x27;s also recommended to add an authentication layer before the requests reach the MLflow AI Gateway. This could be HTTP Basic Authentication, OAuth, or any other method that suits your needs.</p>
<p>For example, here&#x27;s a simple configuration for Nginx with Basic Authentication:</p>
<div class="language-nginx codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-nginx codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token directive keyword" style="color:#00009f">http</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token directive keyword" style="color:#00009f">server</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token directive keyword" style="color:#00009f">listen</span><span class="token directive"> </span><span class="token directive number" style="color:#36acaa">80</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token directive keyword" style="color:#00009f">location</span><span class="token directive"> /</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token directive keyword" style="color:#00009f">auth_basic</span><span class="token directive"> </span><span class="token directive string" style="color:#e3116c">&quot;Restricted Content&quot;</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token directive keyword" style="color:#00009f">auth_basic_user_file</span><span class="token directive"> /etc/nginx/.htpasswd</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token directive keyword" style="color:#00009f">proxy_pass</span><span class="token directive"> http://localhost:5000</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Replace with the MLflow AI Gateway port</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre></div></div>
<p>In this example, <em>/etc/nginx/.htpasswd</em> is a file that contains the username and password for authentication.</p>
<p>These measures, together with a proper network setup, can significantly improve the security of your system and ensure that only authorized users have access to submit requests to your LLM services.</p></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/latest/genai/serving/custom-apps"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Custom Apps</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/latest/genai/governance/ai-gateway/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">MLflow AI Gateway</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#tutorials-and-guides" class="table-of-contents__link toc-highlight">Tutorials and Guides</a></li><li><a href="#deployments-quickstart" class="table-of-contents__link toc-highlight">Quickstart</a><ul><li><a href="#step-1-install-the-mlflow-ai-gateway" class="table-of-contents__link toc-highlight">Step 1: Install the MLflow AI Gateway</a></li><li><a href="#step-2-set-the-openai-api-keys-for-each-provider" class="table-of-contents__link toc-highlight">Step 2: Set the OpenAI API Key(s) for each provider</a></li><li><a href="#step-3-create-a-gateway-server-configuration-file" class="table-of-contents__link toc-highlight">Step 3: Create a gateway server Configuration File</a></li><li><a href="#step-4-start-the-gateway-server" class="table-of-contents__link toc-highlight">Step 4: Start the gateway server</a></li><li><a href="#step-5-access-the-interactive-api-documentation" class="table-of-contents__link toc-highlight">Step 5: Access the Interactive API Documentation</a></li><li><a href="#step-6-send-requests-using-the-client-api" class="table-of-contents__link toc-highlight">Step 6: Send Requests Using the Client API</a></li><li><a href="#step-7-send-requests-to-endpoints-via-rest-api" class="table-of-contents__link toc-highlight">Step 7: Send Requests to Endpoints via REST API</a></li><li><a href="#step-8-compare-provider-models" class="table-of-contents__link toc-highlight">Step 8: Compare Provider Models</a></li><li><a href="#step-9-use-gateway-server-endpoints-for-model-development" class="table-of-contents__link toc-highlight">Step 9: Use gateway server endpoints for model development</a></li></ul></li><li><a href="#deployments-concepts" class="table-of-contents__link toc-highlight">Concepts</a><ul><li><a href="#deployments-providers" class="table-of-contents__link toc-highlight">Providers</a></li></ul></li><li><a href="#deployments-endpoints" class="table-of-contents__link toc-highlight">Endpoints</a></li><li><a href="#deployments-models" class="table-of-contents__link toc-highlight">Models</a></li><li><a href="#deployments-configuration" class="table-of-contents__link toc-highlight">Configuring the gateway server</a><ul><li><a href="#ai-gateway-server-configuration" class="table-of-contents__link toc-highlight">AI Gateway server Configuration</a></li></ul></li><li><a href="#deployments-query" class="table-of-contents__link toc-highlight">Querying the AI Gateway server</a><ul><li><a href="#standard-deployments-parameters" class="table-of-contents__link toc-highlight">Standard Query Parameters</a></li><li><a href="#additional-query-parameters" class="table-of-contents__link toc-highlight">Additional Query Parameters</a></li><li><a href="#fastapi-documentation-docs" class="table-of-contents__link toc-highlight">FastAPI Documentation (&quot;/docs&quot;)</a></li><li><a href="#mlflow-python-client-apis" class="table-of-contents__link toc-highlight">MLflow Python Client APIs</a></li></ul></li><li><a href="#deployments-plugin" class="table-of-contents__link toc-highlight">Plugin LLM Provider</a><ul><li><a href="#example" class="table-of-contents__link toc-highlight">Example</a></li></ul></li><li><a href="#mlflow-ai-gateway-api-documentation" class="table-of-contents__link toc-highlight">MLflow AI Gateway API Documentation</a></li><li><a href="#openai-compatibility" class="table-of-contents__link toc-highlight">OpenAI Compatibility</a></li><li><a href="#unity-catalog-integration" class="table-of-contents__link toc-highlight">Unity Catalog Integration</a></li><li><a href="#deployments-security" class="table-of-contents__link toc-highlight">gateway server Security Considerations</a></li></ul></div></div></div></div></main></div></div></div><footer class="pb-150 flex flex-col pt-37 bg-linear-to-b from-brand-black to-brand-black bg-bottom bg-no-repeat bg-cover w-full bg-(--background-color-dark) bg-size-[100%_340px]" style="background-image:url(/docs/latest/assets/images/footer-red-bg-ec5ecbbbbb62b125aa76b2c5c2af7ab3.png)"><div class="flex flex-row justify-between items-start md:items-center px-6 lg:px-20 gap-10 xs:gap-0 max-w-container"><svg xmlns="http://www.w3.org/2000/svg" width="109" height="40" fill="none" viewBox="0 0 109 40" class="h-[36px] shrink-0"><path fill="#fff" d="M0 31.032v-15.53h3.543v1.968c.893-1.594 2.84-2.425 4.593-2.425 2.042 0 3.828.926 4.658 2.745 1.216-2.043 3.034-2.745 5.043-2.745 2.81 0 5.49 1.787 5.49 5.904v10.083h-3.574v-9.478c0-1.818-.926-3.19-3-3.19-1.947 0-3.224 1.53-3.224 3.445v9.22H9.893v-9.475c0-1.786-.898-3.18-3.003-3.18-1.977 0-3.223 1.467-3.223 3.444v9.221ZM27.855 31.032V7.929h3.703v23.103ZM30.07 39.487c.833.232 1.582.383 3.17.383 2.953 0 6.436-1.665 7.353-6.339l3.786-18.739h5.629l.687-3.117h-5.686l.765-3.725c.586-2.892 2.186-4.358 4.754-4.358.668 0 .48.058 1.076.17L52.427.57c-.793-.237-1.503-.379-3.049-.379a7.32 7.32 0 0 0-4.528 1.484c-1.441 1.114-2.393 2.75-2.827 4.863l-1.066 5.137h-5.034l-.411 3.12h4.823L36.859 32.12c-.383 1.965-1.5 4.315-4.708 4.315-.727 0-.463-.055-1.121-.162ZM53.342 30.905H49.64l5.074-23.309h3.701ZM71.807 16.477A7.962 7.962 0 0 0 60.97 27.904l2.425-1.78a5.005 5.005 0 0 1 3.845-8.145v1.895ZM62.618 29.472a7.962 7.962 0 0 0 10.836-11.428l-2.425 1.78a5.005 5.005 0 0 1-3.845 8.145v-1.894ZM78.092 15.493h4.044l.823 10.612 5.759-10.612 3.839.055 1.508 10.557 5.074-10.612 3.701.055-7.678 15.493H91.46l-1.783-11.106-5.895 11.106h-3.84ZM105.072 15.768h-.766v-.266h1.845v.272h-.765v2.243h-.314ZM106.614 15.502h.383l.482 1.34q.091.259.178.524h.018c.059-.176.113-.352.172-.524l.478-1.34h.383v2.515h-.298V16.63c0-.22.024-.523.04-.747h-.016l-.191.574-.475 1.304h-.208l-.481-1.302-.191-.574h-.015c.017.224.042.527.042.747v1.387h-.291Z"></path></svg><div class="flex flex-col md:flex-row gap-10"><div class="min-w-[120px]"><a href="https://mllfow.org" target="_blank" rel="noopener noreferrer" class="link_LVIP">Product</a></div><div class="min-w-[120px]"><a href="https://mlflow.org/releases" target="_blank" rel="noopener noreferrer" class="link_LVIP">Releases</a></div><div class="min-w-[120px]"><a href="https://mlflow.org/blog" target="_blank" rel="noopener noreferrer" class="link_LVIP">Blog</a></div><div class="min-w-[120px]"><a class="link_LVIP" href="/docs/latest/">Docs</a></div></div></div></footer></div>
</body>
</html>