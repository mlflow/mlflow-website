<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-genai docs-version-current docs-doc-page docs-doc-id-prompt-version-mgmt/prompt-engineering/index" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">Prompt Engineering UI (Experimental) | MLflow</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://mlflow.org/docs/latest/genai/prompt-version-mgmt/prompt-engineering/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-genai-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-genai-current"><meta data-rh="true" property="og:title" content="Prompt Engineering UI (Experimental) | MLflow"><meta data-rh="true" name="description" content="Starting in MLflow 2.7, the MLflow Tracking UI provides a best-in-class experience for prompt"><meta data-rh="true" property="og:description" content="Starting in MLflow 2.7, the MLflow Tracking UI provides a best-in-class experience for prompt"><link data-rh="true" rel="icon" href="/docs/latest/images/favicon.ico"><link data-rh="true" rel="canonical" href="https://mlflow.org/docs/latest/genai/prompt-version-mgmt/prompt-engineering/"><link data-rh="true" rel="alternate" href="https://mlflow.org/docs/latest/genai/prompt-version-mgmt/prompt-engineering/" hreflang="en"><link data-rh="true" rel="alternate" href="https://mlflow.org/docs/latest/genai/prompt-version-mgmt/prompt-engineering/" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://XKVLO8P882-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Prompt Engineering UI","item":"https://mlflow.org/docs/latest/genai/prompt-version-mgmt/prompt-engineering/"}]}</script><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=GTM-N6WMTTJ"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","GTM-N6WMTTJ",{anonymize_ip:!0}),gtag("config","AW-16857946923",{anonymize_ip:!0})</script>
<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var g=t.getElementsByTagName(a)[0],m=t.createElement(a);m.async=!0,m.src="https://www.googletagmanager.com/gtm.js?id=GTM-N6WMTTJ",g.parentNode.insertBefore(m,g)}(window,document,"script","dataLayer")</script>



<link rel="search" type="application/opensearchdescription+xml" title="MLflow" href="/docs/latest/opensearch.xml">





<script src="/docs/latest/js/runllm.js" defer="defer"></script><link rel="stylesheet" href="/docs/latest/assets/css/styles.641babe6.css">
<script src="/docs/latest/assets/js/runtime~main.90112150.js" defer="defer"></script>
<script src="/docs/latest/assets/js/main.faa53f1b.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>


<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/docs/latest/"><div class="navbar__logo"><img src="/docs/latest/images/logo-light.svg" alt="MLflow Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/docs/latest/images/logo-dark.svg" alt="MLflow Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Documentation</a><ul class="dropdown__menu"><li><a class="dropdown__link ml-docs-link" href="/docs/latest/ml/">ML Docs</a></li><li><a aria-current="page" class="dropdown__link genai-docs-link dropdown__link--active" href="/docs/latest/genai/">GenAI Docs</a></li></ul></div><a href="https://mlflow.org/docs/latest/api_reference/index.html" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">API Reference</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/mlflow/mlflow" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link github-link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sidebar-top-level-category"><a class="menu__link" href="/docs/latest/genai/">MLflow for GenAI</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/overview/">Overview 🌟</a><button aria-label="Collapse sidebar category &#x27;Overview 🌟&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/genai/overview/key-challenges">Key Challenges</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/genai/overview/why-mlflow">Why use MLflow</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/developer-workflow/">Developer Workflow 👉</a><button aria-label="Expand sidebar category &#x27;Developer Workflow 👉&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/getting-started/">Getting Started 🚀</a><button aria-label="Expand sidebar category &#x27;Getting Started   🚀&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/tracing/">Tracing (Observability) 🔎</a><button aria-label="Expand sidebar category &#x27;Tracing (Observability) 🔎&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/eval-monitor/">Evaluate &amp; Monitor 📊</a><button aria-label="Expand sidebar category &#x27;Evaluate &amp; Monitor 📊&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/latest/genai/prompt-version-mgmt/version-tracking/">Prompt and Version Management 🔨</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/genai/prompt-version-mgmt/version-tracking/">Version Tracking</a><button aria-label="Expand sidebar category &#x27;Version Tracking&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/genai/prompt-version-mgmt/prompt-registry/">Prompt Registry</a><button aria-label="Expand sidebar category &#x27;Prompt Registry&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/latest/genai/prompt-version-mgmt/prompt-engineering/">Prompt Engineering UI</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/serving/">Application Serving ⛵</a><button aria-label="Expand sidebar category &#x27;Application Serving ⛵&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/governance/ai-gateway/">Governance 🛡️</a><button aria-label="Expand sidebar category &#x27;Governance 🛡️&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/data-model/">Data Model 🧩</a><button aria-label="Expand sidebar category &#x27;Data Model 🧩&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/docs/latest/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Prompt and Version Management 🔨</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Prompt Engineering UI</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Prompt Engineering UI (Experimental)</h1></header>
<p>Starting in MLflow 2.7, the MLflow Tracking UI provides a best-in-class experience for prompt
engineering. With no code required, you can try out multiple LLMs from the
<a href="/docs/latest/genai/governance/ai-gateway">MLflow AI Gateway</a>, parameter configurations, and prompts to build a variety of models for
question answering, document summarization, and beyond. Using the embedded Evaluation UI, you can
also evaluate multiple models on a set of inputs and compare the responses to select the best one.
Every model created with the prompt engineering UI is stored in the <a href="/docs/latest/ml/model">MLflow Model</a>
format and can be deployed for batch or real time inference. All configurations (prompt templates,
choice of LLM, parameters, etc.) are tracked as <a href="/docs/latest/ml/tracking">MLflow Runs</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-engineering-quickstart">Quickstart<a href="#prompt-engineering-quickstart" class="hash-link" aria-label="Direct link to Quickstart" title="Direct link to Quickstart">​</a></h2>
<p>The following guide will get you started with MLflow&#x27;s UI for prompt engineering.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-1-create-an-mlflow-ai-gateway-completions-or-chat-endpoint">Step 1: Create an MLflow AI Gateway Completions or Chat Endpoint<a href="#step-1-create-an-mlflow-ai-gateway-completions-or-chat-endpoint" class="hash-link" aria-label="Direct link to Step 1: Create an MLflow AI Gateway Completions or Chat Endpoint" title="Direct link to Step 1: Create an MLflow AI Gateway Completions or Chat Endpoint">​</a></h3>
<p>To use the prompt engineering UI, you need to create one or more <a href="/docs/latest/genai/governance/ai-gateway">MLflow AI Gateway</a>
completions or chat endpoints. Follow the
<a href="/docs/latest/genai/governance/ai-gateway/guides/step1-create-deployments">MLflow AI Gateway Quickstart guide</a> to easily create an endpoint in less than five
minutes. If you already have access to an MLflow AI Gateway endpoint of type <code>llm/v1/completions</code>
or <code>llm/v1/chat</code>, you can skip this step.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">mlflow gateway start --config-path config.yaml </span><span class="token parameter variable" style="color:#36acaa">--port</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">7000</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-2-connect-the-mlflow-ai-gateway-to-your-mlflow-tracking-server">Step 2: Connect the MLflow AI Gateway to your MLflow Tracking Server<a href="#step-2-connect-the-mlflow-ai-gateway-to-your-mlflow-tracking-server" class="hash-link" aria-label="Direct link to Step 2: Connect the MLflow AI Gateway to your MLflow Tracking Server" title="Direct link to Step 2: Connect the MLflow AI Gateway to your MLflow Tracking Server">​</a></h3>
<p>The prompt engineering UI also requires a connection between the MLflow AI Gateway and the MLflow
Tracking Server. To connect the MLflow AI Gateway with the MLflow Tracking Server, simply set the
<code>MLFLOW_DEPLOYMENTS_TARGET</code> environment variable in the environment where the server is running and
restart the server. For example, if the MLflow AI Gateway is running at <code>http://localhost:7000</code>, you
can start an MLflow Tracking Server in a shell on your local machine and connect it to the
MLflow AI Gateway using the <a href="/docs/latest/api_reference/cli.html" target="_blank">mlflow server</a> command as follows:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">export</span><span class="token plain"> </span><span class="token assign-left variable" style="color:#36acaa">MLFLOW_DEPLOYMENTS_TARGET</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;http://127.0.0.1:7000&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mlflow server </span><span class="token parameter variable" style="color:#36acaa">--port</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">5000</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-3-create-or-find-an-mlflow-experiment">Step 3: Create or find an MLflow Experiment<a href="#step-3-create-or-find-an-mlflow-experiment" class="hash-link" aria-label="Direct link to Step 3: Create or find an MLflow Experiment" title="Direct link to Step 3: Create or find an MLflow Experiment">​</a></h3>
<p>Next, open an existing MLflow Experiment in the MLflow UI, or create a new experiment.</p>
<div class="center-div" style="max-width:650px;width:100%"><p><img decoding="async" loading="lazy" src="/docs/latest/assets/images/experiment_page-2a7cf0b96047619eac6845f09e01807d.png" width="2592" height="1972" class="img_ev3q"></p></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-4-create-a-run-with-prompt-engineering">Step 4: Create a run with prompt engineering<a href="#step-4-create-a-run-with-prompt-engineering" class="hash-link" aria-label="Direct link to Step 4: Create a run with prompt engineering" title="Direct link to Step 4: Create a run with prompt engineering">​</a></h3>
<p>Once you have opened the Experiment, click the <strong>New Run</strong> button and select
<em>using Prompt Engineering</em>. This will open the prompt engineering playground where you can try
out different LLMs, parameters, and prompts.</p>
<div style="display:flex;align-items:center;justify-content:center"><div style="width:25%"><img decoding="async" loading="lazy" src="/docs/latest/assets/images/new_run-2879a8f2ac95f77cfe3173cb320967c9.png" width="1190" height="556" class="img_ev3q"></div><div style="width:70%"><img decoding="async" loading="lazy" src="/docs/latest/assets/images/prompt_modal_1-51ecbda29dcb90d4b7ed59a996470b87.png" width="2404" height="1792" class="img_ev3q"></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-5-select-your-endpoint-and-evaluate-the-example-prompt">Step 5: Select your endpoint and evaluate the example prompt<a href="#step-5-select-your-endpoint-and-evaluate-the-example-prompt" class="hash-link" aria-label="Direct link to Step 5: Select your endpoint and evaluate the example prompt" title="Direct link to Step 5: Select your endpoint and evaluate the example prompt">​</a></h3>
<p>Next, click the <em>Select endpoint</em> dropdown and select the MLflow AI Gateway completions endpoint you created in
Step 1. Then, click the <strong>Evaluate</strong> button to test out an example prompt engineering use case
for generating product advertisements.</p>
<p>MLflow will embed the specified <em>stock_type</em> input
variable value - <code>&quot;books&quot;</code> - into the specified <em>prompt template</em> and send it to the LLM
associated with the MLflow AI Gateway endpoint with the configured <em>temperature</em> (currently <code>0.01</code>)
and <em>max_tokens</em> (currently 1000). The LLM response will appear in the <em>Output</em> section.</p>
<p><img decoding="async" loading="lazy" src="/docs/latest/assets/images/prompt_modal_2-449c061f1e6104c039029c4820d7142a.png" width="4126" height="2266" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-6-try-a-prompt-of-your-choosing">Step 6: Try a prompt of your choosing<a href="#step-6-try-a-prompt-of-your-choosing" class="hash-link" aria-label="Direct link to Step 6: Try a prompt of your choosing" title="Direct link to Step 6: Try a prompt of your choosing">​</a></h3>
<p>Replace the prompt template from the previous step with a prompt template of your choosing.
Prompts can define multiple variables. For example, you can use the following prompt template
to instruct the LLM to answer questions about the MLflow documentation:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Read the following article from the MLflow documentation that appears between triple</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">backticks. Then, answer the question about the documentation that appears between triple quotes.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Include relevant links and code examples in your answer.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```{{article}}```</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{{question}}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;&quot;&quot;</span><br></span></code></pre></div></div>
<p>Then, fill in the input variables. For example, in the MLflow documentation
use case, the <em>article</em> input variable can be set to the contents of
<a href="https://mlflow.org/docs/latest/tracking.html#logging-data-to-runs" target="_blank" rel="noopener noreferrer">https://mlflow.org/docs/latest/tracking.html#logging-data-to-runs</a> and the <em>question</em> input variable
can be set to <code>&quot;How do I create a new MLflow Run using the Python API?&quot;</code>.</p>
<p>Finally, click the <strong>Evaluate</strong> button to see the new output. You can also try choosing a larger
value of <em>temperature</em> to observe how the LLM&#x27;s output changes.</p>
<div class="center-div" style="max-width:820px;width:100%"><p><img decoding="async" loading="lazy" src="/docs/latest/assets/images/prompt_modal_3-78c14b824dfceb50dfac7ef02ed4ccd0.png" width="2360" height="1732" class="img_ev3q"></p></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-7-capture-your-choice-of-llm-prompt-template-and-parameters-as-an-mlflow-run">Step 7: Capture your choice of LLM, prompt template, and parameters as an MLflow Run<a href="#step-7-capture-your-choice-of-llm-prompt-template-and-parameters-as-an-mlflow-run" class="hash-link" aria-label="Direct link to Step 7: Capture your choice of LLM, prompt template, and parameters as an MLflow Run" title="Direct link to Step 7: Capture your choice of LLM, prompt template, and parameters as an MLflow Run">​</a></h3>
<p>Once you&#x27;re satisfied with your chosen prompt template and parameters, click the <strong>Create Run</strong>
button to store this information, along with your choice of LLM, as an MLflow Run. This will
create a new Run with the prompt template, parameters, and choice of LLM stored as Run params.
It will also automatically create an MLflow Model with this information that can be used for batch
or real-time inference.</p>
<ol>
<li>
<p>To view this information, click the Run name to open the <strong>Run</strong> page:</p>
<div class="center-div" style="max-width:750px;width:100%"><p><img decoding="async" loading="lazy" src="/docs/latest/assets/images/prompt_eng_run_page-14d417e3ec68786b5d118ce95b8979e1.png" width="3014" height="1990" class="img_ev3q"></p></div>
</li>
<li>
<p>You can also see the parameters and compare them with other configurations by opening the <strong>Table</strong>
view tab:</p>
<div class="center-div" style="max-width:750px;width:100%"><p><img decoding="async" loading="lazy" src="/docs/latest/assets/images/prompt_eng_table_view-71af8b8369dddf64ff8a00327489d80f.png" width="2892" height="852" class="img_ev3q"></p></div>
</li>
<li>
<p>After your Run is created, MLflow will open the <strong>Evaluation</strong> tab where you can see your latest
playground input &amp; output and try out additional inputs:</p>
<div class="center-div" style="max-width:750px;width:100%"><p><img decoding="async" loading="lazy" src="/docs/latest/assets/images/eval_view_1-2fd57ddf3134c1c646a91d382010ff72.png" width="2898" height="1468" class="img_ev3q"></p></div>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-8-try-new-inputs">Step 8: Try new inputs<a href="#step-8-try-new-inputs" class="hash-link" aria-label="Direct link to Step 8: Try new inputs" title="Direct link to Step 8: Try new inputs">​</a></h3>
<p>To test the behavior of your chosen LLM, prompt template, and parameters on a new inputs:</p>
<ol>
<li>Click the <em>Add Row</em> button and fill in a value(s) your prompt template&#x27;s input variable(s).
For example, in the MLflow documentation use case, you can try asking a question
unrelated to MLflow to see how the LLM responds. This is important to ensure that the application
is robust to irrelevant inputs.</li>
</ol>
<div style="display:flex;align-items:center;justify-content:center"><div style="width:10%"><img decoding="async" loading="lazy" src="/docs/latest/assets/images/add_row-c9216bca634ec1383758a84c35d17101.png" width="438" height="128" class="img_ev3q"></div><div style="width:50%"><img decoding="async" loading="lazy" src="/docs/latest/assets/images/add_row_modal-bf5df9f1c08b8e62c70909dbb4263ea2.png" width="1264" height="990" class="img_ev3q"></div></div>
<ol start="2">
<li>
<p>Then, click the <strong>Evaluate</strong> button to see the output.</p>
<div class="center-div" style="max-width:650px;width:100%"><p><img decoding="async" loading="lazy" src="/docs/latest/assets/images/evaluate_new_input-0ef075da2f4cfc8a430d76119686c836.png" width="1636" height="1206" class="img_ev3q"></p></div>
</li>
<li>
<p>Finally, click the <strong>Save</strong> button to store the new inputs and output.</p>
<div class="center-div" style="max-width:650px;width:100%"><p><img decoding="async" loading="lazy" src="/docs/latest/assets/images/save_new_input-3735297c289381cea11cb1ee60a3dd4f.png" width="1636" height="1208" class="img_ev3q"></p></div>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-9-adjust-your-prompt-template-and-create-a-new-run">Step 9: Adjust your prompt template and create a new Run<a href="#step-9-adjust-your-prompt-template-and-create-a-new-run" class="hash-link" aria-label="Direct link to Step 9: Adjust your prompt template and create a new Run" title="Direct link to Step 9: Adjust your prompt template and create a new Run">​</a></h3>
<p>As you try additional inputs, you might discover scenarios where your choice of LLM, prompt
template, and parameters doesn&#x27;t perform as well as you would like. For example, in the
MLflow documentation use case, the LLM still attempts to answer irrelevant
questions about <a href="/docs/latest/ml/projects">MLflow Projects</a> even if the answer does not appear in the
specified article.</p>
<ol>
<li>
<p>To improve performance, create a new Run by selecting the <em>Duplicate run</em> option from the context
menu. For example, in the MLflow documentation use case, adding the following text to
the prompt template helps improve robustness to irrelevant questions:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">If the question does not relate to the article, respond exactly with the phrase</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;I do not know how to answer that question.&quot; Do not include any additional text in your</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">response.</span><br></span></code></pre></div></div>
<div class="center-div" style="max-width:500px;width:100%"><p><img decoding="async" loading="lazy" src="/docs/latest/assets/images/duplicate_run-71f18e13acc59fb8bc860b27f2c24529.png" width="1096" height="974" class="img_ev3q"></p></div>
</li>
<li>
<p>Then, from the prompt engineering playground, adjust the prompt template (and / or choice of
LLM and parameters), evaluate an input, and click the <strong>Create Run</strong> button to create a new Run.</p>
<p><img decoding="async" loading="lazy" src="/docs/latest/assets/images/prompt_modal_4-9bcc677fe20c9bb937a25ac48e43e89e.png" width="2376" height="1754" class="img_ev3q"></p>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-10-evaluate-the-new-prompt-template-on-previous-inputs">Step 10: Evaluate the new prompt template on previous inputs<a href="#step-10-evaluate-the-new-prompt-template-on-previous-inputs" class="hash-link" aria-label="Direct link to Step 10: Evaluate the new prompt template on previous inputs" title="Direct link to Step 10: Evaluate the new prompt template on previous inputs">​</a></h3>
<p>Now that you&#x27;ve made an adjustment to your prompt template, it&#x27;s important to make sure that
the new template performs well on the previous inputs and compare the outputs with older
configurations.</p>
<ol>
<li>
<p>From the <strong>Evaluation</strong> tab, click the <strong>Evaluate all</strong> button next to the new Run to evaluate
all of the previous inputs.</p>
<div class="center-div" style="max-width:300px;width:100%"><p><img decoding="async" loading="lazy" src="/docs/latest/assets/images/evaluate_all-6b9191a0abf9c0fe077631376c5142e1.png" width="726" height="996" class="img_ev3q"></p></div>
</li>
<li>
<p>Click the <strong>Save</strong> button to store the results.</p>
<p><img decoding="async" loading="lazy" src="/docs/latest/assets/images/evaluate_all_results-7232f268e5e9453ae3fb20cae9009bcf.png" width="2336" height="1204" class="img_ev3q"></p>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-11-load-evaluation-data-programmatically">Step 11: Load evaluation data programmatically<a href="#step-11-load-evaluation-data-programmatically" class="hash-link" aria-label="Direct link to Step 11: Load evaluation data programmatically" title="Direct link to Step 11: Load evaluation data programmatically">​</a></h3>
<p>All of the inputs and outputs produced by the MLflow prompt engineering UI and Evaluation UI are stored
as artifacts in MLflow Runs. They can be accessed programmatically using the <a href="/docs/latest/api_reference/python_api/mlflow.html#mlflow.load_table" target="_blank"><code>mlflow.load_table<!-- -->()</code></a> API
as follows:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">set_experiment</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;/Path/to/your/prompt/engineering/experiment&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Load input and output data across all Runs (configurations) as a Pandas DataFrame</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">inputs_outputs_pdf </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load_table</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># All inputs and outputs created from the MLflow UI are stored in an artifact called</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># &quot;eval_results_table.json&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    artifact_file</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;eval_results_table.json&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Include the run ID as a column in the table to distinguish inputs and outputs</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># produced by different runs</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    extra_columns</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;run_id&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Optionally convert the Pandas DataFrame to Spark where it can be stored as a Delta</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># table or joined with existing Delta tables</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">inputs_outputs_sdf </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> spark</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">createDataFrame</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">inputs_outputs_pdf</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="quickstart-score">Step 12: Generate predictions programmatically<a href="#quickstart-score" class="hash-link" aria-label="Direct link to Step 12: Generate predictions programmatically" title="Direct link to Step 12: Generate predictions programmatically">​</a></h3>
<p>Once you have found a configuration of LLM, prompt template, and parameters that performs well, you
can generate predictions using the corresponding MLflow Model in a Python environment of your choosing,
or you can <a href="#deploy-prompt-serving">deploy it for real-time serving</a>.</p>
<ol>
<li>
<p>To load the MLflow Model in a notebook for batch inference, click on the Run&#x27;s name to open the
<strong>Run Page</strong> and select the <em>model</em> directory in the <strong>Artifact Viewer</strong>. Then, copy the first
few lines of code from the <em>Predict on a Pandas DataFrame</em> section and run them in a Python
environment of your choosing, for example:</p>
<p><img decoding="async" loading="lazy" src="/docs/latest/assets/images/load_model-ab1fe012845f6f7cd5843d91ce3af1b7.png" width="3004" height="1388" class="img_ev3q"></p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">logged_model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;runs:/8451075c46964f82b85fe16c3d2b7ea0/model&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Load model as a PyFuncModel.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">loaded_model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pyfunc</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">logged_model</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
</li>
<li>
<p>Then, to generate predictions, call the <a href="/docs/latest/api_reference/python_api/mlflow.pyfunc.html#mlflow.pyfunc.PyFuncModel.predict" target="_blank"><code>predict()</code></a> method
and pass in a dictionary of input variables. For example:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">article_text </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">An MLflow Project is a format for packaging data science code in a reusable and reproducible way.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">The MLflow Projects component includes an API and command-line tools for running projects, which</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">also integrate with the Tracking component to automatically record the parameters and git commit</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">of your source code for reproducibility.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="display:inline-block;color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">This article describes the format of an MLflow Project and how to run an MLflow project remotely</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">using the MLflow CLI, which makes it easy to vertically scale your data science code.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">question </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;What is an MLflow project?&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">loaded_model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">{</span><span class="token string" style="color:#e3116c">&quot;article&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> article_text</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;question&quot;</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> question</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<p>For more information about deployment for real-time serving with MLflow,
see the <a href="#deploy-prompt-serving">instructions below</a>.</p>
</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-prompt-serving">Deployment for real-time serving<a href="#deploy-prompt-serving" class="hash-link" aria-label="Direct link to Deployment for real-time serving" title="Direct link to Deployment for real-time serving">​</a></h2>
<p>Once you have found a configuration of LLM, prompt template, and parameters that performs well, you
can deploy the corresponding MLflow Model for real-time serving as follows:</p>
<ol>
<li>
<p>Register your model with the MLflow Model Registry. The following example registers
an MLflow Model created from the <a href="#quickstart-score">Quickstart</a> as Version 1 of the
Registered Model named <code>&quot;mlflow_docs_qa_model&quot;</code>.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">mlflow</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">register_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_uri</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;runs:/8451075c46964f82b85fe16c3d2b7ea0/model&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    name</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;mlflow_docs_qa_model&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
</li>
<li>
<p>Define the following environment variables in the environment where you will run your
MLflow Model Server, such as a shell on your local machine:</p>
<ul>
<li><code>MLFLOW_DEPLOYMENTS_TARGET</code>: The URL of the MLflow AI Gateway</li>
</ul>
</li>
<li>
<p>Use the <a href="/docs/latest/api_reference/cli.html" target="_blank">mlflow models serve</a> command to start the MLflow Model Server. For example,
running the following command from a shell on your local machine will serve the model
on port 8000:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">mlflow models serve --model-uri models:/mlflow_docs_qa_model/1 </span><span class="token parameter variable" style="color:#36acaa">--port</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">8000</span><br></span></code></pre></div></div>
</li>
<li>
<p>Once the server has been started, it can be queried via REST API call. For example:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token assign-left variable" style="color:#36acaa">input</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    &quot;dataframe_records&quot;: [</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">            &quot;article&quot;: &quot;An MLflow Project is a format for packaging data science code...&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">            &quot;question&quot;: &quot;What is an MLflow Project?&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">}&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token builtin class-name">echo</span><span class="token plain"> </span><span class="token variable" style="color:#36acaa">$input</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">curl</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-s</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-X</span><span class="token plain"> POST </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  https://localhost:8000/invocations</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-H</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;Content-Type: application/json&#x27;</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token parameter variable" style="color:#36acaa">-d</span><span class="token plain"> @-</span><br></span></code></pre></div></div>
<p>where <code>article</code> and <code>question</code> are replaced with the input variable(s) from your
prompt template.</p>
</li>
</ol></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/latest/genai/prompt-version-mgmt/prompt-registry/use-prompts-in-deployed-apps"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Use Prompts in Deployed Apps</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/latest/genai/serving/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">MLflow Model Serving</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#prompt-engineering-quickstart" class="table-of-contents__link toc-highlight">Quickstart</a><ul><li><a href="#step-1-create-an-mlflow-ai-gateway-completions-or-chat-endpoint" class="table-of-contents__link toc-highlight">Step 1: Create an MLflow AI Gateway Completions or Chat Endpoint</a></li><li><a href="#step-2-connect-the-mlflow-ai-gateway-to-your-mlflow-tracking-server" class="table-of-contents__link toc-highlight">Step 2: Connect the MLflow AI Gateway to your MLflow Tracking Server</a></li><li><a href="#step-3-create-or-find-an-mlflow-experiment" class="table-of-contents__link toc-highlight">Step 3: Create or find an MLflow Experiment</a></li><li><a href="#step-4-create-a-run-with-prompt-engineering" class="table-of-contents__link toc-highlight">Step 4: Create a run with prompt engineering</a></li><li><a href="#step-5-select-your-endpoint-and-evaluate-the-example-prompt" class="table-of-contents__link toc-highlight">Step 5: Select your endpoint and evaluate the example prompt</a></li><li><a href="#step-6-try-a-prompt-of-your-choosing" class="table-of-contents__link toc-highlight">Step 6: Try a prompt of your choosing</a></li><li><a href="#step-7-capture-your-choice-of-llm-prompt-template-and-parameters-as-an-mlflow-run" class="table-of-contents__link toc-highlight">Step 7: Capture your choice of LLM, prompt template, and parameters as an MLflow Run</a></li><li><a href="#step-8-try-new-inputs" class="table-of-contents__link toc-highlight">Step 8: Try new inputs</a></li><li><a href="#step-9-adjust-your-prompt-template-and-create-a-new-run" class="table-of-contents__link toc-highlight">Step 9: Adjust your prompt template and create a new Run</a></li><li><a href="#step-10-evaluate-the-new-prompt-template-on-previous-inputs" class="table-of-contents__link toc-highlight">Step 10: Evaluate the new prompt template on previous inputs</a></li><li><a href="#step-11-load-evaluation-data-programmatically" class="table-of-contents__link toc-highlight">Step 11: Load evaluation data programmatically</a></li><li><a href="#quickstart-score" class="table-of-contents__link toc-highlight">Step 12: Generate predictions programmatically</a></li></ul></li><li><a href="#deploy-prompt-serving" class="table-of-contents__link toc-highlight">Deployment for real-time serving</a></li></ul></div></div></div></div></main></div></div></div><footer class="pb-150 flex flex-col pt-37 bg-linear-to-b from-brand-black to-brand-black bg-bottom bg-no-repeat bg-cover w-full bg-(--background-color-dark) bg-size-[100%_340px]" style="background-image:url(/docs/latest/assets/images/footer-red-bg-ec5ecbbbbb62b125aa76b2c5c2af7ab3.png)"><div class="flex flex-row justify-between items-start md:items-center px-6 lg:px-20 gap-10 xs:gap-0 max-w-container"><svg xmlns="http://www.w3.org/2000/svg" width="109" height="40" fill="none" viewBox="0 0 109 40" class="h-[36px] shrink-0"><path fill="#fff" d="M0 31.032v-15.53h3.543v1.968c.893-1.594 2.84-2.425 4.593-2.425 2.042 0 3.828.926 4.658 2.745 1.216-2.043 3.034-2.745 5.043-2.745 2.81 0 5.49 1.787 5.49 5.904v10.083h-3.574v-9.478c0-1.818-.926-3.19-3-3.19-1.947 0-3.224 1.53-3.224 3.445v9.22H9.893v-9.475c0-1.786-.898-3.18-3.003-3.18-1.977 0-3.223 1.467-3.223 3.444v9.221ZM27.855 31.032V7.929h3.703v23.103ZM30.07 39.487c.833.232 1.582.383 3.17.383 2.953 0 6.436-1.665 7.353-6.339l3.786-18.739h5.629l.687-3.117h-5.686l.765-3.725c.586-2.892 2.186-4.358 4.754-4.358.668 0 .48.058 1.076.17L52.427.57c-.793-.237-1.503-.379-3.049-.379a7.32 7.32 0 0 0-4.528 1.484c-1.441 1.114-2.393 2.75-2.827 4.863l-1.066 5.137h-5.034l-.411 3.12h4.823L36.859 32.12c-.383 1.965-1.5 4.315-4.708 4.315-.727 0-.463-.055-1.121-.162ZM53.342 30.905H49.64l5.074-23.309h3.701ZM71.807 16.477A7.962 7.962 0 0 0 60.97 27.904l2.425-1.78a5.005 5.005 0 0 1 3.845-8.145v1.895ZM62.618 29.472a7.962 7.962 0 0 0 10.836-11.428l-2.425 1.78a5.005 5.005 0 0 1-3.845 8.145v-1.894ZM78.092 15.493h4.044l.823 10.612 5.759-10.612 3.839.055 1.508 10.557 5.074-10.612 3.701.055-7.678 15.493H91.46l-1.783-11.106-5.895 11.106h-3.84ZM105.072 15.768h-.766v-.266h1.845v.272h-.765v2.243h-.314ZM106.614 15.502h.383l.482 1.34q.091.259.178.524h.018c.059-.176.113-.352.172-.524l.478-1.34h.383v2.515h-.298V16.63c0-.22.024-.523.04-.747h-.016l-.191.574-.475 1.304h-.208l-.481-1.302-.191-.574h-.015c.017.224.042.527.042.747v1.387h-.291Z"></path></svg><div class="flex flex-col md:flex-row gap-10"><div class="min-w-[120px]"><a href="https://mllfow.org" target="_blank" rel="noopener noreferrer" class="link_LVIP">Product</a></div><div class="min-w-[120px]"><a href="https://mlflow.org/releases" target="_blank" rel="noopener noreferrer" class="link_LVIP">Releases</a></div><div class="min-w-[120px]"><a href="https://mlflow.org/blog" target="_blank" rel="noopener noreferrer" class="link_LVIP">Blog</a></div><div class="min-w-[120px]"><a class="link_LVIP" href="/docs/latest/">Docs</a></div></div></div></footer></div>
</body>
</html>