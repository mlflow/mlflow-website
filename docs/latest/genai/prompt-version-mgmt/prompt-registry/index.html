<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-genai docs-version-current docs-doc-page docs-doc-id-prompt-version-mgmt/prompt-registry/index" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">Prompt Registry | MLflow</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://mlflow.org/docs/latest/genai/prompt-version-mgmt/prompt-registry/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-genai-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-genai-current"><meta data-rh="true" property="og:title" content="Prompt Registry | MLflow"><meta data-rh="true" name="description" content="MLflow Prompt Registry"><meta data-rh="true" property="og:description" content="MLflow Prompt Registry"><link data-rh="true" rel="icon" href="/docs/latest/images/favicon.ico"><link data-rh="true" rel="canonical" href="https://mlflow.org/docs/latest/genai/prompt-version-mgmt/prompt-registry/"><link data-rh="true" rel="alternate" href="https://mlflow.org/docs/latest/genai/prompt-version-mgmt/prompt-registry/" hreflang="en"><link data-rh="true" rel="alternate" href="https://mlflow.org/docs/latest/genai/prompt-version-mgmt/prompt-registry/" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://XKVLO8P882-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Prompt Registry","item":"https://mlflow.org/docs/latest/genai/prompt-version-mgmt/prompt-registry/"}]}</script><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=GTM-N6WMTTJ"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","GTM-N6WMTTJ",{anonymize_ip:!0}),gtag("config","AW-16857946923",{anonymize_ip:!0})</script>
<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var g=t.getElementsByTagName(a)[0],m=t.createElement(a);m.async=!0,m.src="https://www.googletagmanager.com/gtm.js?id=GTM-N6WMTTJ",g.parentNode.insertBefore(m,g)}(window,document,"script","dataLayer")</script>



<link rel="search" type="application/opensearchdescription+xml" title="MLflow" href="/docs/latest/opensearch.xml">





<script src="/docs/latest/js/runllm.js" defer="defer"></script><link rel="stylesheet" href="/docs/latest/assets/css/styles.9ba9597f.css">
<script src="/docs/latest/assets/js/runtime~main.42f41136.js" defer="defer"></script>
<script src="/docs/latest/assets/js/main.8fe65c16.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>


<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/docs/latest/"><div class="navbar__logo"><img src="/docs/latest/images/logo-light.svg" alt="MLflow Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/docs/latest/images/logo-dark.svg" alt="MLflow Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Documentation</a><ul class="dropdown__menu"><li><a class="dropdown__link ml-docs-link" href="/docs/latest/ml/">ML Docs</a></li><li><a aria-current="page" class="dropdown__link genai-docs-link dropdown__link--active" href="/docs/latest/genai/">GenAI Docs</a></li></ul></div><a href="https://mlflow.org/docs/latest/api_reference/index.html" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">API Reference</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/mlflow/mlflow" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link github-link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sidebar-top-level-category"><a class="menu__link" href="/docs/latest/genai/">MLflow for GenAI</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/mlflow-3/">MLflow 3.0</a><button aria-label="Expand sidebar category &#x27;MLflow 3.0&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/overview/">Overview 🌟</a><button aria-label="Collapse sidebar category &#x27;Overview 🌟&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/genai/overview/key-challenges">Key Challenges</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/genai/overview/why-mlflow">Why use MLflow</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/developer-workflow/">Developer Workflow 👉</a><button aria-label="Expand sidebar category &#x27;Developer Workflow 👉&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/getting-started/">Getting Started 🚀</a><button aria-label="Expand sidebar category &#x27;Getting Started 🚀&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/tracing/">Tracing (Observability) 🔎</a><button aria-label="Expand sidebar category &#x27;Tracing (Observability) 🔎&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/eval-monitor/">Evaluate &amp; Monitor 📊</a><button aria-label="Expand sidebar category &#x27;Evaluate &amp; Monitor 📊&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/latest/genai/prompt-version-mgmt/version-tracking/">Prompt and Version Management 🔨</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/latest/genai/prompt-version-mgmt/version-tracking/">Version Tracking</a><button aria-label="Expand sidebar category &#x27;Version Tracking&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible menu__list-item-collapsible--active"><a class="menu__link menu__link--sublist menu__link--active" aria-current="page" tabindex="0" href="/docs/latest/genai/prompt-version-mgmt/prompt-registry/">Prompt Registry</a><button aria-label="Collapse sidebar category &#x27;Prompt Registry&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/genai/prompt-version-mgmt/prompt-registry/create-and-edit-prompts">Create and Edit Prompts</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/genai/prompt-version-mgmt/prompt-registry/evaluate-prompts">Evaluate Prompts</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/genai/prompt-version-mgmt/prompt-registry/manage-prompt-lifecycles-with-aliases">Manage Prompt Lifecycles with Aliases</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/genai/prompt-version-mgmt/prompt-registry/optimize-prompts">Optimize Prompts 🆕</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/genai/prompt-version-mgmt/prompt-registry/use-prompts-in-apps">Use Prompts in Apps</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/genai/prompt-version-mgmt/prompt-registry/log-with-model">Log Prompts with Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/genai/prompt-version-mgmt/prompt-registry/use-prompts-in-deployed-apps">Use Prompts in Deployed Apps</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/latest/genai/prompt-version-mgmt/prompt-engineering/">Prompt Engineering UI</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/serving/">Application Serving ⛵</a><button aria-label="Expand sidebar category &#x27;Application Serving ⛵&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/governance/ai-gateway/">Governance 🛡️</a><button aria-label="Expand sidebar category &#x27;Governance 🛡️&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed sidebar-top-level-category"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/latest/genai/data-model/">Data Model 🧩</a><button aria-label="Expand sidebar category &#x27;Data Model 🧩&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/docs/latest/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Prompt and Version Management 🔨</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Prompt Registry</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Prompt Registry in Databricks</h1></header>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-mlflow-prompt-registry">What is MLflow Prompt Registry?<a href="#what-is-mlflow-prompt-registry" class="hash-link" aria-label="Direct link to What is MLflow Prompt Registry?" title="Direct link to What is MLflow Prompt Registry?">​</a></h2>
<p><strong>MLflow Prompt Registry</strong> is a powerful tool that streamlines prompt engineering and management in your Generative AI (GenAI) applications. It enables you to version, track, and reuse prompts across your organization, helping maintain consistency and improving collaboration in prompt development.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Key Features</div><div class="admonitionContent_BuS1"><ul>
<li><strong>Reusability</strong> - Store and manage prompts in a centralized registry and reuse them across multiple applications.</li>
<li><strong>Version Control</strong> - Track the evolution of your prompts with Git-inspired commit-based versioning and side-by-side comparison of prompt versions with diff highlighting.</li>
<li><strong>Aliasing</strong> - Build robust yet flexible deployment pipelines for prompts using aliases, allowing you to isolate prompt versions from main application code and perform tasks such as A/B testing and roll-backs with ease.</li>
<li><strong>Lineage</strong> - Seamlessly integrate with MLflow&#x27;s existing features such as model tracking and evaluation for end-to-end GenAI lifecycle management.</li>
<li><strong>Collaboration</strong> - Share prompts across your organization with a centralized registry, enabling teams to build upon each other&#x27;s work.</li>
</ul></div></div>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>The MLflow Prompt Registry integration with Databricks Unity Catalog is coming soon.</p></div></div>
<p>It will be a centralized system for managing, versioning, and governing prompt templates used in your GenAI applications. It will be deeply integrated with Databricks Unity Catalog, providing:</p>
<ul>
<li><strong>Centralized Prompt Management</strong>: Store and organize prompt templates in a governed, searchable registry</li>
<li><strong>Version Control</strong>: Track changes to prompts over time with full lineage and rollback capabilities</li>
<li><strong>Access Control</strong>: Leverage Unity Catalog&#x27;s permissions system to control who can view, edit, and use specific prompts</li>
<li><strong>Collaboration</strong>: Enable teams to share and collaborate on prompt development</li>
<li><strong>Governance</strong>: Apply data governance policies to prompt templates, including classification and compliance requirements</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="integration-with-unity-catalog">Integration with Unity Catalog<a href="#integration-with-unity-catalog" class="hash-link" aria-label="Direct link to Integration with Unity Catalog" title="Direct link to Integration with Unity Catalog">​</a></h2>
<p>The Prompt Registry will leverage Unity Catalog&#x27;s governance framework to provide:</p>
<ul>
<li><strong>Fine-grained Access Control</strong>: Control access to prompts at the individual, team, or organization level</li>
<li><strong>Data Lineage</strong>: Track how prompts are used across different applications and experiments</li>
<li><strong>Audit Trails</strong>: Monitor who accessed or modified prompts and when</li>
<li><strong>Classification and Tagging</strong>: Organize prompts with metadata and apply governance policies</li>
<li><strong>Cross-workspace Sharing</strong>: Share prompts securely across different Databricks workspaces</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="future-capabilities">Future Capabilities<a href="#future-capabilities" class="hash-link" aria-label="Direct link to Future Capabilities" title="Direct link to Future Capabilities">​</a></h2>
<p>When available, the Prompt Registry will support:</p>
<ul>
<li><strong>Template Management</strong>: Create, edit, and version prompt templates with variable substitution</li>
<li><strong>Testing and Validation</strong>: Test prompts against evaluation datasets before deployment</li>
<li><strong>A/B Testing</strong>: Compare different prompt versions to optimize performance</li>
<li><strong>Integration with MLflow Tracking</strong>: Automatically link prompt versions to experiments and model runs</li>
<li><strong>API Access</strong>: Programmatic access to prompts for use in automated workflows</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="stay-updated">Stay Updated<a href="#stay-updated" class="hash-link" aria-label="Direct link to Stay Updated" title="Direct link to Stay Updated">​</a></h2>
<p>For the latest updates on Prompt Registry availability and features, monitor the MLflow documentation and Databricks release notes.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-registry-in-oss-mlflow">Prompt Registry in OSS MLflow<a href="#prompt-registry-in-oss-mlflow" class="hash-link" aria-label="Direct link to Prompt Registry in OSS MLflow" title="Direct link to Prompt Registry in OSS MLflow">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-create-a-prompt">1. Create a Prompt<a href="#1-create-a-prompt" class="hash-link" aria-label="Direct link to 1. Create a Prompt" title="Direct link to 1. Create a Prompt">​</a></h3>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">UI</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Python</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="flex-column"><div style="width:70%;margin:20px"><p><img decoding="async" loading="lazy" alt="Create Prompt UI" src="/docs/latest/assets/images/create-prompt-ui-03c88144e65d28eb7847b2ae5d8dd49a.png" width="1239" height="660" class="img_ev3q"></p></div><ol>
<li>Run <code>mlflow ui</code> in your terminal to start the MLflow UI.</li>
<li>Navigate to the <strong>Prompts</strong> tab in the MLflow UI.</li>
<li>Click on the <strong>Create Prompt</strong> button.</li>
<li>Fill in the prompt details such as name, prompt template text, and commit message (optional).</li>
<li>Click <strong>Create</strong> to register the prompt.</li>
</ol><div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>Prompt template text can contain variables in <code>{{variable}}</code> format. These variables can be filled with dynamic content when using the prompt in your GenAI application. MLflow also provides the <code>to_single_brace_format()</code> API to convert templates into single brace format for frameworks like LangChain or LlamaIndex that require single brace interpolation.</p></div></div></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="flex-column"><p>To create a new prompt using the Python API, use <a href="/docs/latest/api_reference/python_api/mlflow.html#mlflow.genai.register_prompt" target="_blank"><code>mlflow.genai.register_prompt<!-- -->()</code></a> API:</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Use double curly braces for variables in the template</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">initial_template </span><span class="token operator">=</span><span class="token plain"> </span><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">&quot;&quot;&quot;\</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">Summarize content you are provided with in {{ num_sentences }} sentences.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="display:inline-block;color:rgb(255, 121, 198)"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">Sentences: {{ sentences }}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">&quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Register a new prompt</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">prompt </span><span class="token operator">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">genai</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">register_prompt</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    name</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;summarization-prompt&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    template</span><span class="token operator">=</span><span class="token plain">initial_template</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># Optional: Provide a commit message to describe the changes</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    commit_message</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;Initial commit&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># Optional: Specify any additional metadata about the prompt version</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    version_metadata</span><span class="token operator">=</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;author&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;author@example.com&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token comment" style="color:rgb(98, 114, 164)"># Optional: Set tags applies to the prompt (across versions)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    tags</span><span class="token operator">=</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;task&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;summarization&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;language&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;en&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># The prompt object contains information about the registered prompt</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">print</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">f&quot;Created prompt &#x27;</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string-interpolation interpolation">prompt</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token string-interpolation interpolation">name</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">&#x27; (version </span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string-interpolation interpolation">prompt</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token string-interpolation interpolation">version</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">)&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre></div></div></div></div></div></div>
<p>This creates a new prompt with the specified template text and metadata. The prompt is now available in the MLflow UI for further management.</p>
<div style="width:90%;margin:10px"><p><img decoding="async" loading="lazy" alt="Registered Prompt in UI" src="/docs/latest/assets/images/registered-prompt-b8d47ff0d061d8703b61a9a6e94a77c3.png" width="1287" height="616" class="img_ev3q"></p></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-update-the-prompt-with-a-new-version">2. Update the Prompt with a New Version<a href="#2-update-the-prompt-with-a-new-version" class="hash-link" aria-label="Direct link to 2. Update the Prompt with a New Version" title="Direct link to 2. Update the Prompt with a New Version">​</a></h3>
<div class="tabs-container tabList__CuJ"><ul role="tablist" aria-orientation="horizontal" class="tabs"><li role="tab" tabindex="0" aria-selected="true" class="tabs__item tabItem_LNqP tabs__item--active">UI</li><li role="tab" tabindex="-1" aria-selected="false" class="tabs__item tabItem_LNqP">Python</li></ul><div class="margin-top--md"><div role="tabpanel" class="tabItem_Ymn6"><div class="flex-column"><div style="width:70%;margin:20px"><p><img decoding="async" loading="lazy" alt="Update Prompt UI" src="/docs/latest/assets/images/update-prompt-ui-74a489e65098893bbffe253f43fb210d.png" width="1150" height="594" class="img_ev3q"></p></div><ol>
<li>The previous step leads to the created prompt page. (If you closed the page, navigate to the <strong>Prompts</strong> tab in the MLflow UI and click on the prompt name.)</li>
<li>Click on the <strong>Create prompt Version</strong> button.</li>
<li>The popup dialog is pre-filled with the existing prompt text. Modify the prompt as you wish.</li>
<li>Click <strong>Create</strong> to register the new version.</li>
</ol></div></div><div role="tabpanel" class="tabItem_Ymn6" hidden=""><div class="flex-column"><p>To update an existing prompt with a new version, use the <a href="/docs/latest/api_reference/python_api/mlflow.html#mlflow.genai.register_prompt" target="_blank"><code>mlflow.genai.register_prompt<!-- -->()</code></a> API with the existing prompt name:</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">new_template </span><span class="token operator">=</span><span class="token plain"> </span><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">&quot;&quot;&quot;\</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">You are an expert summarizer. Condense the following content into exactly {{ num_sentences }} clear and informative sentences that capture the key points.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="display:inline-block;color:rgb(255, 121, 198)"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">Sentences: {{ sentences }}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="display:inline-block;color:rgb(255, 121, 198)"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">Your summary should:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">- Contain exactly {{ num_sentences }} sentences</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">- Include only the most important information</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">- Be written in a neutral, objective tone</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">- Maintain the same level of formality as the original text</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">&quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Register a new version of an existing prompt</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">updated_prompt </span><span class="token operator">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">genai</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">register_prompt</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    name</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;summarization-prompt&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># Specify the existing prompt name</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    template</span><span class="token operator">=</span><span class="token plain">new_template</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    commit_message</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;Improvement&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    version_metadata</span><span class="token operator">=</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;author&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;author@example.com&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre></div></div></div></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="3-compare-the-prompt-versions">3. Compare the Prompt Versions<a href="#3-compare-the-prompt-versions" class="hash-link" aria-label="Direct link to 3. Compare the Prompt Versions" title="Direct link to 3. Compare the Prompt Versions">​</a></h3>
<p>Once you have multiple versions of a prompt, you can compare them to understand the changes between versions. To compare prompt versions in the MLflow UI, click on the <strong>Compare</strong> tab in the prompt details page:</p>
<div style="width:90%;margin:10px"><p><img decoding="async" loading="lazy" alt="Compare Prompt
Versions" src="/docs/latest/assets/images/compare-prompt-versions-2082121aeaca4be99a0cf968535141ed.png" width="1267" height="713" class="img_ev3q"></p></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="4-load-and-use-the-prompt">4. Load and Use the Prompt<a href="#4-load-and-use-the-prompt" class="hash-link" aria-label="Direct link to 4. Load and Use the Prompt" title="Direct link to 4. Load and Use the Prompt">​</a></h3>
<p>To use a prompt in your GenAI application, you can load it with the <a href="/docs/latest/api_reference/python_api/mlflow.html#mlflow.genai.load_prompt" target="_blank"><code>mlflow.genai.load_prompt<!-- -->()</code></a> API and fill in the variables using the <a href="/docs/latest/api_reference/python_api/mlflow.entities.html#mlflow.entities.Prompt.format" target="_blank"><code>mlflow.entities.Prompt.format<!-- -->()</code></a> method of the prompt object:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> openai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">target_text </span><span class="token operator">=</span><span class="token plain"> </span><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">MLflow is an open source platform for managing the end-to-end machine learning lifecycle.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">It tackles four primary functions in the ML lifecycle: Tracking experiments, packaging ML</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">code for reuse, managing and deploying models, and providing a central model registry.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">MLflow currently offers these functions as four components: MLflow Tracking,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">MLflow Projects, MLflow Models, and MLflow Registry.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">&quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Load the prompt</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">prompt </span><span class="token operator">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">genai</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">load_prompt</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;prompts:/summarization-prompt/2&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Use the prompt with an LLM</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">client </span><span class="token operator">=</span><span class="token plain"> openai</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">OpenAI</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">response </span><span class="token operator">=</span><span class="token plain"> client</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">chat</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">completions</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">create</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    messages</span><span class="token operator">=</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;role&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;user&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;content&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> prompt</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token builtin" style="color:rgb(189, 147, 249)">format</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">num_sentences</span><span class="token operator">=</span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> sentences</span><span class="token operator">=</span><span class="token plain">target_text</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;gpt-4o-mini&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">print</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">response</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">choices</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">message</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">content</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="5-search-prompts">5. Search Prompts<a href="#5-search-prompts" class="hash-link" aria-label="Direct link to 5. Search Prompts" title="Direct link to 5. Search Prompts">​</a></h3>
<p>You can discover prompts by name, tag or other registry fields:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Fluent API: returns a flat list of all matching prompts</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">prompts </span><span class="token operator">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">genai</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">search_prompts</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">filter_string</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;task=&#x27;summarization&#x27;&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">print</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">f&quot;Found </span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string-interpolation interpolation builtin" style="color:rgb(189, 147, 249)">len</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string-interpolation interpolation">prompts</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)"> prompts&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># For pagination control, use the client API:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">tracking </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> MlflowClient</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">client </span><span class="token operator">=</span><span class="token plain"> MlflowClient</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">all_prompts </span><span class="token operator">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">token </span><span class="token operator">=</span><span class="token plain"> </span><span class="token boolean">None</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">while</span><span class="token plain"> </span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    page </span><span class="token operator">=</span><span class="token plain"> client</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">search_prompts</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        filter_string</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;task=&#x27;summarization&#x27;&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        max_results</span><span class="token operator">=</span><span class="token number">50</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        page_token</span><span class="token operator">=</span><span class="token plain">token</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    all_prompts</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">extend</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">page</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    token </span><span class="token operator">=</span><span class="token plain"> page</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">token</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">if</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">not</span><span class="token plain"> token</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">break</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">print</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">f&quot;Total prompts across pages: </span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string-interpolation interpolation builtin" style="color:rgb(189, 147, 249)">len</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string-interpolation interpolation">all_prompts</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="prompt-object">Prompt Object<a href="#prompt-object" class="hash-link" aria-label="Direct link to Prompt Object" title="Direct link to Prompt Object">​</a></h2>
<p>The <code>Prompt</code> object is the core entity in MLflow Prompt Registry. It represents a versioned template text that can contain variables for dynamic content.</p>
<p>Key attributes of a Prompt object:</p>
<ul>
<li><code>Name</code>: A unique identifier for the prompt.</li>
<li><code>Template</code>: The text of the prompt, which can include variables in <code>{{variable}}</code> format.</li>
<li><code>Version</code>: A sequential number representing the revision of the prompt.</li>
<li><code>Commit Message</code>: A description of the changes made in the prompt version, similar to Git commit messages.</li>
<li><code>Version Metadata</code>: Optional key-value pairs for adding metadata to the prompt version. For example, you may use this for tracking the author of the prompt version.</li>
<li><code>Tags</code>: Optional key-value pairs assigned at the prompt level (across versions)
for categorization and filtering. For example, you may add tags for project name, language, etc, which apply to all versions of the prompt.</li>
<li><code>Alias</code>: An mutable named reference to the prompt. For example, you can create an alias named <code>production</code> to refer to the version used in your production system. See <a href="/docs/latest/genai/data-model/prompts#alias-management">Aliases</a> for more details.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="log-prompts-with-models">Log Prompts with Models<a href="#log-prompts-with-models" class="hash-link" aria-label="Direct link to Log Prompts with Models" title="Direct link to Log Prompts with Models">​</a></h2>
<p>Prompts are often used as a part of GenAI applications. Managing the association between prompts and models is crucial for tracking the evolution of models and ensuring consistency across different environments. MLflow Prompt Registry is integrated with MLflow&#x27;s model tracking capability, allowing you to track which prompts (and versions) are used by your models and applications.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="basic-usage">Basic Usage<a href="#basic-usage" class="hash-link" aria-label="Direct link to Basic Usage" title="Direct link to Basic Usage">​</a></h3>
<p>To log a model with associated prompts, use the <code>prompts</code> parameter in the <code>log_model</code> method. The <code>prompts</code> parameter accepts a list of prompt URLs or prompt objects that are associated with the model. The associated prompts are displayed in the MLflow UI for the model run.</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import mlflow</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">with mlflow.start_run():</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    mlflow.&lt;flavor&gt;.log_model(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        model,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        ...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        # Specify a list of prompt URLs or prompt objects.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        prompts=[&quot;prompts:/summarization-prompt/2&quot;]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    )</span><br></span></code></pre></div></div>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>warning</div><div class="admonitionContent_BuS1"><p>The <code>prompts</code> parameter for associating prompts with models is only supported for GenAI flavors such as OpenAI, LangChain, LlamaIndex, DSPy, etc.</p></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="example-1-logging-prompts-with-langchain">Example 1: Logging Prompts with LangChain<a href="#example-1-logging-prompts-with-langchain" class="hash-link" aria-label="Direct link to Example 1: Logging Prompts with LangChain" title="Direct link to Example 1: Logging Prompts with LangChain">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-create-a-prompt-1">1. Create a prompt<a href="#1-create-a-prompt-1" class="hash-link" aria-label="Direct link to 1. Create a prompt" title="Direct link to 1. Create a prompt">​</a></h4>
<p>If you haven&#x27;t already created a prompt, follow <a href="#1-create-a-prompt">this step</a> to create a new prompt.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-define-a-chain-using-the-registered-prompts">2. Define a Chain using the registered prompts<a href="#2-define-a-chain-using-the-registered-prompts" class="hash-link" aria-label="Direct link to 2. Define a Chain using the registered prompts" title="Direct link to 2. Define a Chain using the registered prompts">​</a></h4>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> langchain_core</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">prompts </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> ChatPromptTemplate</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> langchain_openai </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> ChatOpenAI</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Load registered prompt</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">prompt </span><span class="token operator">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">genai</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">load_prompt</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;prompts:/summarization-prompt/2&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Create LangChain prompt object</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">langchain_prompt </span><span class="token operator">=</span><span class="token plain"> ChatPromptTemplate</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">from_messages</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token comment" style="color:rgb(98, 114, 164)"># IMPORTANT: Convert prompt template from double to single curly braces format</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;system&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            prompt</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">to_single_brace_format</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;placeholder&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;{messages}&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Define the LangChain chain</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">llm </span><span class="token operator">=</span><span class="token plain"> ChatOpenAI</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">chain </span><span class="token operator">=</span><span class="token plain"> langchain_prompt </span><span class="token operator">|</span><span class="token plain"> llm</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Invoke the chain</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">response </span><span class="token operator">=</span><span class="token plain"> chain</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">invoke</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;num_sentences&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;sentences&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;This is a test sentence.&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">print</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">response</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="3-log-the-chain-to-mlflow">3. Log the Chain to MLflow<a href="#3-log-the-chain-to-mlflow" class="hash-link" aria-label="Direct link to 3. Log the Chain to MLflow" title="Direct link to 3. Log the Chain to MLflow">​</a></h4>
<p>Then log the chain to MLflow and specify the prompt URL in the <code>prompts</code> parameter:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">with</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">start_run</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">run_name</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;summarizer-model&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">langchain</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">log_model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        chain</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> name</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;model&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> prompts</span><span class="token operator">=</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;prompts:/summarization-prompt/2&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre></div></div>
<p>Now you can view the associated prompts to the model in MLflow UI:</p>
<p><img decoding="async" loading="lazy" alt="Associated Prompts" src="/docs/latest/assets/images/prompt-logged-model-5db16e3e39f3bbd4ca3138c96dff045e.png" width="888" height="382" class="img_ev3q"></p>
<p>Moreover, you can view the list of models (runs) that use a specific prompt in the prompt details page:</p>
<p><img decoding="async" loading="lazy" alt="Associated Prompts" src="/docs/latest/assets/images/prompt-logged-model-links-b4c073f2c15e203ec34d7ef35c840112.png" width="3364" height="1244" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="example-2-automatic-prompt-logging-with-models-from-code">Example 2: Automatic Prompt Logging with Models-from-Code<a href="#example-2-automatic-prompt-logging-with-models-from-code" class="hash-link" aria-label="Direct link to Example 2: Automatic Prompt Logging with Models-from-Code" title="Direct link to Example 2: Automatic Prompt Logging with Models-from-Code">​</a></h3>
<p><a href="/docs/latest/ml/model/models-from-code">Models-from-Code</a> is a feature that allows you to define and log models in code.
Logging a model with code brings several benefits, such as portability, readability, avoiding serialization, and more.</p>
<p>Combining with MLflow Prompt Registry, the feature unlocks even more flexibility to manage prompt versions. Notably,
if your model code uses a prompt from MLflow Prompt Registry, MLflow <strong>automatically</strong> logs it with the model for you.</p>
<p>In the following example, we use LangGraph to define a very simple chat bot using the registered prompt.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-create-a-prompt-2">1. Create a prompt<a href="#1-create-a-prompt-2" class="hash-link" aria-label="Direct link to 1. Create a prompt" title="Direct link to 1. Create a prompt">​</a></h4>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">import mlflow</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Register a new prompt</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">prompt = mlflow.genai.register_prompt(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    name=&quot;chat-prompt&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    template=&quot;You are an expert in programming. Please answer the user&#x27;s question about programming.&quot;,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span></code></pre></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-define-a-graph-using-the-registered-prompt">2. Define a Graph using the registered prompt<a href="#2-define-a-graph-using-the-registered-prompt" class="hash-link" aria-label="Direct link to 2. Define a Graph using the registered prompt" title="Direct link to 2. Define a Graph using the registered prompt">​</a></h4>
<p>Create a Python script <code>chatbot.py</code> with the following content.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>If you are using Jupyter notebook, you can uncomment the <code>%writefile</code> magic
command and run the following code in a cell to generate the script.</p></div></div>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)"># %%writefile chatbot.py</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> typing </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> Annotated</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> typing_extensions </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> TypedDict</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> langchain_openai </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> ChatOpenAI</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> langgraph</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">graph </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> StateGraph</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> START</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> END</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> langgraph</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">graph</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">message </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> add_messages</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">class</span><span class="token plain"> </span><span class="token class-name">State</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">TypedDict</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    messages</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">list</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">llm </span><span class="token operator">=</span><span class="token plain"> ChatOpenAI</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">model</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;gpt-4o-mini&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> temperature</span><span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">system_prompt </span><span class="token operator">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">genai</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">load_prompt</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;prompts:/chat-prompt/1&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">add_system_message</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">state</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> State</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">return</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;messages&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;role&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;system&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;content&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> system_prompt</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">to_single_brace_format</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token operator">*</span><span class="token plain">state</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;messages&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">chatbot</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">state</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> State</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">return</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;messages&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">llm</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">invoke</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">state</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;messages&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">graph_builder </span><span class="token operator">=</span><span class="token plain"> StateGraph</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">State</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">graph_builder</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">add_node</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;add_system_message&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> add_system_message</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">graph_builder</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">add_node</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;chatbot&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> chatbot</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">graph_builder</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">add_edge</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">START</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;add_system_message&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">graph_builder</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">add_edge</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;add_system_message&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;chatbot&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">graph_builder</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">add_edge</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;chatbot&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> END</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">graph </span><span class="token operator">=</span><span class="token plain"> graph_builder</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token builtin" style="color:rgb(189, 147, 249)">compile</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">models</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">set_model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">graph</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="3-log-the-graph-to-mlflow">3. Log the Graph to MLflow<a href="#3-log-the-graph-to-mlflow" class="hash-link" aria-label="Direct link to 3. Log the Graph to MLflow" title="Direct link to 3. Log the Graph to MLflow">​</a></h4>
<p>Specify the file path to the script in the <code>model</code> parameter:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">with</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">start_run</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model_info </span><span class="token operator">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">langchain</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">log_model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        lc_model</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;./chatbot.py&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        name</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;graph&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre></div></div>
<p>We didn&#x27;t specify the <code>prompts</code> parameter this time, but MLflow automatically logs the prompt loaded within the script to the logged model. Now you can view the associated prompt in MLflow UI:</p>
<p><img decoding="async" loading="lazy" alt="Associated Prompts" src="/docs/latest/assets/images/prompt-logged-graph-0b4cd4a6c6e28f2afeffea5a9bcee188.png" width="878" height="413" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="4-load-the-graph-back-and-invoke">4. Load the graph back and invoke<a href="#4-load-the-graph-back-and-invoke" class="hash-link" aria-label="Direct link to 4. Load the graph back and invoke" title="Direct link to 4. Load the graph back and invoke">​</a></h4>
<p>Finally, let&#x27;s load the graph back and invoke it to see the chatbot in action.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)"># Enable MLflow tracing for LangChain to view the prompt passed to LLM.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">langchain</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">autolog</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Load the graph</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">graph </span><span class="token operator">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">langchain</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">load_model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">model_info</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">model_uri</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">graph</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">invoke</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;messages&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;role&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;user&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;content&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;What is the difference between multi-threading and multi-processing?&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre></div></div>
<p><img decoding="async" loading="lazy" alt="Chatbot" src="/docs/latest/assets/images/prompt-logged-trace-f531e466499e24d2b8541d655237ea91.png" width="1751" height="797" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="faq">FAQ<a href="#faq" class="hash-link" aria-label="Direct link to FAQ" title="Direct link to FAQ">​</a></h2>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="q-how-do-i-delete-a-prompt-version">Q: How do I delete a prompt version?<a href="#q-how-do-i-delete-a-prompt-version" class="hash-link" aria-label="Direct link to Q: How do I delete a prompt version?" title="Direct link to Q: How do I delete a prompt version?">​</a></h4>
<p>A: You can delete a prompt version using the MLflow UI or Python API:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Delete a prompt version</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">delete_prompt</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;summarization-prompt&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> version</span><span class="token operator">=</span><span class="token number">2</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre></div></div>
<p>To avoid accidental deletion, you can only delete one version at a time via API. If you delete the all versions of a prompt, the prompt itself will be deleted.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="q-can-i-update-the-prompt-template-of-an-existing-prompt-version">Q: Can I update the prompt template of an existing prompt version?<a href="#q-can-i-update-the-prompt-template-of-an-existing-prompt-version" class="hash-link" aria-label="Direct link to Q: Can I update the prompt template of an existing prompt version?" title="Direct link to Q: Can I update the prompt template of an existing prompt version?">​</a></h4>
<p>A: No, prompt versions are immutable once created. To update a prompt, create a new version with the desired changes.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="q-can-i-use-prompt-templates-with-frameworks-like-langchain-or-llamaindex">Q: Can I use prompt templates with frameworks like LangChain or LlamaIndex?<a href="#q-can-i-use-prompt-templates-with-frameworks-like-langchain-or-llamaindex" class="hash-link" aria-label="Direct link to Q: Can I use prompt templates with frameworks like LangChain or LlamaIndex?" title="Direct link to Q: Can I use prompt templates with frameworks like LangChain or LlamaIndex?">​</a></h4>
<p>A: Yes, you can load prompts from MLflow and use them with any framework. For example, the following example demonstrates how to use a prompt registered in MLflow with LangChain. Also refer to <a href="#example-1-logging-prompts-with-langchain">Logging Prompts with LangChain</a> for more details.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> langchain</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">prompts </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> PromptTemplate</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Load prompt from MLflow</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">prompt </span><span class="token operator">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">genai</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">load_prompt</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;question_answering&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Convert the prompt to single brace format for LangChain (MLflow uses double braces),</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># using the `to_single_brace_format` method.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">langchain_prompt </span><span class="token operator">=</span><span class="token plain"> PromptTemplate</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">from_template</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">prompt</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">to_single_brace_format</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">print</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">langchain_prompt</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">input_variables</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Output: [&#x27;num_sentences&#x27;, &#x27;sentences&#x27;]</span><br></span></code></pre></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="q-is-prompt-registry-integrated-with-the-prompt-engineering-ui">Q: Is Prompt Registry integrated with the Prompt Engineering UI?<a href="#q-is-prompt-registry-integrated-with-the-prompt-engineering-ui" class="hash-link" aria-label="Direct link to Q: Is Prompt Registry integrated with the Prompt Engineering UI?" title="Direct link to Q: Is Prompt Registry integrated with the Prompt Engineering UI?">​</a></h4>
<p>A. Direct integration between the Prompt Registry and the Prompt Engineering UI is coming soon. In the meantime, you can iterate on prompt template in the Prompt Engineering UI and register the final version in the Prompt Registry by manually copying the prompt template.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="whats-next">What&#x27;s Next<a href="#whats-next" class="hash-link" aria-label="Direct link to What&#x27;s Next" title="Direct link to What&#x27;s Next">​</a></h2>
<p>Manage prompts using other MLflow capabilities:</p>
<ul>
<li>Store prompt templates as parameters in MLflow experiments</li>
<li>Version prompts alongside your application code in Git</li>
<li>Use MLflow&#x27;s version tracking features to link specific prompt versions to application versions</li>
<li>Leverage MLflow&#x27;s tagging system to organize and categorize prompts</li>
</ul>
<p>See the <a href="/docs/latest/genai/prompt-version-mgmt/version-tracking">Version Tracking</a> section for current best practices on some of these other approaches.</p></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/latest/genai/flavors/responses-agent-intro"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Building with ResponsesAgent</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/latest/genai/prompt-version-mgmt/prompt-registry/create-and-edit-prompts"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Create and Edit Prompts</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#what-is-mlflow-prompt-registry" class="table-of-contents__link toc-highlight">What is MLflow Prompt Registry?</a></li><li><a href="#integration-with-unity-catalog" class="table-of-contents__link toc-highlight">Integration with Unity Catalog</a></li><li><a href="#future-capabilities" class="table-of-contents__link toc-highlight">Future Capabilities</a></li><li><a href="#stay-updated" class="table-of-contents__link toc-highlight">Stay Updated</a></li><li><a href="#prompt-registry-in-oss-mlflow" class="table-of-contents__link toc-highlight">Prompt Registry in OSS MLflow</a><ul><li><a href="#1-create-a-prompt" class="table-of-contents__link toc-highlight">1. Create a Prompt</a></li><li><a href="#2-update-the-prompt-with-a-new-version" class="table-of-contents__link toc-highlight">2. Update the Prompt with a New Version</a></li><li><a href="#3-compare-the-prompt-versions" class="table-of-contents__link toc-highlight">3. Compare the Prompt Versions</a></li><li><a href="#4-load-and-use-the-prompt" class="table-of-contents__link toc-highlight">4. Load and Use the Prompt</a></li><li><a href="#5-search-prompts" class="table-of-contents__link toc-highlight">5. Search Prompts</a></li></ul></li><li><a href="#prompt-object" class="table-of-contents__link toc-highlight">Prompt Object</a></li><li><a href="#log-prompts-with-models" class="table-of-contents__link toc-highlight">Log Prompts with Models</a><ul><li><a href="#basic-usage" class="table-of-contents__link toc-highlight">Basic Usage</a></li><li><a href="#example-1-logging-prompts-with-langchain" class="table-of-contents__link toc-highlight">Example 1: Logging Prompts with LangChain</a></li><li><a href="#example-2-automatic-prompt-logging-with-models-from-code" class="table-of-contents__link toc-highlight">Example 2: Automatic Prompt Logging with Models-from-Code</a></li></ul></li><li><a href="#faq" class="table-of-contents__link toc-highlight">FAQ</a></li><li><a href="#whats-next" class="table-of-contents__link toc-highlight">What&#39;s Next</a></li></ul></div></div></div></div></main></div></div></div><footer class="pb-30 flex flex-col pt-30 bg-bottom bg-no-repeat bg-cover bg-size-[auto_360px] 2xl:bg-size-[100%_360px] bg-brand-black" style="background-image:linear-gradient(#0e1414 60%, #0c141400 90% 100%),url(/docs/latest/assets/images/footer-red-bg-ec5ecbbbbb62b125aa76b2c5c2af7ab3.png)"><div class="flex flex-row justify-between items-start md:items-center px-6 lg:px-20 gap-10 xs:gap-0 max-w-container"><div class="flex flex-col gap-8"><svg xmlns="http://www.w3.org/2000/svg" width="109" height="40" fill="none" viewBox="0 0 109 40" class="h-[36px] shrink-0"><path fill="#fff" d="M0 31.032v-15.53h3.543v1.968c.893-1.594 2.84-2.425 4.593-2.425 2.042 0 3.828.926 4.658 2.745 1.216-2.043 3.034-2.745 5.043-2.745 2.81 0 5.49 1.787 5.49 5.904v10.083h-3.574v-9.478c0-1.818-.926-3.19-3-3.19-1.947 0-3.224 1.53-3.224 3.445v9.22H9.893v-9.475c0-1.786-.898-3.18-3.003-3.18-1.977 0-3.223 1.467-3.223 3.444v9.221ZM27.855 31.032V7.929h3.703v23.103ZM30.07 39.487c.833.232 1.582.383 3.17.383 2.953 0 6.436-1.665 7.353-6.339l3.786-18.739h5.629l.687-3.117h-5.686l.765-3.725c.586-2.892 2.186-4.358 4.754-4.358.668 0 .48.058 1.076.17L52.427.57c-.793-.237-1.503-.379-3.049-.379a7.32 7.32 0 0 0-4.528 1.484c-1.441 1.114-2.393 2.75-2.827 4.863l-1.066 5.137h-5.034l-.411 3.12h4.823L36.859 32.12c-.383 1.965-1.5 4.315-4.708 4.315-.727 0-.463-.055-1.121-.162ZM53.342 30.905H49.64l5.074-23.309h3.701ZM71.807 16.477A7.962 7.962 0 0 0 60.97 27.904l2.425-1.78a5.005 5.005 0 0 1 3.845-8.145v1.895ZM62.618 29.472a7.962 7.962 0 0 0 10.836-11.428l-2.425 1.78a5.005 5.005 0 0 1-3.845 8.145v-1.894ZM78.092 15.493h4.044l.823 10.612 5.759-10.612 3.839.055 1.508 10.557 5.074-10.612 3.701.055-7.678 15.493H91.46l-1.783-11.106-5.895 11.106h-3.84ZM105.072 15.768h-.766v-.266h1.845v.272h-.765v2.243h-.314ZM106.614 15.502h.383l.482 1.34q.091.259.178.524h.018c.059-.176.113-.352.172-.524l.478-1.34h.383v2.515h-.298V16.63c0-.22.024-.523.04-.747h-.016l-.191.574-.475 1.304h-.208l-.481-1.302-.191-.574h-.015c.017.224.042.527.042.747v1.387h-.291Z"></path></svg><div class="text-xs text-left md:text-nowrap md:w-0">© 2025 MLflow Project, a Series of LF Projects, LLC.</div></div><div class="flex flex-col flex-wrap justify-end md:text-right md:flex-row gap-x-10 lg:gap-x-20 gap-y-5 w-2/5 md:w-auto md:pt-2 max-w-fit"><div><a href="https://mlflow.org" target="_blank" rel="noopener noreferrer" class="text-[15px] font-medium no-underline hover:no-underline transition-opacity hover:opacity-80 text-white visited:text-white">Components</a></div><div><a href="https://mlflow.org/releases" target="_blank" rel="noopener noreferrer" class="text-[15px] font-medium no-underline hover:no-underline transition-opacity hover:opacity-80 text-white visited:text-white">Releases</a></div><div><a href="https://mlflow.org/blog" target="_blank" rel="noopener noreferrer" class="text-[15px] font-medium no-underline hover:no-underline transition-opacity hover:opacity-80 text-white visited:text-white">Blog</a></div><div><a class="text-[15px] font-medium no-underline hover:no-underline transition-opacity hover:opacity-80 text-white visited:text-white" href="/docs/latest/">Docs</a></div><div><a href="https://mlflow.org/ambassadors" target="_blank" rel="noopener noreferrer" class="text-[15px] font-medium no-underline hover:no-underline transition-opacity hover:opacity-80 text-white visited:text-white">Ambassador Program</a></div></div></div></footer></div>
</body>
</html>