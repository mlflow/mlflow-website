<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.0.1">
<title data-rh="true">Deep Learning with MLflow (Part 2) | MLflow</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://your-docusaurus-site.example.com/mlflow-website/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://your-docusaurus-site.example.com/mlflow-website/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://your-docusaurus-site.example.com/mlflow-website/blog/deep-learning-part-2"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Deep Learning with MLflow (Part 2) | MLflow"><meta data-rh="true" name="description" content="Using MLflow&#x27;s Deep Learning tracking features for fine tuning an LLM"><meta data-rh="true" property="og:description" content="Using MLflow&#x27;s Deep Learning tracking features for fine tuning an LLM"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2024-04-26T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://www.linkedin.com/in/puneetjain159/,https://www.linkedin.com/in/avi-data-ml/,https://www.linkedin.com/in/abeomor/,https://www.linkedin.com/in/benjamin-wilson-arch/"><meta data-rh="true" property="article:tag" content="Deep Learning"><link data-rh="true" rel="icon" href="/mlflow-website/img/mlflow-favicon.ico"><link data-rh="true" rel="canonical" href="https://your-docusaurus-site.example.com/mlflow-website/blog/deep-learning-part-2"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/mlflow-website/blog/deep-learning-part-2" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-docusaurus-site.example.com/mlflow-website/blog/deep-learning-part-2" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/mlflow-website/blog/rss.xml" title="MLflow RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/mlflow-website/blog/atom.xml" title="MLflow Atom Feed">

<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n,g){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var m=t.getElementsByTagName(a)[0],r=t.createElement(a);r.async=!0,r.src="https://www.googletagmanager.com/gtm.js?id=GTM-N6WMTTJ",m.parentNode.insertBefore(r,m)}(window,document,"script","dataLayer")</script>


<link rel="alternate" type="application/rss+xml" href="/mlflow-website/releases/rss.xml" title="MLflow RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/mlflow-website/releases/atom.xml" title="MLflow Atom Feed"><link rel="stylesheet" href="/mlflow-website/assets/css/styles.0f14d625.css">
<script src="/mlflow-website/assets/js/runtime~main.db8009cd.js" defer="defer"></script>
<script src="/mlflow-website/assets/js/main.73845989.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-N6WMTTJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/mlflow-website/"><div class="navbar__logo"><img src="/mlflow-website/img/mlflow-white.svg" alt="MLflow" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/mlflow-website/img/mlflow-black.svg" alt="MLflow" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a></div><div class="navbar__items navbar__items--right"><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/mlflow-website/blog">Blog</a><a class="navbar__item navbar__link" href="/mlflow-website/releases">Releases</a><a href="/mlflow-website/docs/latest/index.html" target="_self" rel="noopener noreferrer" class="navbar__item navbar__link">Docs</a><a href="https://github.com/mlflow/mlflow" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Contribute<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a class="navbar__item navbar__link" href="/mlflow-website/ambassador">Ambassador Program</a><a href="/mlflow-website/docs/latest/getting-started/index.html" target="_self" rel="noopener noreferrer" class="navbar__item navbar__link navbar__item__get-started">Get Started</a><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">All posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mlflow-website/blog/mlflow-tracing">Introducing MLflow Tracing</a></li><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/mlflow-website/blog/deep-learning-part-2">Deep Learning with MLflow (Part 2)</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mlflow-website/blog/release-candidates">MLflow Release Candidates</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mlflow-website/blog/deep-learning-part-1">Announcing MLflow Enhancements - Deep Learning with MLflow (Part 1)</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mlflow-website/blog/mlflow-year-in-review">2023 Year in Review</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mlflow-website/blog/databricks-ce">Streamline your MLflow Projects with Free Hosted MLflow</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mlflow-website/blog/custom-pyfunc">Custom MLflow Models with mlflow.pyfunc</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mlflow-website/blog/ai-gateway-rename">MLflow AI Gateway renamed to MLflow Deployments for LLMs</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mlflow-website/blog/mlflow-autolog">Automatic Metric, Parameter, and Artifact Logging with mlflow.autolog</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/mlflow-website/blog/mlflow-docs-overhaul">MLflow Docs Overhaul</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="https://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting"><meta itemprop="description" content="Using MLflow&#x27;s Deep Learning tracking features for fine tuning an LLM"><header><h1 class="title_f1Hy" itemprop="headline">Deep Learning with MLflow (Part 2)</h1><div class="container_mt6G margin-vert--md"><time datetime="2024-04-26T00:00:00.000Z" itemprop="datePublished">April 26, 2024</time> · <!-- -->12 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/puneetjain159/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="/img/authors/puneet.png" alt="Puneet Jain" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/puneetjain159/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Puneet Jain</span></a></div><small class="avatar__subtitle" itemprop="description">Sr. Specialist Solutions Architect at Databricks</small></div></div></div><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/avi-data-ml/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="/img/authors/avinash.png" alt="Avinash Sooriyarachchi" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/avi-data-ml/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Avinash Sooriyarachchi</span></a></div><small class="avatar__subtitle" itemprop="description">Sr. Solutions Architect at Databricks</small></div></div></div><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/abeomor/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="/img/authors/abe.png" alt="Abe Omorogbe" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/abeomor/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Abe Omorogbe</span></a></div><small class="avatar__subtitle" itemprop="description">Product Manager, ML at Databricks</small></div></div></div><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://www.linkedin.com/in/benjamin-wilson-arch/" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="/img/authors/ben.png" alt="Ben Wilson" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://www.linkedin.com/in/benjamin-wilson-arch/" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Ben Wilson</span></a></div><small class="avatar__subtitle" itemprop="description">Software Engineer at Databricks</small></div></div></div></div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody"><p>In the realm of deep learning, finetuning of pre-trained Large Language Models (LLMs) on private datasets is an excellent customization
option to increase a model’s relevancy for a specific task. This practice is not only common, but also essential for developing specialized
models, particularly for tasks like text classification and summarization.</p>
<p>In such scenarios, tools like MLflow are invaluable. Tracking tools like MLflow help to ensure that every aspect of the training
process - metrics, parameters, and artifacts - are reproducibly tracked and logged, allowing for the analysis, comparison, and sharing of tuning iterations.</p>
<p>In this blog post, we are going to be using <a href="https://mlflow.org/releases/2.12.1" target="_blank" rel="noopener noreferrer">MLflow 2.12</a> and the
<a href="https://mlflow.org/blog/deep-learning-part-1" target="_blank" rel="noopener noreferrer">recently introduced MLflow Deep Learning features</a> to track all the important aspects of fine
tuning a large language model for text classification, including the use of automated logging of training checkpoints in order to simplify
the process of resumption of training.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="use-case-fine-tuning-a-transformer-model-for-text-classification">Use Case: Fine Tuning a Transformer Model for Text Classification<a href="#use-case-fine-tuning-a-transformer-model-for-text-classification" class="hash-link" aria-label="Direct link to Use Case: Fine Tuning a Transformer Model for Text Classification" title="Direct link to Use Case: Fine Tuning a Transformer Model for Text Classification">​</a></h2>
<p>The example scenario that we&#x27;re using within this blog utilizes the <a href="https://huggingface.co/datasets/coastalcph/lex_glue/viewer/unfair_tos" target="_blank" rel="noopener noreferrer">unfair-TOS</a> dataset.</p>
<p>In today’s world, it’s hard to find a service, platform, or even a consumer good that doesn’t have a legally-binding terms of service connected
with it. These encyclopedic size agreements, filled with dense legal jargon and sometimes baffling levels of specificity, are so large that
most people simply accept them without reading them. However, reports have indicated over time that occasionally, some suspiciously unfair
terms are embedded within them.</p>
<p>Addressing unfair clauses in Terms of Service (TOS) agreements through machine learning (ML) is particularly relevant due to the pressing
need for transparency and fairness in legal agreements that affect consumers. Consider the following clause from an example TOS
agreement: <strong>&quot;We may revise these Terms from time to time. The changes will not be retroactive, and the most current version of the Terms, which will always...&quot;</strong>
This clause stipulates that the service provider may suspend or terminate the service at any time for any reason,
with or without notice. Most people would consider this to be quite unfair.</p>
<p>While this sentence is buried quite deeply within a fairly dense document, an ML algorithm is not burdened by the exhaustion that a human
would have for combing through the text and identifying clauses that might seem a bit unfair. By automatically identifying potentially
unfair clauses, a transformers-based Deep Learning (DL) model can help protect consumers from exploitative practices, ensure greater compliance with legal standards,
and foster trust between service providers and users.</p>
<p>A base pre-trained transformer model, without specialized fine-tuning, faces several challenges in accurately identifying unfair Terms of Service clauses.
Firstly, it lacks the domain-specific knowledge essential for understanding complex legal language. Secondly, its training objectives are
too general to capture the nuanced interpretation required for legal analysis. Lastly, it may not effectively recognize the subtle
contextual meanings that determine the fairness of contractual terms, making it less effective for this specialized task.</p>
<p>Using prompt engineering to address the identification of unfair Terms of Service clauses with a closed-source Large language model
can be prohibitively expensive. This approach requires extensive trial and error to refine prompts without the ability to tweak
the underlying model mechanics. Each iteration can consume significant computational resources , especially when using
<a href="https://www.promptingguide.ai/techniques/fewshot" target="_blank" rel="noopener noreferrer">few-shot prompting</a>, leading to escalating costs without guaranteeing a corresponding
increase in accuracy or effectiveness.</p>
<p>In this context, the use of the <strong>RoBERTa-base</strong> model is particularly effective, provided that it is fine-tuned. This model is robust
enough to handle complex tasks like discerning embedded instructions within texts, yet it is sufficiently compact to be fine-tuned
on modest hardware, such as an Nvidia T4 GPU.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-peft">What is PEFT?<a href="#what-is-peft" class="hash-link" aria-label="Direct link to What is PEFT?" title="Direct link to What is PEFT?">​</a></h3>
<p><a href="https://huggingface.co/docs/peft/en/index" target="_blank" rel="noopener noreferrer">Parameter-Efficient Fine-Tuning (PEFT)</a> approaches are advantageous as they involve
keeping the bulk of the pre-trained model parameters fixed while either only training a few additional layers or modifying the parameters used
when interacting with the model&#x27;s weights. This methodology not only conserves memory during training, but also significantly reduces the overall training time. When
compared with the alternative of fine-tuning a base model&#x27;s weights in order to customize its performance for a specific targeted task, the PEFT
approach can save significant cost in both time and money, while providing an equivalent or better performance results with less data than is required
for a comprehensive fine-tuning training task.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="integrating-hugging-face-models-and-the-pytorch-lightning-framework">Integrating Hugging-Face models and the PyTorch Lightning framework<a href="#integrating-hugging-face-models-and-the-pytorch-lightning-framework" class="hash-link" aria-label="Direct link to Integrating Hugging-Face models and the PyTorch Lightning framework" title="Direct link to Integrating Hugging-Face models and the PyTorch Lightning framework">​</a></h2>
<p><a href="https://lightning.ai/docs/pytorch/stable/" target="_blank" rel="noopener noreferrer">PyTorch Lightning</a> integrates seamlessly with
<a href="https://huggingface.co/docs/transformers/en/index" target="_blank" rel="noopener noreferrer">Hugging Face&#x27;s Transformers library</a>, enabling streamlined model training workflows
that capitalize on Lightning&#x27;s easy-to-use Higher level API’s and HF&#x27;s state-of-the-art pre-trained models. The combination of Lightning with transformers’
<a href="https://huggingface.co/blog/peft" target="_blank" rel="noopener noreferrer">PEFT module</a> enhances productivity and scalability by reducing code complexity and enabling the use of
high-quality pre-optimized models for a range of diverse NLP tasks.</p>
<p>Below is an example of configuring the PEFT-based fine tuning of a base model using PyTorch Lightning and HuggingFace&#x27;s <code>peft</code> module.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token keyword" style="color:rgb(86, 156, 214)">from</span><span class="token plain"> typing </span><span class="token keyword" style="color:rgb(86, 156, 214)">import</span><span class="token plain"> List</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">from</span><span class="token plain"> lightning </span><span class="token keyword" style="color:rgb(86, 156, 214)">import</span><span class="token plain"> LightningModule</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">from</span><span class="token plain"> peft </span><span class="token keyword" style="color:rgb(86, 156, 214)">import</span><span class="token plain"> get_peft_model</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> LoraConfig</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> TaskType</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:rgb(86, 156, 214)">import</span><span class="token plain"> AutoModelForSequenceClassification</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">class</span><span class="token plain"> </span><span class="token class-name" style="color:rgb(78, 201, 176)">TransformerModule</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">LightningModule</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token keyword" style="color:rgb(86, 156, 214)">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(220, 220, 170)">__init__</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        pretrained_model</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">str</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        num_classes</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">int</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">2</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        lora_alpha</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">int</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">32</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        lora_dropout</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">float</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">0.1</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        r</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">int</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">8</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        lr</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">float</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">2e-4</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        </span><span class="token builtin" style="color:rgb(86, 156, 214)">super</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">__init__</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">model </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">create_model</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">pretrained_model</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> num_classes</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> lora_alpha</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> lora_dropout</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> r</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">lr </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> lr</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">save_hyperparameters</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;pretrained_model&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token keyword" style="color:rgb(86, 156, 214)">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(220, 220, 170)">create_model</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> pretrained_model</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> num_classes</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> lora_alpha</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> lora_dropout</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> r</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        </span><span class="token triple-quoted-string string" style="color:rgb(206, 145, 120)">&quot;&quot;&quot;Create and return the PEFT model with the given configuration.</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token triple-quoted-string string" style="display:inline-block;color:rgb(206, 145, 120)"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token triple-quoted-string string" style="color:rgb(206, 145, 120)">        Args:</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token triple-quoted-string string" style="color:rgb(206, 145, 120)">            pretrained_model: The path or identifier for the pretrained model.</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token triple-quoted-string string" style="color:rgb(206, 145, 120)">            num_classes: The number of classes for the sequence classification.</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token triple-quoted-string string" style="color:rgb(206, 145, 120)">            lora_alpha: The alpha parameter for LoRA.</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token triple-quoted-string string" style="color:rgb(206, 145, 120)">            lora_dropout: The dropout rate for LoRA.</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token triple-quoted-string string" style="color:rgb(206, 145, 120)">            r: The rank of LoRA adaptations.</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token triple-quoted-string string" style="display:inline-block;color:rgb(206, 145, 120)"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token triple-quoted-string string" style="color:rgb(206, 145, 120)">        Returns:</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token triple-quoted-string string" style="color:rgb(206, 145, 120)">            Model: A model configured with PEFT.</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token triple-quoted-string string" style="color:rgb(206, 145, 120)">        &quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        model </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> AutoModelForSequenceClassification</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">            pretrained_model_name_or_path</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">pretrained_model</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">            num_labels</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">num_classes</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        peft_config </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> LoraConfig</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">            task_type</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">TaskType</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">SEQ_CLS</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">            inference_mode</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token boolean">False</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">            r</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">r</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">            lora_alpha</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">lora_alpha</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">            lora_dropout</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">lora_dropout</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        </span><span class="token keyword" style="color:rgb(86, 156, 214)">return</span><span class="token plain"> get_peft_model</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">model</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> peft_config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token keyword" style="color:rgb(86, 156, 214)">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(220, 220, 170)">forward</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> input_ids</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> List</span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token builtin" style="color:rgb(86, 156, 214)">int</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> attention_mask</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> List</span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token builtin" style="color:rgb(86, 156, 214)">int</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> label</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> List</span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token builtin" style="color:rgb(86, 156, 214)">int</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        </span><span class="token triple-quoted-string string" style="color:rgb(206, 145, 120)">&quot;&quot;&quot;Calculate the loss by passing inputs to the model and comparing against ground truth labels.</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token triple-quoted-string string" style="display:inline-block;color:rgb(206, 145, 120)"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token triple-quoted-string string" style="color:rgb(206, 145, 120)">        Args:</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token triple-quoted-string string" style="color:rgb(206, 145, 120)">            input_ids: List of token indices to be fed to the model.</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token triple-quoted-string string" style="color:rgb(206, 145, 120)">            attention_mask: List to indicate to the model which tokens should be attended to, and which should not.</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token triple-quoted-string string" style="color:rgb(206, 145, 120)">            label: List of ground truth labels associated with the input data.</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token triple-quoted-string string" style="display:inline-block;color:rgb(206, 145, 120)"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token triple-quoted-string string" style="color:rgb(206, 145, 120)">        Returns:</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token triple-quoted-string string" style="color:rgb(206, 145, 120)">            torch.Tensor: The computed loss from the model as a tensor.</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token triple-quoted-string string" style="color:rgb(206, 145, 120)">        &quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        </span><span class="token keyword" style="color:rgb(86, 156, 214)">return</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">model</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">            input_ids</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">input_ids</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">            attention_mask</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">attention_mask</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">            labels</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">label</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Additional references for the full implementation can be <a href="https://github.com/puneet-jain159/deeplearning_with_mlfow/blob/master/custom_module/fine_tune_clsify_head.py" target="_blank" rel="noopener noreferrer">seen within the companion repository here</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="configuring-mlflow-for-peft-based-fine-tuning">Configuring MLflow for PEFT-based fine-tuning<a href="#configuring-mlflow-for-peft-based-fine-tuning" class="hash-link" aria-label="Direct link to Configuring MLflow for PEFT-based fine-tuning" title="Direct link to Configuring MLflow for PEFT-based fine-tuning">​</a></h2>
<p>Before initiating the training process, it&#x27;s crucial to configure MLFlow so that all system metrics, loss metrics, and parameters are logged for the training run.
As of MLFlow 2.12, auto-logging for TensorFlow and PyTorch now includes support for checkpointing model weights during training, giving a snapshot of the model
weights at defined epoch frequencies in order to provide for training resumption in the case of an error or loss of the compute environment.
Below is an example of how to enable this feature:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token keyword" style="color:rgb(86, 156, 214)">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">mlflow</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">enable_system_metrics_logging</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">mlflow</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">pytorch</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">autolog</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">checkpoint_save_best_only </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token boolean">False</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> checkpoint_save_freq</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;epoch&#x27;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>In the code above we are doing the following:</p>
<ul>
<li><strong>Enabling System Metrics Logging</strong>: The system resources will be logged to MLflow in order to understand where bottlenecks in memory, CPU, GPU, disk usage, and network traffic are throughout the training process.</li>
</ul>
<p><img loading="lazy" alt="MLflow UI System Metrics" src="/mlflow-website/assets/images/sys_metrics-9423a86b67b9aeeac27ee5aea7be01e2.png" width="1600" height="866" class="img_ev3q"></p>
<ul>
<li><strong>Configuring Auto Logging to log parameters, metrics and checkpoints for all epochs</strong>: Deep learning involves experimenting with various model architectures and hyperparameter settings. Auto logging plays a crucial role in systematically recording these experiments, making it easier to compare different runs and determine which configurations yield the best results. Checkpoints are logged at every epoch, enabling detailed evaluations of all intermediate epochs during the initial exploration phase of the project. However, it is generally not advisable to log all epochs during late-stage development to avoid excessive data writes and latency in the final training stages.</li>
</ul>
<p><img loading="lazy" alt="System Metrics Logged" src="/mlflow-website/assets/images/epoch_logging-c21dd79a1004d20b4804923690472a18.png" width="1600" height="864" class="img_ev3q"></p>
<p>The auto-logged checkpoint metrics and model artifacts will be viewable in the MLflow UI as the model trains, as shown below:</p>
<p><img loading="lazy" alt="Metrics logged with each epoch" src="/mlflow-website/assets/images/checkpoint_metrics-ad7d10db8f81555e3ab4d04c8fb63240.png" width="1600" height="731" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-importance-of-logging-and-early-stopping">The Importance of Logging and Early-stopping<a href="#the-importance-of-logging-and-early-stopping" class="hash-link" aria-label="Direct link to The Importance of Logging and Early-stopping" title="Direct link to The Importance of Logging and Early-stopping">​</a></h2>
<p>The integration of the Pytorch Lightning <code>Trainer</code> callback with MLflow is crucial within this training exercise. The integration allows for comprehensive
tracking and logging of metrics, parameters, and artifacts during model finetuning without having to explicitly call MLflow logging APIs. Additionally,
the autologging API allows for modifying the default logging behavior, permitting changes to the logging frequency, allowing for logging to occur at each
epoch, after a specified number of epochs, or at explicitly defined steps.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="early-stopping">Early stopping<a href="#early-stopping" class="hash-link" aria-label="Direct link to Early stopping" title="Direct link to Early stopping">​</a></h3>
<p>Early stopping is a critical regularization technique in neural network training, designed to assist in preventing overfitting through the act of
halting training when validation performance plateaus. Pytorch Lightning includes APIs that allow for an easy high-level control of training cessation,
as demonstrated below.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="configuring-pytorch-trainer-callback-with-early-stopping">Configuring Pytorch Trainer Callback with Early stopping<a href="#configuring-pytorch-trainer-callback-with-early-stopping" class="hash-link" aria-label="Direct link to Configuring Pytorch Trainer Callback with Early stopping" title="Direct link to Configuring Pytorch Trainer Callback with Early stopping">​</a></h3>
<p>The example below shows the configuration of the <code>Trainer</code> object within <code>Lightning</code> to leverage early stopping to prevent overfitting. Once configured, the
training is executed by calling <code>fit</code> on the <code>Trainer</code> object. By providing the <code>EarlyStopping</code> callback, in conjunction with MLflow&#x27;s autologging, the
appropriate number of epochs will be used, logged, and tracked without any additional effort.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token keyword" style="color:rgb(86, 156, 214)">from</span><span class="token plain"> dataclasses </span><span class="token keyword" style="color:rgb(86, 156, 214)">import</span><span class="token plain"> dataclass</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> field</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">import</span><span class="token plain"> os</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">from</span><span class="token plain"> data </span><span class="token keyword" style="color:rgb(86, 156, 214)">import</span><span class="token plain"> LexGlueDataModule</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">from</span><span class="token plain"> lightning </span><span class="token keyword" style="color:rgb(86, 156, 214)">import</span><span class="token plain"> Trainer</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">from</span><span class="token plain"> lightning</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">pytorch</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">callbacks </span><span class="token keyword" style="color:rgb(86, 156, 214)">import</span><span class="token plain"> EarlyStopping</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token decorator annotation punctuation" style="color:rgb(212, 212, 212)">@dataclass</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token keyword" style="color:rgb(86, 156, 214)">class</span><span class="token plain"> </span><span class="token class-name" style="color:rgb(78, 201, 176)">TrainConfig</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    pretrained_model</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">str</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;bert-base-uncased&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    num_classes</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">int</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">2</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    lr</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">float</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">2e-4</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    max_length</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">int</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">128</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    batch_size</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">int</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">256</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    num_workers</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">int</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> os</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">cpu_count</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    max_epochs</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">int</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">10</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    debug_mode_sample</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">int</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">|</span><span class="token plain"> </span><span class="token boolean">None</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token boolean">None</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    max_time</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">dict</span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token builtin" style="color:rgb(86, 156, 214)">str</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">float</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> field</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">default_factory</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token keyword" style="color:rgb(86, 156, 214)">lambda</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(212, 212, 212)">{</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;hours&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">3</span><span class="token punctuation" style="color:rgb(212, 212, 212)">}</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    model_checkpoint_dir</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">str</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;/local_disk0/tmp/model-checkpoints&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    min_delta</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">float</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">0.005</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    patience</span><span class="token punctuation" style="color:rgb(212, 212, 212)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(86, 156, 214)">int</span><span class="token plain"> </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">4</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">train_config </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> TrainConfig</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token comment" style="color:rgb(106, 153, 85)"># Instantiate the custom Transformer class for PEFT training</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">nlp_model </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> TransformerModule</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        pretrained_model</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">train_config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">pretrained_model</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        num_classes</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">train_config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">num_classes</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        lr</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">train_config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">lr</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">datamodule </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> LexGlueDataModule</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        pretrained_model</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">train_config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">pretrained_model</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        max_length</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">train_config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">max_length</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        batch_size</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">train_config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">batch_size</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        num_workers</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">train_config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">num_workers</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        debug_mode_sample</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">train_config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">debug_mode_sample</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token comment" style="color:rgb(106, 153, 85)"># Log system metrics while training loop is running</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">mlflow</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">enable_system_metrics_logging</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token comment" style="color:rgb(106, 153, 85)"># Automatically log per-epoch parameters, metrics, and checkpoint weights</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">mlflow</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">pytorch</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">autolog</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">checkpoint_save_best_only </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token boolean">False</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token comment" style="color:rgb(106, 153, 85)"># Define the Trainer configuration</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">trainer </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> Trainer</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">   callbacks</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">       EarlyStopping</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           monitor</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;Val_F1_Score&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           min_delta</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">train_config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">min_delta</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           patience</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">train_config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">patience</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           verbose</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">           mode</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;max&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">       </span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">   </span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">   default_root_dir</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">train_config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">model_checkpoint_dir</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">   fast_dev_run</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token builtin" style="color:rgb(86, 156, 214)">bool</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">train_config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">debug_mode_sample</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">   max_epochs</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">train_config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">max_epochs</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">   max_time</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">train_config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">max_time</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">   precision</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;32-true&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain"></span><span class="token comment" style="color:rgb(106, 153, 85)"># Execute the training run</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">trainer</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">fit</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">model</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">nlp_model</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> datamodule</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">datamodule</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="visualization-and-sharing-capabilities-within-mlflow">Visualization and Sharing Capabilities within MLflow<a href="#visualization-and-sharing-capabilities-within-mlflow" class="hash-link" aria-label="Direct link to Visualization and Sharing Capabilities within MLflow" title="Direct link to Visualization and Sharing Capabilities within MLflow">​</a></h2>
<p>The newly introduced DL-specific visualization capabilities introduced in MLflow 2.12 enable you to make comparisons between different runs and artifacts over epochs.
When comparing training runs, MLflow is capable of generating useful visualization that can be integrated into dashboards, facilitating
easy sharing. Additionally, the centralized storage of metrics, in conjunction with parameters, allows for effective analysis of the training
efficacy, as shown in the image below.</p>
<p><img loading="lazy" alt="Epoch Run Compare" src="/mlflow-website/assets/images/compare-ea0bead7c1244ca8868d1f039c791ac4.png" width="1600" height="820" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="when-to-stop-training">When to stop training?<a href="#when-to-stop-training" class="hash-link" aria-label="Direct link to When to stop training?" title="Direct link to When to stop training?">​</a></h2>
<p>When training DL models, it is important to understand when to stop. Efficient training (for minimizing the overall cost incurred for
conducting training) and optimal model performance rely heavily on preventing a model from overfitting on the training data. A model
that trains for too long will invariably become quite good at effectively ‘memorizing’ the training data, resulting in a reduction in
the performance of the model when presented with novel data. A straightforward way to evaluate this behavior is to ensure that
validation data set metrics (scoring loss metrics on data that is not in the training data set) are captured during the training
loop. Integrating the MLflow callback into the PyTorch Lightning Trainer allows for iterative logging of loss metrics at
configurable iterations, enabling an easily debuggable evaluation of the training performance, ensuring that stopping criteria
can be enforced at the appropriate time to prevent overfitting.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="evaluating-epoch-checkpoints-of-fine-tuned-models-with-mlflow">Evaluating epoch checkpoints of Fine Tuned Models with MLflow<a href="#evaluating-epoch-checkpoints-of-fine-tuned-models-with-mlflow" class="hash-link" aria-label="Direct link to Evaluating epoch checkpoints of Fine Tuned Models with MLflow" title="Direct link to Evaluating epoch checkpoints of Fine Tuned Models with MLflow">​</a></h3>
<p>With your training process meticulously tracked and logged by MLflow, you have the flexibility to retrieve and test your model at
any arbitrary checkpoint. To do this, you can use the mlflow.pytorch.load_model() API to load the model from a specific run
and use the <code>predict()</code> method for evaluation.</p>
<p>In the example below, we will load the model checkpoint from the 3rd epoch and use the <code>Lightning</code> train module to generate predictions based on the
checkpoint state of the saved training epoch.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#9CDCFE;--prism-background-color:#1E1E1E"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#9CDCFE;background-color:#1E1E1E"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#9CDCFE"><span class="token keyword" style="color:rgb(86, 156, 214)">import</span><span class="token plain"> mlflow</span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">mlflow</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">pytorch</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">autolog</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">disable </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">run_id </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&#x27;&lt;Add the run ID&gt;&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">model </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> mlflow</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">pytorch</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">load_checkpoint</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">TransformerModule</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> run_id</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token number" style="color:rgb(181, 206, 168)">3</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">examples_to_test </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;We reserve the right to modify the service price at any time and retroactively apply the adjusted price to historical service usage.&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">train_module </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> Trainer</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">tokenizer </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> AutoTokenizer</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">train_config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">pretrained_model</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">tokens </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> tokenizer</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">examples_to_test</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                  max_length</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain">train_config</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">max_length</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                  padding</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;max_length&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">                  truncation</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">ds </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> Dataset</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">from_dict</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token builtin" style="color:rgb(86, 156, 214)">dict</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">tokens</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">ds</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">set_format</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">            </span><span class="token builtin" style="color:rgb(86, 156, 214)">type</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;torch&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> columns</span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token punctuation" style="color:rgb(212, 212, 212)">[</span><span class="token string" style="color:rgb(206, 145, 120)">&quot;input_ids&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(206, 145, 120)">&quot;attention_mask&quot;</span><span class="token punctuation" style="color:rgb(212, 212, 212)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#9CDCFE"><span class="token plain">train_module</span><span class="token punctuation" style="color:rgb(212, 212, 212)">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">model</span><span class="token punctuation" style="color:rgb(212, 212, 212)">,</span><span class="token plain"> dataloaders </span><span class="token operator" style="color:rgb(212, 212, 212)">=</span><span class="token plain"> DataLoader</span><span class="token punctuation" style="color:rgb(212, 212, 212)">(</span><span class="token plain">ds</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><span class="token punctuation" style="color:rgb(212, 212, 212)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="summary">Summary<a href="#summary" class="hash-link" aria-label="Direct link to Summary" title="Direct link to Summary">​</a></h2>
<p>The integration of MLflow into the finetuning process of pre-trained language models, particularly for applications like custom
named entity recognition, text classification and instruction-following represents a significant advancement in managing and
optimizing deep learning workflows. Leveraging the autologging and tracking capabilities of MLflow in these workstreams not only
enhances the reproducibility and efficiency of model development, but also fosters a collaborative environment where insights
and improvements can be easily shared and implemented.</p>
<p>As we continue to push the boundaries of what these models can achieve, tools like MLflow will be instrumental in harnessing their full potential.</p>
<p>If you&#x27;re interested in seeing the full example in its entirety, feel free to <a href="https://github.com/puneet-jain159/deeplearning_with_mlfow" target="_blank" rel="noopener noreferrer">see the full example implementation</a></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="check-out-the-code">Check out the code<a href="#check-out-the-code" class="hash-link" aria-label="Direct link to Check out the code" title="Direct link to Check out the code">​</a></h3>
<p>The code we provide will delve into additional aspects such as training from a checkpoint, integrating MLflow and TensorBoard, and utilizing Pyfunc for model wrapping, among others. These resources are specifically tailored for implementation on <a href="https://mlflow.org/blog/databricks-ce" target="_blank" rel="noopener noreferrer">Databricks Community Edition</a>. The main runner notebook
within the full example repository <a href="https://github.com/puneet-jain159/deeplearning_with_mlfow/blob/master/train.ipynb" target="_blank" rel="noopener noreferrer">can be found here</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="get-started-with-mlflow-212-today">Get Started with MLflow 2.12 Today<a href="#get-started-with-mlflow-212-today" class="hash-link" aria-label="Direct link to Get Started with MLflow 2.12 Today" title="Direct link to Get Started with MLflow 2.12 Today">​</a></h2>
<p>Dive into the latest MLflow updates today and enhance the way you manage your machine learning projects! With our newest enhancements,
including advanced metric aggregation, automatic capturing of system metrics, intuitive feature grouping, and streamlined search capabilities,
MLflow is here to elevate your ML workflow to new heights. <a href="https://mlflow.org/releases/2.12.1" target="_blank" rel="noopener noreferrer">Get started now with MLflow&#x27;s cutting-edge tools and features</a>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="feedback">Feedback<a href="#feedback" class="hash-link" aria-label="Direct link to Feedback" title="Direct link to Feedback">​</a></h2>
<p>We value your input! Our feature prioritization is guided by feedback from the MLflow late 2023 survey. Please fill out our
<a href="https://surveys.training.databricks.com/jfe/form/SV_3jGIliwGC0g5xTU" target="_blank" rel="noopener noreferrer">Spring 2024 survey</a>, and by participating, you can help ensure that the features
you want most are implemented in MLflow.</p></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_mRVl"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/mlflow-website/blog/tags/deep-learning">Deep Learning</a></li></ul></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/mlflow-website/blog/mlflow-tracing"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Introducing MLflow Tracing</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/mlflow-website/blog/release-candidates"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">MLflow Release Candidates</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#use-case-fine-tuning-a-transformer-model-for-text-classification" class="table-of-contents__link toc-highlight">Use Case: Fine Tuning a Transformer Model for Text Classification</a><ul><li><a href="#what-is-peft" class="table-of-contents__link toc-highlight">What is PEFT?</a></li></ul></li><li><a href="#integrating-hugging-face-models-and-the-pytorch-lightning-framework" class="table-of-contents__link toc-highlight">Integrating Hugging-Face models and the PyTorch Lightning framework</a></li><li><a href="#configuring-mlflow-for-peft-based-fine-tuning" class="table-of-contents__link toc-highlight">Configuring MLflow for PEFT-based fine-tuning</a></li><li><a href="#the-importance-of-logging-and-early-stopping" class="table-of-contents__link toc-highlight">The Importance of Logging and Early-stopping</a><ul><li><a href="#early-stopping" class="table-of-contents__link toc-highlight">Early stopping</a></li><li><a href="#configuring-pytorch-trainer-callback-with-early-stopping" class="table-of-contents__link toc-highlight">Configuring Pytorch Trainer Callback with Early stopping</a></li></ul></li><li><a href="#visualization-and-sharing-capabilities-within-mlflow" class="table-of-contents__link toc-highlight">Visualization and Sharing Capabilities within MLflow</a></li><li><a href="#when-to-stop-training" class="table-of-contents__link toc-highlight">When to stop training?</a><ul><li><a href="#evaluating-epoch-checkpoints-of-fine-tuned-models-with-mlflow" class="table-of-contents__link toc-highlight">Evaluating epoch checkpoints of Fine Tuned Models with MLflow</a></li></ul></li><li><a href="#summary" class="table-of-contents__link toc-highlight">Summary</a><ul><li><a href="#check-out-the-code" class="table-of-contents__link toc-highlight">Check out the code</a></li></ul></li><li><a href="#get-started-with-mlflow-212-today" class="table-of-contents__link toc-highlight">Get Started with MLflow 2.12 Today</a></li><li><a href="#feedback" class="table-of-contents__link toc-highlight">Feedback</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><a class="footerLogoLink_DDai" href="/mlflow-website/"><img src="/mlflow-website/img/mlflow-white.svg" alt="MLflow" class="footer__logo themedComponent_mlkZ themedComponent--light_NVdE" width="200px"><img src="/mlflow-website/img/mlflow-black.svg" alt="MLflow" class="footer__logo themedComponent_mlkZ themedComponent--dark_xIcU" width="200px"></a></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/mlflow" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.linkedin.com/company/mlflow-org" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://x.com/mlflow" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Resources</div><ul class="footer__items clean-list"><li class="footer__item"><a href="/mlflow-website/docs/latest/index.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Docs</a></li><li class="footer__item"><a class="footer__link-item" href="/mlflow-website/releases">Releases</a></li><li class="footer__item"><a class="footer__link-item" href="/mlflow-website/blog">Blog</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">© 2024 MLflow Project, a Series of LF Projects, LLC.</div></div></div></footer></div>
</body>
</html>