"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[6511],{3815:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>d,contentTitle:()=>s,default:()=>m,frontMatter:()=>i,metadata:()=>a,toc:()=>r});var t=o(5893),l=o(1151);const i={title:"Custom MLflow Models with mlflow.pyfunc",description:"A guide for creating custom MLflow models",slug:"custom-pyfunc",authors:["daniel-liden"],tags:["pyfunc","models"],thumbnail:"/img/blog/custom-pyfunc.png"},s=void 0,a={permalink:"/mlflow-website/blog/custom-pyfunc",source:"@site/blog/2024-01-23-custom-pyfunc/index.md",title:"Custom MLflow Models with mlflow.pyfunc",description:"A guide for creating custom MLflow models",date:"2024-01-23T00:00:00.000Z",formattedDate:"January 23, 2024",tags:[{label:"pyfunc",permalink:"/mlflow-website/blog/tags/pyfunc"},{label:"models",permalink:"/mlflow-website/blog/tags/models"}],readingTime:15.29,hasTruncateMarker:!0,authors:[{name:"Daniel Liden",title:"Developer Advocate at Databricks",url:"https://www.linkedin.com/in/danielliden",imageURL:"/img/authors/daniel_liden.png",key:"daniel-liden"}],frontMatter:{title:"Custom MLflow Models with mlflow.pyfunc",description:"A guide for creating custom MLflow models",slug:"custom-pyfunc",authors:["daniel-liden"],tags:["pyfunc","models"],thumbnail:"/img/blog/custom-pyfunc.png"},unlisted:!1,prevItem:{title:"Streamline your MLflow Projects with Free Hosted MLflow",permalink:"/mlflow-website/blog/databricks-ce"},nextItem:{title:"MLflow AI Gateway renamed to MLflow Deployments for LLMs",permalink:"/mlflow-website/blog/ai-gateway-rename"}},d={authorsImageUrls:[void 0]},r=[{value:"Models and Model Flavors",id:"models-and-model-flavors",level:2},{value:"Defining Custom MLflow Pyfunc Models",id:"defining-custom-mlflow-pyfunc-models",level:2},{value:"Defining a custom <code>predict</code> method",id:"defining-a-custom-predict-method",level:3},{value:"Parameterizing the custom model",id:"parameterizing-the-custom-model",level:3},{value:"Loading external resources with <code>load_context</code>",id:"loading-external-resources-with-load_context",level:3},{value:"Defining custom methods",id:"defining-custom-methods",level:3},{value:"Dependencies and Source Code",id:"dependencies-and-source-code",level:3},{value:"Summary: Custom Pyfunc Models in MLflow",id:"summary-custom-pyfunc-models-in-mlflow",level:3},{value:"Further Learning",id:"further-learning",level:3}];function c(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:"If you're looking to learn about all of the flexibility and customization that is possible within\nMLflow's custom models, this blog will help you on your journey in understanding more about how to\nleverage this powerful and highly customizable model storage format."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Welcome",src:o(411).Z+"",width:"1200",height:"629"})}),"\n",(0,t.jsxs)(n.p,{children:["MLflow offers built-in methods for logging and working with models from many popular machine\nlearning and generative AI frameworks and model providers, such as scikit-learn, PyTorch,\nHuggingFace transformers, and LangChain. For example,\n",(0,t.jsx)(n.a,{href:"https://mlflow.org/docs/latest/python_api/mlflow.sklearn.html#mlflow.sklearn.log_model",children:"mlflow.sklearn.log_model"}),"\nwill log a scikit-learn model as an MLflow artifact without requiring you to define custom methods for\nprediction or for handling artifacts."]}),"\n",(0,t.jsx)(n.p,{children:"In some cases, however, you might be working in a framework for which MLflow does not have\nbuilt-in methods, or you might want something different than the model\u2019s default prediction\noutputs. In those cases, MLflow allows you to create custom models to work with essentially\nany framework and to integrate custom logic to existing supported frameworks."}),"\n",(0,t.jsx)(n.p,{children:"In its simplest form, all that\u2019s required is to define a custom predict method and log the model.\nThe following example defines a simple pyfunc model that just returns the square of its input:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import mlflow\n\n# Define a custom model\nclass MyModel(mlflow.pyfunc.PythonModel):\n    def predict(self, context, model_input):\n        # Directly return the square of the input\n        return model_input**2\n\n\n# Save the model\nwith mlflow.start_run():\n    model_info = mlflow.pyfunc.log_model(\n        artifact_path="model",\n        python_model=MyModel()\n    )\n\n# Load the model\nloaded_model = mlflow.pyfunc.load_model(\n    model_uri=model_info.model_uri\n)\n\n# Predict\nloaded_model.predict(2)\n'})}),"\n",(0,t.jsx)(n.p,{children:"Let\u2019s dig into how this works, starting with some basic concepts."}),"\n",(0,t.jsx)(n.h2,{id:"models-and-model-flavors",children:"Models and Model Flavors"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Models and Flavors",src:o(5914).Z+"",width:"2235",height:"1332"})}),"\n",(0,t.jsxs)(n.p,{children:["An MLflow model is a directory that includes everything needed to reproduce a machine learning model\nacross different environments. Aside from the stored model itself, the most important component\nstored is an ",(0,t.jsx)(n.code,{children:"MLmodel"})," YAML file that specifies the model\u2019s supported model flavors.\nA ",(0,t.jsx)(n.a,{href:"https://mlflow.org/docs/latest/traditional-ml/creating-custom-pyfunc/part1-named-flavors.html#components-of-a-model-in-mlflow",children:"model flavor"}),"\nis a set of rules specifying how MLflow can interact with the model (i.e., save it, load it, and\nget predictions from it)."]}),"\n",(0,t.jsxs)(n.p,{children:["When you create a custom model in MLflow, it has the ",(0,t.jsx)(n.code,{children:"python_function"})," or pyfunc model flavor,\nwhich is a kind of \u201cuniversal translator\u201d across formats in MLflow. When you save a model in MLflow\nusing a built-in model flavor, e.g. with ",(0,t.jsx)(n.a,{href:"https://mlflow.org/docs/latest/python_api/mlflow.sklearn.html#mlflow.sklearn.log_model",children:"mlflow.sklearn.log_model"}),",\nthat model also has the pyfunc model flavor in addition to its framework-specific flavor.\nHaving both framework-specific and pyfunc model flavors allows you to use the model via the\nframework\u2019s native API (e.g., ",(0,t.jsx)(n.code,{children:"scikit-learn"}),") or via the pyfunc flavor\u2019s framework-agnostic inference API."]}),"\n",(0,t.jsxs)(n.p,{children:["Models with the pyfunc flavor are loaded as instances of the ",(0,t.jsx)(n.a,{href:"https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html?highlight=pyfunc#mlflow.pyfunc.PyFuncModel",children:"mlflow.pyfunc.PyfuncModel"}),"\nclass, which exposes a standardized predict method. This enables straightforward inference through a single\nfunction call, regardless of the underlying model's implementation details."]}),"\n",(0,t.jsx)(n.h2,{id:"defining-custom-mlflow-pyfunc-models",children:"Defining Custom MLflow Pyfunc Models"}),"\n",(0,t.jsxs)(n.p,{children:["Saving a model from any supported machine learning framework as an MLflow model results in the\ncreation of a pyfunc model flavor that provides a framework-agnostic interface for managing and\nusing the model. But what if you\u2019re using a framework without an MLflow integration, or you\u2019re\ntrying to elicit some custom behavior from a model? ",(0,t.jsx)(n.a,{href:"https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html#creating-custom-pyfunc-models",children:"Custom pyfunc models"}),"\nallow you to work with essentially any framework and to integrate custom logic."]}),"\n",(0,t.jsx)(n.p,{children:"To implement a custom pyfunc model, define a new Python class inheriting from the PythonModel class\nand implement the necessary methods. Minimally, this will involve implementing a custom predict\nmethod. Next, create an instance of your model and log or save the model. Once you\u2019ve loaded the\nsaved or logged model, you can use it for predictions."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Creating a custom model",src:o(442).Z+"",width:"2235",height:"1383"})}),"\n",(0,t.jsx)(n.p,{children:"Let\u2019s work through a few examples, each adding a little more complexity and highlighting different\naspects of defining a custom pyfunc model. We\u2019ll cover four main techniques for implementing custom\nbehaviors in pyfunc models:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["Implementing a custom ",(0,t.jsx)(n.code,{children:"predict"})," method"]}),"\n",(0,t.jsxs)(n.li,{children:["Implementing a custom ",(0,t.jsx)(n.code,{children:"__init__"})," method"]}),"\n",(0,t.jsxs)(n.li,{children:["Implementing a custom ",(0,t.jsx)(n.code,{children:"load_context"})," method"]}),"\n",(0,t.jsx)(n.li,{children:"Implementing user-defined custom methods"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Pyfunc model customization",src:o(6011).Z+"",width:"2239",height:"1100"})}),"\n",(0,t.jsxs)(n.h3,{id:"defining-a-custom-predict-method",children:["Defining a custom ",(0,t.jsx)(n.code,{children:"predict"})," method"]}),"\n",(0,t.jsxs)(n.p,{children:["At a minimum, a pyfunc model should specify a custom predict method that defines what happens when\nwe call ",(0,t.jsx)(n.code,{children:"model.predict"}),". Here\u2019s an example of a custom model that applies a simple linear\ntransformation to the model inputs, multiplying each input by two and adding three:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import pandas as pd\nimport mlflow\nfrom mlflow.pyfunc import PythonModel\n\n\n# Custom PythonModel class\nclass SimpleLinearModel(PythonModel):\n    def predict(self, context, model_input):\n        """\n        Applies a simple linear transformation\n        to the input data. For example, y = 2x + 3.\n        """\n        # Assuming model_input is a pandas DataFrame with one column\n        return pd.DataFrame(2 * model_input + 3)\n\n\nwith mlflow.start_run():\n    model_info = mlflow.pyfunc.log_model(\n        artifact_path="linear_model",\n        python_model=SimpleLinearModel(),\n        input_example=pd.DataFrame([10, 20, 30]),\n    )\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Note that you can (and should) also include a ",(0,t.jsx)(n.a,{href:"https://mlflow.org/docs/latest/models.html#model-signature",children:"signature"}),"\nand an ",(0,t.jsx)(n.a,{href:"https://mlflow.org/docs/latest/models.html#model-input-example",children:"input example"})," when saving/logging a\nmodel. If you pass an input example, the signature will be inferred automatically. The model\nsignature provides a way for MLflow to enforce correct usage of your model."]}),"\n",(0,t.jsx)(n.p,{children:"Once we\u2019ve defined the model path and saved an instance of the model, we can load the saved model\nand use it to generate predictions:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Now the model can be loaded and used for predictions\nloaded_model = mlflow.pyfunc.load_model(model_uri=model_info.model_uri)\nmodel_input = pd.DataFrame([1, 2, 3])  # Example input data\nprint(loaded_model.predict(model_input))  # Outputs transformed data\n"})}),"\n",(0,t.jsx)(n.p,{children:"Which will return:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:":    0\n: 0  5\n: 1  7\n: 2  9\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Note that if a custom ",(0,t.jsx)(n.code,{children:"predict"})," method is all you need\u2014that is, if your model does not have any\nartifacts that require special handling\u2014you can save or log the ",(0,t.jsx)(n.code,{children:"predict"})," method directly without\nneeding to wrap it in a Python class:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import mlflow\nimport pandas as pd\n\n\ndef predict(model_input):\n    """\n    Applies a simple linear transformation\n    to the input data. For example, y = 2x + 3.\n    """\n    # Assuming model_input is a pandas DataFrame with one column\n    return pd.DataFrame(2 * model_input + 3)\n\n\n# Pass predict method as python_model argument to save/log model\nwith mlflow.start_run():\n    model_info = mlflow.pyfunc.log_model(\n        artifact_path="simple_function",\n        python_model=predict,\n        input_example=pd.DataFrame([10, 20, 30]),\n    )\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Note that with this approach, we ",(0,t.jsx)(n.strong,{children:"must include"})," an input example along with the custom predict\nmethod. We also have to modify the predict method such that it takes only one input (i.e., no self or context).\nRunning this example and then loading with the same code as the preceding code block will retain the same output as\nthe example using a class definiton."]}),"\n",(0,t.jsx)(n.h3,{id:"parameterizing-the-custom-model",children:"Parameterizing the custom model"}),"\n",(0,t.jsxs)(n.p,{children:["Now suppose we want to parameterize the custom linear function model so that it can be used with\ndifferent slopes and intercepts. We can define the ",(0,t.jsx)(n.code,{children:"__init__"})," method to set up custom parameters,\nas in the following example. Note that the custom model class\u2019s ",(0,t.jsx)(n.code,{children:"__init__"})," method should not be used\nto load external resources like data files or pretrained models; these are handled in the\n",(0,t.jsx)(n.code,{children:"load_context"})," method, which we\u2019ll discuss shortly."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import pandas as pd\nimport mlflow\nfrom mlflow.pyfunc import PythonModel\n\n\n# Custom PythonModel class\nclass ParameterizedLinearModel(PythonModel):\n    def __init__(self, slope, intercept):\n        """\n        Initialize the parameters of the model. Note that we are not loading\n        any external resources here, just setting up the parameters.\n        """\n        self.slope = slope\n        self.intercept = intercept\n\n    def predict(self, context, model_input):\n        """\n        Applies a simple linear transformation\n        to the input data. For example, y = 2x + 3.\n        """\n        # Assuming model_input is a pandas DataFrame with one column\n        return pd.DataFrame(self.slope * model_input + self.intercept)\n\n\nlinear_model = ParameterizedLinearModel(10, 20)\n\n# Saving the model with mlflow\nwith mlflow.start_run():\n    model_info = mlflow.pyfunc.log_model(\n        artifact_path="parameter_model",\n        python_model=linear_model,\n        input_example=pd.DataFrame([10, 20, 30]),\n    )\n'})}),"\n",(0,t.jsx)(n.p,{children:"Again, we can load this model and make some predictions:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"loaded_model = mlflow.pyfunc.load_model(model_uri=model_info.model_uri)\nmodel_input = pd.DataFrame([1, 2, 3])  # Example input data\nprint(loaded_model.predict(model_input))  # Outputs transformed data\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:":     0\n: 0  30\n: 1  40\n: 2  50\n"})}),"\n",(0,t.jsxs)(n.p,{children:["There are many cases where we might want to parameterize a model in this manner. We can define\nvariables in the ",(0,t.jsx)(n.code,{children:"__init__"})," method to:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Set model hyperparameters."}),"\n",(0,t.jsx)(n.li,{children:"A/B test models with different parameter sets."}),"\n",(0,t.jsx)(n.li,{children:"Set user-specific customizations."}),"\n",(0,t.jsx)(n.li,{children:"Toggle features."}),"\n",(0,t.jsx)(n.li,{children:"Set, e.g., access credentials and endpoints for models that access external APIs."}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["In some cases, we may want to be able to pass parameters at inference time rather than when we\ninitialize the model. This can be accomplished with\n",(0,t.jsx)(n.a,{href:"https://mlflow.org/docs/latest/models.html#model-inference-params",children:"model inference params"}),". To use\ninference params, we must pass a valid model signature including ",(0,t.jsx)(n.code,{children:"params"}),". Here\u2019s how to adapt the\npreceding example to use inference params:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import pandas as pd\nimport mlflow\nfrom mlflow.models import infer_signature\nfrom mlflow.pyfunc import PythonModel\n\n\n# Custom PythonModel class\nclass LinearFunctionInferenceParams(PythonModel):\n    def predict(self, context, model_input, params):\n        """\n        Applies a simple linear transformation\n        to the input data. For example, y = 2x + 3.\n        """\n        slope = params["slope"]\n        # Assuming model_input is a pandas DataFrame with one column\n        return pd.DataFrame(slope * model_input + params["intercept"])\n\n\n# Set default params\nparams = {"slope": 2, "intercept": 3}\n\n# Define model signature\nsignature = infer_signature(model_input=pd.DataFrame([10, 20, 30]), params=params)\n\n# Save the model with mlflow\nwith mlflow.start_run():\n    model_info = mlflow.pyfunc.log_model(\n        artifact_path="model_with_params",\n        python_model=LinearFunctionInferenceParams(),\n        signature=signature,\n    )\n'})}),"\n",(0,t.jsxs)(n.p,{children:["After loading the model as before, you can now pass a ",(0,t.jsx)(n.code,{children:"params"})," argument to the ",(0,t.jsx)(n.code,{children:"predict"})," method,\nenabling you to use the same loaded model for different combinations of parameters:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'loaded_model = mlflow.pyfunc.load_model(model_uri=model_info.model_uri)\n\nparameterized_predictions = loaded_model.predict(\n    pd.DataFrame([10, 20, 30]), params={"slope": 2, "intercept": 10}\n)\nprint(parameterized_predictions)\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:":     0\n: 0  30\n: 1  50\n: 2  70\n"})}),"\n",(0,t.jsxs)(n.h3,{id:"loading-external-resources-with-load_context",children:["Loading external resources with ",(0,t.jsx)(n.code,{children:"load_context"})]}),"\n",(0,t.jsxs)(n.p,{children:["Custom models often require external files such as model weights in order to perform inference.\nThese files, or artifacts, must be handled carefully to avoid unnecessarily loading files into\nmemory or errors during model serialization. When building custom pyfunc models in MLflow, you can\nuse the ",(0,t.jsx)(n.code,{children:"load_context"})," method to handle model artifacts correctly."]}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"load_context"})," method receives a ",(0,t.jsx)(n.code,{children:"context"})," object containing artifacts the model can use during\ninference. You can specify these artifacts using the ",(0,t.jsx)(n.code,{children:"artifacts"})," argument when saving or logging\nmodels, making them accessible to the ",(0,t.jsx)(n.code,{children:"load_context"})," method via the ",(0,t.jsx)(n.code,{children:"context.artifacts"})," dictionary."]}),"\n",(0,t.jsxs)(n.p,{children:["In practice, the ",(0,t.jsx)(n.code,{children:"load_context"})," method often initializes the model called by the ",(0,t.jsx)(n.code,{children:"predict"})," method by\nhandling the loading of model artifacts."]}),"\n",(0,t.jsxs)(n.p,{children:["This raises an important question: why do we load artifacts and define the model in the ",(0,t.jsx)(n.code,{children:"load_context"}),"\nmethod and not in ",(0,t.jsx)(n.code,{children:"__init__"})," or directly in ",(0,t.jsx)(n.code,{children:"predict"}),"? Correct usage of ",(0,t.jsx)(n.code,{children:"load_context"})," is essential\nfor the maintainability, efficiency, scalability, and portability of MLflow pyfunc models. This is because:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["The ",(0,t.jsx)(n.code,{children:"load_context"})," method is executed once when the model is loaded via ",(0,t.jsx)(n.code,{children:"mlflow.pyfunc.load_model"}),".\nThis setup ensures that resource-intensive processes defined within this method, such as loading\nlarge model files, are not repeated unnecessarily. If artifact loading is done in the predict\nmethod, it will occur every single time a prediction is made. This is highly inefficient for\nresource-intensive models."]}),"\n",(0,t.jsxs)(n.li,{children:["Saving or logging an MLflow ",(0,t.jsx)(n.code,{children:"pyfunc"})," model involves serializing the Python model class (the subclass\nof ",(0,t.jsx)(n.a,{href:"https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html#mlflow.pyfunc.PythonModel",children:"mlflow.pyfunc.PythonModel"}),"\nyou created) and its attributes. Complex ML models are not always compatible with the methods used\nto serialize the Python object, which can lead to errors if they are created as attributes of the Python object."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["As an example, suppose we want to load a large language model (LLM) in the ",(0,t.jsx)(n.code,{children:"gguf"})," model format\n(a file format designed for storing models for inference) and run it with the\n",(0,t.jsx)(n.a,{href:"https://pypi.org/project/ctransformers",children:"ctransformers library"}),". At the time of writing, there is\nno built-in model flavor that lets us use ",(0,t.jsx)(n.code,{children:"gguf"})," models for inference, so we\u2019ll create a custom\npyfunc model that loads the required libraries and model files in the ",(0,t.jsx)(n.code,{children:"load_context"})," method.\nSpecifically, we\u2019re going to load a quantized version of the ",(0,t.jsx)(n.a,{href:"https://huggingface.co/TheBloke/Mistral-7B-v0.1-AWQ",children:"AWQ version of the Mistral 7B model"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"First, we\u2019ll download the model snapshot using the huggingface hub cli:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"huggingface-cli download TheBloke/Mistral-7B-v0.1-GGUF \\\n                mistral-7b-v0.1.Q4_K_M.gguf \\\n                --local-dir /path/to/mistralfiles/ \\\n                --local-dir-use-symlinks False\n"})}),"\n",(0,t.jsxs)(n.p,{children:["And then we\u2019ll define our custom ",(0,t.jsx)(n.code,{children:"pyfunc"})," model. Note the addition of the ",(0,t.jsx)(n.code,{children:"load_context"})," method:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import ctransformers\nfrom mlflow.pyfunc import PythonModel\n\n\nclass CTransformersModel(PythonModel):\n    def __init__(self, gpu_layers):\n        """\n        Initialize with GPU layer configuration.\n        """\n        self.gpu_layers = gpu_layers\n        self.model = None\n\n    def load_context(self, context):\n        """\n        Load the model from the specified artifacts directory.\n        """\n        model_file_path = context.artifacts["model_file"]\n\n        # Load the model\n        self.model = ctransformers.AutoModelForCausalLM.from_pretrained(\n            model_path_or_repo_id=model_file_path,\n            gpu_layers=self.gpu_layers,\n        )\n\n    def predict(self, context, model_input):\n        """\n        Perform prediction using the loaded model.\n        """\n        if self.model is None:\n            raise ValueError(\n                "The model has not been loaded. "\n                "Ensure that \'load_context\' is properly executed."\n            )\n        return self.model(model_input)\n'})}),"\n",(0,t.jsx)(n.p,{children:"There\u2019s a lot going on here, so let\u2019s break it down. Here are the key points:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["As before, we use the ",(0,t.jsx)(n.code,{children:"__init__"})," method to parameterize the model (in this case, to set the\n",(0,t.jsx)(n.code,{children:"gpu_layers"})," argument for the model)."]}),"\n",(0,t.jsxs)(n.li,{children:["The purpose of the ",(0,t.jsx)(n.code,{children:"load_context"})," method is to load the artifacts required for use in the\n",(0,t.jsx)(n.code,{children:"predict"})," method. In this case, we need to load the model and its weights."]}),"\n",(0,t.jsxs)(n.li,{children:["You\u2019ll notice that we reference ",(0,t.jsx)(n.code,{children:'context.artifacts["model_file"]'}),". This comes from the artifacts\nargument to ",(0,t.jsx)(n.code,{children:"mlflow.pyfunc.save_model"})," or ",(0,t.jsx)(n.code,{children:"mlflow.pyfunc.load_model"}),", as shown in the following\ncode snippet. This is an important part of working with ",(0,t.jsx)(n.code,{children:"pyfunc"})," models. The ",(0,t.jsx)(n.code,{children:"predict"})," and\n",(0,t.jsx)(n.code,{children:"load_context"})," methods can access the artifacts defined in the artifacts argument to the\n",(0,t.jsx)(n.code,{children:"save_model"})," or ",(0,t.jsx)(n.code,{children:"log_model"})," method via the ",(0,t.jsx)(n.code,{children:"context.artifacts"})," object. ",(0,t.jsx)(n.code,{children:"load_context"})," is executed\nwhen the model is loaded via ",(0,t.jsx)(n.code,{children:"load_model"}),"; as described earlier, this provides a way to ensure that\nthe potentially time-consuming initialization of a model does not occur each time the model is used\nfor prediction."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Now we can initialize and save an instance of the model. Note the artifacts argument to the\n",(0,t.jsx)(n.code,{children:"save_model"})," function:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Create an instance of the model\nmistral_model = CTransformersModel(gpu_layers=50)\n\n# Log the model using mlflow with the model file as an artifact\nwith mlflow.start_run():\n    model_info = mlflow.pyfunc.log_model(\n        artifact_path="mistral_model",\n        python_model=mistral_model,\n        artifacts={"model_file": model_file_path},\n        pip_requirements=[\n            "ctransformers==0.2.27",\n        ],\n    )\n\n# Load the saved model\nloaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n\n# Make a prediction with the model\nloaded_model.predict("Question: What is the MLflow Pyfunc model flavor?")\n'})}),"\n",(0,t.jsxs)(n.p,{children:["To recap: correct use of the ",(0,t.jsx)(n.code,{children:"load_context"})," method helps to ensure efficient handling of model\nartifacts and prevents errors in serialization that could result from attempting to define artifacts\nas model attributes."]}),"\n",(0,t.jsx)(n.h3,{id:"defining-custom-methods",children:"Defining custom methods"}),"\n",(0,t.jsxs)(n.p,{children:["You can define your own methods in the custom ",(0,t.jsx)(n.code,{children:"pyfunc"})," model to handle tasks like preprocessing\ninputs or post-processing outputs. These custom methods can then be called by the predict method.\nKeep in mind that these custom methods, just like ",(0,t.jsx)(n.code,{children:"__init__"})," and ",(0,t.jsx)(n.code,{children:"predict"}),", should ",(0,t.jsx)(n.strong,{children:"not be used"})," for\nloading artifacts. Loading artifacts is the exclusive role of the ",(0,t.jsx)(n.code,{children:"load_context"})," method."]}),"\n",(0,t.jsxs)(n.p,{children:["For example, we can modify the ",(0,t.jsx)(n.code,{children:"CTransformersModel"})," to incorporate some prompt formatting as follows:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import ctransformers\nfrom mlflow.pyfunc import PythonModel\n\n\nclass CTransformersModel(PythonModel):\n    def __init__(self, gpu_layers):\n        """\n        Initialize with GPU layer configuration.\n        """\n        self.gpu_layers = gpu_layers\n        self.model = None\n\n    def load_context(self, context):\n        """\n        Load the model from the specified artifacts directory.\n        """\n        model_file_path = context.artifacts["model_file"]\n\n        # Load the model\n        self.model = ctransformers.AutoModelForCausalLM.from_pretrained(\n            model_path_or_repo_id=model_file_path,\n            gpu_layers=self.gpu_layers,\n        )\n\n    @staticmethod\n    def _format_prompt(prompt):\n        """\n        Formats the user\'s prompt\n        """\n        formatted_prompt = (\n            "Question: What is an MLflow Model?\\n\\n"\n            "Answer: An MLflow Model is a directory that includes "\n            "everything that is needed to reproduce a machine "\n            "learning model across different environments. "\n            "It is essentially a container holding the trained model "\n            "files, dependencies, environment details, input examples, "\n            "and additional metadata. The directory also includes an "\n            "MLmodel YAML file, which describes the different "\n            f"flavors of the model.\\n\\nQuestion: {prompt}\\nAnswer: "\n        )\n\n        return formatted_prompt\n\n    def predict(self, context, model_input):\n        """\n        Perform prediction using the loaded model.\n        """\n        if self.model is None:\n            raise ValueError(\n                "Model was not loaded. Ensure that \'load_context\' "\n                "is properly executed."\n            )\n        return self.model(self._format_prompt(model_input))\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Now the ",(0,t.jsx)(n.code,{children:"predict"})," method can access the private ",(0,t.jsx)(n.code,{children:"_format_prompt"})," static method to apply custom formatting to the prompts."]}),"\n",(0,t.jsx)(n.h3,{id:"dependencies-and-source-code",children:"Dependencies and Source Code"}),"\n",(0,t.jsxs)(n.p,{children:["The custom ",(0,t.jsx)(n.code,{children:"CTransformersModel"})," defined above uses the ",(0,t.jsx)(n.code,{children:"ctransformers"})," library. There are a few\ndifferent approaches for making sure this library (and any other source code, including from your\nlocal device) is correctly loaded with your model. Correctly specifying dependencies is essential\nfor ensuring that custom models work as expected across environments."]}),"\n",(0,t.jsx)(n.p,{children:"There are three main approaches to be aware of for specifying dependencies:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Define pip requirements explicitly with the ",(0,t.jsx)(n.code,{children:"pip_requirements"})," argument to ",(0,t.jsx)(n.code,{children:"save_model"})," or ",(0,t.jsx)(n.code,{children:"log_model"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["Add extra pip requirements to an automatically generated set of requirements with the\n",(0,t.jsx)(n.code,{children:"extra_pip_requirements"})," argument to ",(0,t.jsx)(n.code,{children:"save_model"})," or ",(0,t.jsx)(n.code,{children:"log_model"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["Define a Conda environment with the ",(0,t.jsx)(n.code,{children:"conda_env"})," argument to ",(0,t.jsx)(n.code,{children:"save_model"})," or ",(0,t.jsx)(n.code,{children:"log_model"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Earlier, we used the first approach to specify that the ",(0,t.jsx)(n.code,{children:"ctransformers"})," library was needed:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Log the model using mlflow with the model file as an artifact\nwith mlflow.start_run():\n    model_info = mlflow.pyfunc.save_model(\n        artifact_path="mistralmodel",\n        python_model=mistral_model,\n        artifacts={"model_file": "path/to/mistral/model/on/local/filesystem"},\n        pip_requirements=[\n            "ctransformers==0.2.27",\n        ],\n    )\n'})}),"\n",(0,t.jsxs)(n.p,{children:["If you do not specify dependencies explicitly, MLflow will attempt to infer the correct set of\nrequirements and environment details. To enable greater accuracy, it is ",(0,t.jsx)(n.strong,{children:"strongly recommended"})," to\ninclude an ",(0,t.jsx)(n.code,{children:"input_example"})," when saving or logging your model due to the internal execution of a\nsample inference step that will capture any loaded library references associated with the inference\nexecution, enabling a higher probability that the correct dependencies will be recorded."]}),"\n",(0,t.jsxs)(n.p,{children:["You can also work with custom code on your own filesystem with the ",(0,t.jsx)(n.code,{children:"code_path"})," argument.\n",(0,t.jsx)(n.code,{children:"code_path"})," takes a list of paths to Python file dependencies and prepends them to the system\npath before the model is loaded, so the custom pyfunc model can import from these modules."]}),"\n",(0,t.jsxs)(n.p,{children:["See the documentation for the ",(0,t.jsx)(n.a,{href:"https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html?highlight=pyfunc#mlflow.pyfunc.log_model",children:"log_model"})," and\n",(0,t.jsx)(n.a,{href:"https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html?highlight=pyfunc#mlflow.pyfunc.save_model",children:"save_model"}),"\nfunctions for more details on the accepted formats for ",(0,t.jsx)(n.code,{children:"pip"}),", ",(0,t.jsx)(n.code,{children:"Conda"}),", and local code requirements."]}),"\n",(0,t.jsx)(n.h3,{id:"summary-custom-pyfunc-models-in-mlflow",children:"Summary: Custom Pyfunc Models in MLflow"}),"\n",(0,t.jsxs)(n.p,{children:["MLflow has built-in methods for working with models from many popular machine learning frameworks,\nsuch as ",(0,t.jsx)(n.a,{href:"https://www.mlflow.org/docs/latest/models.html#scikit-learn-sklearn",children:"scikit-learn"}),",\n",(0,t.jsx)(n.a,{href:"https://www.mlflow.org/docs/latest/models.html#pytorch-pytorch",children:"PyTorch"}),", and\n",(0,t.jsx)(n.a,{href:"https://www.mlflow.org/docs/latest/llms/transformers/index.html",children:"Transformers"}),". You can define your own custom\n",(0,t.jsx)(n.code,{children:"mlflow.pyfunc"})," model when you want to work with models that do not yet have built-in model\nflavors, or when you want to implement a custom predict method for models with built-in model flavors."]}),"\n",(0,t.jsxs)(n.p,{children:["There are several ways to customize ",(0,t.jsx)(n.code,{children:"pyfunc"})," models to get the desired behavior. Minimally, you can\nimplement a custom ",(0,t.jsx)(n.code,{children:"predict"})," method. If your model requires saving or loading artifacts, you should also\nimplement a ",(0,t.jsx)(n.code,{children:"load_context"})," method. For further customization, you can use the ",(0,t.jsx)(n.code,{children:"__init__"})," method for\nsetting custom attributes and define your own custom methods for pre- and post-processing.\nCombining these approaches gives you the ability to flexibly define custom logic for your machine\nlearning models."]}),"\n",(0,t.jsx)(n.h3,{id:"further-learning",children:"Further Learning"}),"\n",(0,t.jsxs)(n.p,{children:["Interested in learning more about custom ",(0,t.jsx)(n.code,{children:"pyfunc"})," implementations? You can visit:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://www.mlflow.org/docs/latest/llms/custom-pyfunc-for-llms/notebooks/index.html",children:"Custom Pyfuncs for Advanced LLMs with MLflow"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://www.mlflow.org/docs/latest/traditional-ml/creating-custom-pyfunc/index.html",children:"Build Custom Python Function Models for traditional ML"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://www.mlflow.org/docs/latest/traditional-ml/creating-custom-pyfunc/notebooks/index.html",children:"Custom PyFunc notebook examples"})}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,l.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},442:(e,n,o)=>{o.d(n,{Z:()=>t});const t=o.p+"assets/images/custom-model-creation-d615de1b07178eaeaa25b55443690d17.png"},6011:(e,n,o)=>{o.d(n,{Z:()=>t});const t=o.p+"assets/images/custom-pyfunc-types-5cd29c2ba155b783ed35f0231432922f.png"},411:(e,n,o)=>{o.d(n,{Z:()=>t});const t=o.p+"assets/images/header-63bc1d1400bae90d4022e288cb0c513d.png"},5914:(e,n,o)=>{o.d(n,{Z:()=>t});const t=o.p+"assets/images/models-and-flavors-51143bf4059c2106bb267bc53daa31bb.png"},1151:(e,n,o)=>{o.d(n,{Z:()=>a,a:()=>s});var t=o(7294);const l={},i=t.createContext(l);function s(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:s(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);