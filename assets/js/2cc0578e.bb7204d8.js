"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[8150],{15851:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/claude_code_tracing-846580680a7d7ef3964ff808f7182bdc.gif"},17563:e=>{e.exports=JSON.parse('{"permalink":"/mlflow-website/blog/mlflow-autolog-claude-agents-sdk","source":"@site/blog/2025-10-15-claude-agents-sdk-autolog/index.mdx","title":"Rapidly Prototype and Evaluate Agents with Claude Agent SDK and MLflow","description":"How to quickly prototype an agent using the Claude Agent SDK then instrument and evaluate it with MLflow","date":"2025-10-15T00:00:00.000Z","tags":[{"inline":true,"label":"genai","permalink":"/mlflow-website/blog/tags/genai"},{"inline":true,"label":"anthropic","permalink":"/mlflow-website/blog/tags/anthropic"},{"inline":true,"label":"tracing","permalink":"/mlflow-website/blog/tags/tracing"},{"inline":true,"label":"evaluation","permalink":"/mlflow-website/blog/tags/evaluation"},{"inline":true,"label":"claude-agents-sdk","permalink":"/mlflow-website/blog/tags/claude-agents-sdk"},{"inline":true,"label":"claude-code","permalink":"/mlflow-website/blog/tags/claude-code"}],"readingTime":9.855,"hasTruncateMarker":false,"authors":[{"name":"Samraj Moorjani","title":"Software Engineer at Databricks","url":"https://www.linkedin.com/in/samrajmoorjani/","imageURL":"/mlflow-website/img/authors/samraj_moorjani.png","key":"samraj-moorjani","page":null}],"frontMatter":{"title":"Rapidly Prototype and Evaluate Agents with Claude Agent SDK and MLflow","description":"How to quickly prototype an agent using the Claude Agent SDK then instrument and evaluate it with MLflow","slug":"mlflow-autolog-claude-agents-sdk","authors":["samraj-moorjani"],"tags":["genai","anthropic","tracing","evaluation","claude-agents-sdk","claude-code"],"thumbnail":"/img/blog/claude-tracing-thumbnail.png","image":"/img/blog/claude-tracing-thumbnail.png"},"unlisted":false,"prevItem":{"title":"Systematic Prompt Optimization for OpenAI Agents with GEPA","permalink":"/mlflow-website/blog/mlflow-prompt-optimization"},"nextItem":{"title":"Beyond Manually Crafted LLM Judges: Automate Building Domain-Specific Evaluators with MLflow","permalink":"/mlflow-website/blog/custom-llm-judges-make-judge"}}')},28453:(e,t,n)=>{n.d(t,{R:()=>s,x:()=>r});var a=n(96540);const i={},o=a.createContext(i);function s(e){const t=a.useContext(o);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),a.createElement(o.Provider,{value:t},e.children)}},29090:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/travel_agent_eval_results_after-5e8b49db1774525a2fb2453e1b9c99fb.png"},33343:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/travel_agent_eval_results_before-a63102e56eba022c4fd1eddc5c402d24.png"},36030:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>u,frontMatter:()=>s,metadata:()=>a,toc:()=>c});var a=n(17563),i=n(74848),o=n(28453);const s={title:"Rapidly Prototype and Evaluate Agents with Claude Agent SDK and MLflow",description:"How to quickly prototype an agent using the Claude Agent SDK then instrument and evaluate it with MLflow",slug:"mlflow-autolog-claude-agents-sdk",authors:["samraj-moorjani"],tags:["genai","anthropic","tracing","evaluation","claude-agents-sdk","claude-code"],thumbnail:"/img/blog/claude-tracing-thumbnail.png",image:"/img/blog/claude-tracing-thumbnail.png"},r=void 0,l={authorsImageUrls:[void 0]},c=[{value:"Why Quickly Building Agents is Hard",id:"why-quickly-building-agents-is-hard",level:2},{value:"Why Observability and Evaluation Matters",id:"why-observability-and-evaluation-matters",level:2},{value:"Requirements",id:"requirements",level:2},{value:"Agent Creation",id:"agent-creation",level:2},{value:"Running your Agent",id:"running-your-agent",level:2},{value:"How should I implement my tools?",id:"how-should-i-implement-my-tools",level:3},{value:"Tracing the Agent",id:"tracing-the-agent",level:2},{value:"Running Evaluations",id:"running-evaluations",level:2},{value:"What goes in <code>predict_fn</code>?",id:"what-goes-in-predict_fn",level:3},{value:"What goes in <code>data</code>?",id:"what-goes-in-data",level:3},{value:"What goes in <code>scorers</code>?",id:"what-goes-in-scorers",level:3},{value:"Putting it all together",id:"putting-it-all-together",level:3},{value:"Conclusion",id:"conclusion",level:2}];function d(e){const t={a:"a",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.p,{children:"Building agentic applications is complex, but it doesn't have to take weeks or months. In this blog, we'll show you how to prototype an agent using the Claude Agent SDK then instrument and evaluate it with MLflow, going from idea to measurable results in hours, not weeks or months."}),"\n",(0,i.jsx)(t.h2,{id:"why-quickly-building-agents-is-hard",children:"Why Quickly Building Agents is Hard"}),"\n",(0,i.jsx)(t.p,{children:"Building an agent from scratch means heavy infrastructure work before you can test your core idea. In addition to writing agent logic, you're building workflow orchestration, tool connectors, and data pipelines. This delays answering the critical question: does your agent actually solve your core business problem?"}),"\n",(0,i.jsx)(t.p,{children:"Recently, many companies have released their own coding agents like Claude Code, Codex, and Gemini CLI. While these are primarily developer tools that provide automated experiences for tasks like debugging and refactoring, they contain the building blocks for powerful agent frameworks. Anthropic's Claude Agent SDK takes this further, offering the same underlying framework as Claude Code in a production-ready SDK you can integrate directly into your applications."}),"\n",(0,i.jsx)(t.h2,{id:"why-observability-and-evaluation-matters",children:"Why Observability and Evaluation Matters"}),"\n",(0,i.jsx)(t.p,{children:"Whichever framework you choose, observability and evaluations are still crucial to ensure your agent is production-ready. Without tracing, your agent is a black box that is difficult to debug and reason about. Without systematic evaluation, you can't measure improvements, catch regressions, or understand where your agent succeeds and fails. These capabilities must be built in from day one."}),"\n",(0,i.jsx)(t.p,{children:"In this blog, we'll prototype a travel agent with the Claude Agent SDK and use MLflow's automatic tracing and evaluation suite to understand and improve its behavior."}),"\n",(0,i.jsx)(t.h2,{id:"requirements",children:"Requirements"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.code,{children:"claude-agent-sdk >= 0.1.0"})}),"\n",(0,i.jsx)(t.li,{children:(0,i.jsx)(t.code,{children:"mlflow >= 3.5.0"})}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"agent-creation",children:"Agent Creation"}),"\n",(0,i.jsx)(t.p,{children:"Imagine you're running a travel agency where your team spends hours searching flight options and travel documentation for clients. An AI agent could automate this research, but you don't want to spend months building infrastructure before validating the idea. Let's see how quickly we can prototype a travel agent."}),"\n",(0,i.jsx)(t.p,{children:"Here is the structure of our prototype travel agent:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"travel-agent-prototype/\n\u251c\u2500\u2500 run_agent.py           # Driver code for running the agent\n\u2514\u2500\u2500 tools/                 # CLI wrappers for your APIs\n     \u251c\u2500\u2500 __init__.py\n     \u251c\u2500\u2500 docs.py           # Travel document search tool\n     \u251c\u2500\u2500 flights.py        # Flight search tool\n     \u2514\u2500\u2500 server.py         # MCP server for the tools\n"})}),"\n",(0,i.jsx)(t.p,{children:"Let's walk through what goes in each of these files."}),"\n",(0,i.jsx)(t.h2,{id:"running-your-agent",children:"Running your Agent"}),"\n",(0,i.jsxs)(t.p,{children:["In the following section, we define the driver code for your agent (",(0,i.jsx)(t.code,{children:"run_agent.py"}),"). First, we will define the ",(0,i.jsx)(t.code,{children:"ClaudeCodeOptions"})," object which specifies various useful options, including allowed and disallowed tools, the maximum number of turns, environment variables, and much more."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'from pathlib import Path\n\nfrom claude_agent_sdk import ClaudeAgentOptions\nfrom tools import travel_mcp_server\n\nTRAVEL_AGENT_OPTIONS = ClaudeAgentOptions(\n    mcp_servers={"travel": travel_mcp_server},\n    allowed_tools=[\n        "mcp__travel__search_flights",\n        "mcp__travel__search_travel_docs",\n    ],\n    system_prompt=TRAVEL_AGENT_SYSTEM_PROMPT,\n    cwd=str(Path.cwd()),\n    max_turns=10,\n)\n'})}),"\n",(0,i.jsx)(t.p,{children:"You may notice that we didn't define the system prompt yet. Your system prompt is where you will define the behavior of your agent as well as what tools it has access to and how the agent should use them. You can have Claude write this, but you should be judicious about what goes in here as it determines the behavior of your agent."}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'TRAVEL_AGENT_SYSTEM_PROMPT = """\n# Travel Agent Assistant\n\nYou are a travel agent assistant with access to flight search and travel documentation tools.\n\n## Execution Flow\n1. Determine user intent: flight search or travel information lookup\n2. For flight searches, use the `search_flights` tool with origin, destination, dates, and preferences\n3. For travel information, use the `search_travel_docs` tool to extract relevant information about destinations, activities, logistics\n4. Combine both capabilities when planning complete trips\n\n## Success Criteria\nPresent the user with clear, relevant, specific, and actionable advice. Cover all aspects of their travel (e.g., logistics, activities, local insights, etc.) and present them with tradeoffs of any choices they need to make.\n"""\n'})}),"\n",(0,i.jsx)(t.p,{children:"Once we have our options set up, we can run our agent using the following:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"from claude_agent_sdk import ClaudeSDKClient\n\nasync def run_travel_agent(query: str) -> str:\n    messages = []\n    async with ClaudeSDKClient(options=TRAVEL_AGENT_OPTIONS) as client:\n        await client.query(query)\n\n        async for message in client.receive_response():\n            messages.append(message)\n\n    return messages[-1].result  # Return the final output\n"})}),"\n",(0,i.jsx)(t.h3,{id:"how-should-i-implement-my-tools",children:"How should I implement my tools?"}),"\n",(0,i.jsxs)(t.p,{children:["In the example above, we have implemented our tools in Python and created an in-process MCP server. The following is the code for ",(0,i.jsx)(t.code,{children:"tools/server.py"}),":"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'from claude_agent_sdk import create_sdk_mcp_server\n\nfrom .docs import search_travel_docs\nfrom .flights import search_flights\n\ntravel_mcp_server = create_sdk_mcp_server(\n    name="travel",\n    version="1.0.0",\n    tools=[search_flights, search_travel_docs],\n)\n'})}),"\n",(0,i.jsx)(t.p,{children:"As an example, here's the signature of search_travel_docs which goes in tools/docs.py:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'from claude_agent_sdk import tool\n\n@tool(\n    "search_travel_docs",\n    "Search travel documentation and guides",\n    {\n        "query": str,\n        "num_results": int,\n    },\n)\nasync def search_travel_docs(args):\n    pass\n'})}),"\n",(0,i.jsx)(t.p,{children:"You can put anything in these functions! In this instance, our search flights tool connects to a third-party flight search API and the travel documentation tool utilizes a remote vector store."}),"\n",(0,i.jsx)(t.p,{children:"You are also not limited to using a MCP server - implementing your tools within a CLI is a great way to limit the amount of context your agent has to contend with until it requires the tool."}),"\n",(0,i.jsx)(t.h2,{id:"tracing-the-agent",children:"Tracing the Agent"}),"\n",(0,i.jsx)(t.p,{children:"Now that we have a powerful agent created, we probably want to understand what's happening under the hood. MLflow can automatically trace Claude Code, logging the inputs, outputs, and metadata of every step that Claude Code takes. This is crucial for pinpointing the source of bugs and unexpected behaviors."}),"\n",(0,i.jsx)(t.p,{children:"We can enable automatic tracing with a simple one liner:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"import mlflow\n\n@mlflow.anthropic.autolog()\n\n# Define ClaudeSDKClient after this...\n"})}),"\n",(0,i.jsxs)(t.p,{children:["Once you have autotracing set up, invocations of claude should result in new traces flowing into your experiment. You can configure your experiment or the tracking store using ",(0,i.jsx)(t.code,{children:"mlflow.set_experiment"})," and ",(0,i.jsx)(t.code,{children:"mlflow.set_tracking_uri"}),", respectively."]}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"MLflow Trace UI showing autotracing of the Claude Agent SDK",src:n(15851).A+"",width:"1060",height:"720"})}),"\n",(0,i.jsx)(t.p,{children:"As we were going through some of the traces, we noticed that our agent tends to have redundant retrieval steps."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"MLflow Trace UI showing redundant retrieval steps in our traces",src:n(81051).A+"",width:"1176",height:"720"})}),"\n",(0,i.jsx)(t.p,{children:"In the next section, we\u2019re going to discuss how we can use MLflow evaluations to confidently iterate on our agent to resolve these issues."}),"\n",(0,i.jsx)(t.h2,{id:"running-evaluations",children:"Running Evaluations"}),"\n",(0,i.jsxs)(t.p,{children:["Building an agentic system is just the first step. To ensure your travel agent performs reliably in production, you need systematic evaluation. Without structured testing, you can't measure improvements, catch regressions, or understand where your agent succeeds and fails. Now that we have tracing enabled for the Claude Agent SDK, running evaluations is really easy with ",(0,i.jsx)(t.code,{children:"mlflow.genai.evaluate"}),":"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"mlflow.genai.evaluate(\n    predict_fn=...,\n    data=...,\n    scorers=...,\n)\n"})}),"\n",(0,i.jsx)(t.p,{children:"We'll talk about what goes in each of these parameters in the following sections."}),"\n",(0,i.jsxs)(t.h3,{id:"what-goes-in-predict_fn",children:["What goes in ",(0,i.jsx)(t.code,{children:"predict_fn"}),"?"]}),"\n",(0,i.jsxs)(t.p,{children:["The predict function is the code that runs your agent and produces a trace to evaluate. Here's a ",(0,i.jsx)(t.code,{children:"predict_fn"})," for our travel agent working example:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"def run_travel_agent_with_timeout(query: str, timeout: int = 300) -> str:\n    async def run_with_timeout():\n        return await asyncio.wait_for(run_travel_agent(query), timeout=timeout)\n\n    return asyncio.run(run_with_timeout())\n"})}),"\n",(0,i.jsxs)(t.h3,{id:"what-goes-in-data",children:["What goes in ",(0,i.jsx)(t.code,{children:"data"}),"?"]}),"\n",(0,i.jsxs)(t.p,{children:["The ",(0,i.jsx)(t.code,{children:"data"})," parameter takes in the set of inputs, and optional expectations, you want to use for evaluation. Think of these as unit tests - each row in this dataset is a case you want to test against each iteration of your agent. In our case, it might look like:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'data = [\n    {\n        "inputs": {\n            "query": "What are some essential winter travel tips for New York City?"\n        },\n        "expectations": {\n            "expected_topics": "The response should cover topics like clothing and transportation"\n        }\n    },\n    {\n        "inputs": {\n            "query": "Where is a better place to visit in the summer, Tokyo or Paris?"\n        },\n        "expectations": {\n            "expected_topics": "The response should cover topics like weather, activities, and vibes"\n        }\n    },\n    {\n        "inputs": {\n            "query": "I only have a day in Athens, what should I do?"\n        },\n        "expectations": {\n            "expected_topics": "The response should cover topics like food, attractions, and activities."\n        }\n    },\n]\n'})}),"\n",(0,i.jsxs)(t.p,{children:["We often want to persist our test cases, which can be done with ",(0,i.jsx)(t.a,{href:"https://mlflow.org/docs/latest/genai/datasets/",children:"MLflow evaluation datasets"}),":"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'from mlflow.genai.datasets import create_dataset\n\ndataset = create_dataset(\n    name="travel_agent_test_cases",\n    experiment_id=["YOUR_EXPERIMENT_ID"],\n    tags={"complexity": "basic", "priority": "critical"},\n)\n\ndataset.merge_records(data)\n'})}),"\n",(0,i.jsxs)(t.h3,{id:"what-goes-in-scorers",children:["What goes in ",(0,i.jsx)(t.code,{children:"scorers"}),"?"]}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://mlflow.org/docs/latest/genai/eval-monitor/scorers/",children:"Scorers"})," are a unified interface to define evaluation criteria for your agent. You should spend most of your time thinking about how to define these as they define how you think about the quality of your agent. For our scenario above, we may want to define a retrieval redundancy judge that can look over the trace and determine if redundant retrieval calls are made:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'from mlflow.genai.judges import make_judge\n\nredundancy_judge = make_judge(\n    name="retrieval_redundancy",\n    model="openai:/gpt-4o",\n    instructions=(\n        "Analyze {{ trace }} to check if there are redundant retrieval calls. "\n        "Look at the source IDs returned from the retrieval tool. "\n        "If multiple retrieval calls have the same source IDs, there is likely a redundancy. "\n        "Return \'pass\' if there are no redundant calls, \'fail\' if there are redundant calls."\n    ),\n)\n'})}),"\n",(0,i.jsx)(t.p,{children:"We can also define operational metrics, like the number of retrieval calls used by the agent:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'from mlflow.genai import scorer\n\n@scorer\ndef num_retrieval_calls(trace):\n    return sum(\n        [\n            1 if span.span_type == "TOOL" and "search_travel_docs" in span.name else 0\n            for span in trace.data.spans\n        ]\n    )\n'})}),"\n",(0,i.jsx)(t.p,{children:"Lastly, as we iterate, we want to make sure the quality of our agent does not degrade. We\u2019ll introduce a generic comprehensiveness scorer for this:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'from mlflow.genai.judges import make_judge\n\ncomprehensive_judge = make_judge(\n    name="comprehensive",\n    model="openai:/gpt-4o-mini",\n    instructions="""\nEvaluate if the outputs comprehensively covers all relevant aspects for the query in the inputs, including the expected topics. Does the response address the full scope of what a traveler would need to know? Return \'pass\' if the output is comprehensive or \'fail\' if not.\n\nOutputs: {{outputs}}\nExpected Topics: {{expectations}}\n    """\n)\n'})}),"\n",(0,i.jsx)(t.h3,{id:"putting-it-all-together",children:"Putting it all together"}),"\n",(0,i.jsx)(t.p,{children:"Now that we have all the components of evaluation, we can put it all together as follows:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"from mlflow.genai import evaluate\n\nevaluate(\n    data=dataset,\n    predict_fn=run_travel_agent_with_timeout,\n    scorers=[\n        redundancy_judge,\n        num_retrieval_calls,\n        comprehensive_judge,\n    ],\n)\n"})}),"\n",(0,i.jsx)(t.p,{children:"This will generate evaluation results on your traces as well as a new run to store these results in one place:"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"MLflow Evaluations UI showing evaluations of the travel agent",src:n(33343).A+"",width:"3388",height:"1294"})}),"\n",(0,i.jsx)(t.p,{children:"Getting back to our original scenario with redundant retrieval calls - we can see that our retrieval redundancy judge is failing on many of our test cases. To combat this, we\u2019ve added a line into the system prompt to emphasize efficiency with retrieval calls:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'TRAVEL_AGENT_SYSTEM_PROMPT = """\n...\n3. For travel information, use the `search_travel_docs` tool to extract relevant information about destinations, activities, logistics\n  - When using this tool, please ensure you only query about a topic once. All queries should be completely distinct!\n...\n"""\n'})}),"\n",(0,i.jsx)(t.p,{children:"Re-running our evaluation yields the following results:"}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"MLflow Evaluations UI showing evaluations of the travel agent after our change",src:n(29090).A+"",width:"3382",height:"1208"})}),"\n",(0,i.jsx)(t.p,{children:"Now we can see that the retrieval redundancy metric is now passing across all our examples and the average number of retrieval calls dropped from 3.2 to 1.8 after our change! We\u2019ve also maintained the quality of our agent as shown by the comprehensiveness scorer!"}),"\n",(0,i.jsx)(t.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,i.jsx)(t.p,{children:"Prototyping agents doesn't require months of infrastructure work. By leveraging the Claude Agent SDK and MLflow's observability tools, we built and validated a travel agent prototype in a fraction of the time traditional approaches would require."}),"\n",(0,i.jsx)(t.p,{children:"The key takeaways:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"Rapid prototyping: Use existing agent frameworks like Claude Agent SDK to validate your ideas quickly"}),"\n",(0,i.jsxs)(t.li,{children:["Automatic tracing: MLflow's ",(0,i.jsx)(t.code,{children:"@mlflow.anthropic.autolog()"})," captures every action your agent takes with zero instrumentation"]}),"\n",(0,i.jsxs)(t.li,{children:["Iterate with confidence: Use ",(0,i.jsx)(t.code,{children:"mlflow.genai.evaluate()"})," to measure quality improvements objectively through custom scorers and judges"]}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"With observability and evaluation built in from day one, you can move from prototype to production-ready agent with confidence that your system performs reliably.\nNext Steps"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["Explore the ",(0,i.jsx)(t.a,{href:"https://docs.claude.com/en/api/agent-sdk/python#claudeagentoptions",children:"Claude Agent SDK documentation"})," for advanced agent features"]}),"\n",(0,i.jsxs)(t.li,{children:["Learn about ",(0,i.jsx)(t.a,{href:"https://mlflow.org/docs/latest/genai/tracing/integrations/listing/claude_code/",children:"Claude Code Auto-tracing"})," for tracing the Claude Agent SDK and Claude Code CLI automatically"]}),"\n",(0,i.jsxs)(t.li,{children:["Read about ",(0,i.jsx)(t.a,{href:"https://mlflow.org/docs/latest/genai/eval-monitor/",children:"MLflow's evaluation and monitoring framework"})," for the complete evaluation ecosystem"]}),"\n"]})]})}function u(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},81051:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/redundant_retrievals-17b12e1e6c05c41cc4958e38006d6b64.gif"}}]);