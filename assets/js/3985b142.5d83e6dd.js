"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[9703],{2985:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>r,metadata:()=>i,toc:()=>d});var i=n(31667),s=n(74848),a=n(28453);const r={title:"MLflow 3.9.0 Highlights: AI Assistant, Dashboards, and Judge Optimization",sidebar_label:"MLflow 3.9.0",slug:"3.9.0",authors:["mlflow-maintainers"]},o=void 0,l={authorsImageUrls:[void 0]},d=[{value:"1. MLflow Assistant Powered by Claude Code",id:"1-mlflow-assistant-powered-by-claude-code",level:2},{value:"2. Dashboards for Agent Performance Metrics",id:"2-dashboards-for-agent-performance-metrics",level:2},{value:"3. MemAlign: A New Judge Optimizer Algorithm",id:"3-memalign-a-new-judge-optimizer-algorithm",level:2},{value:"4. Configuring and Building a Judge with Judge Builder UI",id:"4-configuring-and-building-a-judge-with-judge-builder-ui",level:2},{value:"5. Continuous Online Monitoring with MLflow LLM Judges",id:"5-continuous-online-monitoring-with-mlflow-llm-judges",level:2},{value:"6. Distributed Tracing for Tracking End-to-end Requests",id:"6-distributed-tracing-for-tracking-end-to-end-requests",level:2},{value:"Full Changelog",id:"full-changelog",level:2},{value:"What&#39;s Next",id:"whats-next",level:2},{value:"Get Started",id:"get-started",level:3},{value:"Share Your Feedback",id:"share-your-feedback",level:3},{value:"Learn More",id:"learn-more",level:3}];function c(e){const t={a:"a",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.p,{children:"MLflow 3.9.0 is a major release focused on AI Observability and Evaluation capabilities, bringing powerful new features for building, monitoring, and optimizing AI agents. This release introduces an AI-powered assistant, comprehensive dashboards for agent performance, a new judge optimization algorithm, judge builder UI, continuous monitoring with LLM judges, and distributed tracing."}),"\n",(0,s.jsx)(t.h2,{id:"1-mlflow-assistant-powered-by-claude-code",children:"1. MLflow Assistant Powered by Claude Code"}),"\n",(0,s.jsx)("video",{controls:!0,autoplay:!0,muted:!0,loop:!0,playsinline:!0,width:"100%",children:(0,s.jsx)("source",{src:"/img/releases/3.9.0/mlflow_assistant.mp4",type:"video/mp4"})}),"\n",(0,s.jsxs)(t.p,{children:["MLflow Assistant transforms coding agents like Claude Code into experienced AI engineers by your side. Unlike typical chatbots, the assistant is ",(0,s.jsx)(t.strong,{children:"aware of your codebase and context"}),"\u2014it's not just a Q&A tool, but a full-fledged AI engineer that can find root causes for issues, set up quality tests, and apply LLMOps best practices to your project."]}),"\n",(0,s.jsx)(t.p,{children:"Key capabilities include:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"No additional costs"}),": Use your existing Claude Code subscription. MLflow provides the knowledge and integration at no cost."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Context-rich assistance"}),": Understands your local codebase, project structure, and provides tailored recommendations\u2014not generic advice."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Complete dev-loop"}),": Goes beyond Q&A to fetch MLflow data, read your code, and add tracing, evaluation, and versioning to your project."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Fully customizable"}),": Add custom skills, sub-agents, and permissions. Everything runs on your machine with full transparency."]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"Open the MLflow UI, navigate to the Assistant panel in any experiment page, and follow the setup wizard to get started."}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.a,{href:"https://mlflow.org/docs/latest/genai/getting-started/try-assistant/",children:"Learn more about MLflow Assistant"})}),"\n",(0,s.jsx)(t.h2,{id:"2-dashboards-for-agent-performance-metrics",children:"2. Dashboards for Agent Performance Metrics"}),"\n",(0,s.jsx)("video",{controls:!0,autoplay:!0,muted:!0,loop:!0,playsinline:!0,width:"100%",children:(0,s.jsx)("source",{src:"/blog/mlflow-agent-dashboard/overview_demo.mp4",type:"video/mp4"})}),"\n",(0,s.jsx)(t.p,{children:'A new "Overview" tab in GenAI experiments provides pre-built charts and visualizations for monitoring agent performance at a glance. Monitor key metrics like latency, request counts, and quality scores without manual configuration. Identify performance trends and anomalies across your agent deployments, and get tool call summaries to understand how your agents are utilizing available tools.'}),"\n",(0,s.jsxs)(t.p,{children:['Navigate to any GenAI experiment and click the "Overview" tab to access the dashboard. Charts are automatically populated based on your trace data. Have a specific visualization need? Request additional charts via ',(0,s.jsx)(t.a,{href:"https://github.com/mlflow/mlflow/issues",children:"GitHub Issues"}),"."]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.a,{href:"https://mlflow.org/docs/latest/genai/tracing/observe-with-traces/ui/",children:"Learn more about GenAI Dashboards"})}),"\n",(0,s.jsx)(t.h2,{id:"3-memalign-a-new-judge-optimizer-algorithm",children:"3. MemAlign: A New Judge Optimizer Algorithm"}),"\n",(0,s.jsx)(t.p,{children:"MemAlign is a new optimization algorithm that learns evaluation guidelines from past feedback and dynamically retrieves relevant examples at runtime. Improve judge accuracy by learning from human feedback patterns, reduce prompt engineering effort with automatic guideline extraction, and adapt judge behavior dynamically based on the input being evaluated."}),"\n",(0,s.jsxs)(t.p,{children:["Use the ",(0,s.jsx)(t.code,{children:"MemAlignOptimizer"})," to optimize your judges with historical feedback:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'from mlflow.genai.judges.optimize import MemAlignOptimizer\n\n# Initialize optimizer with your judge\noptimizer = MemAlignOptimizer(\n    judge=my_custom_judge,\n    feedback_dataset="human_feedback_traces",\n)\n\n# Train on historical feedback\noptimizer.fit()\n\n# The optimized judge now retrieves relevant guidelines dynamically\noptimized_judge = optimizer.get_optimized_judge()\n\n# Use in evaluation\nresult = optimized_judge.evaluate(trace)\n'})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.a,{href:"https://mlflow.org/docs/latest/genai/eval-monitor/scorers/llm-judge/memalign/",children:"Learn more about MemAlign"})}),"\n",(0,s.jsx)(t.h2,{id:"4-configuring-and-building-a-judge-with-judge-builder-ui",children:"4. Configuring and Building a Judge with Judge Builder UI"}),"\n",(0,s.jsx)("video",{controls:!0,autoplay:!0,muted:!0,loop:!0,playsinline:!0,width:"100%",children:(0,s.jsx)("source",{src:"/img/releases/3.9.0/judge_builder_ui.mp4",type:"video/mp4"})}),"\n",(0,s.jsx)(t.p,{children:"A new visual interface lets you create and test custom LLM judge prompts without writing code. Iterate quickly on judge criteria and scoring rubrics with immediate feedback, test judges on sample traces before deploying to production, and export validated judges to the Python SDK for programmatic integration."}),"\n",(0,s.jsx)(t.p,{children:'Navigate to the "Judges" section in the MLflow UI and click "Create Judge." Define your evaluation criteria, scoring rubric, and test your judge against sample traces. Once satisfied, export the configuration to use with the MLflow SDK.'}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.a,{href:"https://mlflow.org/docs/latest/genai/eval-monitor/scorers/llm-judge/make-judge/",children:"Learn more about Judge Builder"})}),"\n",(0,s.jsx)(t.h2,{id:"5-continuous-online-monitoring-with-mlflow-llm-judges",children:"5. Continuous Online Monitoring with MLflow LLM Judges"}),"\n",(0,s.jsx)(t.p,{children:"Automatically run LLM judges on incoming traces without writing any code, enabling continuous quality monitoring of your agents in production. Detect quality issues in real-time as traces flow through your system, leverage pre-defined judges for common evaluations like safety, relevance, groundedness, and correctness, and get actionable assessments attached directly to your traces."}),"\n",(0,s.jsx)(t.p,{children:'Go to the "Judges" tab in your experiment, select from pre-defined judges or use your custom judges, and configure which traces to evaluate. Assessments are automatically attached to matching traces as they arrive.'}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.a,{href:"https://mlflow.org/docs/latest/genai/eval-monitor/",children:"Learn more about Agent Evaluation"})}),"\n",(0,s.jsx)(t.h2,{id:"6-distributed-tracing-for-tracking-end-to-end-requests",children:"6. Distributed Tracing for Tracking End-to-end Requests"}),"\n",(0,s.jsx)(t.p,{children:"Track requests across multiple services with context propagation, enabling end-to-end visibility into distributed AI systems. Maintain trace continuity across microservices and external API calls, debug issues that span multiple services with a unified trace view, and understand latency and errors at each step of your distributed pipeline."}),"\n",(0,s.jsxs)(t.p,{children:["Use the ",(0,s.jsx)(t.code,{children:"mlflow.tracing.distributed"})," module to inject and extract trace context:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'from mlflow.tracing.distributed import inject_trace_context, extract_trace_context\nimport requests\n\n# Service A: Inject context into outgoing request\ndef call_downstream_service(data):\n    headers = {}\n    inject_trace_context(headers)\n    response = requests.post(\n        "http://service-b/process",\n        json=data,\n        headers=headers,\n    )\n    return response.json()\n\n# Service B: Extract context from incoming request\ndef process_request(request):\n    extract_trace_context(request.headers)\n    # Continue tracing in this service\n    with mlflow.start_span(name="process") as span:\n        result = do_processing(request.json)\n    return result\n'})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.a,{href:"https://mlflow.org/docs/latest/genai/tracing/app-instrumentation/distributed-tracing/",children:"Learn more about Distributed Tracing"})}),"\n",(0,s.jsx)(t.h2,{id:"full-changelog",children:"Full Changelog"}),"\n",(0,s.jsxs)(t.p,{children:["For a comprehensive list of changes, see the ",(0,s.jsx)(t.a,{href:"https://github.com/mlflow/mlflow/releases/tag/v3.9.0",children:"release change log"}),"."]}),"\n",(0,s.jsx)(t.h2,{id:"whats-next",children:"What's Next"}),"\n",(0,s.jsx)(t.h3,{id:"get-started",children:"Get Started"}),"\n",(0,s.jsx)(t.p,{children:"Install MLflow 3.9.0 to try these new features:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-bash",children:"pip install mlflow==3.9.0\n"})}),"\n",(0,s.jsx)(t.h3,{id:"share-your-feedback",children:"Share Your Feedback"}),"\n",(0,s.jsx)(t.p,{children:"We'd love to hear about your experience with these new features:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.a,{href:"https://github.com/mlflow/mlflow/issues",children:"GitHub Issues"})," - Report bugs or request features"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.a,{href:"https://github.com/mlflow/mlflow/discussions/19855",children:"MLflow Roadmap"})," - See what's coming next and share your ideas"]}),"\n",(0,s.jsxs)(t.li,{children:["\u2b50 ",(0,s.jsx)(t.a,{href:"https://github.com/mlflow/mlflow",children:"Star us on GitHub"})," - Show your support for the project"]}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"learn-more",children:"Learn More"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.a,{href:"https://luma.com/mlflow-204",children:"Join our upcoming webinar"})," to see these features in action"]}),"\n",(0,s.jsxs)(t.li,{children:["Check out the ",(0,s.jsx)(t.a,{href:"https://mlflow.org/docs/latest",children:"MLflow documentation"})," for detailed guides"]}),"\n"]})]})}function u(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},28453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>o});var i=n(96540);const s={},a=i.createContext(s);function r(e){const t=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),i.createElement(a.Provider,{value:t},e.children)}},31667:e=>{e.exports=JSON.parse('{"permalink":"/mlflow-website/releases/3.9.0","source":"@site/releases/2026-01-30-3.9.0-release.md","title":"MLflow 3.9.0 Highlights: AI Assistant, Dashboards, and Judge Optimization","description":"MLflow 3.9.0 is a major release focused on AI Observability and Evaluation capabilities, bringing powerful new features for building, monitoring, and optimizing AI agents. This release introduces an AI-powered assistant, comprehensive dashboards for agent performance, a new judge optimization algorithm, judge builder UI, continuous monitoring with LLM judges, and distributed tracing.","date":"2026-01-30T00:00:00.000Z","tags":[],"readingTime":5.01,"hasTruncateMarker":false,"authors":[{"name":"MLflow maintainers","title":"MLflow maintainers","url":"https://github.com/mlflow/mlflow.git","imageURL":"https://github.com/mlflow-automation.png","key":"mlflow-maintainers","page":null}],"frontMatter":{"title":"MLflow 3.9.0 Highlights: AI Assistant, Dashboards, and Judge Optimization","sidebar_label":"MLflow 3.9.0","slug":"3.9.0","authors":["mlflow-maintainers"]},"unlisted":false,"nextItem":{"title":"MLflow 3.8.1","permalink":"/mlflow-website/releases/3.8.1"}}')}}]);